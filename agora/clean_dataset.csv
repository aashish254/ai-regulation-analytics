id,title,authority,country,region,topic,document_type,date,year,month,sentiment,sentiment_score,risk_level,risk_score,document_length,confidence_score,status,content,url,language,tags
1,"National Defense Authorization Act for Fiscal Year 2022, Section 1531 (""Digital development infrastructure plan and working group"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-12-27,2021,12,positive,0.9042,low,0.0,199,1.0,Enacted,"SEC. 1531. DIGITAL DEVELOPMENT INFRASTRUCTURE PLAN AND WORKING GROUP. (a) Plan Required.--Not later than one year after the date of the enactment of this Act, the Secretary of Defense, acting through the working group established under subsection (d)(1), shall develop a plan for the establishment of a modern information technology infrastructure that supports state of the art tools and modern processes to enable effective and efficient development, testing, fielding, and continuous updating of artificial intelligence-capabilities. (b) Contents of Plan.--The plan developed pursuant to subsection (a) shall include at a minimum the following: (1) A technical plan and guidance for necessary technical investments in the infrastructure described in subsection (a) that address critical technical issues, including issues relating to common interfaces, authentication, applications, platforms, software, hardware, and data infrastructure. (2) A governance structure, together with associated policies and guidance, to support the implementation throughout the Department of such plan. (3) Identification and minimum viable instantiations of prototypical development and platform environments with such infrastructure, including enterprise data sets assembled under subsection (e). (c) Harmonization With Departmental Efforts.--The plan developed pursuant to subsection (a) shall include a description of the aggregated and consolidated financial and personnel requirements necessary to implement e",https://www.congress.gov/bill/117th-congress/senate-bill/1605/text,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Convening, Strategies: Governance development, Strategies: New institution, Applications: Government: military and public safety"
2,"National Defense Authorization Act for Fiscal Year 2022, Section 226 (""Review of artificial intelligence applications and establishment of performance metrics"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-12-27,2021,12,positive,0.9699,low,0.0,210,1.0,Enacted,"SEC. 226. REVIEW OF ARTIFICIAL INTELLIGENCE APPLICATIONS AND ESTABLISHMENT OF PERFORMANCE METRICS. (a) In General.--Not later than 180 days after the date of the enactment of this Act, the Secretary of Defense shall-- (1) review the potential applications of artificial intelligence and digital technology to the platforms, processes, and operations of the Department of Defense; and (2) establish performance objectives and accompanying metrics for the incorporation of artificial intelligence and digital readiness into such platforms, processes, and operations. (b) Performance Objectives and Accompanying Metrics.-- (1) Skill gaps.--In carrying out subsection (a), the Secretary of Defense shall require each Secretary of a military department and the heads of such other organizations and elements of the Department of Defense as the Secretary of Defense determines appropriate to-- (A) conduct a comprehensive review and assessment of-- (i) skill gaps in the fields of software development, software engineering, data science, and artificial intelligence; (ii) the qualifications of civilian personnel needed for both management and specialist tracks in such fields; and (iii) the qualifications of military personnel (officer and enlisted) needed for both management and specialist tracks in such fields; and (B) establish recruiting, training, and talent management performance objectives and accompanying metrics for achieving and maintaining staffing levels needed to fill identified gaps a",https://www.congress.gov/bill/117th-congress/senate-bill/1605/text,en,"Strategies: Evaluation, Strategies: Government study or report, Strategies: Governance development, Strategies: Performance requirements, Applications: Medicine, life sciences and public health, Applications: Transportation, Applications: Consumer goods, Applications: Sales, retail, and customer relations, Applications: Business services and analytics, Applications: Government: military and public safety"
3,"National Defense Authorization Act for Fiscal Year 2022, Section 227 (""Modification of the joint common foundation program"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-12-27,2021,12,positive,0.9911,low,0.1111,202,1.0,Enacted,"SEC. 227. MODIFICATION OF THE JOINT COMMON FOUNDATION PROGRAM. (a) Modification of Joint Common Foundation.--The Secretary of Defense shall modify the Joint Common Foundation program conducted by the Joint Artificial Intelligence Center to ensure that Department of Defense components can more easily contract with leading commercial artificial intelligence companies to support the rapid and efficient development and deployment of applications and capabilities. (b) Qualifying Commercial Companies.--The Secretary of Defense shall take such actions as may be necessary to increase the number of commercial artificial intelligence companies eligible to provide support to Department of Defense components, including with respect to requirements for cybersecurity protections and processes, to achieve automatic authority to operate and provide continuous delivery, security clearances, data portability, and interoperability. (c) Use of FAR Part 12.--The Secretary of Defense shall ensure that, to the maximum extent practicable, commercial artificial intelligence companies are able to offer platforms, services, applications, and tools to Department of Defense components through processes and procedures under part 12 of the Federal Acquisition Regulation.(d) Objectives of the Joint Common Foundation Program.--The objectives of the Joint Common Foundation program shall include the following: (1) Relieving Department of Defense components of the need to design or develop or independently cont",https://www.congress.gov/bill/117th-congress/senate-bill/1605/text,en,"Risk factors: Security, Risk factors: Security: Cybersecurity, Strategies: Government support, Strategies: Convening, Applications: Government: other applications/unspecified"
4,"National Defense Authorization Act for Fiscal Year 2022, Section 232 (""Pilot program on data repositories to facilitate the development of artificial intelligence capabilities for the Department of Defense"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-12-27,2021,12,positive,0.9851,low,0.0,206,1.0,Enacted,"SEC. 232. PILOT PROGRAM ON DATA REPOSITORIES TO FACILITATE THE DEVELOPMENT OF ARTIFICIAL INTELLIGENCE CAPABILITIES FOR THE DEPARTMENT OF DEFENSE. (a) Establishment of Data Repositories.-- The Secretary of Defense, acting through the Chief Data Officer of the Department of Defense and the Director of the Joint Artificial Intelligence Center (and such other officials as the Secretary determines appropriate), may carry out a pilot program under which the Secretary-- (1) establishes data repositories containing Department of Defense data sets relevant to the development of artificial intelligence software and technology; and (2) allows appropriate public and private sector organizations to access such data repositories for the purpose of developing improved artificial intelligence and machine learning software capabilities that may, as determined appropriate by the Secretary, be procured by the Department to satisfy Department requirements and technology development goals. (b) Elements.--If the Secretary of Defense carries out the pilot program under subsection (a), the data repositories established under the program-- (1) may include unclassified training quality data sets and associated labels representative of diverse types of information, representing Department of Defense missions, business processes, and activities; and (2) shall-- (A) be categorized and annotated to support development of a common evaluation framework for artificial intelligence models and other technical",https://www.congress.gov/bill/117th-congress/senate-bill/1605/text,en,"Strategies: Evaluation, Strategies: Government study or report, Strategies: Pilots and testbeds, Applications: Government: military and public safety"
5,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 212 (""Clarification of role of senior official with principal responsibility for artificial intelligence and machine learning"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9822,low,0.0,222,1.0,Enacted,"SEC. 212. CLARIFICATION OF ROLE OF SENIOR OFFICIAL WITH PRINCIPAL RESPONSIBILITY FOR ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING. (a) Personnel Management Authority to Attract Experts in Science and Engineering.--Section 4092 of title 10, United States Code, is amended-- (1) in subsection (a)(6)-- (A) by striking Director of the Joint Artificial Intelligence Center'' and inserting official designated under section 238(b) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Public Law 115-232)''; (B) by striking for the Center'' and inserting to support the activities of such official under section 238 of such Act''; and (C) in the paragraph heading, by striking ``Center''; (2) in subsection (b)(1)(F)-- (A) by striking Joint Artificial Intelligence Center'' and inserting office of the official designated under section 238(b) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Public Law 115- 232)''; and (B) by striking in the Center'' and inserting in support of the activities of such official under section 238 of such Act''; and (3) in subsection (c)(2), by striking Joint Artificial Intelligence Center'' and inserting the activities under section 238 of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Public Law 115-232)''. (b) Review of Artificial Intelligence Applications and Establishment of Performance Metrics.--Section 226(b) of the National Defense Authorization Act for Fiscal Year 2022 (Pu",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Evaluation, Strategies: Government support: AI workforce-related, Strategies: Pilots and testbeds, Applications: Security, Applications: Government: military and public safety"
6,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 1513 (""Establishing projects for data management, artificial intelligence, and digital solutions"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9817,low,0.1111,205,1.0,Enacted,"SEC. 1513. ESTABLISHING PROJECTS FOR DATA MANAGEMENT, ARTIFICIAL INTELLIGENCE, AND DIGITAL SOLUTIONS. (a) Establishment of Priority Projects.--The Deputy Secretary of Defense shall-- (1) establish priority enterprise projects for data management, artificial intelligence, and digital solutions for both business efficiency and warfighting capabilities intended to accelerate decision advantage; and (2) assign responsibilities for execution and funding of the projects established under paragraph (1). (b) Actions Required.--To ensure implementation of the priority projects of the Deputy Secretary of Defense under subsection (a), and to instill data science and technology as a core discipline in the Department of Defense, the Deputy Secretary shall-- (1) hold the heads of components accountable for-- (A) making their component's data available for use pursuant to the memorandum of the Deputy Secretary of Defense dated May 5, 2021, and titled ``Creating Data Advantage'', in accordance with plans developed and approved by the head of the component and the Deputy Secretary; (B) developing, implementing, and reporting measurable actions to acquire, preserve, and grow the population of government and contractor personnel with expertise in data management, artificial intelligence, and digital solutions; (C) making their components use data management practices, analytics processes, enterprise cloud computing environments, and operational test environments that are made available and spec",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Risk factors: Security, Risk factors: Security: Cybersecurity, Strategies: Evaluation, Strategies: Evaluation: Adversarial testing, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: AI workforce-related, Applications: Business services and analytics, Applications: Government: military and public safety"
7,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 1554 (""Roadmap and implementation plan for cyber adoption of artificial intelligence"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9864,low,0.0,202,1.0,Enacted,"SEC. 1554. ROADMAP AND IMPLEMENTATION PLAN FOR CYBER ADOPTION OF ARTIFICIAL INTELLIGENCE. (a) Roadmap and Implementation Plan Required.--Not later than 270 days after the date of the enactment of this Act, the Commander of the United States Cyber Command and the Chief Information Officer of the Department of Defense, in coordination with the Chief Digital and Artificial Intelligence Officer of the Department, the Director of the Defense Advanced Research Projects Agency, the Director of the National Security Agency, and the Under Secretary of Defense for Research and Engineering, shall jointly develop a five-year roadmap and implementation plan for rapidly adopting and acquiring artificial intelligence systems,applications, and supporting data and data management processes for the Cyberspace Operations Forces of the Department of Defense. (b) Elements.--The roadmap and implementation plan required by subsection (a) shall include the following: (1) Identification and prioritization of artificial intelligence systems, applications, data identification, and processing to cyber missions within the Department, and ameliorating threats to, and from, artificial intelligence systems, including-- (A) advancing the cybersecurity of Department systems with artificial intelligence; (B) uses of artificial intelligence for cyber effects operations; (C) assessing and mitigating vulnerabilities of artificial intelligence systems supporting cybersecurity and cyber operations to attacks; and (",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Evaluation, Strategies: Government study or report, Strategies: Convening, Strategies: Governance development, Applications: Government: military and public safety"
8,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 6702 (""Additional responsibilities of Director of National Intelligence for artificial intelligence policies, standards, and guidance for the intelligence community"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9947,low,0.1111,192,1.0,Enacted,"SEC. 6702. ADDITIONAL RESPONSIBILITIES OF DIRECTOR OF NATIONAL INTELLIGENCE FOR ARTIFICIAL INTELLIGENCE POLICIES, STANDARDS, AND GUIDANCE FOR THE INTELLIGENCE COMMUNITY. (a) Responsibilities of Director of National Intelligence.--The Director of National Intelligence, in consultation with the heads of the elements of the intelligence community or the officials designated under subsection (b), shall-- (1) establish, and periodically conduct reviews of, policies, standards, and procedures relating to the acquisition, adoption, development, use, coordination, and maintenance of artificial intelligence capabilities and associated data, frameworks, computing environments, and other enablers by the intelligence community (including by incorporating and updating such policies based on emerging technology capabilities), to accelerate and increase the adoption of artificial intelligence capabilities within the intelligence community; (2) ensure policies established or updated pursuant to paragraph (1) are consistent with-- (A) the principles outlined in the guidance of the Office of the Director of National Intelligence titled ``Principles of Artificial Intelligence Ethics for the Intelligence Community and its Artificial Intelligence Ethics Framework for the Intelligence Community'', or any successor guidance; and (B) any other principles developed by the Director relating to the governance, documentation, auditability, or evaluation of artificial intelligence systems or the accurate",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Risk factors: Reliability, Risk factors: Security, Strategies: Evaluation, Strategies: Government support, Strategies: Government support: For R&D, Strategies: New institution, Applications: Security, Applications: Government: military and public safety"
9,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 6717 (""Policy on required user adoption metrics in certain contracts for artificial intelligence and emerging technology software products"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9939,low,0.0,237,1.0,Enacted,"SEC. 6717. POLICY ON REQUIRED USER ADOPTION METRICS IN CERTAIN CONTRACTS FOR ARTIFICIAL INTELLIGENCE AND EMERGING TECHNOLOGY SOFTWARE PRODUCTS. (a) Policy.--Not later than 180 days after the date of the enactment of this Act, the Director of National Intelligence shall establish a policy regarding user adoption metrics for contracts and other agreements for the procurement of covered products as follows: (1) With respect to a contract or other agreement entered into between the head of an element of the intelligence community and a commercial provider for the procurement of a covered product for users within the intelligence community, a requirement that each such contract or other agreement include, as a term of the contract or agreement, an understanding of the anticipated use of the covered product with a clear metric for success and for collecting user adoption metrics, as appropriate, for assessing the adoption of the covered product by such users. (2) Such exceptions to the requirements under paragraph (1) as may be determined appropriate pursuant to guidance established by the Director of National Intelligence. (3) A requirement that prior to the procurement of, or the continuation of the use of, any covered product procured by the head of an element of the intelligence community, the head has determined a method for assessing the success of the covered product from user adoption metrics. (b) Submission.--Not later than 60 days after the date on which the policy under",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Government study or report, Strategies: Government support, Strategies: Governance development, Applications: Government: military and public safety"
10,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 6721 (""Reports on integration of artificial intelligence within intelligence community"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9918,low,0.0,221,1.0,Enacted,"SEC. 6721. REPORTS ON INTEGRATION OF ARTIFICIAL INTELLIGENCE WITHIN INTELLIGENCE COMMUNITY. (a) Reports by Elements of Intelligence Community.--Not later than 180 days after the date of the enactment of this Act, each senior official within an element of the intelligence community identified as a designated element lead pursuant to section 6702(b) shall submit to the congressional intelligence committees, the Subcommittee on Defense of the Committee on Appropriations of the Senate, and the Subcommittee on Defense of the Committee on Appropriations of the House of Representatives a report on the efforts of that element to develop, acquire, adopt, and maintain artificial intelligence to improve intelligence collection and analysis and optimize internal work flows. Each such report shall include the following: (1) A description of the authorities of the element relating to the use of artificial intelligence. (2) A list of any resource or authority necessary to accelerate the adoption by the element of artificial intelligence solutions, including commercial products, or personnel authorities. (3) A description of the element's roles, responsibilities, and authorities for accelerating the adoption by the element of artificial intelligence solutions. (4) The application of the policies and principles described in section 6702(a)(2) to paragraphs (1), (2), and (3). (b) Audits by Inspectors General.-- (1) Audits.--Not later than 2 years after the date of the enactment of this Act, ea",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Strategies: Governance development, Strategies: Performance requirements, Applications: Government: military and public safety"
11,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 6723 (""Requirements and report on workforce needs of intelligence community relating to science, technology, engineering, and math, and related areas"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9905,low,0.0,218,1.0,Enacted,"SEC. 6723. REQUIREMENTS AND REPORT ON WORKFORCE NEEDS OF INTELLIGENCE COMMUNITY RELATING TO SCIENCE, TECHNOLOGY, ENGINEERING, AND MATH, AND RELATED AREAS. (a) Requirements.--The Director of National Intelligence, in coordination with the heads of human capital from each element of the intelligence community, shall-- (1) develop a plan for the recruitment and retention of personnel to positions the primary duties of which involve the integration, maintenance, or use of artificial intelligence (and the retention and training of personnel serving in such positions), including with respect to the authorities and requirements under section 6732(b); (2) develop a plan for the review and evaluation, on a continuous basis, of the expertise necessary to accelerate the adoption of artificial intelligence and other emerging technology solutions; and (3) coordinate and share information and best practices relating to such recruitment and retention within the element and across the intelligence community. (b) Report.-- (1) Submission.--Not later than January 1, 2024, the Director of National Intelligence, in coordination with heads of human capital from each element of the intelligence community, shall submit to the congressional intelligence committees, the Subcommittee on Defense of the Committee on Appropriations of the Senate, and the Subcommittee on Defense of the Committee on Appropriations of the House of Representatives a single report on the workforce needs of each element of the",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Government support: AI workforce-related, Applications: Government: military and public safety"
12,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 6731 (""Report on establishment of technology acquisition cadre"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9907,low,0.0,209,1.0,Enacted,"SEC. 6731. REPORT ON ESTABLISHMENT OF TECHNOLOGY ACQUISITION CADRE. (a) Report.--Not later than 180 days after the date of the enactment of this Act, the Director of National Intelligence shall submit to the congressional intelligence committees, the Subcommittee on Defense of the Committee on Appropriations of the Senate, and the Subcommittee on Defense of the Committee on Appropriations of the House of Representatives a report containing a feasibility and advisability study on establishing a cadre of personnel who are experts in emerging technologies, software development, systems integration, and acquisition, to improve the adoption of commercial solutions for emerging technologies across the intelligence community, particularly as the technologies relate to artificial intelligence. (b) Elements.--The study under subsection (a) shall include the following: (1) An examination regarding whether a cadre of personnel described in subsection (a) would be an effective and efficient means to substantially improve and accelerate the adoption of commercial artificial intelligence and other emerging technology products and services in support of the missions of the intelligence community if the cadre has the capacity and relevant expertise to-- (A) accelerate the adoption of emerging technologies, including with respect to artificial intelligence; (B) assist with software development and acquisition; and (C) develop training requirements for acquisition professionals within the elem",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Evaluation, Strategies: Government study or report, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Strategies: Governance development, Strategies: New institution, Applications: Government: military and public safety"
13,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 6742 (""Code-free artificial intelligence enablement tools policy"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9956,low,0.0,211,1.0,Enacted,"SEC. 6742. CODE-FREE ARTIFICIAL INTELLIGENCE ENABLEMENT TOOLS POLICY. (a) Draft Policy.--Not later than 1 year after the date of the enactment of this Act, the Director of National Intelligence, in consultation with the Director of the Central Intelligence Agency, the Director of the National Security Agency, the Director of the National Reconnaissance Office, the Director of the National Geospatial- Intelligence Agency, and the Director of the Defense Intelligence Agency, and any additional heads of the elements of the intelligence community that the Director of National Intelligence determines appropriate, shall draft a potential policy to promote the intelligence community-wide use of code-free artificial intelligence enablement tools. (b) Elements.--The draft policy under subsection (a) shall include the following: (1) The objective for the use by the intelligence community of code-free artificial intelligence enablement tools. (2) A detailed set of incentives for using code-free artificial intelligence enablement tools. (3) A plan to ensure coordination throughout the intelligence community, including consideration of designating an official of each element of the intelligence community to oversee implementation of the policy and such coordination. (c) Submission.--Not later than 180 days after the date of the enactment of this Act, the Director of National Intelligence shall submit to the congressional intelligence committees, the Subcommittee on Defense of the Committe",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Government support, Strategies: Government support: For R&D, Strategies: New institution, Applications: Government: military and public safety, Applications: Government: benefits and welfare"
14,Advancing American Artificial Intelligence Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-12-23,2022,12,positive,0.9931,low,0.0556,212,1.0,Enacted,"Subtitle B SHORT TITLE. This subtitle may be cited as the ``Advancing American AI Act''. SEC. 7222. PURPOSES. The purposes of this subtitle are to-- (1) encourage agency artificial intelligence-related programs and initiatives that enhance the competitiveness of the United States and foster an approach to artificial intelligence that builds on the strengths of the United States in innovation and entrepreneurialism; (2) enhance the ability of the Federal Government to translate research advances into artificial intelligence applications to modernize systems and assist agency leaders in fulfilling their missions; (3) promote adoption of modernized business practices and advanced technologies across the Federal Government that align with the values of the United States, including the protection of privacy, civil rights, and civil liberties; and (4) test and harness applied artificial intelligence to enhance mission effectiveness, agency program integrity, and business practice efficiency. SEC. 7223. DEFINITIONS. In this subtitle: (1) Agency.--The term ``agency'' has the meaning given the term in section 3502 of title 44, United States Code. (2) Appropriate congressional committees.--The term ``appropriate congressional committees'' means-- (A) the Committee on Homeland Security and Governmental Affairs of the Senate; (B) the Committee on Oversight and Reform of the House of Representatives; and (C) the Committee on Homeland Security of the House of Representatives. (3) Artificia",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Risk factors: Privacy, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Government study or report, Strategies: Government support: AI workforce-related, Strategies: Convening, Strategies: Governance development, Applications: Government: other applications/unspecified"
15,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 11226 (""Artificial intelligence strategy"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9791,low,0.0,187,1.0,Enacted,"SEC. 11226. ARTIFICIAL INTELLIGENCE STRATEGY. (a) Coordination of Data and Artificial Intelligence Activities Relating to Identifying, Demonstrating, and Where Appropriate Transitioning to Operational Use.-- (1) In general.--The Commandant shall coordinate data and artificial intelligence activities relating to identifying, demonstrating and where appropriate transitioning to operational use of artificial intelligence technologies when such technologies enhance mission capability or performance. (2) Emphasis.--The set of activities established under paragraph (1) shall-- (A) apply data analytics, artificial intelligence, and machine-learning solutions to operational and mission-support problems; and (B) coordinate activities involving artificial intelligence and artificial intelligence-enabled capabilities within the Coast Guard. (b) Designated Official.-- (1) In general.--Not later than 1 year after the date of enactment of this Act, the Commandant shall designate a senior official of the Coast Guard (referred to in this section as the ``designated official'') with the principal responsibility for the coordination of data and artificial intelligence activities relating to identifying, demonstrating, and, where appropriate, transitioning to operational use artificial intelligence and machine learning for the Coast Guard. (2) Governance and oversight of artificial intelligence and machine learning policy.--The designated official shall regularly convene appropriate officials o",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Evaluation, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Convening, Applications: Government: military and public safety, Applications: Government: judicial and law enforcement"
16,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 11227 (""Review of artificial intelligence applications and establishment of performance metrics"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9748,low,0.0,208,1.0,Enacted,"SEC. 11227. REVIEW OF ARTIFICIAL INTELLIGENCE APPLICATIONS AND ESTABLISHMENT OF PERFORMANCE METRICS. (a) In General.--Not later than 2 years after the date of enactment of this Act, the Commandant shall-- (1) review the potential applications of artificial intelligence and digital technology to the platforms, processes, and operations of the Coast Guard; (2) identify the resources necessary to improve the use of artificial intelligence and digital technology in such platforms, processes, and operations; and (3) establish performance objectives and accompanying metrics for the incorporation of artificial intelligence and digital readiness into such platforms, processes, and operations. (b) Performance Objectives and Accompanying Metrics.-- (1) Skill gaps.--In carrying out subsection (a), the Commandant shall-- (A) conduct a comprehensive review and assessment of-- (i) skill gaps in the fields of software development, software engineering, data science, and artificial intelligence; (ii) the qualifications of civilian personnel needed for both management and specialist tracks in such fields; and (iii) the qualifications of military personnel (officer and enlisted) needed for both management and specialist tracks in such fields; and (B) establish recruiting, training, and talent management performance objectives and accompanying metrics for achieving and maintaining staffing levels needed to fill identified gaps and meet the needs of the Coast Guard for skilled personnel. (2) AI",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Evaluation, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Strategies: Governance development, Strategies: Performance requirements, Applications: Business services and analytics, Applications: Government: military and public safety, Applications: Government: judicial and law enforcement"
17,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 162 (""Assessment and strategy for fielding capabilities to counter threats posed by unmanned aerial system swarms"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,negative,-0.7603,low,0.1111,221,1.0,Enacted,"SEC. 162. ASSESSMENT AND STRATEGY FOR FIELDING CAPABILITIES TO COUNTER THREATS POSED BY UNMANNED AERIAL SYSTEM SWARMS. (a) Assessment, Analysis, and Review.--The Secretary of Defense shall conduct-- (1) an assessment of the threats posed by unmanned aerial system swarms and unmanned aerial systems with swarm capabilities to installations and deployed Armed Forces; (2) an analysis of the use or potential use of unmanned aerial system swarms by adversaries, including the People's Republic of China, the Russian Federation, the Islamic Republic of Iran, the Democratic People's Republic of North Korea, and non-state actors; (3) an analysis of the national security implications of swarming technologies such as autonomous intelligence and machine learning; (4) a review of the capabilities used by the Department of Defense to counter threats posed by unmanned aerial systems and an assessment of the effectiveness of such capabilities at countering the threat of unmanned aerial system swarms; and (5) an overview of the efforts of the Department of Defense to develop and field test technologies that offer scalable, modular, and rapidly deployable capabilities with the ability to counter unmanned aerial system swarms. (b) Strategy Development and Implementation Required.-- (1) In general.--The Secretary of Defense shall develop and implement a strategy to field capabilities to counter threats posed by unmanned aerial system swarms. (2) Elements.--The strategy required by paragraph (1) sh",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Harms: Harm to health/safety, Harms: Harm to infrastructure, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Post-market monitoring, Strategies: Government study or report, Strategies: Governance development, Applications: Government: military and public safety"
23,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title VII, Section 808 (""Acquisition authority of the Director of the Joint Artificial Intelligence Center"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.9783,low,0.0,221,1.0,Enacted,"SEC. 808. ACQUISITION AUTHORITY OF THE DIRECTOR OF THE JOINT ARTIFICIAL INTELLIGENCE CENTER. (a) AUTHORITY.— The Secretary of Defense shall delegate to the Director of the Joint Artificial Intelligence Center the acquisition authority to exercise the functions of a head of an agency (as defined in section 2302 of title 10, United States Code) with respect to appropriate acquisition activities of the Center. (b) JAIC ACQUISITION EXECUTIVE.— (1) IN GENERAL.—The staff of the Director shall include an acquisition executive who shall be responsible for the supervision of appropriate acquisition activities under subsection (a). Subject to the authority, direction, and control of the Director of the Center, the acquisition executive shall have the authority— (A) to negotiate memoranda of agreement with any element of the Department of Defense to carry out the acquisition of technologies, services, and capabilities developed or identified by the Center; (B) to supervise the acquisition of technologies, services, and capabilities to support the mission of the Center; (C) to represent the Center in discussions with the Secretaries concerned regarding acquisition programs relating to such appropriate acquisition activities for which the Center is involved; and (D) to work with the Secretaries concerned to ensure that the Center is appropriately represented in any joint working group or integrated product team regarding acquisition programs relating to such appropriate activities for whi",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Government support, Strategies: Convening, Strategies: Governance development, Strategies: New institution, Applications: Government: military and public safety"
24,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title XVII, Section 1751 (""Guidance and direction on use of direct hiring processes for artificial intelligence professionals and other data science and software development personnel"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.9772,low,0.0,207,1.0,Enacted,"SEC. 1751. GUIDANCE AND DIRECTION ON USE OF DIRECT HIRING PROCESSES FOR ARTIFICIAL INTELLIGENCE PROFESSIONALS AND OTHER DATA SCIENCE AND SOFTWARE DEVELOPMENT PERSONNEL. (a) GUIDANCE REQUIRED.—Not later than 180 days after the date of the enactment of this Act, the Secretary of Defense shall review applicable Department of Defense guidance and where beneficial issue new guidance to the secretaries of the military departments and the heads of the defense components on improved use of the direct hiring processes for artificial intelligence professionals and other data science and software development personnel. (b) OBJECTIVE.—The objective of the guidance issued under subsection (a) shall be to ensure that organizational leaders assume greater responsibility for the results of civilian hiring of artificial intelligence professionals and other data science and software development personnel. (c) CONTENTS OF GUIDANCE.—At a minimum, the guidance required by subsection (a) shall— (1) instruct human resources professionals and hiring authorities to utilize available direct hiring authorities (including excepted service authorities) for the hiring of artificial intelligence professionals and other data science and software development personnel, to the maximum extent practicable; (2) instruct hiring authorities, when using direct hiring authorities, to prioritize utilization of panels of subject matter experts over human resources professionals to assess applicant qualifications and d",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Government study or report, Strategies: Government support: AI workforce-related, Applications: Government: military and public safety"
25,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division E (""National Artificial Intelligence Initiative Act"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2021-01-01,2021,1,positive,0.9509,medium,0.6111,205,1.0,Enacted,"SEC. 5001. SHORT TITLE. This division may be cited as the ‘‘National Artificial Intelligence Initiative Act of 2020’’. SEC. 5002. DEFINITIONS. In this division: (1) ADVISORY COMMITTEE.—The term ‘‘Advisory Committee’’ means the National Artificial Intelligence Advisory Committee established under section 5104(a). (2) AGENCY HEAD.—The term ‘‘agency head’’ means the head of any Executive agency (as defined in section 105 of TITLE 5, United States Code). (3) ARTIFICIAL INTELLIGENCE.—The term ‘‘artificial intelligence’’ means a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations or decisions influencing real or virtual environments. Artificial intelligence systems use machine and humanbased inputs to— (A) perceive real and virtual environments; (B) abstract such perceptions into models through analysis in an automated manner; and (C) use model inference to formulate options for information or action. (4) COMMUNITY COLLEGE.—The term ‘‘community college’’ means a public institution of higher education at which the highest degree that is predominantly awarded to students is an associate’s degree, including 2-year Tribal Colleges or Universities under section 316 of the Higher Education Act of 1965 (20 U.S.C. 1059c) and public 2-year State institutions of higher education.(5) INITIATIVE.—The term ‘‘Initiative’’ means the National Artificial Intelligence Initiative established under section 5101(a). (6) INITIATIVE OFFICE.—The te",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Risk factors: Bias, Risk factors: Reliability, Risk factors: Reliability: Robustness, Risk factors: Interpretability and explainability, Risk factors: Privacy, Risk factors: Safety, Risk factors: Security, Risk factors: Security: Dissemination, Risk factors: Transparency, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: External auditing, Strategies: Disclosure"
26,"An act to include certain computer-related projects in the Federal permitting program under title XLI of the FAST Act, and for other purposes",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-08-16,2022,8,positive,0.9396,low,0.0,97,1.0,Enacted,"An Act To include certain computer-related projects in the Federal permitting program under title XLI of the FAST Act, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. FEDERAL PERMITTING IMPROVEMENT. Section 41001(6)(A) of the FAST Act (42 U.S.C. 4370m(6)(A)) is amended, in the matter preceding clause (i), by inserting semiconductors, artificial intelligence and machine learning, high-performance computing and advanced computer hardware and software, quantum information science and technology, data storage and data management, cybersecurity,'' after manufacturing,''. Approved August 16, 2022.",https://www.congress.gov/bill/117th-congress/senate-bill/3451/text?s=6&r=1&q=%7B%22search%22%3A%5B%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%5D%7D,en,
27,Artificial Intelligence Training for the Acquisition Workforce Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-10-17,2022,10,positive,0.9714,low,0.0,221,1.0,Enacted,"SECTION 1. SHORT TITLE. This Act may be cited as the ``Artificial Intelligence Training for the Acquisition Workforce Act'' or the ``AI Training Act''. SEC. 2. ARTIFICIAL INTELLIGENCE TRAINING PROGRAMS. (a) Definitions.--In this section: (1) AI.--The term ``AI'' has the meaning given the term ``artificial intelligence'' in section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (10 U.S.C. 2358 note). (2) AI training program.--The term ``AI training program'' means the training program established under subsection (b)(1). (3) Covered workforce.--The term ``covered workforce'' means-- (A) employees of an executive agency who are responsible for-- (i) program management; (ii) the planning, research, development, engineering, testing, and evaluation of systems, including quality control and assurance; (iii) procurement and contracting; (iv) logistics; or (v) cost estimating; and (B) other personnel of an executive agency designated by the head of the executive agency to participate in the AI training program. (4) Director.--The term ``Director'' means the Director of the Office of Management and Budget. (5) Executive agency.--The term ``executive agency''-- (A) has the meaning given the term in section 133 of title 41, United States Code; and (B) does not include-- (i) the Department of Defense or a component of the Department of Defense; or (ii) the National Nuclear Security Administration or a component of the National Nuclear Security Admin",https://www.congress.gov/bill/117th-congress/senate-bill/2551/text,en,"Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Government study or report, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Strategies: New institution, Applications: Education, Applications: Government: other applications/unspecified"
28,"Countering Human Trafficking Act of 2021, Section 4 (""Specialized Initiatives"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-12-27,2022,12,positive,0.9231,low,0.0,167,1.0,Enacted,"SEC. 4. SPECIALIZED INITIATIVES. (a) Human Trafficking Information Modernization Initiative.--The CCHT Director, in conjunction with the Science and Technology Directorate Office of Science and Engineering, shall develop a strategy and proposal to modify systems and processes throughout the Department of Homeland Security that are related to CCHT's mission in order to-- (1) decrease the response time to access victim protections; (2) accelerate lead development; (3) advance the identification of human trafficking characteristics and trends; (4) fortify the security and protection of sensitive information; (5) apply analytics to automate manual processes; and (6) provide artificial intelligence and machine learning to increase system capabilities and enhance data availability, reliability, comparability, and verifiability. (b) Submission of Plan.--Upon the completion of the strategy and proposal under subsection (a), the Secretary of Homeland Security shall submit a summary of the strategy and plan for executing the strategy to-- (1) the Committee on Homeland Security and Governmental Affairs of the Senate; and (2) the Committee on Homeland Security of the House of Representatives.",https://www.congress.gov/bill/117th-congress/senate-bill/2991/text?s=6&r=3&q=%7B%22search%22%3A%5B%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%5D%7D,en,"Strategies: Government study or report, Strategies: Governance development, Applications: Security"
29,William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021,United States Congress,United States,Federal government,,Law/Act,2021-01-01,2021,1,neutral,0.0,low,0.0,0,0.5,Enacted,,https://www.congress.gov/bill/116th-congress/house-bill/6395/text,,
34,"Flood Level Observation, Operations, and Decision Support Act, Section 14 (""National Weather Service hydrologic research fellowship program"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-12-27,2022,12,positive,0.8658,low,0.0,200,1.0,Enacted,"SEC. 14. NATIONAL WEATHER SERVICE HYDROLOGIC RESEARCH FELLOWSHIP PROGRAM. (a) Definitions.--In this section: (1) Assistant administrator.--The term ``Assistant Administrator'' means the Assistant Administrator for Weather Services of the National Oceanic and Atmospheric Administration. (2) Decision support services.--The term ``decision support services'' means information, including data and refined products, that supports water resources-related decision-making processes. (3) Institution of higher education.--The term ``institution of higher education'' has the meaning given that term in section 101 of the Higher Education Act of 1965 (20 U.S.C. 1001). (4) NOAA line offices.--The term ``NOAA line offices'' means the following offices of the National Oceanic and Atmospheric Administration: (A) The National Ocean Service. (B) The National Environmental Satellite, Data, and Information Service. (C) The National Marine Fisheries Service. (D) The Office of Oceanic and Atmospheric Research. (E) The Office of Marine and Aviation Operations. (b) Hydrologic Research Fellowship Program.-- (1) Establishment.--The Administrator shall establish a hydrologic research fellowship program (in this section referred to as the ``program'') for qualified individuals. (2) Qualified individual.--For purposes of this section, a qualified individual is an individual who is-- (A) a citizen of the United States; and (B) enrolled in a research-based graduate program, at an institution of higher educat",https://www.congress.gov/bill/117th-congress/senate-bill/558/text?s=6&r=6&q=%7B%22search%22%3A%5B%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%5D%7D,en,"Strategies: Government support, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related"
35,Governance Principles for a New Generation of Artificial Intelligence: Develop Responsible Artificial Intelligence,Chinese central government,China,China,Chinese law and policy,Other,2019-06-17,2019,6,positive,0.9962,low,0.0556,207,1.0,Enacted,"Governance Principles for a New Generation of Artificial Intelligence: Develop Responsible Artificial Intelligence The global development of artificial intelligence (AI) has entered a new stage, presenting new features such as cross-domain integration, human-machine cooperation, and swarm integrated intelligence. It is profoundly changing the life of human society and changing the world. In order to promote the healthy development of a new generation of AI; better coordinate the relationship between development and governance, ensure that AI is safe/secure, reliable, and controllable; promote economically, socially, and ecologically sustainable development; and jointly build a community of common destiny for humanity; various parties related to AI development should adhere to the following principles: I. Harmony and friendliness. AI development should begin from the objective of enhancing the common well-being of humanity; it should conform to human values, ethics, and morality, promote human-machine harmony, and serve the progress of human civilization; it should be based on the premise of safeguarding societal security and respecting human rights, avoid misuse, and prohibit abuse and malicious application. II. Fairness and justice. AI development should promote fairness and justice, protect the rights and interests of stakeholders, and promote equality of opportunity. Through continuously raising the level of technology and improving management methods, eliminate bias and d",https://digichina.stanford.edu/work/translation-chinese-expert-group-offers-governance-principles-for-responsible-ai/,en,"Harms: Violation of civil or human rights, including privacy, Strategies: Disclosure, Strategies: Convening, Strategies: Governance development, Strategies: Performance requirements"
36,Provisions on the Administration of Deep Synthesis Internet Information Services,Chinese central government,China,China,Chinese law and policy,Other,2022-11-25,2022,11,positive,0.9782,medium,0.4444,207,1.0,Enacted,"Chapter I: General Provisions Article 1: These Provisions are drafted on the basis of the Cybersecurity Law of the PRC, the PRC Data Security Law, the Personal Information Protection Law of the PRC, The Measures on the Administration of Internet Information Services, and other relevant laws and administrative regulations, so as to strengthen the management of deep synthesis internet information services, carry forward the Core Socialist Values, preserve national security and the societal public interest, and protect the lawful rights and interests of citizens, legal persons, and other organizations. Article 2: These Provisions apply to the application of deep synthesis technology to provide internet information services (hereinafter simply Deep Synthesis Services). Where laws or administrative regulations otherwise provide, follow those provisions. Article 3: The state internet information department is responsible for the overall planning and coordination of the nation's governance of deep synthesis services and related oversight and management efforts. The State Council Departments for telecommunications and public security are responsible for efforts on the oversight and management of deep synthesis services in accordance with their respective duties. Local internet information departments are responsible for the overall planning and coordination of the governance of deep synthesis services and related oversight and management efforts within the corresponding administrativ",https://www.chinalawtranslate.com/en/deep-synthesis/,en,"Harms: Violation of civil or human rights, including privacy, Strategies: Tiering: Tiering based on domain of application, Applications: Government: judicial and law enforcement, Applications: Networking and telecommunications, Harms: Detrimental content, Strategies: Governance development, Risk factors: Privacy, Risk factors: Security, Risk factors: Safety, Risk factors: Transparency, Strategies: Disclosure, Strategies: Evaluation, Applications: Security, Risk factors: Security: Cybersecurity, Strategies: Evaluation: Post-market monitoring"
37,Measures for the Management of Generative Artificial Intelligence Services (Draft for Comment),Chinese central government,China,China,Chinese law and policy,Other,2023-04-11,2023,4,positive,0.985,low,0.3333,221,1.0,Proposed,"Measures for the Management of Generative Artificial Intelligence Services (Draft for Comment) Article 1: In order to stimulate the healthy development and standardized application of generative artificial intelligence (AI), on the basis of the Cybersecurity Law of the People’s Republic of China, the Data Security Law of the People’s Republic of China, the Personal Information Protection Law of the People’s Republic of China, and other such laws and administrative regulations, these Measures are formulated. Article 2: These Measures apply to the research, development, and use of products with generative AI functions, and to the provision of services to the public within the [mainland] territory of the People’s Republic of China. Generative AI, as mentioned in these Measures, refers to technologies generating text, image, audio, video, code, or other such content based on algorithms, models, or rules. Article 3: The State supports indigenous innovation, broad application, and international cooperation in foundational technologies such as AI algorithms and frameworks, and encourages the prioritized use of secure and reliable software, tools, computing, and data resources. Article 4: The provision of generative AI products or services shall abide by the requirements of laws and regulations, respect social virtue and good public customs, and conform to the following requirements: Content generated through the use of generative AI shall reflect the Socialist Core Values, and may n",https://digichina.stanford.edu/work/translation-measures-for-the-management-of-generative-artificial-intelligence-services-draft-for-comment-april-2023/,en,"Harms: Harm to health/safety, Harms: Financial loss, Harms: Harm to property, Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Disclosure: Accuracy thereof, Strategies: Performance requirements, Strategies: Licensing, registration, and certification, Incentives: Criminal liability"
50,"Department of Defense Directive 3000.09 (""Autonomy in weapon systems"")",Department of Defense,United States,Federal government,Editors' Picks,Regulation,2023-01-25,2023,1,positive,0.3542,medium,0.4444,206,0.7,Enacted,"DOD DIRECTIVE 3000.09 AUTONOMY IN WEAPON SYSTEMS Originating Component: Office of the Under Secretary of Defense for Policy Effective: January 25, 2023 Releasability: Cleared for public release. Available on the Directives Division Website at https://www.esd.whs.mil/DD/. Reissues and Cancels: DoD Directive 3000.09, “Autonomy in Weapon Systems,” November 21, 2012 Approved by: Kathleen H. Hicks, Deputy Secretary of Defense [Introductory material omitted.] SECTION 1: GENERAL ISSUANCE INFORMATION 1.1. APPLICABILITY. a. This directive applies to: (1) OSD, the Military Departments, the Office of the Chairman of the Joint Chiefs of Staff (CJCS) and the Joint Staff, the Combatant Commands, the Office of Inspector General of the Department of Defense, the Defense Agencies, the DoD Field Activities, and all other organizational entities within the DoD. (2) The design, development, acquisition, testing, fielding, and employment of autonomous and semi-autonomous weapon systems, including guided munitions that are capable of automated target selection. (3) The application of lethal or non-lethal, kinetic or non-kinetic, force by autonomous or semi-autonomous weapon systems. b. This directive does not apply to: (1) Autonomous or semi-autonomous cyberspace capabilities. (2) Unarmed platforms, whether remotely operated or operated by onboard personnel, and whether autonomous or semi-autonomous. (3) Unguided munitions. (4) Munitions manually guided by the operator (e.g., laser- or wire-guided",https://www.esd.whs.mil/portals/54/documents/dd/issuances/dodd/300009p.pdf,en,"Strategies: Government support, Applications: Government: military and public safety, Risk factors: Safety, Risk factors: Reliability, Strategies: Government support: For R&D, Strategies: Pilots and testbeds, Strategies: Convening, Strategies: Government support: AI workforce-related, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Risk factors: Security: Cybersecurity, Risk factors: Interpretability and explainability, Risk factors: Transparency, Harms: Violation of civil or human rights, including privacy, Risk factors: Reliability: Robustness"
52,"Intelligence Authorization Act for Fiscal Year 2022, Section 834 (""Plan for Artificial Intelligence Digital Ecosystem"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-03-15,2022,3,positive,0.9843,low,0.0556,212,1.0,Enacted,"SEC. 834. PLAN FOR ARTIFICIAL INTELLIGENCE DIGITAL ECOSYSTEM. (a) Plan.--Not later than 1 year after the date of the enactment of this Act, the Director of National Intelligence shall coordinate with the heads of other elements of the intelligence community and, in conjunction with the heads of those elements, shall-- (1) develop a plan for the development and resourcing of a modern digital ecosystem that embraces state-of-the-art tools and modern processes to enable development, testing, fielding, and continuous updating of artificial intelligence-powered applications at speed and scale from headquarters to the tactical edge; and (2) submit to the congressional intelligence committees the plan developed under paragraph (1). (b) Contents of Plan.--At a minimum, the plan required by subsection (a) shall include the following: (1) Policies to enable elements of the intelligence community to adopt a hoteling model to allow trusted small- and medium-sized artificial intelligence companies access to classified facilities on a flexible basis. (2) Policies for an open architecture and an evolving reference design and guidance for needed technical investments in the proposed ecosystem that address issues, including common interfaces, authentication, applications, platforms, software, hardware, and data infrastructure. (3) Policies to ensure, to the extent possible, interoperability, and the reduction of duplication, of artificial intelligence capabilities developed or acquired by ele",https://www.congress.gov/bill/117th-congress/house-bill/2471/text?s=1&r=8&q=%7B%22search%22%3A%5B%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%5D%7D,en,"Risk factors: Transparency, Strategies: Government study or report, Applications: Government: military and public safety"
54,"Health Extenders, Improving Access to Medicare, Medicaid, and CHIP, and Strengthening Public Health Act of 2022, Section 1432 (""Research on the Health and Development Effects of Media and Related Technology on Infants, Children, and Adolescents"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-12-29,2022,12,positive,0.886,low,0.1111,209,1.0,Enacted,"SEC. 1432. RESEARCH ON THE HEALTH AND DEVELOPMENT EFFECTS OF MEDIA AND RELATED TECHNOLOGY ON INFANTS, CHILDREN, AND ADOLESCENTS. (a) In General.--The Secretary of Health and Human Services (in this section referred to as the ``Secretary'') shall, as appropriate, conduct or support research related to the health and developmental effects, including long-term effects, of media and related technology use on infants, children, and adolescents, which may include the effects of exposure to, and use of, media and related technology, such as social media, applications, websites, television, motion pictures, artificial intelligence, mobile devices, computers, video games, virtual and augmented reality, and other content, networks, or platforms disseminated through the internet, broadcasted, or other media technologies, as applicable. (b) Activities.--In carrying out subsection (a), the Secretary, acting through the Director of the National Institutes of Health, shall, as appropriate, develop a research agenda to assess the effects of media and related technologies on infants, children, and adolescents, which may include consideration of the following, as appropriate: (1) The cognitive development of infants, children, and adolescents, which may include effects related to language development, learning abilities, and other areas of cognitive development. (2) The physical health of infants, children, and adolescents, which may include effects related to diet, exercise, sleeping and eati",https://www.congress.gov/bill/117th-congress/house-bill/2617/text?s=1&r=10&q=%7B%22search%22%3A%5B%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%5D%7D,en,"Risk factors: Safety, Harms: Harm to health/safety, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Applications: Medicine, life sciences and public health, Applications: Consumer goods, Applications: Broadcasting and media production, Applications: Government: other applications/unspecified"
55,"Consolidated Appropriations Act, 2023, Section 101 (""Manufacturing.gov Hub"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-12-29,2022,12,positive,0.6369,low,0.0,215,1.0,Enacted,"SEC. 101. MANUFACTURING.GOV HUB. (a) Definition.--In this section, the term ``Secretary'' means the Secretary of Commerce. (b) Establishment.--Not later than 1 year after the date of enactment of this Act, the Secretary, in coordination with the Chief Information Officer of the Department of Commerce, shall modify the manufacturing.gov website by establishing a section of the website to be known as the ``manufacturing.gov hub''. (c) Functions.--The manufacturing.gov hub established under subsection (b) shall-- (1) serve as the primary hub for information relating to every Federal manufacturing program, including the programs identified in the report of the Government Accountability Office entitled ``U.S. Manufacturing'' (GAO 17-240), published on March 28, 2017; (2) provide the contact information of relevant program offices carrying out the Federal manufacturing programs described in paragraph (1); (3) provide an avenue for public input and feedback relating to-- (A) the functionality of the website of the Department of Commerce; (B) the Federal manufacturing programs described in paragraph (1); and (C) any other manufacturing-related challenges experienced by manufacturers in the United States; (4) establish web pages within the hub that shall focus on-- (A) technology and research and development; (B) trade; (C) workforce development and training; (D) industrial commons and supply chains; and (E) small and medium manufacturers; and (5) use machine learning to-- (A) identif",https://www.congress.gov/bill/117th-congress/house-bill/2617/text?s=1&r=10&q=%7B%22search%22%3A%5B%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%5D%7D,en,"Applications: Manufacturing and process automation, Applications: Government: other applications/unspecified"
56,"Infrastructure Investment and Jobs Act, Section 40210 (""Critical Minerals Mining and Recycling Research"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2021-11-15,2021,11,positive,0.0943,low,0.0,227,1.0,Enacted,"SEC. 40210. CRITICAL MINERALS MINING AND RECYCLING RESEARCH. (a) Definitions.--In this section: (1) Critical mineral.--The term ``critical mineral'' has the meaning given the term in section 7002(a) of the Energy Act of 2020 (30 U.S.C. 1606(a)). (2) Critical minerals and metals.--The term ``critical minerals and metals'' includes any host mineral of a critical mineral. (3) Director.--The term ``Director'' means the Director of the Foundation. (4) End-to-end.--The term ``end-to-end'', with respect to the integration of mining or life cycle of minerals, means the integrated approach of, or the lifecycle determined by, examining the research and developmental process from the mining of the raw minerals to its processing into useful materials, its integration into components and devices, the utilization of such devices in the end-use application to satisfy certain performance metrics, and the recycling or disposal of such devices. (5) Foreign entity of concern.--The term ``foreign entity of concern'' means a foreign entity that is-- (A) designated as a foreign terrorist organization by the Secretary of State under section 219(a) of the Immigration and Nationality Act (8 U.S.C. 1189(a)); (B) included on the list of specially designated nationals and blocked persons maintained by the Office of Foreign Assets Control of the Department of the Treasury (commonly known as the SDN list); (C) owned by, controlled by, or subject to the jurisdiction or direction of a government of a foreig",https://www.congress.gov/bill/117th-congress/house-bill/3684/text?s=1&r=12&q=%7B%22search%22%3A%5B%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%5D%7D,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Governance development, Applications: Security, Applications: Education, Applications: Government: military and public safety, Applications: Government: benefits and welfare"
57,"Infrastructure Investment and Jobs Act, Section 40433 (""Digital Climate Solutions Report"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2021-11-15,2021,11,positive,0.9426,low,0.0,184,1.0,Enacted,"SEC. 40433. DIGITAL CLIMATE SOLUTIONS REPORT. (a) In General.--Not later than 1 year after the date of enactment of this Act, the Secretary, in consultation with appropriate Federal agencies and relevant stakeholders, shall submit to the Committee on Energy and Natural Resources of the Senate and the Committee on Energy and Commerce of the House of Representatives a report that assesses using digital tools and platforms as climate solutions, including-- (1) artificial intelligence and machine learning; (2) blockchain technologies and distributed ledgers; (3) crowdsourcing platforms; (4) the Internet of Things; (5) distributed computing for the grid; and (6) software and systems. (b) Contents.--The report required under subsection (a) shall include-- (1) as practicable, a full inventory and assessment of digital climate solutions; (2) an analysis of how the private sector can utilize the digital tools and platforms included in the inventory under paragraph (1) to accelerate digital climate solutions; and (3) a summary of opportunities to enhance the standardization of voluntary and regulatory climate disclosure protocols, including enabling the data to be disseminated through an application programming interface that is accessible to the public.",https://www.congress.gov/bill/117th-congress/house-bill/3684/text?s=1&r=12&q=%7B%22search%22%3A%5B%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%5D%7D,en,"Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Government study or report, Applications: Energy and utilities"
58,"Infrastructure Investment and Jobs Act, Title V, Subtitle C, Part II (""Smart Manufacturing"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2021-11-15,2021,11,positive,0.9723,low,0.0,194,1.0,Enacted,"PART II--SMART MANUFACTURING SEC. 40531. DEFINITIONS. In this part: (1) Energy management system.--The term ``energy management system'' means a business management process based on standards of the American National Standards Institute that enables an organization to follow a systematic approach in achieving continual improvement of energy performance, including energy efficiency, security, use, and consumption. (2) Industrial research and assessment center.--The term ``industrial research and assessment center'' means a center located at an institution of higher education, a trade school, a community college, or a union training program that-- (A) receives funding from the Department; (B) provides an in-depth assessment of small- and medium-size manufacturer plant sites to evaluate the facilities, services, and manufacturing operations of the plant site; and (C) identifies opportunities for potential savings for small- and medium-size manufacturer plant sites from energy efficiency improvements, waste minimization, pollution prevention, and productivity improvement. (3) Information and communication technology.--The term ``information and communication technology'' means any electronic system or equipment (including the content contained in the system or equipment) used to create, convert, communicate, or duplicate data or information, including computer hardware, firmware, software, communication protocols, networks, and data interfaces. (4) Institution of higher education",https://www.congress.gov/bill/117th-congress/house-bill/3684/text?s=1&r=12&q=%7B%22search%22%3A%5B%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%5D%7D,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Applications: Manufacturing and process automation"
60,Identifying Outputs of Generative Adversarial Networks Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2020-12-23,2020,12,positive,0.7845,low,0.2222,223,1.0,Enacted,"An Act To direct the Director of the National Science Foundation to support research on the outputs that may be generated by generative adversarial networks, otherwise known as deepfakes, and other comparable techniques that may be developed in the future, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the Identifying Outputs of Generative Adversarial Networks Act'' or the IOGAN Act''. SEC. 2. FINDINGS. Congress finds the following: (1) Gaps currently exist on the underlying research needed to develop tools that detect videos, audio files, or photos that have manipulated or synthesized content, including those generated by generative adversarial networks. Research on digital forensics is also needed to identify, preserve, recover, and analyze the provenance of digital artifacts. (2) The National Science Foundation's focus to support research in artificial intelligence through computer and information science and engineering, cognitive science and psychology, economics and game theory, control theory, linguistics, mathematics, and philosophy, is building a better understanding of how new technologies are shaping the society and economy of the United States. (3) The National Science Foundation has identified the 10 Big Ideas for NSF Future Investment'' including Harnessing the Data Revolution'' and the ``Future of Work at the Human- Technolog",https://www.congress.gov/bill/116th-congress/senate-bill/2904/text,en,"Risk factors: Safety, Risk factors: Security, Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Convening, Applications: Government: military and public safety"
61,AI in Government Act of 2020,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2020-12-27,2020,12,positive,0.9871,low,0.2222,242,1.0,Enacted,"SEC. 101. SHORT TITLE. This title may be cited as the ``AI in Government Act of 2020''. SEC. 102. DEFINITIONS. In this Act-- (1) the term ``Administrator'' means the Administrator of General Services; (2) the term ``agency'' has the meaning given the term in section 3502 of title 44, United States Code; (3) the term ``AI CoE'' means the AI Center of Excellence described in section 103; (4) the term ``artificial intelligence'' has the meaning given the term in section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (10 U.S.C. 2358 note); (5) the term ``Director'' means the Director of the Office of Management and Budget; (6) the term ``institution of higher education'' has the meaning given the term in section 101 of the Higher Education Act of 1965 (20 U.S.C. 1001); and (7) the term ``nonprofit organization'' means an organization described in section 501(c)(3)of the Internal Revenue Code of 1986 and exempt from taxation under section 501(a) of that Code. SEC. 103. AI CENTER OF EXCELLENCE. (a) In General.--There is created within the General Services Administration a program to be known as the ``AI Center of Excellence'', which shall-- (1) facilitate the adoption of artificial intelligence technologies in the Federal Government; (2) improve cohesion and competency in the adoption and use of artificial intelligence within the Federal Government; and (3) carry out paragraphs (1) and (2) for the purposes of benefitting the public and enhancin",https://www.congress.gov/bill/116th-congress/house-bill/133/text,en,"Risk factors: Bias, Risk factors: Privacy, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Strategies: Convening, Strategies: Governance development, Strategies: New institution, Applications: Government: military and public safety"
63,"Consolidated Appropriations Act, 2021, Division W, Title V, Section 502 (""Seedling investment in next-generation microelectronics in support of artificial intelligence"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2020-12-27,2020,12,positive,0.997,low,0.0,201,1.0,Enacted,"SEC. 502. SEEDLING INVESTMENT IN NEXT-GENERATION MICROELECTRONICS IN SUPPORT OF ARTIFICIAL INTELLIGENCE. (a) Findings.--Congress finds that-- (1) developing faster, more energy efficient, and more resilient computing is important to the future of the national security of the United States and the leadership by the United States in artificial intelligence; and (2) multidisciplinary teams co-designing microelectronics for artificial intelligence will lead to unprecedented capabilities that will help ensure that the United States maintains its superiority in this worldwide competition for economic and national security. (b) Awards for Research and Development.--The Director of National Intelligence, acting through the Director of the Intelligence Advanced Research Projects Activity, shall award contracts or grants, or enter into transactions other than contracts, to encourage microelectronics research. (c) Use of Funds.--The Director shall award contracts or grants to, or enter into transactions other than contracts with, entities under subsection (b) to carry out any of the following: (1) Advanced engineering and applied research into novel computing models, materials, devices, architectures, or algorithms to enable the advancement of artificial intelligence and machine learning. (2) Research efforts to-- (A) overcome challenges with engineering and applied research of microelectronics, including with respect to the physical limits on transistors, electrical interconnects, and",https://www.congress.gov/bill/116th-congress/house-bill/133/text,en,"Strategies: Government support, Strategies: Government support: For R&D, Applications: Government: military and public safety"
64,"Consolidated Appropriations Act, 2021, Division W, Title V, Section 604 (""Assessment of critical technology trends relating to artificial intelligence, microchips, and semiconductors and related supply chains"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2020-12-27,2020,12,positive,0.9726,low,0.0,193,1.0,Enacted,"SEC. 604. ASSESSMENT OF CRITICAL TECHNOLOGY TRENDS RELATING TO ARTIFICIAL INTELLIGENCE, MICROCHIPS, AND SEMICONDUCTORS AND RELATED SUPPLY CHAINS. (a) Assessment Required.--Not later than 180 days after the date of the enactment of this Act, the Director of National Intelligence shall complete a detailed assessment of critical technology trends relating to artificial intelligence, microchips, and semiconductors and related supply chains. (b) Elements.--The assessment required by subsection (a) shall include the following: (1) Export controls.-- (A) In general.--An assessment of efforts by partner countries to enact and implement export controls and other technology transfer measures with respect to artificial intelligence, microchips, advanced manufacturing equipment, and other artificial intelligence enabled technologies critical to United States supply chains. (B) Identification of opportunities for cooperation.--The assessment under subparagraph (A) shall identify opportunities for further cooperation with international partners on a multilateral and bilateral basis to strengthen export control regimes and address technology transfer threats. (2) Semiconductor supply chains.-- (A) In general.--An assessment of global semiconductor supply chains, including areas to reduce United States vulnerabilities and maximize points of leverage. (B) Analysis of potential effects.--The assessment under subparagraph (A) shall include an analysis of thepotential effects of significant geop",https://www.congress.gov/bill/116th-congress/house-bill/133/text,en,"Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Government study or report, Applications: Manufacturing and process automation, Applications: Government: military and public safety"
65,"Energy Act of 2020, Title III, Section 3002(g) (""Advanced Geothermal Computing and Data Science Research and Development"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2020-12-27,2020,12,positive,0.9816,low,0.0556,191,1.0,Enacted,"(g) Advanced Geothermal Computing and Data Science Research and Development.-- (1) In general.--Section 618 of the Energy Independence and Security Act of 2007 (42 U.S.C. 17197) is amended to read as follows: ``SEC. 618. ADVANCED GEOTHERMAL COMPUTING AND DATA SCIENCE RESEARCH AND DEVELOPMENT. ``(a) In General.--The Secretary shall carry out a program of research and development of advanced computing and data science tools for geothermal energy. ``(b) Programs.--The program authorized in subsection (a) shall include the following: ``(1) Advanced computing for geothermal systems technologies.--Research, development, and demonstration of technologies to develop advanced data, machine learning, artificial intelligence, and related computing tools to assist in locating geothermal resources, to increase the reliability of site characterization, to increase the rate and efficiency of drilling, to improve induced seismicity mitigation, and to support enhanced geothermal systems technologies. ``(2) Geothermal systems reservoir modeling.--Research, development, and demonstration of models of geothermal reservoir performance and enhanced geothermal systems reservoir stimulation technologies and techniques, with an emphasis on accurately modeling fluid and heat flow, permeability evolution, geomechanics, geochemistry, seismicity, andoperational performance over time, including collaboration with industry and field validation. ``(c) Coordination.--In carrying out these programs, the Secre",https://www.congress.gov/bill/116th-congress/house-bill/133/text,en,"Risk factors: Reliability, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Convening, Applications: Agriculture and resource extraction"
66,"Energy Act of 2020, Title VI, Section 6006 (""Development of National Smart Manufacturing Plan"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2020-12-27,2020,12,positive,0.9918,low,0.1667,208,1.0,Enacted,"SEC. 6006. DEVELOPMENT OF NATIONAL SMART MANUFACTURING PLAN. (a) In General.--Not later than 3 years after the date of enactment of this Act, the Secretary of Energy (in this section referred to as the ``Secretary''), in consultation with the National Academies, shall develop and complete a national plan for smart manufacturing technology development and deployment to improve the productivity and energy efficiency of the manufacturing sector of the United States. (b) Content.-- (1) In general.--The plan developed under subsection (a) shall identify areas in which agency actions by the Secretary and other heads of relevant Federal agencies would-- (A) facilitate quicker development, deployment, and adoption of smart manufacturing technologies and processes; (B) result in greater energy efficiency and lower environmental impacts for all American manufacturers; and(C) enhance competitiveness and strengthen the manufacturing sectors of the United States. (2) Inclusions.--Agency actions identified under paragraph (1) shall include-- (A) an assessment of previous and current actions of the Department relating to smart manufacturing; (B) the establishment of voluntary interconnection protocols and performance standards; (C) the use of smart manufacturing to improve energy efficiency and reduce emissions in supply chains across multiple companies; (D) actions to increase cybersecurity in smart manufacturing infrastructure; (E) deployment of existing research results; (F) the leveragi",https://www.congress.gov/bill/116th-congress/house-bill/133/text,en,"Risk factors: Security, Risk factors: Security: Cybersecurity, Harms: Financial loss, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Government study or report, Applications: Manufacturing and process automation, Applications: Energy and utilities, Applications: Networking and telecommunications"
67,"Energy Act of 2020, Title VIII, Section 8002 (""Smart grid modeling, visualization, architecture, and controls"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2020-12-27,2020,12,positive,0.9522,low,0.0556,208,1.0,Enacted,"SEC. 8002. SMART GRID MODELING, VISUALIZATION, ARCHITECTURE, AND CONTROLS. Title XIII of the Energy Independence and Security Act of 2007 (42 U.S.C. 17381 et seq.) is amended by inserting after section 1304 the following: ``SEC. 1304A. SMART GRID MODELING, VISUALIZATION, ARCHITECTURE, AND CONTROLS. ``(a) In General.--Not later than 180 days after the enactment of this section, the Secretary shall establish a program of research, development, demonstration, and commercial application on electric grid modeling, sensing, visualization, architecture development, and advanced operation and controls. ``(b) Modeling Research and Development.--The Secretary shall support development of models of emerging technologies and systems to facilitate the secure and reliable design, planning, and operation of the electric grid for use by industry stakeholders. In particular, the Secretary shall support development of-- ``(1) models to analyze and predict the effects of adverse physical and cyber events on the electric grid; ``(2) coupled models of electrical, physical, and cyber systems; ``(3) models of existing and emerging technologies being deployed on the electric grid due to projected changes in the electric generation mix and loads, for a variety of regional characteristics; and ``(4) integrated models of the communications, transmission, distribution, and other interdependent systems for existing, new, and emerging technologies. ``(c) Situational Awareness Research and Development.-- `",https://www.congress.gov/bill/116th-congress/house-bill/133/text,en,"Harms: Harm to infrastructure, Strategies: Evaluation, Strategies: Government study or report, Strategies: Governance development, Applications: Energy and utilities"
68,"Energy Act of 2020, Title IX, Section 9008 (""Veterans' health initiative"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2020-12-27,2020,12,positive,0.9902,low,0.2778,195,1.0,Enacted,"SEC. 9008. <<NOTE: 15 USC 5544.>> VETERANS' HEALTH INITIATIVE. (a) Purposes.--The purposes of this section are to advance Department of Energy expertise in artificial intelligence and high- performance computing in order to improve health outcomes for veteran populations by-- (1) supporting basic research through the application of artificial intelligence, high-performance computing, modeling and simulation, machine learning, and large-scale data analytics to identify and solve outcome-defined challenges in the health sciences; (2) maximizing the impact of the Department of Veterans Affairs' health and genomics data housed at the National Laboratories, as well as data from other sources, on science, innovation, and health care outcomes through the use and advancement of artificial intelligence and high-performance computing capabilities of the Department; (3) promoting collaborative research through the establishment of partnerships to improve data sharing between Federal agencies, National Laboratories, institutions of higher education, and nonprofit institutions; (4) establishing multiple scientific computing user facilities to house and provision available data to foster transformational outcomes; and (5) driving the development of technology to improve artificial intelligence, high-performance computing, and networking relevant to mission applications of the Department, including modeling, simulation, machine learning, and advanced data analytics. (b) Veterans Health Rese",https://www.congress.gov/bill/116th-congress/house-bill/133/text,en,"Risk factors: Privacy, Risk factors: Security, Risk factors: Security: Cybersecurity, Risk factors: Security: Dissemination, Harms: Violation of civil or human rights, including privacy, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Convening, Strategies: Performance requirements, Applications: Medicine, life sciences and public health, Applications: Government: benefits and welfare, Applications: Government: other applications/unspecified"
69,American Competitiveness Of a More Productive Emerging Tech Economy Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2020-12-27,2020,12,positive,0.9896,medium,0.6111,222,1.0,Enacted,"SEC. 1501. AMERICAN COMPETITIVENESS OF A MORE PRODUCTIVE EMERGING TECH ECONOMY. (a) Short Title.--This title may be cited as the ``American Competitiveness Of a More Productive Emerging Tech Economy Act'' or the ``American COMPETE Act''. (b) Study to Advance Artificial Intelligence.-- (1) In general.-- (A) Study required.--Not later than 1 year after the date of enactment of this Act, the Secretary of Commerce and the Federal Trade Commission shall complete a study on the state of the artificial intelligence industry and the impact of such industry on the United States economy. (B) Requirements for study.--In conducting the study, the Secretary and the Commission shall-- (i) develop and conduct a survey of the artificial intelligence industry through outreach to participating entities as appropriate to-- (I) establish a list of industry sectors that implement and promote the use of artificial intelligence; (II) establish a list of public- private partnerships focused on promoting the adoption and use of artificial intelligence, as well as industry-based bodies, including international bodies, which have developed, or are developing, mandatory or voluntary standards for artificial intelligence; (III) the status of such industry- based mandatory or voluntary standards; and (IV) provide a description of the ways entities or industry sectors implement and promote the use of artificial intelligence; (ii) develop a comprehensive list of Federal agencies with jurisdiction over the e",https://www.congress.gov/bill/116th-congress/house-bill/133/text,en,"Risk factors: Bias, Risk factors: Privacy, Risk factors: Safety, Risk factors: Security, Harms: Harm to health/safety, Harms: Financial loss, Harms: Harm to property, Harms: Harm to infrastructure, Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Government study or report, Strategies: Governance development"
70,Information Technology Modernization Centers of Excellence Program Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2020-12-03,2020,12,positive,0.9841,low,0.1111,216,1.0,Enacted,"Public Law 116-194 116th Congress An Act To establish a program to facilitate the adoption of modern technology by executive agencies, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the ``Information Technology Modernization Centers of Excellence Program Act''. SEC. 2. GSA MODERNIZATION CENTERS OF EXCELLENCE PROGRAM. (a) Definitions.--In this section: (1) Cloud computing.--The term ``cloud computing'' has the meaning given the term in section 1076 of the National Defense Authorization Act for Fiscal Year 2018 (40 U.S.C. 11301 note). (2) Executive agency.--The term executive agency'' has the meaning given the term Executive agency'' in section 105 of title 5, United States Code. (3) Program.--The term ``Program'' means the Information Technology Modernization Centers of Excellence Program established under subsection (b). (b) Establishment.--The Administrator of General Services shall establish a program to be known as the Information Technology Modernization Centers of Excellence Program to facilitate the adoption of modern technology by executive agencies on a reimbursable basis. (c) Responsibilities.--The Program shall have the following responsibilities: (1) To encourage the modernization of information technology used by an executive agency and how a customer interacts with an executive agency. (2) To improve cooperation between commerc",https://www.congress.gov/bill/116th-congress/house-bill/5901/text?s=1&r=17&q=%7B%22search%22%3A%5B%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%5D%7D,en,"Risk factors: Security, Risk factors: Security: Cybersecurity, Strategies: Government study or report, Strategies: Government support, Strategies: New institution"
72,"A Local Law to amend the administrative code of the city of New York, in relation to automated employment decision tools","New York, NY",United States,Local governments,U.S. state and local documents,State/Local Law or Policy,2021-12-11,2021,12,positive,0.2535,low,0.2222,218,1.0,Enacted,"Int. No. 1894-A By Council Members Cumbo, Ampry-Samuel, Rosenthal, Cornegy, Kallos, Adams, Louis, Chin, Cabrera, Rose, Gibson, Brannan, Rivera, Levine, Ayala, Miller, Levin and Barron A Local Law to amend the administrative code of the city of New York, in relation to automated employment decision tools Be it enacted by the Council as follows: Section 1. Chapter 5 of title 20 of the administrative code of the city of New York is amended by adding a new subchapter 25 to read as follows: Subchapter 25 Automated Employment Decision Tools § 20-870 Definitions. For the purposes of this subchapter, the following terms have the following meanings: Automated employment decision tool. The term “automated employment decision tool” means any computational process, derived from machine learning, statistical modeling, data analytics, or artificial intelligence, that issues simplified output, including a score, classification, or recommendation, that is used to substantially assist or replace discretionary decision making for making employment decisions that impact natural persons. The term “automated employment decision tool” does not include a tool that does not automate, support, substantially assist or replace discretionary decision-making processes and that does not materially impact natural persons, including, but not limited to, a junk email filter, firewall, antivirus software, calculator, spreadsheet, database, data set, or other compilation of data. Bias audit. The term “bias aud",https://legistar.council.nyc.gov/LegislationDetail.aspx?ID=4344524&GUID=B051915D-A9AC-451E-81F8-6596032FA3F9&Options=ID%7CText%7C&Search=,en,"Risk factors: Bias, Risk factors: Transparency, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: External auditing, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About evaluation, Strategies: New institution, Incentives: Civil liability, Incentives: Fines, Applications: Business services and analytics"
73,"21 CFR § 876.1520 (""Gastrointestinal lesion software detection system"")",Food and Drug Administration,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2023-01-03,2023,1,positive,0.5267,low,0.2778,214,1.0,Enacted,"PART 876—GASTROENTEROLOGY-UROLOGY DEVICES 1. The authority citation for part 876 continues to read as follows: Authority: 21 U.S.C. 351, 360, 360c, 360e, 360j, 360l, 371. 1. Add § 876.1520 to subpart B to read as follows: § 876.1520 Gastrointestinal lesion software detection system. (a) Identification. A gastrointestinal lesion software detection system is a computer-assisted detection device used in conjunction with endoscopy for the detection of abnormal lesions in the gastrointestinal tract. This device with advanced software algorithms brings attention to images to aid in the detection of lesions. The device may contain hardware to support interfacing with an endoscope. (b) Classification. Class II (special controls). The special controls for this device are: (1) Clinical performance testing must demonstrate that the device performs as intended under anticipated conditions of use, including detection of gastrointestinal lesions and evaluation of all adverse events. (2) Non-clinical performance testing must demonstrate that the device performs as intended under anticipated conditions of use. Testing must include: (i) Standalone algorithm performance testing; (ii) Pixel-level comparison of degradation of image quality due to the device; (iii) Assessment of video delay due to marker annotation; and (iv) Assessment of real-time endoscopic video delay due to the device. (3) Usability assessment must demonstrate that the intended user(s) can safely and correctly use the device.",https://www.federalregister.gov/documents/2023/01/03/2022-28494/medical-devices-gastroenterology-urology-devices-classification-of-the-gastrointestinal-lesion,en,"Risk factors: Reliability, Risk factors: Interpretability and explainability, Risk factors: Safety, Risk factors: Transparency, Harms: Harm to health/safety, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Performance requirements, Applications: Medicine, life sciences and public health"
75,"Research and Development, Competition, and Innovation Act, Title I (""Department of Energy Science for the Future"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-08-09,2022,8,positive,0.9692,low,0.0,212,1.0,Enacted,"TITLE I--DEPARTMENT OF ENERGY SCIENCE FOR THE FUTURE SEC. 10101. MISSION OF THE OFFICE OF SCIENCE. Section 209 of the Department of Energy Organization Act (42 U.S.C. 7139) is amended by adding at the end the following: ``(d) User Facilities.--The Director shall carry out the construction, operation, and maintenance of user facilities to support the mission described in subsection (c). As practicable, these facilities shall serve the needs of the Department, industry, the academic community, and other relevant entities for the purposes of advancing the missions of the Department, improving the competitiveness of the United States, protecting public health and safety, and addressing other national priorities including emergencies. ``(e) Coordination.-- ``(1) In general.--The Secretary-- ``(A) shall ensure the coordination of the Office of Science with the other activities of the Department, including the transfer of knowledge, capabilities, and relevant technologies from basic research programs of the Department to applied research and development programs of the Department for the purpose of enabling development of mission-relevant technologies; ``(B) shall support joint activities among the programs of the Department; ``(C) shall coordinate with other relevant Federal agencies operating under existing authorizations relating to subjects relating to the mission described in subsection (c) in supporting advancements in related research areas as appropriate; and ``(D) may form",https://www.congress.gov/bill/117th-congress/house-bill/4346/text?s=1&r=4&q=%7B%22search%22%3A%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%7D,en,"Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Pilots and testbeds, Applications: Medicine, life sciences and public health, Applications: Energy and utilities, Applications: Security, Applications: Education"
76,"Research and Development, Competition, and Innovation Act, Title II (""National Institute of Standards and Technology for the Future""), Subtitle B (""Measurement Research"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-08-09,2022,8,positive,0.9337,low,0.2222,189,1.0,Enacted,"SEC. 10221. ENGINEERING BIOLOGY AND BIOMETROLOGY. (a) In General.--The Director, in coordination with the National Engineering Biology Research and Development Initiative established pursuant to title IV, shall-- (1) support basic measurement science and technology research for engineering biology, biomanufacturing, and biometrology to advance-- (A) measurement technologies to support foundational understanding of the mechanisms of conversion of DNA information into cellular function; (B) technologies for measurement of such biomolecular components and related systems; (C) new data tools, techniques, and processes to improve engineering biology, biomanufacturing, and biometrology research; and (D) other areas of measurement science and technology research determined by the Director to be critical to the development and deployment of engineering biology, biomanufacturing and biometrology; (2) support activities to inform and expand the development of measurements infrastructure needed to develop technical standards to establish interoperability and facilitate commercial development of biomolecular measurement technology and engineering biology applications; (3) convene industry, institutions of higher education, nonprofit organizations, Federal laboratories, and other Federal agencies engaged in engineering biology research and development to develop coordinated technical roadmaps for authoritative measurement of the molecular components of the cell; (4) provide access to user",https://www.congress.gov/bill/117th-congress/house-bill/4346/text?s=1&r=4&q=%7B%22search%22%3A%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%7D,en,"Risk factors: Reliability, Risk factors: Interpretability and explainability, Risk factors: Privacy, Risk factors: Security, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: AI workforce-related, Strategies: Pilots and testbeds, Strategies: Governance development, Applications: Agriculture and resource extraction, Applications: Security, Applications: Networking and telecommunications, Applications: Education"
77,"Research and Development, Competition, and Innovation Act, Title III (""National Science Foundation for the Future"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-08-09,2022,8,positive,0.9913,low,0.0,213,1.0,Enacted,"TITLE III--NATIONAL SCIENCE FOUNDATION FOR THE FUTURE Subtitle A--Preliminary Matters SEC. 10301. SENSE OF CONGRESS. It is the sense of Congress that-- (1) the National Science Foundation, the Department of Energy and its National Laboratories, and other key Federal agencies have carried out vital work supporting basic and applied research to create knowledge that is a key driver of the economy of the United States and a critical component of national security; (2) openness to diverse perspectives and a focus on freedom from censorship and political bias will continue to make educational and research institutions in the United States beacons to thousands of students from across the world; (3) increasing research and technology transfer investments, building regional capacity and reducing geographic disparity, strengthening supply chains, and increasing capabilities in key technology focus areas will enhance the competitive advantage and leadership of the United States in the global economy; (4) the Federal Government must utilize the full talent and potential of the entire Nation by avoiding undue geographic concentration of research and STEM education funding, encouraging broader participation of populations underrepresented in STEM, and collaborating with nongovernment partners to ensure the leadership of the United States in technological innovation; and (5) authorization and funding for investments in research, education, technology transfer, intellectual property, manufa",https://www.congress.gov/bill/117th-congress/house-bill/4346/text?s=1&r=4&q=%7B%22search%22%3A%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%7D,en,"Strategies: Evaluation, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Strategies: Pilots and testbeds, Strategies: Convening, Strategies: Governance development, Incentives: Subsidies, Applications: Agriculture and resource extraction, Applications: Manufacturing and process automation, Applications: Construction and field services, Applications: Government: military and public safety"
78,"Research and Development, Competition, and Innovation Act, Title IV, Section 10402 (""National engineering biology research and development initiative"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-08-09,2022,8,positive,0.9834,low,0.0,196,1.0,Enacted,"SEC. 10402. NATIONAL ENGINEERING BIOLOGY RESEARCH AND DEVELOPMENT INITIATIVE. (a) In General.--The President, acting through the Office of Science and Technology Policy, shall implement a National Engineering Biology Research and Development Initiative to advance societal well-being, national security, sustainability, and economic productivity and competitiveness through the following: (1) Advancing areas of research at the intersection of the biological, physical, chemical, data, and computational and information sciences and engineering to accelerate scientific understanding and technological innovation in engineering biology. (2) Advancing areas of biomanufacturing research to optimize, standardize, scale, and deliver new products and solutions. (3) Supporting social and behavioral sciences and economics research that advances the field of engineering biology and contributes to the development and public understanding of new products, processes, and technologies. (4) Improving the understanding of engineering biology of the scientific and lay public and supporting greater evidence- based public discourse about its benefits and risks. (5) Supporting research relating to the risks and benefits of engineering biology, including under subsection (d). (6) Supporting the development of novel tools and technologies to accelerate scientific understanding and technological innovation in engineering biology. (7) Expanding the number of researchers, educators, and students and a reto",https://www.congress.gov/bill/117th-congress/house-bill/4346/text?s=1&r=4&q=%7B%22search%22%3A%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%7D,en,"Strategies: Government support, Strategies: Government support: For R&D, Applications: Medicine, life sciences and public health"
79,"Research and Development, Competition, and Innovation Act, Title VI, Section 10731 (""Microelectronics research for energy innovation"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-08-09,2022,8,positive,0.8056,low,0.0556,204,1.0,Enacted,SEC. 10731. MICROELECTRONICS RESEARCH FOR ENERGY INNOVATION. (a) Definitions.--In this section: (1) Center.--The term ``Center'' means a Microelectronics Science Research Center established pursuant to subsection (d). (2) Department.--The term ``Department'' means the Department of Energy. (3) Director.--The term ``Director'' means the Director of the Office of Science. (4) Historically black college or university.--The term historically Black college or university'' has the meaning given the term part B institution'' in section 322 of the Higher Education Act of 1965 (20 U.S.C. 1061). (5) Institution of higher education.--The term ``institution of higher education'' has the meaning given the term in section 101(a) of the Higher Education Act of 1965 (20 U.S.C. 1001(a)). (6) Microelectronics.--The term ``microelectronics'' means-- (A) a semiconductor and related materials; (B) processing chemistries; (C) design technologies; (D) fabrication technologies; (E) lithography technologies; (F) packaging technologies; (G) a sensor; (H) a device; (I) an integrated circuit; (J) a processor; (K) computing architecture; (L) modeling and simulation; (M) a software tool; and (N) any other related technology. (7) Minority-serving institution.--The term ``minority-serving institution'' means-- (A) a Hispanic-serving institution (as defined in section 502(a) of the Higher Education Act of 1965 (20 U.S.C. 1101a(a))); (B) an Alaska Native-serving institution (as defined in section 317(b) of th,https://www.congress.gov/bill/117th-congress/house-bill/4346/text?s=1&r=4&q=%7B%22search%22%3A%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%7D,en,"Harms: Harm to infrastructure, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Strategies: Convening, Strategies: New institution, Applications: Energy and utilities"
80,"Research and Development, Competition, and Innovation Act, Title VI, Section 10771 (""Department of Energy research, development, and demonstration activities"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-08-09,2022,8,positive,0.9758,low,0.0,200,1.0,Enacted,"SEC. 10771. DEPARTMENT OF ENERGY RESEARCH, DEVELOPMENT, AND DEMONSTRATION ACTIVITIES. For the purpose of carrying out research, development, and demonstration activities and addressing energy-related supply chain activities in the key technology focus areas (as described in section 10387), there are authorized to be appropriated the following amounts: (1) Office of energy efficiency and renewable energy.--In addition to amounts otherwise authorized to be appropriated or made available, there are authorized to be appropriated to the Secretary of Energy (referred to in this section as the ``Secretary''), acting through the Office of Energy Efficiency and Renewable Energy, for the period of fiscal years 2023 through 2026-- (A) $1,200,000,000 to carry out building technologies research, development, and demonstration activities; (B) $1,200,000,000 to carry out sustainable transportation research, development, and demonstration activities; (C) $1,000,000,000 to carry out advanced manufacturing research, development, and demonstration activities, excluding activities carried out pursuant to subparagraph (D); (D) $1,000,000,000 to carry out section 454 of the Energy Independence and Security Act of 2007 (42 U.S.C. 17113); (E) $600,000,000 to carry out advanced materials research, development, and demonstration activities, including relating to upcycling, recycling, and biobased materials; and (F) $800,000,000 to carry out renewable power research, development, and demonstration acti",https://www.congress.gov/bill/117th-congress/house-bill/4346/text?s=1&r=4&q=%7B%22search%22%3A%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%7D,en,"Strategies: Government support, Strategies: Government support: For R&D"
89,Creating Resources for Every American To Experiment with Artificial Intelligence Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2023-07-28,2023,7,positive,0.9944,medium,0.3889,212,1.0,Defunct,"SECTION 1. Short title. This Act may be cited as the “Creating Resources for Every American To Experiment with Artificial Intelligence Act of 2023” or the “CREATE AI Act of 2023”. SEC. 2. Findings. Congress finds the following: (1) Cutting-edge artificial intelligence research relies on access to computational resources and large datasets. (2) Access to the computational resources and datasets necessary for artificial intelligence research and development is often limited to very large technology companies. (3) The lack of access to computational and data resources has resulted in insufficient diversity in the artificial intelligence research and development community. (4) Engaging the full and diverse talent of the United States is critical for maintaining United States leadership in artificial intelligence and ensuring that artificial intelligence is developed in a manner that benefits all people of the United States. (5) The National Artificial Intelligence Research Resource Task Force, authorized under section 5106 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401 et seq.), recommended the establishment of a National Artificial Intelligence Research Resource in a report entitled “Strengthening and Democratizing the U.S. Artificial Intelligence Innovation Ecosystem: An Implementation Plan for a National Artificial Intelligence Research Resource”, issued on January 24, 2023. SEC. 3. National Artificial Intelligence Research Resource. (a) NAIRR s",https://congress.gov/bill/118th-congress/house-bill/5077,en,"Risk factors: Reliability, Risk factors: Reliability: Robustness, Risk factors: Privacy, Risk factors: Safety, Risk factors: Security, Risk factors: Security: Cybersecurity, Harms: Violation of civil or human rights, including privacy, Strategies: Evaluation, Strategies: Evaluation: Adversarial testing, Strategies: Evaluation: Impact assessment, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Strategies: Pilots and testbeds"
139,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title II, Subtitle C (""Artificial Intelligence and Emerging Technology"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.973,low,0.0556,214,1.0,Enacted,"Subtitle C—Artificial Intelligence and Emerging Technology SEC. 231. MODIFICATION OF BIANNUAL REPORT ON THE JOINT ARTIFICIAL INTELLIGENCE CENTER. Section 260(b) of the National Defense Authorization Act for Fiscal Year 2020 (Public Law 116–92; 133 Stat. 1293) is amended by adding at the end the following new paragraphs: ‘‘(11) The results of an assessment, conducted biannually, on the efforts of the Center and the Department of Defense to develop or contribute to the development of standards for artificial intelligence, including— ‘‘(A) a description of such efforts; ‘‘(B) an evaluation of the need to incorporate standards for artificial intelligence into the strategies and doctrine of the Department and a description of any efforts undertaken to further the development and adoption of such standards; ‘‘(C) an explanation of any collaboration on artificial intelligence standards development with— ‘‘(i) other organizations and elements of the Department of Defense (including the Defense Agencies and the military departments); ‘‘(ii) agencies of the Federal Government; ‘‘(iii) the intelligence community; ‘‘(iv) representatives of the defense industrial base and other sectors of private industry; and ‘‘(v) any other agencies, entities, organizations, or persons the Secretary considers appropriate; and ‘‘(D) an explanation of any participation by the Center and the Department of Defense in international or other multi-stakeholder standard-setting bodies. ‘‘(12) For each member of",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Risk factors: Security, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Government study or report, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Strategies: Pilots and testbeds, Strategies: Convening, Strategies: New institution, Applications: Security, Applications: Business services and analytics, Applications: Education, Applications: Government: military and public safety"
140,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title I, Section 152 (""Transfer of responsibilities and functions relating to electromagnetic spectrum operations"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.7579,low,0.0,211,1.0,Enacted,"SEC. 152. TRANSFER OF RESPONSIBILITIES AND FUNCTIONS RELATING TO ELECTROMAGNETIC AND SPECTRUM OPERATIONS. (a) TRANSFER.—Not later than two years after the date of the enactment of this Act and in accordance with the plan developed pursuant to subsection (b), the Secretary of Defense shall transfer to an appropriate entity within the Department of Defense all the responsibilities and functions of the Commander of the United States Strategic Command that are germane to electromagnetic spectrum operations (EMSO), including— (1) advocacy for joint electronic warfare capabilities; (2) providing contingency electronic warfare support to other combatant commands; and (3) supporting combatant command joint training and planning related to electromagnetic spectrum operations. (b) PLAN FOR TRANSFER OF RESPONSIBILITIES.— (1) IN GENERAL.—Not later than 180 days before the date of the transfer of responsibilities required by subsection (a), the Secretary shall develop a plan to carry out the transfer. (2) CONSIDERATIONS.—In developing the plan required by paragraph (1), the Secretary shall consider the following: (A) All appropriate entities having potential for designation as the receiving electromagnetic spectrum operations organization, including elements of the Joint Staff, the functional and geographic combatant commands, Department of Defense offices and agencies, and other organizations, including the establishment of a new entity for that purpose within any such entity. (B) Whethe",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Evaluation, Strategies: Government study or report, Applications: Government: military and public safety"
141,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title II, Section 241 (""Measuring and incentivizing programming proficiency"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.967,low,0.0,211,1.0,Enacted,"SEC. 241. MEASURING AND INCENTIVIZING PROGRAMMING PROFICIENCY. (a) IN GENERAL.—Not later than two years after the date of the enactment of this Act, the Secretary of Defense shall carry out the following activities: (1) Leverage existing civilian software development and software architecture certification programs to implement coding language proficiency and artificial intelligence competency tests within the Department of Defense that— (A) measure an individual’s competency in using machine learning tools, in a manner similar to the way the Defense Language Proficiency Test measures competency in foreign language skills; (B) enable the identification of members of the Armed Forces and civilian employees of the Department of Defense who have varying levels of quantified coding comprehension and skills and a propensity to learn new programming paradigms, algorithms, and data analytics; and (C) include hands-on coding demonstrations and challenges. (2) Update existing recordkeeping systems to track artificial intelligence and programming certification testing results in a manner that is comparable to the system used for tracking and documenting foreign language competency, and use that recordkeeping system to ensure that workforce coding and artificial intelligence comprehension and skills are taken into consideration when making assignments. (3) Implement a system of rewards, including appropriate incentive pay and retention incentives, for members of the Armed Forces and civ",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Government support, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Applications: Education, Applications: Government: military and public safety"
142,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title II, Section 247 (""Pilot program on the use of electronic portfolios to evaluate certain applicants for technical positions"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.9463,low,0.0,227,1.0,Enacted,"SEC. 247. PILOT PROGRAM ON THE USE OF ELECTRONIC PORTFOLIOS TO EVALUATE CERTAIN APPLICANTS FOR TECHNICAL POSITIONS. (a) PILOT PROGRAM.—Beginning not later than one year after the date of the enactment of this Act, the Secretary of Defense shall carry out a pilot program under which certain applicants for technical positions within the Department of Defense will be evaluated, in part, based on electronic portfolios of the applicant’s work, as described in subsection (b). (b) ACTIVITIES.—Under the pilot program, the human resources manager of each organization of the Department of Defense participating in the program, in consultation with relevant subject matter experts, shall— (1) identify a subset of technical positions for which the evaluation of electronic portfolios would be appropriate as part of the hiring process; and (2) as appropriate, assess applicants for such positions by reviewing electronic portfolios of the applicants’ best work, as selected by the applicant concerned. (c) SCOPE OF PROGRAM.—The Secretary of Defense shall carry out the pilot program under subsection (a) in— (1) the Joint Artificial Intelligence Center; (2) the Defense Digital Service; (3) at least one activity of each military department, as identified by the Secretary of the department concerned; and (4) such other organizations and elements of the Department of Defense as the Secretary determines appropriate. (d) REPORT.—Not later than two years after the commencement of the pilot program under",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Evaluation, Strategies: Government study or report, Strategies: Pilots and testbeds, Applications: Government: military and public safety"
143,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title II, Section 248 (""Pilot program on self-directed training in advanced technologies"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.9806,low,0.0,230,1.0,Enacted,"SEC. 248. PILOT PROGRAM ON SELF-DIRECTED TRAINING IN ADVANCED TECHNOLOGIES. (a) ONLINE COURSES.—The Secretary of Defense shall carry out a pilot program under which the Secretary makes available a list of approved online courses relating to advanced technologies that may be taken by civilian employees of the Department of Defense and members of the Armed Forces on a voluntary basis while not engaged in the performance of their duties. (b) PROCEDURES.—The Secretary shall establish procedures for the development, selection, approval, adoption, and evaluation of online courses under subsection (a) to ensure that such courses are supportive of the goals of this section and overall goals for the training and education of the civilian and military workforce of the Department of Defense. (c) DOCUMENTATION OF COMPLETION.—The Secretary of Defense shall develop and implement a system— (1) to confirm whether a civilian employee of the Department of Defense or member of the Armed Forces has completed an online course approved by the Secretary under subsection (a); and (2) to document the completion of such course by such employee or member. (d) INCENTIVES.—The Secretary of Defense shall develop and implement incentives to encourage civilian employees of the Department of Defense and members of the Armed Forces to complete online courses approved by the Secretary under subsection (a). (e) METRICS.—The Secretary of Defense shall develop metrics to evaluate whether, and to what extent, the",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Government support, Strategies: Government support: AI workforce-related, Strategies: Pilots and testbeds, Applications: Government: military and public safety"
144,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title II, Section 249 (""Part-time and term employment of university faculty and students in the Defense science and technology enterprise"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.8816,low,0.0,226,1.0,Enacted,"SEC. 249. PART-TIME AND TERM EMPLOYMENT OF UNIVERSITY FACULTY AND STUDENTS IN THE DEFENSE SCIENCE AND TECHNOLOGY ENTERPRISE. (a) PROGRAM REQUIRED.—Not later than 180 days after the Deadline. date of the enactment of this Act, the Secretary of Defense shall establish a program under which opportunities for part-time and term employment are made available in the Defense science and technology enterprise for faculty and students of institutions of higher education for the purpose of enabling such faculty and students to carry out research projects in accordance with subsection (b). (b) RESEARCH PROJECTS.— (1) FACULTY.—A faculty member who is employed in position made available under subsection (a) shall, in the course of such employment, carry out a research project that— (A) relates to a topic in the field of science, technology, engineering, or mathematics; and (B) contributes to the objectives of the Department of Defense, as determined by the Secretary of Defense. (2) STUDENTS.—A student employed in position made available under subsection (a) shall assist a faculty member with a research project described in paragraph (1). (c) SELECTION OF PARTICIPANTS.—The Secretary of Defense, acting through the heads of participating organizations in the Defense science and technology enterprise, shall select individuals for participation in the program under subsection (a) as follows: (1) Faculty members shall be selected for participation on the basis of— (A) the academic credentials a",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Applications: Government: military and public safety"
145,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title II, Section 513 (""Grants to support STEM education in the Junior Reserve Officers’ Training Corps"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.9765,low,0.0,213,1.0,Enacted,"SEC. 513. GRANTS TO SUPPORT STEM EDUCATION IN THE JUNIOR RESERVE OFFICERS’ TRAINING CORPS. (a) PROGRAM AUTHORITY.— (1) IN GENERAL.—Chapter 102 of title 10, United States Code, is amended by adding at the end the following new section: ‘‘§ 2036. Grants to support science, technology, engineering, and mathematics education ‘‘(a) AUTHORITY.—The Secretary, in consultation with the Secretary of Education, may carry out a program to make grants to eligible entities to assist such entities in providing education in covered subjects to students in the Junior Reserve Officers’ Training Corps. ‘‘(b) COORDINATION.—In carrying out a program under subsection (a), the Secretary may coordinate with the following: ‘‘(1) The Director of the National Science Foundation. ‘‘(2) The Administrator of the National Aeronautics and Space Administration. ‘‘(3) The heads of such other Federal, State, and local government entities the Secretary of Defense determines to be appropriate. ‘‘(c) ACTIVITIES.—Activities funded with grants under this section may include the following: ‘‘(1) Training and other support for instructors to teach courses in covered subjects to students. ‘‘(2) The acquisition of materials, hardware, and software necessary for the instruction of covered subjects. ‘‘(3) Activities that improve the quality of educational materials, training opportunities, and curricula available to students and instructors in covered subjects. ‘‘(4) Development of travel opportunities, demonstrations, m",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Government support, Strategies: Government support: AI workforce-related, Applications: Education"
146,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title XI, Section 1102 (""Enhancement of public-private talent exchange programs in the Department of Defense"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.983,low,0.0,234,1.0,Enacted,"SEC. 1102. ENHANCEMENT OF PUBLIC-PRIVATE TALENT EXCHANGE PROGRAMS IN THE DEPARTMENT OF DEFENSE. (a) PUBLIC-PRIVATE TALENT EXCHANGE.—Section 1599g of title 10, United States Code, is amended— (1) in subsection (b)(1), by amending subparagraph (C) to read as follows: ‘‘(C) shall contain language ensuring that such employee of the Department does not improperly use information that such employee knows relates to a Department acquisition or procurement for the benefit or advantage of the private-sector organization.’’; and (2) by amending paragraph (4) of subsection (f) to read as follows: ‘‘(4) may not perform work that is considered inherently governmental in nature; and’’. (b) APPLICATION OF EXCHANGE AUTHORITY TO MODERNIZATION PRIORITIES.—Not later than 90 days after the date of the enactment of this Act, the Secretary of Defense shall take steps to ensure that the authority of the Secretary to carry out a public-private talent exchange program under section 1599g of title 10, United States Code (as amended by subsection (a)), is used to— (1) carry out exchanges of personnel with private sector entities that are working on the modernization priorities of the Department of Defense; and (2) carry out exchanges in— (A) the office of the Under Secretary of Defense for Research and Engineering; (B) the office of the Chief Information Officer of the Department of Defense; (C) each Armed Force under the jurisdiction of the Secretary of a military department; and (D) any other organiz",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Government support: AI workforce-related, Applications: Government: military and public safety"
147,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title XV, Section 6505 (""GAO studies on trafficking"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,negative,-0.9526,low,0.0,209,1.0,Enacted,"SEC. 6505. GAO STUDIES ON TRAFFICKING. (a) DEFINITION OF HUMAN TRAFFICKING.—In this section, the term ‘‘human trafficking’’ has the meaning given the term ‘‘severe forms of trafficking in persons’’ in section 103 of the Trafficking Victims Protection Act of 2000 (22 U.S.C. 7102). (b) GAO STUDY AND REPORT ON STOPPING TRAFFICKING, ILLICIT FLOWS, LAUNDERING, AND EXPLOITATION.— (1) STUDY.—The Comptroller General of the United States shall carry out a study, in consultation with law enforcement, relevant Federal agencies, appropriate private sector stakeholders (including financial institutions and data and technology companies), academic and other research organizations (including survivor and victim advocacy organizations), and any other group that the Comptroller General determines is appropriate on— (A) the major trafficking routes used by transnational criminal organizations, terrorists, and others, and to what extent the trafficking routes for people (including children), drugs, weapons, cash, child sexual exploitation materials, or other illicit goods are similar, related, or contiguous; (B) commonly used methods to launder and move the proceeds of trafficking; (C) the types of suspicious financial activity that are associated with illicit trafficking networks, and how financial institutions identify and report such activity; (D) the nexus between the identities and finances of trafficked persons and fraud; (E) the tools, guidance, training, partnerships, supervision, or ot",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Government study or report, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Applications: Security, Applications: Government: military and public safety"
148,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title XCII, Section 9203 (""Spectrum information technology modernization efforts"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.9833,low,0.1667,202,1.0,Enacted,"SEC. 9203. SPECTRUM INFORMATION TECHNOLOGY MODERNIZATION EFFORTS. (a) INITIAL INTERAGENCY SPECTRUM INFORMATION TECHNOLOGY COORDINATION.—Not later than 90 days after the date of the enactment of this Act, the Assistant Secretary of Commerce for Communications and Information, in consultation with the Policy and Plans Steering Group, shall identify a process to establish goals, including parameters to measure the achievement of such goals, for the modernization of the infrastructure of covered agencies relating to managing the use of Federal spectrum by such agencies, which shall include— (1) the standardization of data inputs, modeling algorithms, modeling and simulation processes, analysis tools with respect to Federal spectrum, assumptions, and any other tool to ensure interoperability and functionality with respect to such infrastructure; (2) other potential innovative technological capabilities with respect to such infrastructure, including cloud-based databases, artificial intelligence technologies, automation, and improved modeling and simulation capabilities; (3) ways to improve the management of the use of Federal spectrum by covered agencies through such infrastructure, including by— (A) increasing the efficiency of such infrastructure; (B) addressing validation of usage with respect to such infrastructure; (C) increasing the accuracy of such infrastructure; (D) validating models used by such infrastructure; and (E) monitoring and enforcing requirements that are impos",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Risk factors: Reliability, Risk factors: Security, Risk factors: Security: Dissemination, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure: In deployment, Strategies: Disclosure: Accuracy thereof, Strategies: Convening, Strategies: Governance development, Applications: Manufacturing and process automation, Applications: Construction and field services, Applications: Security"
149,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title XC, Section 9004 (""Department of Homeland Security reports on digital content forgery technology"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.2342,low,0.1111,224,1.0,Enacted,"SEC. 9004. DEPARTMENT OF HOMELAND SECURITY REPORTS ON DIGITAL CONTENT FORGERY TECHNOLOGY. (a) REPORTS REQUIRED.—Not later than one year after the Time period. date of enactment of this Act, and annually thereafter for 5 years, Consultation. the Secretary of Homeland Security, acting through the Under Secretary for Science and Technology of the Department of Homeland Security, and with respect to paragraphs (6) and (7) of subsection (b), in consultation with the Director of National Intelligence, shall submit to Congress a report on the state of digital content forgery technology. (b) CONTENTS.—Each report produced under subsection (a) shall include the following: (1) An assessment of the underlying technologies used to create or propagate digital content forgeries, including the evolution of such technologies and patterns of dissemination of such technologies. (2) A description of the types of digital content forgeries, including those used to commit fraud, cause harm, harass, coerce, or silence vulnerable groups or individuals, or violate civil rights recognized under Federal law. (3) An assessment of how foreign governments, and the proxies and networks thereof, use, or could use, digital content forgeries to harm national security. (4) An assessment of how non-governmental entities in the United States use, or could use, digital content forgeries. (5) An assessment of the uses, applications, dangers, and benefits, including the impact on individuals, of deep learning or di",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content, Strategies: Government study or report, Strategies: Convening"
150,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title XCIV, Section 9412 (""Industries of the future"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2021-01-01,2021,1,positive,0.948,low,0.0,225,0.7,Enacted,"SEC. 9412. INDUSTRIES OF THE FUTURE. (a) SHORT TITLE.—This section may be cited as the ‘‘Industries of the Future Act of 2020’’. (b) REPORT ON FEDERAL RESEARCH AND DEVELOPMENT FOCUSED ON INDUSTRIES OF THE FUTURE.— (1) IN GENERAL.—Not later than 120 days after the date of the enactment of this Act, the Director of the Office of Science and Technology Policy shall submit to Congress a report on research and development investments, infrastructure, and workforce development investments of the Federal Government that enable continued United States leadership in industries of the future. (2) CONTENTS.—The report submitted under paragraph (1) shall include the following: (A) A definition, for purposes of this section, of the term ‘‘industries of the future’’ that includes emerging technologies. (B) An assessment of the current baseline of investments in civilian research and development investments of the Federal Government in the industries of the future. (C) A plan to double such baseline investments in artificial intelligence and quantum information science by fiscal year 2022. (D) A detailed plan to increase investments described in subparagraph (B) in industries of the future to $10,000,000,000 per year by fiscal year 2025. (E) A plan to leverage investments described in subparagraphs (B), (C), and (D) in industries of the future to elicit complimentary investments by non-Federal entities, including providing incentives for significant complementary investments by such entitie",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Government support, Strategies: Government support: For R&D, Applications: Government: military and public safety, Applications: Government: judicial and law enforcement"
151,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title XCIV, Section 9414 (""Study on Chinese policies and influence in the development of international standards for emerging technologies"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.9643,low,0.0,222,1.0,Enacted,"SEC. 9414. STUDY ON CHINESE POLICIES AND INFLUENCE IN THE DEVELOPMENT OF INTERNATIONAL STANDARDS FOR EMERGING TECHNOLOGIES. (a) STUDY.—Not later than 180 days after the date of the enactment of this Act, the Director of the National Institute of Standards and Technology shall enter into an agreement with an appropriate entity with relevant expertise, as determined by the Director, to conduct a study and make recommendations with respect to the effect of the policies of the People’s Republic of China and coordination among industrial entities within the Peo.ple’s Republic of China on international bodies engaged in developing and setting international standards for emerging technologies. The study may include— (1) an assessment of how the role of the People’s Republic of China in international standards setting organizations has grown over the previous 10 years, including in leadership roles in standards-drafting technical committees, and the quality or value of that participation; (2) an assessment of the effect of the standardization strategy of the People’s Republic of China, as identified in the ‘‘Chinese Standard 2035’’, on international bodies engaged in developing and setting standards for select emerging technologies, such as advanced communication technologies or cloud computing and cloud services; (3) an examination of whether international standards for select emerging technologies are being designed to promote interests of the People’s Republic of China that are ex",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Evaluation, Strategies: Government study or report, Strategies: Governance development"
152,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title V, Section 589F (""Study on cyberexploitation and online deception of members of the Armed Forces and their families"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,negative,-0.9488,low,0.1111,225,1.0,Enacted,"SEC. 589F. STUDY ON CYBEREXPLOITATION AND ONLINE DECEPTION OF MEMBERS OF THE ARMED FORCES AND THEIR FAMILIES. (a) STUDY.—Not later than 150 days after the date of the enactment of this Act, the Secretary of Defense shall complete a study on— (1) the cyberexploitation of the personal information and accounts of members of the Armed Forces and their families; and (2) the risks of deceptive online targeting of members and their families. (b) ELEMENTS.—The study under subsection (a) shall include the following: (1) An assessment of predatory loans, other financial products, or educational products being targeted to members of the Armed Forces and their families. (2) An assessment of unproven or unnecessary medical treatments or procedures being targeted to members and their families. (3) An assessment of ethnic or racial violent extremism messages targeting members and their families. (4) An assessment of the ways in which social media algorithms may amplify the targeting described in paragraphs (1) through (3). (5) An intelligence assessment of the threat currently posed by foreign government and non-state actors carrying out the cyberexploitation of members and their families, including generalized assessments as to— (A) whether such cyberexploitation is a substantial threat as compared to other means of information warfare; and (B) whether such cyberexploitation is an increasing threat. (6) A case-study analysis of three known occurrences of attempted cyberexploitation against",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content, Strategies: Government study or report, Strategies: Governance development, Applications: Government: military and public safety"
153,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title I, Section 164 (""Acceleration of development and fielding of counter unmanned aircraft systems across the joint force"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,neutral,0.0077,low,0.0,222,1.0,Enacted,"SEC. 164. ACCELERATION OF DEVELOPMENT AND FIELDING OF COUNTER UNMANNED AIRCRAFT SYSTEMS ACROSS THE JOINT FORCE. (a) IMMEDIATE OBJECTIVE FOR EXECUTIVE AGENT FOR C– SUAS.—The Executive Agent of the Joint Counter Small Unmanned Aircraft Systems (C–sUAS) Office, as designated by the Under Secretary of Defense for Acquisition and Sustainment, shall prioritize the objective of developing and executing a plan to develop, test, and begin production of a counter unmanned aircraft system that can be fielded as early as fiscal year 2021 to meet immediate operational needs in countering Group 1, 2, and 3 unmanned aircraft systems and, to the extent practical, has the potential to counter other, larger unmanned aircraft systems. (b) DEVELOPMENT AND FIELDING OF C–SUAS SYSTEMS IN FISCAL YEAR 2021.—In carrying out subsection (a), the Executive Agent shall consider the selection of counter unmanned aircraft systems with specific emphasis on systems that— (1) have undergone successful realistic operational tests or assessments, or have been or are currently deployed; (2) will meet the operational requirements of deployed forces facing current and anticipated unmanned aircraft system (UAS) threats, including effectiveness against unmanned aircraft systems that are not remotely piloted or are not reliant on a command link; (3) use autonomous and semi-autonomous systems and processes; (4) are affordable, with low operating and sustainment costs; (5) build, to the extent practicable, upon systems",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Government study or report, Strategies: Performance requirements, Applications: Government: military and public safety"
155,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title II, Section 218 (""Executive agent for autonomy"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.4215,low,0.0,118,1.0,Enacted,"SEC. 218. EXECUTIVE AGENT FOR AUTONOMY. (a) IN GENERAL.—Not later than February 1, 2022, the Secretary of the Navy shall designate an existing program executive officer from within the Department of the Navy to serve as the acquisition executive agent for autonomy who shall be the official within the Department with primary responsibility for the acquisition of autonomous technology. The officer designated as acquisition executive agent for autonomy shall carry out the responsibilities of such position in addition to the responsibilities otherwise assigned to such officer as a program executive officer. (b) PROGRAM EXECUTIVE OFFICER DEFINED.—In this section, the term ‘‘program executive officer’’ has the meaning given that term in section 1737(a)(4) of title 10, United States Code.",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,Applications: Government: military and public safety
157,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title II, Section 227 (""Limitation on contract awards for certain unmanned vessels"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.8941,low,0.0,229,1.0,Enacted,"SEC. 227. LIMITATION ON CONTRACT AWARDS FOR CERTAIN UNMANNED VESSELS. (a) LIMITATION.—Not less than 30 days before awarding a contract using any funds from the Research, Development, Test, and Evaluation, Navy account for the purchase of a covered vessel, the Secretary of the Navy shall submit to the congressional defense committees a report and certification described in subsection (c) for such contract and covered vessel. (b) COVERED VESSELS.—For purposes of this section, a covered vessel is one of the following: (1) A large unmanned surface vessel (LUSV). (2) A medium unmanned surface vehicle (MUSV). (c) REPORT AND CERTIFICATION DESCRIBED.—A report and certification described in this subsection regarding a contract for a covered vessel is— (1) a report— (A) submitted to the congressional defense committees not later than 60 days after the date of the completion of an independent technical risk assessment for such covered vessel; (B) on the findings and recommendations of the Senior Technical Authority for the class of naval vessels that includes the covered vessel with respect to such assessment; and (C) that includes such assessment; and (2) a certification, submitted to the congressional defense committees with the report described in paragraph (1), that certifies that— (A) the Secretary has determined, in conjunction with the Senior Technical Authority for the class of naval vessels that includes the covered vessel, that the critical mission, hull, mechanical, and elect",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Government study or report, Strategies: Performance requirements, Applications: Government: military and public safety"
158,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title XVI, Section 1601 (""Space Development Agency development requirements and transfer to Space Force"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.9423,low,0.0,221,1.0,Enacted,"SEC. 1601. SPACE DEVELOPMENT AGENCY DEVELOPMENT REQUIREMENTS AND TRANSFER TO SPACE FORCE. (a) IN GENERAL.—Chapter 908 of title 10, United States Code, is amended by adding at the end the following new section: ‘‘§ 9084. Space Development Agency 10 USC 9084. ‘‘(a) IN GENERAL.— (1) There is a Space Development Agency of the Department of Defense (in this section referred to as the ‘Agency’). The Director of the Space Development Agency shall be the head of the Agency. ‘‘(2) Effective on October 1, 2022— ‘‘(A) the Agency shall be an element of the Space Force; and ‘‘(B) the Director shall report— ‘‘(i) pursuant to section 9016(b)(6)(B)(iv)(III) of this title, to the Assistant Secretary of the Air Force for Space Acquisition and Integration with respect to acquisition decisions; and ‘‘(ii) directly to the Chief of Space Operations with respect to requirements decisions, personnel decisions, and any other matter not covered by clause (i).‘‘(b) DEVELOPMENT AND INTEGRATION AUTHORITIES.—The Director shall lead— ‘(1) the development and demonstration of a resilient military space-based sensing, tracking, and data transport architecture that uses proliferated low-Earth orbit systems and services; ‘‘(2) the integration of next-generation space capabilities, such as novel sensors (including with respect to alternate navigation, and autonomous battle management features), and sensor and tracking components (including a hypersonic and ballistic missile tracking space sensor payload pursuan",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Government support, Strategies: Government support: For R&D, Strategies: New institution, Applications: Government: military and public safety"
159,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title XXXV, Section 3521 (""Maritime security and domain awareness"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.9737,low,0.0,230,1.0,Enacted,"SEC. 3521. MARITIME SECURITY AND DOMAIN AWARENESS. (a) PROGRESS REPORT ON MARITIME SECURITY.— (1) IN GENERAL.—Not later than 180 days after the date of the enactment of this Act, the Secretary of Defense, in coordination with the Secretary of State, the Secretary of the Department in which the Coast Guard is operating, and the heads of other appropriate Federal agencies, shall submit to the congressional defense committees, the Committee on Foreign Affairs of the House of Representatives, and the Committee on Foreign Relations of the Senate a report on the steps taken since December 20, 2019, to make further use of the following mechanisms to combat IUU fishing: (A) Inclusion of counter-IUU fishing in existing shiprider agreements to which the United States is a party. (B) Entry into shiprider agreements that include counter-IUU fishing with priority flag states and countries in priority regions with which the United States does not already have such agreements. (C) Inclusion of counter-IUU fishing in the mission of the Combined Maritime Forces. (D) Inclusion of counter-IUU fishing exercises in the annual at-sea exercises conducted by the Department of Defense, in coordination with the United States Coast Guard. (E) Development of partnerships similar to the Oceania Maritime Security Initiative and the Africa Maritime Law Enforcement Partnership in other priority regions. (2) ELEMENT.—The report required by paragraph (1) shall include a description of specific steps taken by",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Government study or report, Strategies: Convening, Applications: Government: military and public safety, Applications: Government: judicial and law enforcement"
160,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title LVXXXIV, Section 8411 (""Unmanned maritime systems and satellite vessel tracking technologies"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,negative,-0.5719,low,0.0,222,1.0,Enacted,"SEC. 8411. UNMANNED MARITIME SYSTEMS AND SATELLITE VESSEL TRACKING TECHNOLOGIES. (a) ASSESSMENT.—The Commandant, acting through the Blue Technology Center of Expertise, shall regularly assess available unmanned maritime systems and satellite vessel tracking technologies for potential use to support missions of the Coast Guard. (b) REPORT.— (1) IN GENERAL.—Not later than 1 year after the date of the enactment of this Act, and biennially thereafter, the Commandant shall submit to the Committee on Transportation and Infrastructure of the House of Representatives and the Committee on Commerce, Science, and Transportation of the Senate a report on the actual and potential effects of the use of then-existing unmanned maritime systems and satellite vessel tracking technologies on the mission effectiveness of the Coast Guard. (2) CONTENTS.—Each report submitted under paragraph (1) shall include the following: (A) An inventory of current unmanned maritime systems used by the Coast Guard, an overview of such usage, and a discussion of the mission effectiveness of such systems, including any benefits realized or risks or negative aspects of such usage. (B) An inventory of satellite vessel tracking technologies, and a discussion of the potential mission effectiveness of such technologies, including any benefits or risks or negative aspects of such usage. (C) A prioritized list of Coast Guard mission requirements that could be met with additional unmanned maritime systems, or with satelli",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Government study or report, Applications: Transportation, Applications: Government: military and public safety"
161,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title XCIV, Section 9407 (""National cybersecurity challenges"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.9718,low,0.0,197,1.0,Enacted,"SEC. 9407. NATIONAL CYBERSECURITY CHALLENGES. (a) IN GENERAL.—Title II of the Cybersecurity Enhancement Act of 2014 (15 U.S.C. 7431 et seq.) is amended by adding at the end the following: ‘‘SEC. 205. NATIONAL CYBERSECURITY CHALLENGES. ‘‘(a) ESTABLISHMENT OF NATIONAL CYBERSECURITY CHALLENGES.— ‘‘(1) IN GENERAL.—To achieve high-priority breakthroughs in cybersecurity by 2028, the Secretary of Commerce shall establish the following national cybersecurity challenges: ‘‘(A) ECONOMICS OF A CYBER ATTACK.—Building more resilient systems that measurably and exponentially raise adversary costs of carrying out common cyber attacks. ‘‘(B) CYBER TRAINING.— ‘‘(i) Empowering the people of the United States with an appropriate and measurably sufficient level of digital literacy to make safe and secure decisions online. ‘‘(ii) Developing a cybersecurity workforce with measurable skills to protect and maintain information systems. ‘‘(C) EMERGING TECHNOLOGY.—Advancing cybersecurity efforts in response to emerging technology, such as artificial intelligence, quantum science, next generation communications, autonomy, data science, and computational technologies. ‘‘(D) REIMAGINING DIGITAL IDENTITY.—Maintaining a high sense of usability while improving the privacy, security, and safety of online activity of individuals in the United States. ‘‘(E) FEDERAL AGENCY RESILIENCE.—Reducing cybersecurity risks to Federal networks and systems, and improving the response of Federal agencies to cybersecurity i",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Evaluation, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Strategies: Convening, Strategies: Governance development, Strategies: New institution, Applications: Government: other applications/unspecified"
162,"Infrastructure Investment and Jobs Act, Section 11401 (""Grants for Charging and Fueling Infrastructure"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-12-29,2022,12,positive,0.977,low,0.0,210,1.0,Enacted,"SEC. 11401. GRANTS FOR CHARGING AND FUELING INFRASTRUCTURE. (a) Purpose.--The purpose of this section is to establish a grant program to strategically deploy publicly accessible electric vehicle charging infrastructure, hydrogen fueling infrastructure, propane fueling infrastructure, and natural gas fueling infrastructure along designated alternative fuel corridors or in certain other locations that will be accessible to all drivers of electric vehicles, hydrogen vehicles, propane vehicles, and natural gas vehicles. (b) Grant Program.--Section 151 of title 23, United States Code, is amended-- (1) in subsection (a)-- (A) by striking Not later than 1 year after the date of enactment of the FAST Act, the Secretary shall'' and inserting The Secretary shall periodically''; and (B) by striking to improve the mobility'' and inserting to support changes in the transportation sector that help achieve a reduction in greenhouse gas emissions and improve the mobility''; (2) in subsection (b)(2), by inserting previously designated by the Federal Highway Administration or'' before designated by''; (3) by striking subsection (d) and inserting the following: ``(d) Redesignation.-- ``(1) Initial redesignation.--Not later than 180 days after the date of enactment of the Surface Transportation Reauthorization Act of 2021, the Secretary shall update and redesignate the corridors under subsection (a). ``(2) Subsequent redesignation.--The Secretary shall establish a recurring process to regularly",https://www.congress.gov/bill/117th-congress/house-bill/3684/text?s=1&r=12&q=%7B%22search%22%3A%5B%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%5D%7D,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Applications: Transportation"
163,"Infrastructure Investment and Jobs Act, Section 13005 (""Emerging Technology Research Pilot Program"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-12-29,2022,12,positive,0.9545,low,0.0556,200,1.0,Enacted,"SEC. 13005. EMERGING TECHNOLOGY RESEARCH PILOT PROGRAM. (a) Establishment.--The Secretary shall establish a pilot program to conduct emerging technology research in accordance with this section. (b) Activities.--The pilot program under this section shall include-- (1) research and development activities relating to leveraging advanced and additive manufacturing technologies to increase the structural integrity and cost-effectiveness of surface transportation infrastructure; and (2) research and development activities (including laboratory and test track supported accelerated pavement testing research regarding the impacts of connected, autonomous, and platooned vehicles on pavement and infrastructure performance)-- (A) to reduce the impact of automated and connected driving systems and advanced driver-assistance systems on pavement and infrastructure performance; and (B) to improve transportation infrastructure design in anticipation of increased usage of automated driving systems and advanced driver-assistance systems. (c) Treatment.--Except as otherwise provided in this section, the Secretary shall carry out activities under the pilot program under this section as if-- (1) those activities were authorized under chapter 5 of title 23, United States Code; and (2) the funds made available to carry out the pilot program were made available under that chapter. (d) Authorization of Appropriations.--There is authorized to be appropriated to carry out this section $5,000,000 for ea",https://www.congress.gov/bill/117th-congress/house-bill/3684/text?s=1&r=12&q=%7B%22search%22%3A%5B%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%5D%7D,en,"Harms: Harm to infrastructure, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Pilots and testbeds, Applications: Transportation, Applications: Manufacturing and process automation"
164,"Infrastructure Investment and Jobs Act, Section 25005 (""Strengthening Mobility and Revolutionizing Transportation Grant Program"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-12-29,2022,12,positive,0.9827,low,0.1111,226,1.0,Enacted,"SEC. 25005. STRENGTHENING MOBILITY AND REVOLUTIONIZING TRANSPORTATION GRANT PROGRAM. (a) Definitions.--In this section: (1) Eligible entity.--The term ``eligible entity'' means-- (A) a State; (B) a political subdivision of a State; (C) a Tribal government; (D) a public transit agency or authority; (E) a public toll authority; (F) a metropolitan planning organization; and (G) a group of 2 or more eligible entities described in any of subparagraphs (A) through (F) applying through a single lead applicant. (2) Eligible project.--The term ``eligible project'' means a project described in subsection (e). (3) Large community.--The term ``large community'' means a community with a population of not less than 400,000 individuals, as determined under the most recent annual estimate of the Bureau of the Census. (4) Midsized community.--The term ``midsized community'' means any community that is not a large community or a rural community. (5) Regional partnership.--The term ``regional partnership'' means a partnership composed of 2 or more eligible entities located in jurisdictions with a combined population that is equal to or greater than the population of any midsized community. (6) Rural community.--The term ``rural community'' means a community that is located in an area that is outside of an urbanized area (as defined in section 5302 of title 49, United States Code). (7) SMART grant.--The term ``SMART grant'' means a grant provided to an eligible entity under the Strengthening Mob",https://www.congress.gov/bill/117th-congress/house-bill/3684/text?s=1&r=12&q=%7B%22search%22%3A%5B%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%5D%7D,en,"Risk factors: Security, Risk factors: Security: Cybersecurity, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Performance requirements, Applications: Transportation"
165,"Infrastructure Investment and Jobs Act, Section 25017 (""University Transportation Centers Program"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2022-12-29,2022,12,positive,0.5994,low,0.1667,225,1.0,Enacted,"SEC. 25017. UNIVERSITY TRANSPORTATION CENTERS PROGRAM. Section 5505 of title 49, United States Code, is amended-- (1) in subsection (a)-- (A) in paragraph (1), by inserting of Transportation, acting through the Assistant Secretary for Research and Technology (referred to in this section as the `Secretary'),'' after The Secretary''; and (B) in paragraph (2)-- (i) in subparagraph (B), by inserting multimodal'' after critical''; and (ii) in subparagraph (C), by inserting with respect to the matters described in subparagraphs (A) through (G) of section 6503(c)(1)'' after transportation leaders''; (2) in subsection (b)-- (A) in paragraph (2)(A), by striking for each of the transportation centers described under paragraphs (2), (3), and (4) of subsection (c)'' and inserting as a lead institution under this section, except as provided in subparagraph (B)''; (B) in paragraph (4)-- (i) in subparagraph (A), by striking identified in chapter 65'' and inserting described in subparagraphs (A) through (G) of section 6503(c)(1)''; and (ii) in subparagraph (B), in the matter preceding clause (i), by striking the Assistant Secretary'' and all that follows through modal administrations'' and inserting ``the heads of the modal administrations of the Department of Transportation,''; and (C) in paragraph (5)(B), in the matter preceding clause (i), by striking submit'' and all that follows through of the Senate'' and inserting ``make available to the public on a website of the Department of Transp",https://www.congress.gov/bill/117th-congress/house-bill/3684/text?s=1&r=12&q=%7B%22search%22%3A%5B%22%5C%22artificial+intelligence%5C%22+OR+%5C%22machine+learning%5C%22+OR+%5C%22algorithm%5C%22%22%5D%7D,en,"Risk factors: Security, Risk factors: Security: Cybersecurity, Harms: Harm to infrastructure, Strategies: Evaluation, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Applications: Transportation"
168,Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence,"Copyright Office, Library of Congress",United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2023-03-16,2023,3,positive,0.8807,low,0.0,208,1.0,Enacted,"AGENCY: U.S. Copyright Office, Library of Congress. ACTION: Statement of policy. SUMMARY: The Copyright Office issues this statement of policy to clarify its practices for examining and registering works that contain material generated by the use of artificial intelligence technology. DATES: This statement of policy is effective March 16, 2023. FOR FURTHER INFORMATION CONTACT: Rhea Efthimiadis, Assistant to the General Counsel, by email at meft@copyright.gov or telephone at 202-707-8350. SUPPLEMENTARY INFORMATION: I. Background The Copyright Office (the “Office”) is the Federal agency tasked with administering the copyright registration system, as well as advising Congress, other agencies, and the Federal judiciary on copyright and related matters.[1] Because the Office has overseen copyright registration since its origins in 1870, it has developed substantial experience and expertise regarding “the distinction between copyrightable and noncopyrightable works.” [2] The Office is empowered by the Copyright Act to establish the application used by applicants seeking registration of their copyrighted works.[3] While the Act identifies certain minimum requirements, the Register may determine that additional information is necessary for the Office to evaluate the “existence, ownership, or duration of the copyright.” [4] Because the Office receives roughly half a million applications for registration each year, it sees new trends in registration activity that may require modifying",https://www.govinfo.gov/content/pkg/FR-2023-03-16/pdf/2023-05321.pdf,en,"Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Performance requirements, Strategies: Licensing, registration, and certification, Applications: Arts, sports, leisure, travel, and lifestyle"
169,"21 CFR § 864.3750 (""Software algorithm device to assist users in digital pathology"")",Food and Drug Administration,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2023-02-02,2023,2,positive,0.8225,low,0.3333,231,1.0,Enacted,"§ 864.3750 Software algorithm device to assist users in digital pathology. (a) Identification. A software algorithm device to assist users in digital pathology is an in vitro diagnostic device intended to evaluate acquired scanned pathology whole slide images. The device uses software algorithms to provide information to the user about presence, location, and characteristics of areas of the image with clinical implications. Information from this device is intended to assist the user in determining a pathology diagnosis. (b) Classification. Class II (special controls). The special controls for this device are: (1) The intended use on the device's label and labeling required under § 809.10 of this chapter must include: (i) Specimen type; (ii) Information on the device input(s) (e.g., scanned whole slide images (WSI), etc.); (iii) Information on the device output(s) (e.g., format of the information provided by the device to the user that can be used to evaluate the WSI, etc.); (iv) Intended users; (v) Necessary input/output devices (e.g., WSI scanners, viewing software, etc.); (vi) A limiting statement that addresses use of the device as an adjunct; and (vii) A limiting statement that users should use the device in conjunction with complete standard of care evaluation of the WSI. (2) The labeling required under § 809.10(b) of this chapter must include: (i) A detailed description of the device, including the following: (A) Detailed descriptions of the software device, including t",https://www.federalregister.gov/documents/2023/02/02/2023-02141/medical-devices-hematology-and-pathology-devices-classification-of-the-software-algorithm-device-to,en,"Risk factors: Reliability, Risk factors: Safety, Risk factors: Security, Risk factors: Security: Cybersecurity, Risk factors: Transparency, Harms: Harm to health/safety, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Performance requirements, Strategies: Licensing, registration, and certification, Applications: Medicine, life sciences and public health"
170,"21 CFR § 870.2785 (""Software for optical camera-based measurement of pulse rate, heart rate, breathing rate, and/or respiratory rate"")",Food and Drug Administration,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2023-01-31,2023,1,positive,0.9313,medium,0.3889,208,1.0,Enacted,"§ 870.2785 Software for optical camera-based measurement of pulse rate, heart rate, breathing rate, and/or respiratory rate. (a) Identification. The device uses software algorithms to analyze video signal and estimate pulse rate, heart rate, breathing rate, and/or respiratory rate. This device is not intended to independently direct therapy. (b) Classification. Class II (special controls). The special controls for this device are: (1) A software description and the results of verification and validation testing based on a comprehensive hazard analysis and risk assessment must include: (i) A full characterization of the software technical parameters, including algorithms; (ii) If required image acquisition hardware is not included with the device, full specifications of the hardware requirements and testing to demonstrate the specified hardware ensures adequate data for validated and accurate measurements; (iii) A description of the expected impact of all applicable sensor acquisition hardware characteristics and associated hardware specifications; (iv) A description of all mitigations for user error or failure of any subsystem components (including signal detection, signal analysis, data display, and storage) on output accuracy; and (v) Software documentation must include a cybersecurity vulnerability and management process to assure software functionality. (2) Clinical data must be provided. This assessment must fulfill the following: (i) The clinical data must be representa",https://www.federalregister.gov/documents/2023/01/31/2023-01967/medical-devices-cardiovascular-devices-classification-of-the-software-for-optical-camera-based,en,"Risk factors: Reliability, Risk factors: Interpretability and explainability, Risk factors: Safety, Risk factors: Security, Risk factors: Security: Cybersecurity, Risk factors: Transparency, Harms: Harm to health/safety, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Performance requirements, Strategies: Licensing, registration, and certification, Applications: Medicine, life sciences and public health"
173,"21 CFR § 882.1491 (""Pediatric Autism Spectrum Disorder diagnosis aid"")",Food and Drug Administration,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2022-12-30,2022,12,negative,-0.2263,low,0.3333,208,1.0,Enacted,"§ 882.1491 Pediatric Autism Spectrum Disorder diagnosis aid. (a) Identification. A pediatric Autism Spectrum Disorder diagnosis aid is a prescription device that is intended for use as an aid in the diagnosis of Autism Spectrum Disorder in pediatric patients. (b) Classification. Class II (special controls). The special controls for this device are: (1) Clinical performance testing must demonstrate that the device performs as intended under anticipated conditions of use, including an evaluation of sensitivity, specificity, positive predictive value, and negative predictive value using a reference method of diagnosis and assessment of patient behavioral symptomology. (2) Software verification, validation, and hazard analysis must be provided. Software documentation must include a detailed, technical description of the algorithm(s) used to generate device output(s), and a cybersecurity assessment of the impact of threats and vulnerabilities on device functionality and user(s). (3) Usability assessment must demonstrate that the intended user(s) can safely and correctly use the device. (4) Labeling must include: (i) Instructions for use, including a detailed description of the device, compatibility information, and information to facilitate clinical interpretation of all device outputs; and (ii) A summary of any clinical testing conducted to demonstrate how the device functions as an interpretation of patient behavioral symptomology associated with Autism Spectrum Disorder. The su",https://www.federalregister.gov/documents/2022/12/30/2022-28430/medical-devices-neurological-devices-classification-of-the-pediatric-autism-spectrum-disorder,en,"Risk factors: Reliability, Risk factors: Interpretability and explainability, Risk factors: Security, Risk factors: Security: Cybersecurity, Risk factors: Transparency, Harms: Harm to health/safety, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Performance requirements, Strategies: Licensing, registration, and certification, Applications: Medicine, life sciences and public health"
174,"21 CFR § 864.3750 (""Adjunctive hemodynamic indicator with decision point"")",Food and Drug Administration,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2022-12-27,2022,12,positive,0.9042,low,0.2222,198,1.0,Enacted,"§ 870.2220 Adjunctive hemodynamic indicator with decision point. (a) Identification. An adjunctive hemodynamic indicator with decision point is a device that identifies and monitors hemodynamic condition(s) of interest and provides notifications at a clinically meaningful decision point. This device is intended to be used adjunctively along with other monitoring and patient information. (b) Classification. Class II (special controls). The special controls for this device are: (1) Software description, verification, and validation based on comprehensive hazard analysis and risk assessment must be provided, including: (i) Full characterization of technical parameters of the software, including algorithm(s); (ii) Description of the expected impact of all applicable sensor acquisition hardware characteristics on performance and any associated hardware specifications; (iii) Specification of acceptable incoming sensor data quality control measures; (iv) Mitigation of impact of user error or failure of any subsystem components (signal detection and analysis, data display, and storage) on output accuracy; and (v) The sensitivity, specificity, positive predictive value, and negative predictive value in both percentage and number form for clinically meaningful pre-specified time windows consistent with the device output. (2) Scientific justification for the validity of the hemodynamic indicator algorithm(s) must be provided. Verification of algorithm calculations and validation testing",https://www.federalregister.gov/documents/2022/12/27/2022-28131/medical-devices-cardiovascular-devices-classification-of-the-adjunctive-hemodynamic-indicator-with,en,"Risk factors: Reliability, Risk factors: Interpretability and explainability, Risk factors: Safety, Harms: Harm to health/safety, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Disclosure: Accuracy thereof, Strategies: Performance requirements, Applications: Medicine, life sciences and public health"
175,Limited Applicability of Consumer Financial Protection Act's “Time or Space” Exception With Respect to Digital Marketing Providers,Consumer Financial Protection Bureau,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Law/Act,2022-08-17,2022,8,positive,0.7542,low,0.0556,215,1.0,Enacted,"I. Background Financial services companies rely on digital marketing providers to target and deliver advertisements across various platforms to consumers on their behalf. By doing so, financial services companies may be able to engage with audiences in ways that they were previously unable to with traditional advertising methods. Many modern digital marketing providers (or “digital marketers”) play a dramatically different role in consumer advertising than did traditional media sources like print newspapers or radio stations. Many digital marketers target and deliver ads to specific consumers using sophisticated analytical techniques, including machine learning and behavioral analytics, to process large amounts of consumer data. In other words, many digital marketers aggregate and analyze immense amounts of granular consumer data, and then use that data to determine what advertisements to provide to specific consumers at what times. Accordingly, digital marketing providers commingle the service of targeting and delivering advertisements with the activities of traditional media sources in providing airtime or physical space. Digital marketing providers obtain data from a variety of sources, including but not limited to data collected directly from consumers, for example when registering for an account or when conducting a search query into a search bar. Further, digital marketers may harvest a wide variety of consumer data by monitoring and tracking a consumer's web activity,",https://www.federalregister.gov/documents/2022/08/17/2022-17699/limited-applicability-of-consumer-financial-protection-acts-time-or-space-exception-with-respect-to,en,"Harms: Financial loss, Strategies: Government study or report, Strategies: Performance requirements, Applications: Sales, retail, and customer relations"
176,"21 CFR § 870.1345 (""Intravascular bleed monitor"")",Food and Drug Administration,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2022-06-08,2022,6,positive,0.8402,low,0.1111,206,1.0,Enacted,"§ 870.1345 Intravascular bleed monitor. (a) Identification. An intravascular bleed monitor is a probe, catheter, or catheter introducer that measures changes in bioimpedance and uses an algorithm to detect or monitor progression of potential internal bleeding complications. (b) Classification. Class II (special controls). The special controls for this device are: (1) In vivo animal performance testing must demonstrate that the device performs as intended under anticipated conditions of use and evaluate the following: (i) Device performance characteristics; (ii) Adverse effects, including gross necropsy and histopathology; and (iii) Device usability, including device preparation, device handling, and user interface. (2) Non-clinical performance testing data must demonstrate that the device performs as intended under anticipated conditions of use. The following performance characteristics must be tested: (i) Tensile testing of joints and materials; (ii) Mechanical integrity testing; (iii) Friction testing; (iv) Flush testing; (v) Air leakage and liquid leakage testing; (vi) Latching and unlatching testing; (vii) Kink and bend testing; (viii) Insertion force testing; (ix) Torque testing; (x) Corrosion testing; and (xi) Dimensional tolerance testing. (3) Performance data must support the sterility and pyrogenicity of the device components intended to be provided sterile. (4) Performance data must support the shelf life of the device by demonstrating continued sterility, package i",https://www.federalregister.gov/documents/2022/06/08/2022-12364/medical-devices-cardiovascular-devices-classification-of-the-intravascular-bleed-monitor,en,"Risk factors: Reliability, Harms: Harm to health/safety, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Performance requirements, Strategies: Licensing, registration, and certification, Applications: Medicine, life sciences and public health"
177,"21 CFR § 870.1420 (""Coronary artery disease risk indicator using acoustic heart signals"")",Food and Drug Administration,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2022-06-01,2022,6,positive,0.9791,low,0.2222,214,1.0,Enacted,"§ 870.1420 Coronary artery disease risk indicator using acoustic heart signals. (a) Identification. A coronary artery disease risk indicator using acoustic heart signals is a device that records heart sounds including murmurs and vibrations to calculate a patient-specific risk of presence of coronary artery disease, as an aid in cardiac analysis and diagnosis. (b) Classification. Class II (special controls). The special controls for this device are: (1) Clinical performance testing must fulfill the following: (i) Testing must include a discussion of the patient population and any statistical techniques used for analyzing the data; and (ii) Testing must be representative of the intended use population for the device. Any selection criteria or sample limitations must be fully described and justified. (2) Acoustic performance testing must evaluate microphone sensitivity, sound acquisition bandwidth, and amplitude accuracy. The acoustic sensor specifications and mechanism used to capture heart sounds must be described. (3) A scientific justification for the validity of the algorithm(s) must be provided. This justification must fulfill the following: (i) All inputs and outputs of the algorithm must be fully described; (ii) The procedure for segmenting, characterizing, and classifying the acoustic signal must be fully described; and (iii) This justification must include verification of the algorithm calculations and validation using an independent data set. (4) The patient-contacti",https://www.federalregister.gov/documents/2022/06/01/2022-11699/medical-devices-cardiovascular-devices-classification-of-the-coronary-artery-disease-risk-indicator,en,"Risk factors: Reliability, Risk factors: Interpretability and explainability, Risk factors: Transparency, Harms: Harm to health/safety, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About evaluation, Strategies: Disclosure: In standard form, Applications: Medicine, life sciences and public health"
178,"21 CFR § 870.2210 (""Adjunctive predictive cardiovascular indicator"")",Food and Drug Administration,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2022-02-14,2022,2,positive,0.7717,low,0.2778,207,1.0,Enacted,"§ 870.2210 Adjunctive predictive cardiovascular indicator. (a) Identification. The adjunctive predictive cardiovascular indicator is a prescription device that uses software algorithms to analyze cardiovascular vital signs and predict future cardiovascular status or events. This device is intended for adjunctive use with other physical vital sign parameters and patient information and is not intended to independently direct therapy. (b) Classification. Class II (special controls). The special controls for this device are: (1) A software description and the results of verification and validation testing based on a comprehensive hazard analysis and risk assessment must be provided, including: (i) A full characterization of the software technical parameters, including algorithms; (ii) A description of the expected impact of all applicable sensor acquisition hardware characteristics and associated hardware specifications; (iii) A description of sensor data quality control measures; (iv) A description of all mitigations for user error or failure of any subsystem components (including signal detection, signal analysis, data display, and storage) on output accuracy; (v) A description of the expected time to patient status or clinical event for all expected outputs, accounting for differences in patient condition and environment; and (vi) The sensitivity, specificity, positive predictive value, and negative predictive value in both percentage and number form. (2) A scientific justifi",https://www.federalregister.gov/documents/2022/02/14/2022-03096/medical-devices-cardiovascular-devices-classification-of-the-adjunctive-predictive-cardiovascular,en,"Risk factors: Reliability, Risk factors: Interpretability and explainability, Risk factors: Safety, Risk factors: Transparency, Harms: Harm to health/safety, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Disclosure: In standard form, Strategies: Disclosure: Accuracy thereof, Strategies: Performance requirements, Applications: Medicine, life sciences and public health"
179,"21 CFR § 870.2790 (""Photoplethysmograph analysis software for over-the-counter use"")",Food and Drug Administration,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2022-02-04,2022,2,positive,0.9432,low,0.2778,208,1.0,Enacted,"§ 870.2790 Photoplethysmograph analysis software for over-the-counter use. (a) Identification. A photoplethysmograph analysis software device for over-the-counter use analyzes photoplethysmograph data and provides information for identifying irregular heart rhythms. This device is not intended to provide a diagnosis. (b) Classification. Class II (special controls). The special controls for this device are: (1) Clinical performance testing must demonstrate the performance characteristics of the detection algorithm under anticipated conditions of use. (2) Software verification, validation, and hazard analysis must be performed. Documentation must include a characterization of the technical specifications of the software, including the detection algorithm and its inputs and outputs. (3) Non-clinical performance testing must demonstrate the ability of the device to detect adequate photoplethysmograph signal quality. (4) Human factors and usability testing must demonstrate the following: (i) The user can correctly use the device based solely on reading the device labeling; and (ii) The user can correctly interpret the device output and understand when to seek medical care. (5) Labeling must include: (i) Hardware platform and operating system requirements; (ii) Situations in which the device may not operate at an expected performance level; (iii) A summary of the clinical performance testing conducted with the device; (iv) A description of what the device measures and outputs to th",https://www.federalregister.gov/documents/2022/02/04/2022-02358/medical-devices-cardiovascular-devices-classification-of-the-photoplethysmograph-analysis-software,en,"Risk factors: Reliability, Risk factors: Interpretability and explainability, Risk factors: Safety, Risk factors: Transparency, Harms: Harm to health/safety, Strategies: Evaluation: Impact assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Disclosure: In standard form, Strategies: Performance requirements, Applications: Medicine, life sciences and public health"
180,"21 CFR § 870.2345 (""Electrocardiograph software for over-the-counter use"")",Food and Drug Administration,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2022-01-18,2022,1,positive,0.9612,low,0.2222,205,1.0,Enacted,"§ 870.2345 Electrocardiograph software for over-the-counter use. (a) Identification. An electrocardiograph software device for over-the-counter use creates, analyzes, and displays electrocardiograph data and can provide information for identifying cardiac arrhythmias. This device is not intended to provide a diagnosis. (b) Classification. Class II (special controls). The special controls for this device are: (1) Clinical performance testing under anticipated conditions of use must demonstrate the following: (i) The ability to obtain an electrocardiograph of sufficient quality for display and analysis; and (ii) The performance characteristics of the detection algorithm as reported by sensitivity and either specificity or positive predictive value. (2) Software verification, validation, and hazard analysis must be performed. Documentation must include a characterization of the technical specifications of the software, including the detection algorithm and its inputs and outputs. (3) Non-clinical performance testing must validate detection algorithm performance using a previously adjudicated data set. (4) Human factors and usability testing must demonstrate the following: (i) The user can correctly use the device based solely on reading the device labeling; and (ii) The user can correctly interpret the device output and understand when to seek medical care. (5) Labeling must include: (i) Hardware platform and operating system requirements; (ii) Situations in which the device may",https://www.federalregister.gov/documents/2022/01/18/2022-00827/medical-devices-cardiovascular-devices-classification-of-the-electrocardiograph-software-for,en,"Risk factors: Reliability, Risk factors: Interpretability and explainability, Risk factors: Safety, Harms: Harm to health/safety, Strategies: Evaluation: Impact assessment, Strategies: Performance requirements, Applications: Medicine, life sciences and public health"
181,"15 CFR part 7 (""Securing the Information and Communications Technology and Services Supply Chain"")",Department of Commerce,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2021-03-22,2021,3,positive,0.802,medium,0.3889,217,1.0,Enacted,"PART 7—SECURING THE INFORMATION AND COMMUNICATIONS TECHNOLOGY AND SERVICES SUPPLY CHAIN Subpart A—General § 7.1 Purpose. These regulations set forth the procedures by which the Secretary may: (a) Determine whether any acquisition, importation, transfer, installation, dealing in, or use of any information and communications technology or service (ICTS Transaction) that has been designed, developed, manufactured, or supplied by persons owned by, controlled by, or subject to the jurisdiction or direction of foreign adversaries poses certain undue or unacceptable risks as identified in the Executive Order; (b) issue a determination to prohibit an ICTS Transaction; (c) direct the timing and manner of the cessation of the ICTS Transaction; and (d) consider factors that may mitigate the risks posed by the ICTS Transaction. The Secretary will evaluate ICTS Transactions under this rule, which include classes of transactions, on a case-by-case basis. The Secretary, in consultation with appropriate agency heads specified in Executive Order 13873 and other relevant governmental bodies, as appropriate, shall make an initial determination as to whether to prohibit a given ICTS Transaction or propose mitigation measures, by which the ICTS Transaction may be permitted. Parties may submit information in response to the initial determination, including a response to the initial determination and any supporting materials and/or proposed measures to remediate or mitigate the risks identified in",https://www.federalregister.gov/documents/2021/01/19/2021-01234/securing-the-information-and-communications-technology-and-services-supply-chain,en,"Risk factors: Privacy, Risk factors: Security, Risk factors: Security: Cybersecurity, Harms: Harm to health/safety, Harms: Harm to infrastructure, Harms: Ecological harm, Harms: Violation of civil or human rights, including privacy, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Convening, Incentives: Criminal liability, Incentives: Civil liability, Incentives: Fines, Incentives: Imprisonment, Applications: Transportation"
182,"21 CFR § 892.2060 (""Radiological computer-assisted diagnostic software for lesions suspicious of cancer"")",Food and Drug Administration,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2020-01-22,2020,1,negative,-0.5182,low,0.3333,205,1.0,Enacted,"§ 892.2060 Radiological computer-assisted diagnostic software for lesions suspicious of cancer. (a) Identification. A radiological computer-assisted diagnostic software for lesions suspicious of cancer is an image processing prescription device intended to aid in the characterization of lesions as suspicious for cancer identified on acquired medical images such as magnetic resonance, mammography, radiography, or computed tomography. The device characterizes lesions based on features or information extracted from the images and provides information about the lesion(s) to the user. Diagnostic and patient management decisions are made by the clinical user. (b) Classification. Class II (special controls). The special controls for this device are: (1) Design verification and validation must include: (i) A detailed description of the image analysis algorithms including, but not limited to, a detailed description of the algorithm inputs and outputs, each major component or block, and algorithm limitations. (ii) A detailed description of pre-specified performance testing protocols and dataset(s) used to assess whether the device will improve reader performance as intended. (iii) Results from performance testing protocols that demonstrate that the device improves reader performance in the intended use population when used in accordance with the instructions for use. The performance assessment must be based on appropriate diagnostic accuracy measures (e.g., receiver operator characteri",https://www.federalregister.gov/documents/2020/01/22/2020-00497/medical-devices-radiology-devices-classification-of-the-radiological-computer-assisted-diagnostic,en,"Risk factors: Reliability, Risk factors: Interpretability and explainability, Risk factors: Safety, Risk factors: Security, Risk factors: Security: Cybersecurity, Harms: Harm to health/safety, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Performance requirements, Applications: Medicine, life sciences and public health"
183,"21 CFR § 892.2070 (""Medical image analyzer"")",Food and Drug Administration,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2020-02-21,2020,2,positive,0.5627,low,0.3333,208,1.0,Enacted,"§ 892.2070 Medical image analyzer. (a) Identification. Medical image analyzers, including computer-assisted/aided detection (CADe) devices for mammography breast cancer, ultrasound breast lesions, radiograph lung nodules, and radiograph dental caries detection, is a prescription device that is intended to identify, mark, highlight, or in any other manner direct the clinicians' attention to portions of a radiology image that may reveal abnormalities during interpretation of patient radiology images by the clinicians. This device incorporates pattern recognition and data analysis capabilities and operates on previously acquired medical images. This device is not intended to replace the review by a qualified radiologist, and is not intended to be used for triage, or to recommend diagnosis. (b) Classification. Class II (special controls). The special controls for this device are: (1) Design verification and validation must include: (i) A detailed description of the image analysis algorithms including a description of the algorithm inputs and outputs, each major component or block, and algorithm limitations. (ii) A detailed description of pre-specified performance testing methods and dataset(s) used to assess whether the device will improve reader performance as intended and to characterize the standalone device performance. Performance testing includes one or more standalone tests, side-by-side comparisons, or a reader study, as applicable. (iii) Results from performance testing",https://www.federalregister.gov/documents/2020/01/22/2020-00494/radiology-devices-reclassification-of-medical-image-analyzers,en,"Risk factors: Reliability, Risk factors: Interpretability and explainability, Risk factors: Safety, Risk factors: Security: Cybersecurity, Risk factors: Transparency, Harms: Harm to health/safety, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Disclosure: In standard form, Strategies: Performance requirements, Applications: Medicine, life sciences and public health"
186,"National Defense Authorization Act for Fiscal Year 2024, Section 346 (""Pilot program on optimization of aerial refueling and fuel management in contested logistics environments through use of artificial intelligence"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.9861,low,0.0556,217,1.0,Enacted,"SEC. 346. PILOT PROGRAM ON OPTIMIZATION OF AERIAL REFUELING AND FUEL MANAGEMENT IN CONTESTED LOGISTICS ENVIRONMENTS THROUGH USE OF ARTIFICIAL INTELLIGENCE. (a) Design of Pilot Program.-- (1) Design.--Not later than 90 days after the date of the enactment of this Act, the Chief Digital and Artificial Intelligence Officer of the Department of Defense, in collaboration with the Under Secretary of Defense for Acquisition and Sustainment and the Chief of Staff of the Air Force, shall design a pilot program to optimize the logistics of aerial refueling and fuel management in the context of contested logistics environments through the use of advanced digital technologies and artificial intelligence (in this section referred to as the ``pilot program''). (2) Coordination and consultation.--In designing the pilot program, the Chief Digital and Artificial Intelligence Officer shall-- (A) coordinate with the Commander of the United States Transportation Command and the Commander of the United States Indo-Pacific Command regarding the activities to be carried out under the pilot program, to ensure the pilot program will align with existing operational requirements; and (B) seek to consult with relevant experts in the fields of artificial intelligence, logistics, aviation, and fuel management. (b) Objectives.--The objectives of the pilot program shall include the following: (1) Assessing the feasibility and effectiveness of artificial intelligence-driven approaches in enhancing aerial ref",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Risk factors: Security: Cybersecurity, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Government study or report, Strategies: Pilots and testbeds, Strategies: Convening, Strategies: Performance requirements, Applications: Government: military and public safety"
187,"National Defense Authorization Act for Fiscal Year 2024, Section 350 (""Strategy and assessment on use of automation and artificial intelligence for shipyard optimization"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.992,low,0.0,216,1.0,Enacted,"SEC. 350. STRATEGY AND ASSESSMENT ON USE OF AUTOMATION AND ARTIFICIAL INTELLIGENCE FOR SHIPYARD OPTIMIZATION. (a) Strategy.--The Secretary of the Navy, in coordination with the Shipyard Infrastructure Optimization Program of the Department of the Navy, shall develop and implement a strategy to leverage commercial best practices used in shipyards to improve the efficiency of operations and to demonstrate a digital platform that uses artificial intelligence to analyze data on the maintenance and condition of shipboard assets of the Navy at shipyards, for the purpose of improving the readiness of the Armed Forces, predicting and diagnosing issues prior to the occurrence of such issues, and lowering maintenance costs. (b) Assessment.--The Secretary of the Navy shall conduct an assessment of the costs of maintenance delays on shipboard assets of the Navy and the potential cost savings of adopting artificial intelligence predictive maintenance technologies to assist in the determination of the condition of in-service equipment and estimate when maintenance should be performed prior to failure or end of life of such equipment. Such assessment shall include-- (1) an analysis of maintenance delays and costs due to unplanned and unpredicted maintenance issues; (2) an evaluation of opportunities to demonstrate commercial best practices at shipyards, including the demonstration of artificial intelligence technologies to ensure timely predictions for individuals responsible for maintenanc",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Government study or report, Strategies: Pilots and testbeds, Applications: Government: military and public safety"
188,"National Defense Authorization Act for Fiscal Year 2024, Section 811 (""Modernizing the Department of Defense requirements process"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.8985,low,0.0,213,1.0,Enacted,"SEC. 811. MODERNIZING THE DEPARTMENT OF DEFENSE REQUIREMENTS PROCESS. (a) Modernizing the Department of Defense Requirements Process. --Not later than October 1, 2025, the Secretary of Defense, acting through the Vice Chairman of the Joint Chiefs of Staff, in coordination with the Secretaries of the military departments and the commanders of the combatant commands, and in consultation with the Under Secretary of Defense for Acquisition and Sustainment, shall develop and implement a streamlined requirements development process for the Department of Defense, to include revising the Joint Capabilities Integration and Development System, in order to improve alignment between modern warfare concepts, technologies, and system development and reduce the time to deliver needed capabilities to warfighters. (b) Reform Elements.--The process required by subsection (a) shall-- (1) streamline requirements documents, reviews, and approval processes, focusing on programs below the major defense acquisition program threshold described in section 4201 of title 10, United States Code; (2) revise requirements management practices using a clean-sheet approach that avoids prescriptive language, is based on mission outcomes and assessed threats, enables a more iterative and collaborative approach with the Armed Forces, maximizes the use of commercial products or commercial services in accordance with section 3453 of title 10, United States Code, and allows for a broader range of new or alternative",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Strategies: Evaluation: Conformity assessment, Strategies: Government support: For R&D, Strategies: Convening, Strategies: Governance development, Incentives: Access to business opportunities, Applications: Government: military and public safety"
189,"National Defense Authorization Act for Fiscal Year 2024, Section 856 (""Pilot program to analyze and monitor certain supply chains"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,negative,-0.8877,low,0.0,233,1.0,Enacted,"SEC. 856. PILOT PROGRAM TO ANALYZE AND MONITOR CERTAIN SUPPLY CHAINS. (a) In General.--Not later than 90 days after the date of the enactment of this Act, the Under Secretary of Defense for Acquisition and Sustainment shall establish and carry out a pilot program to analyze, map, and monitor supply chains for up to five covered weapons platforms, under which the Under Secretary shall-- (1) identify impediments to production and opportunities to expand the production of components of such a covered weapons platform; (2) identify potential risks to and vulnerabilities of suppliers for such covered weapons platforms and ways to mitigate such risks; and (3) identify critical suppliers for such covered weapons platforms.(b) Use of Tools.--The Under Secretary may use a combination of commercial tools and tools available to the Department of Defense to carry out the program established under this section, including artificial intelligence and machine learning tools to improve data analysis capabilities for such supply chains. (c) Annual Reports.--Not later than one year after the date of the enactment of this Act, and annually thereafter until the date specified in subsection (d), the Under Secretary shall submit to the congressional defense committees a report containing-- (1) a list of the vulnerabilities of the supply chains for each covered weapons platform selected under subsection (a), categorized by severity of threat or risk to deployment of such a platform; (2) for each vul",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Strategies: Government study or report, Strategies: Pilots and testbeds, Strategies: Performance requirements, Applications: Government: military and public safety"
190,"National Defense Authorization Act for Fiscal Year 2024, Title XIII, Subtitle B (""Other Matters Relating to Foreign Nations: Matters Relating to the AUKUS Partnership"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.9565,low,0.0,197,1.0,Enacted,"Subtitle B--Matters Relating to the AUKUS Partnership SEC. 1321. DEFINITIONS. In this subtitle: (1) Appropriate congressional committees.--Except as otherwise provided, the term ``appropriate congressional committees'' means-- (A) the Committee on Foreign Relations and the Committee on Armed Services of the Senate; and (B) the Committee on Foreign Affairs and the Committee on Armed Services of the House of Representatives. (2) AUKUS partnership.-- (A) In general.--The term ``AUKUS partnership'' means the enhanced trilateral security partnership between Australia, the United Kingdom, and the United States announced in September 2021. (B) Pillars.--The AUKUS partnership includes the following two pillars: (i) Pillar One is focused on developing a pathway for Australia to acquire conventionally armed, nuclear-powered submarines. (ii) Pillar Two is focused on enhancing trilateral collaboration on advanced defense capabilities, including hypersonic and counter hypersonic capabilities, quantum technologies, undersea technologies, and artificial intelligence. (3) International traffic in arms regulations.--The term ``International Traffic in Arms Regulations'' means subchapter M of chapter I of title 22, Code of Federal Regulations (or successor regulations). PART 1--ADMINISTRATIVE PROVISIONS SEC. 1331. AUKUS PARTNERSHIP OVERSIGHT AND ACCOUNTABILITY FRAMEWORK. (a) Senior Advisor.-- (1) Designation.-- (A) In general.--The Secretary of State shall designate a senior advisor at the Dep",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Strategies: Government study or report, Strategies: Governance development, Strategies: Licensing, registration, and certification, Applications: Government: military and public safety"
191,"National Defense Authorization Act for Fiscal Year 2024, Section 1507 (""Review and plan relating to cyber red teams of Department of Defense"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.873,low,0.0,233,1.0,Enacted,"SEC. 1507. REVIEW AND PLAN RELATING TO CYBER RED TEAMS OF DEPARTMENT OF DEFENSE. (a) Review Relating to Prior Joint Assessment.-- (1) Review required.--Not later than 90 days after the date of the enactment of this Act, the officials described in subsection (c) shall review, and assess the status of the implementation of, the recommendations set forth by the Secretary of Defense in response to the joint assessment requirement under section 1660 of the National Defense Authorization Act for Fiscal Year 2020 (Public Law 116-92; 133 Stat. 1771). (2) Elements.--The review under paragraph (1) shall include, with respect to the recommendations specified in such paragraph-- (A) the timelines associated with each such recommendation, regardless of whether the recommendation is fully implemented or yet to be fully implemented; and (B) a description of any impediments to the implementation of such recommendations encountered. (b) Plan Required.-- (1) Plan.--Not later than 180 days after the date of the enactment of this Act, the officials described in subsection (c) shall submit to the congressional defense committees a plan, developed taking into account the findings of the review under subsection (a), to ensure cyber red teams of the Department of Defense achieve sufficient capacity and capability to provide services and meet current and projected future demands on a Defense-wide basis. Such plan shall include-- (A) a description of the funding necessary for such cyber red teams to a",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Strategies: Evaluation, Strategies: Evaluation: Adversarial testing, Strategies: Government study or report, Applications: Government: military and public safety"
192,"National Defense Authorization Act for Fiscal Year 2024, Section 1521 (""Control and management of Department of Defense data; establishment of Chief Digital and Artificial Intelligence Officer Governing Council"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.9864,low,0.1667,217,1.0,Enacted,"SEC. 1521. CONTROL AND MANAGEMENT OF DEPARTMENT OF DEFENSE DATA; ESTABLISHMENT OF CHIEF DIGITAL AND ARTIFICIAL INTELLIGENCE OFFICER GOVERNING COUNCIL. (a) Control and Management of Department of Defense Data.--The Chief Digital and Artificial Intelligence Officer of the Department of Defense may access and control, on behalf of the Secretary of Defense, any data collected, acquired, accessed, or used by a component (as such term is defined in section 1513 of the James M. Inhofe National Defense Authorization Act for Fiscal Year 2023 (Public Law 117-263; 10 U.S.C. 4001 note)), consistent with such section. (b) Chief Digital and Artificial Intelligence Officer Governing Council.--Section 238(d)(3) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Public Law 115-232; 10 U.S.C. note prec. 4061) is amended to read as follows: ``(3) Chief digital and artificial intelligence officer governing council.-- ``(A) Establishment.--The Secretary shall establish a council to provide policy oversight to ensure the responsible, coordinated, and ethical employment of data and artificial intelligence capabilities across Department of Defense missions and operations. Such council shall be known as the Chief Digital and Artificial Intelligence Officer Governing Council' (in this paragraph referred to as the Council'). ``(B) Membership.--The Council shall be composed of the following: ``(i) Joint Staff J-6. ``(ii) The Under Secretary of Defense for Acquisition and Sust",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Risk factors: Bias, Risk factors: Security, Risk factors: Security: Dissemination, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: AI workforce-related, Strategies: Convening, Strategies: Governance development, Strategies: Performance requirements, Strategies: New institution, Applications: Government: military and public safety"
193,"National Defense Authorization Act for Fiscal Year 2024, Title XV, Subtitle C (""Cyberspace-Related Matters: Information Technology and Data Management"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.9858,low,0.1111,214,1.0,Enacted,"Subtitle C--Information Technology and Data Management SEC. 1521. CONTROL AND MANAGEMENT OF DEPARTMENT OF DEFENSE DATA; ESTABLISHMENT OF CHIEF DIGITAL AND ARTIFICIAL INTELLIGENCE OFFICER GOVERNING COUNCIL. (a) Control and Management of Department of Defense Data.--The Chief Digital and Artificial Intelligence Officer of the Department of Defense may access and control, on behalf of the Secretary of Defense, any data collected, acquired, accessed, or used by a component (as such term is defined in section 1513 of the James M. Inhofe National Defense Authorization Act for Fiscal Year 2023 (Public Law 117-263; 10 U.S.C. 4001 note)), consistent with such section. (b) Chief Digital and Artificial Intelligence Officer Governing Council.--Section 238(d)(3) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Public Law 115-232; 10 U.S.C. note prec. 4061) is amended to read as follows: ``(3) Chief digital and artificial intelligence officer governing council.-- ``(A) Establishment.--The Secretary shall establish a council to provide policy oversight to ensure the responsible, coordinated, and ethical employment of data and artificial intelligence capabilities across Department of Defense missions and operations. Such council shall be known as the Chief Digital and Artificial Intelligence Officer Governing Council' (in this paragraph referred to as the Council'). ``(B) Membership.--The Council shall be composed of the following: ``(i) Joint Staff J-6. ``(ii)",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Risk factors: Security, Risk factors: Security: Cybersecurity, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Strategies: Pilots and testbeds, Strategies: New institution, Applications: Business services and analytics, Applications: Broadcasting and media production, Applications: Government: military and public safety"
194,"National Defense Authorization Act for Fiscal Year 2024, Title XV, Subtitle E (""Artificial Intelligence"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.9569,medium,0.6111,230,1.0,Enacted,"Subtitle E--Artificial Intelligence SEC. 1541. MODIFICATION TO ACQUISITION AUTHORITY OF SENIOR OFFICIAL WITH PRINCIPAL RESPONSIBILITY FOR ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING. Section 808 of the William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021 (Public Law 116-283; 10 U.S.C. 4001 note) is amended-- (1) in subsection (c)(1), by striking The Secretary of Defense shall provide the Office with at least 10 full-time employees'' and inserting The Secretary of Defense shall ensure that, at any given time for the duration of the period specified in subsection (d), the Office has at least 10 full- time employees provided by the Secretary''; (2) in subsection (d), by striking in each of fiscal years 2021, 2022, 2023, 2024, and 2025'' and inserting in each of fiscal years 2024 through 2029''; (3) by amending subsection (e)(1) to read as follows: ``(1) In general.--``(A) Plan required.--Not later than 30 days after the date of the enactment of the National Defense Authorization Act for Fiscal Year 2024, the Secretary of Defense, acting through the Under Secretary of Defense for Acquisition and Sustainment, shall submit to the congressional defense committees a plan for the delegation and exercise of the acquisition authority described in subsection (a).``(B) Demonstration required.--Not later than 90 days after the date of the enactment of the National Defense Authorization Act for Fiscal Year 2024, the Secretary of Defense, acting through the Ch",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Risk factors: Bias, Risk factors: Reliability, Risk factors: Reliability: Robustness, Risk factors: Interpretability and explainability, Risk factors: Privacy, Risk factors: Safety, Risk factors: Security, Risk factors: Security: Cybersecurity, Risk factors: Security: Dissemination, Harms: Harm to health/safety, Harms: Detrimental content, Strategies: Evaluation, Strategies: Disclosure, Strategies: Government study or report, Strategies: Government support"
195,"National Defense Authorization Act for Fiscal Year 2024, Section 1682 (""Electromagnetic Warfare"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.873,low,0.0,191,1.0,Enacted,"SEC. 1682. ELECTROMAGNETIC WARFARE. (a) In General.--Part I of subtitle A of title 10, United States Code, is amended by adding at the end the following new chapter: ``CHAPTER 25-- ELECTROMAGNETIC WARFARE ``500. Electromagnetic Spectrum Operations Executive Committee. ``500a. Guidance on electromagnetic spectrum operations mission area and joint electromagnetic spectrum operations. ``500b. Annual report on electromagnetic spectrum operations strategy of the Department of Defense. ``500c. Annual assessment of budget with respect to electromagnetic spectrum operations capabilities. ``500d. Electromagnetic spectrum superiority implementation plan. ``500e. Electromagnetic Spectrum Enterprise Operational Lead for Joint Electromagnetic Spectrum Operations. ``500f. Evaluations of abilities of armed forces and combatant commands to perform electromagnetic spectrum operations missions. ``Sec. 500. Electromagnetic Spectrum Operations Executive Committee `(a) In General.--There is within the Department of Defense an Electromagnetic Spectrum Operations Executive Committee (in this section referred to as the Executive Committee'). ``(b) Purposes.--The Executive Committee shall-- ``(1) serve as the principal forum within the Department of Defense to inform, coordinate, and evaluate matters relating to electromagnetic warfare; ``(2) provide senior oversight, coordination, and budget and capability harmonization with respect to such matters; and ``(3) act as an advisory body to the Secretary",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Strategies: Evaluation, Strategies: Government study or report, Applications: Government: military and public safety"
196,"National Defense Authorization Act for Fiscal Year 2024, Section 6303 (""Establishment of the Chief Artificial Intelligence Officer of the Department of State"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.9866,low,0.0,211,1.0,Enacted,"SEC. 6303. ESTABLISHMENT OF THE CHIEF ARTIFICIAL INTELLIGENCE OFFICER OF THE DEPARTMENT OF STATE. Section 1 of the State Department Basic Authorities Act of 1956 (22 U.S.C. 2651a) is amended by adding at the end the following new subsection: ``(n) Chief Artificial Intelligence Officer.-- ``(1) In general.--There shall be within the Department of State a Chief Artificial Intelligence Officer, which may be dual-hatted as the Department's Chief Data Officer, who shall be a member of the Senior Executive Service.``(2) Duties described.--The principal duties and responsibilities of the Chief Artificial Intelligence Officer shall be-- ``(A) to evaluate, oversee, and, if appropriate, facilitate the responsible adoption of artificial intelligence (AI) and machine learning applications to help inform decisions by policymakers and to support programs and management operations of the Department of State; and ``(B) to act as the principal advisor to the Secretary of State on the ethical use of AI and advanced analytics in conducting data-informed diplomacy.``(3) Qualifications.--The Chief Artificial Intelligence Officer should be an individual with demonstrated skill and competency in-- ``(A) the use and application of data analytics, AI, and machine learning; and ``(B) transformational leadership and organizational change management, particularly within large, complex organizations. ``(4) Partner with the chief information officer on scaling artificial intelligence use cases.-- To ensur",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Strategies: Evaluation, Applications: Government: military and public safety, Applications: Government: other applications/unspecified"
197,"National Defense Authorization Act for Fiscal Year 2024, Section 7356 (""Analysis of commercial cloud initiatives of intelligence community"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.9881,low,0.0,221,1.0,Enacted,"SEC. 7356. ANALYSIS OF COMMERCIAL CLOUD INITIATIVES OF INTELLIGENCE COMMUNITY. (a) In General.--Not later than 90 days after the date of the enactment of this Act, the Director of National Intelligence shall, in coordination with such heads of elements of the intelligence community as the Director considers appropriate-- (1) complete a comprehensive analysis of the commercial cloud initiatives of the intelligence community relating to the Commercial Cloud Enterprise contract entered into by the Director of the Central Intelligence Agency in November 2020; and(2) provide to the congressional intelligence committees, the Committee on the Appropriations of the Senate, and the Committee on Appropriations of the House of Representatives a briefing on the findings of the Director with respect to the analysis conducted pursuant to paragraph (1).(b) Elements.--The analysis conducted under subsection (a) shall include-- (1) the current year and 5-year projected costs for commercial cloud utilization for each element of the intelligence community, including costs related to data storage, data migration, egress fees, and any other commercial cloud services; (2) the termination or planned termination, as the case may be, of legacy data storage capacity of an element of the intelligence community and the projected cost savings resulting from such termination; (3) efforts underway by the Office of the Director of National Intelligence and elements of the intelligence community to utilize m",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Government study or report, Applications: Government: military and public safety"
198,"National Defense Authorization Act for Fiscal Year 2024, Section 7507 (""Programs for next-generation microelectronics in support of artificial intelligence"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.9895,low,0.0556,183,1.0,Enacted,"SEC. 7507. PROGRAMS FOR NEXT-GENERATION MICROELECTRONICS IN SUPPORT OF ARTIFICIAL INTELLIGENCE. (a) Program Establishment.--Subject to the availability of appropriations, the Director of National Intelligence, acting through the Director of the Intelligence Advanced Research Projects Activity, shall establish or otherwise oversee a program to advance microelectronics research. (b) Research Focus.--The Director of National Intelligence shall ensure that the research carried out under the program established under subsection (a) is focused on the following: (1) Advanced engineering and applied research into next- generation computing models, materials, devices, architectures, and algorithms to enable the advancement of artificial intelligence and machine learning. (2) Efforts to-- (A) overcome challenges with engineering and applied research of microelectronics, including with respect to the physical limits on transistors, electrical interconnects, and memory elements; (B) promote long-term advancements in computing technologies, including by fostering a unified and multidisciplinary approach encompassing research and development into-- (i) next-generation algorithm design; (ii) next-generation compute capability; (iii) generative and adaptive artificial intelligence for design applications; (iv) photonics-based microprocessors, including electrophotonics; (v) the chemistry and physics of new materials; (vi) optical communication networks, including electrophotonics; and (vii)",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Risk factors: Safety, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Convening, Applications: Government: military and public safety"
199,"National Defense Authorization Act for Fiscal Year 2024, Section 7510 (""Requirement to ensure intelligence community directives appropriately account for artificial intelligence and machine learning tools in intelligence products"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.9965,low,0.0,203,1.0,Enacted,"SEC. 7510. REQUIREMENT TO ENSURE INTELLIGENCE COMMUNITY DIRECTIVES APPROPRIATELY ACCOUNT FOR ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING TOOLS IN INTELLIGENCE PRODUCTS. (a) Requirement.--Not later than 120 days after the date of the enactment of this Act, the Director of National Intelligence shall provide to the appropriate committees of Congress a briefing on whether intelligence community directives in effect as of the date such briefing is provided furnish intelligence community analysts with sufficient guidance and direction with respect to the use of artificial intelligence and machine learning tools in intelligence products produced by the intelligence community. (b) Elements.--The briefing required under subsection (a) shall include-- (1) a determination by the Director as to-- (A) whether Intelligence Community Directive 203, Analytic Standards, Intelligence Community Directive 206, Sourcing Requirements for Disseminated Analytic Products, and any other intelligence community directive related to the production and dissemination of intelligence products by the intelligence community in effect as of the date the briefing under subsection (a) is provided furnish intelligence community analysts with sufficient guidance and direction on how to properly use, provide sourcing information about, and otherwise provide transparency to customers regarding the use of artificial intelligence and machine learning tools in intelligence products produced by the intelligence commun",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Strategies: Disclosure, Strategies: Government study or report, Strategies: Governance development, Applications: Government: military and public safety"
200,"National Defense Authorization Act for Fiscal Year 2024, Section 7511 (""Expanded annual assessment of economic and technological capabilities of the People's Republic of China and related briefing"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.9698,low,0.0,227,1.0,Enacted,"SEC. 7511. EXPANDED ANNUAL ASSESSMENT OF ECONOMIC AND TECHNOLOGICAL CAPABILITIES OF THE PEOPLE'S REPUBLIC OF CHINA AND RELATED BRIEFING. (a) Briefing Required.--Not later than 45 days after the date of the enactment of this Act, the Director of National Intelligence shall provide to the congressional intelligence committees a briefing on the status of the implementation by the Director of section 6503 of the Intelligence Authorization Act for Fiscal Year 2023 (division F of Public Law 117-263), including-- (1) the expected timeline for establishing the working group required by subsection (a) of such section; (2) the expected timeline for such working group to submit to Congress the first assessment required by subsection (c)(2) of such section; and (3) whether any elements of the assessment described in subsection (c)(3) of such section, as amended by subsection (b), should be prepared in consultation with other working groups or entities within the Office of the Director of National Intelligence. (b) Modifications.--Section 6503(c) of the Intelligence Authorization Act for Fiscal Year 2023 (division F of Public Law 117- 1. is amended-- (1) in paragraph (1)-- (A) in subparagraph (B), by inserting the Committee on Energy and Natural Resources, the Committee on Homeland Security and Governmental Affairs,'' after Transportation,''; and (B) in subparagraph (C), by inserting the Committee on Oversight and Accountability,'' after and Means,''; and (2) in paragraph (3), by adding a",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Strategies: Government study or report, Strategies: Convening, Applications: Energy and utilities"
201,"National Defense Authorization Act for Fiscal Year 2024, Section 7513 (""Policies established by Director of National Intelligence for artificial intelligence capabilities"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.9879,low,0.3333,211,1.0,Enacted,"SEC. 7513. POLICIES ESTABLISHED BY DIRECTOR OF NATIONAL INTELLIGENCE FOR ARTIFICIAL INTELLIGENCE CAPABILITIES. (a) In General.--Section 6702 of the Intelligence Authorization Act for Fiscal Year 2023 (50 U.S.C. 3334m) is amended-- (1) in subsection (a), in the matter preceding paragraph (1), by striking subsection (b)'' and inserting subsection (c)''; (2) by redesignating subsection (b) as subsection (c); and (3) by inserting after subsection (a) the following: ``(b) Policies.-- ``(1) In general.--In carrying out subsection (a)(1), not later than 1 year after the date of the enactment of the Intelligence Authorization Act for Fiscal Year 2024, the Director of National Intelligence, in consultation with the heads of the elements of the intelligence community, the Director of the Office of Management and Budget, and such other officials as the Director of National Intelligence determines appropriate, shall establish the policies described in paragraph (2). ``(2) Policies described.--The policies described in this paragraph are policies for the acquisition, adoption, development, use, coordination, and maintenance of artificial intelligence capabilities that-- ``(A) establish a lexicon relating to the use of machine learning and artificial intelligence developed or acquired by elements of the intelligence community;``(B) establish minimum guidelines for evaluating the performance of models developed or acquired by elements of the intelligence community, such as by-- ``(i) specif",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Risk factors: Reliability, Risk factors: Interpretability and explainability, Risk factors: Privacy, Risk factors: Security, Risk factors: Security: Cybersecurity, Risk factors: Security: Dissemination, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Evaluation: External auditing, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About evaluation, Strategies: Disclosure: In standard form, Strategies: Government support: For R&D, Strategies: Convening"
202,"National Defense Authorization Act for Fiscal Year 2024, Section 253 (""Annual review of status of implementation plan for digital engineering career tracks"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.7269,low,0.0,166,1.0,Enacted,"SEC. 253. ANNUAL REVIEW OF STATUS OF IMPLEMENTATION PLAN FOR DIGITAL ENGINEERING CAREER TRACKS. Not less frequently than once each year until December 31, 2029, the Secretary of Defense shall-- (1) conduct an internal review of the status of the implementation of the plan submitted to Congress pursuant to section 230(b) of the National Defense Authorization Act for Fiscal Year 2020 (Public Law 116-92; 10 U.S.C. 501 note prec.), which shall include consideration of how the rapid rate of technological change in data science and machine learning may affect the implementation of the plan; and (2) submit to the congressional defense committees a report that includes-- (A) a summary of the status of the implementation of the plan described in paragraph (1); (B) the findings of the Secretary with respect to the most recent review conducted under such paragraph; and(C) the plan of the Secretary for addressing the digital engineering personnel needs of the Department of Defense in the years following the date of the report.",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Strategies: Disclosure, Strategies: Government study or report, Applications: Government: military and public safety"
203,"National Defense Authorization Act for Fiscal Year 2024, Section 112 (""Strategy for Army tactical wheeled vehicle program"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.9711,low,0.0,233,1.0,Enacted,"SEC. 112. STRATEGY FOR ARMY TACTICAL WHEELED VEHICLE PROGRAM. (a) Strategy Required.--In the budget justification materials submitted in support of the budget of the Department of Defense (as submitted with the budget of the President under section 1105(a) of title 31, United States Code) for each of fiscal years 2025, 2030, and 2035, the Secretary of the Army shall include a report on the strategy of the Army for tactical wheeled vehicles. (b) Requirements for Strategy.--Each strategy required by subsection (a) shall-- (1) align with the applicable national defense strategy under section 113(g) of title 10, United States Code, and applicable policies; (2) be designed so that the force of tactical wheeled vehicles provided under the strategy supports the national security strategy of the United States as set forth in the most recent national security strategy report of the President under section 108 of the National Security Act of 1947 (50 U.S.C. 3043); and (3) define capabilities and capacity requirements across the entire fleet of tactical wheeled vehicles, including-- (A) light, medium, and heavy tactical wheeled vehicles; and (B) associated trailer and support equipment. (c) Strategy Elements.--Each strategy required by subsection (a) shall include the following: (1) A detailed program for the construction of light, medium, and heavy tactical wheeled vehicles for the Army over the period of five fiscal years following the date of the strategy. (2) A description of the ne",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Strategies: Government study or report, Strategies: Government support, Applications: Government: military and public safety"
204,"National Defense Authorization Act for Fiscal Year 2024, Section 251 (""Congressional notification of changes to Department of Defense policy on autonomy in weapon systems"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,negative,-0.1027,low,0.0556,68,1.0,Enacted,SEC. 251. CONGRESSIONAL NOTIFICATION OF CHANGES TO DEPARTMENT OF DEFENSE POLICY ON AUTONOMY IN WEAPON SYSTEMS. Not later than 30 days after making a modification to Department of Defense Directive 3000.09 (relating to autonomy in weapon systems) the Secretary of Defense shall provide to the congressional defense committees a briefing that includes-- (1) a description of the modification; and (2) an explanation of the reasons for the modification.,https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Harms: Harm to health/safety, Strategies: Disclosure, Applications: Government: military and public safety"
205,"National Defense Authorization Act for Fiscal Year 2024, Section 903 (""Establishment of Office of Strategic Capital"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.9069,low,0.0,227,1.0,Enacted,"SEC. 903. ESTABLISHMENT OF OFFICE OF STRATEGIC CAPITAL. (a) Establishment of Office.--Chapter 4 of title 10, United States Code, as amended by section 241, is further amended by adding at the end the following new section: ``Sec. 149. Office of Strategic Capital `(a) Establishment.--There is in the Office of the Secretary of Defense an office to be known as the Office of Strategic Capital (in this section referred to as the Office'). `(b) Director.--The Office shall be headed by a Director (in this section referred to as the Director'), who shall be appointed by the Secretary from among employees in Senior Executive Service positions (as defined in section 3132 of title 5), or from outside the civil service who have successfully held equivalent positions. ``(c) Duties.--The Office shall-- ``(1) develop, integrate, and implement capital investment strategies proven in the commercial sector to shape and scale investment in critical technologies and assets; ``(2) identify and prioritize promising critical technologies and assets that require capital assistance and have the potential to benefit the Department of Defense; and ``(3) make eligible investments in such technologies and assets, such as supply chain technologies not always supported through direct investment. ``(d) Non-Federal Funding Requirements for Certain Investments.--In the case of an eligible investment made through a direct loan, not less than 80 percent of the total capital provided for the specific technology",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Pilots and testbeds, Strategies: Governance development, Strategies: New institution, Applications: Government: military and public safety"
207,"An Act Providing for Transferring and Renumbering; Amending Section 41-2414, Arizona Revised Statutes, as Transferred and Renumbered; Relating to Crime Victims",Arizona,United States,State governments,U.S. state and local documents,Law/Act,2023-05-19,2023,5,negative,-0.8316,low,0.0,56,1.0,Enacted,"Creates a law enforcement crime victims notification system to automatically update crime victims on their crime reports, investigations, and cases. Requires the notification system to provide a virtual agent that employs artificial intelligence to answer citizens' questions and respond to their comments through voice, text, or email. Appropriates funds for the creation of the notification system.",https://www.azleg.gov/legtext/56leg/1R/laws/0154.pdf,en,"Strategies: Government support, Strategies: Performance requirements, Applications: Government: judicial and law enforcement"
208,"An act to add Section 11546.45.5 to the Government Code, relating to automated decision systems",California,United States,State governments,U.S. state and local documents,Law/Act,2023-10-13,2023,10,positive,0.9532,low,0.2778,210,1.0,Enacted,"The people of the State of California do enact as follows: SECTION 1. Section 11546.45.5 is added to the Government Code, to read: 11546.45.5. (a) For purposes of this section: (1) “Automated decision system” means a computational process derived from machine learning, statistical modeling, data analytics, or artificial intelligence that issues simplified output, including a score, classification, or recommendation, that is used to assist or replace human discretionary decisionmaking and materially impacts natural persons. “Automated decision system” does not include a spam email filter, firewall, antivirus software, identity and access management tools, calculator, database, dataset, or other compilation of data. (2) “Board” means any administrative or regulatory board, commission, committee, council, association, or authority consisting of more than one person whose members are appointed by the Governor, the Legislature, or both. (3) “Department” means the Department of Technology. (4) “High-risk automated decision system” means an automated decision system that is used to assist or replace human discretionary decisions that have a legal or similarly significant effect, including decisions that materially impact access to, or approval for, housing or accommodations, education, employment, credit, health care, and criminal justice. (5) (A) “State agency” means any of the following: (i) Any state office, department, division, or bureau. (ii) The California State University. (",https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240AB302,en,"Risk factors: Bias, Risk factors: Privacy, Risk factors: Security, Risk factors: Security: Cybersecurity, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Government study or report, Applications: Government: benefits and welfare, Applications: Government: judicial and law enforcement, Applications: Government: other applications/unspecified"
210,"An act to amend and reenact subsection 8 of section 1-01-49 of the North Dakota Century Code, relating to the definition of person; and to declare an emergency",North Dakota,United States,State governments,U.S. state and local documents,Law/Act,2023-04-11,2023,4,negative,-0.6633,low,0.0,99,1.0,Enacted,"AN ACT to amend and reenact subsection 8 of section 1-01-49 of the North Dakota Century Code, relating to the definition of person; and to declare an emergency. BE IT ENACTED BY THE LEGISLATIVE ASSEMBLY OF NORTH DAKOTA: SECTION 1. AMENDMENT. Subsection 8 of section 1-01-49 of the North Dakota Century Code is amended and reenacted as follows: 1. ""Person"" means an individual, organization, government, political subdivision, or government agency or instrumentality. The term does not include environmental elements, artificial intelligence, an animal, or an inanimate object. SECTION 2. EMERGENCY. This Act is declared to be an emergency measure.",https://ndlegis.gov/assembly/68-2023/regular/documents/23-0346-05000.pdf,en,
211,"National Defense Authorization Act for Fiscal Year 2022, Section 247 (""Reports and briefings on recommendations of the National Security Commission on Artificial Intelligence regarding the Department of Defense"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-12-27,2021,12,positive,0.9836,low,0.0,223,1.0,Enacted,"SEC. 247. REPORTS AND BRIEFINGS ON RECOMMENDATIONS OF THE NATIONAL SECURITY COMMISSION ON ARTIFICIAL INTELLIGENCE REGARDING THE DEPARTMENT OF DEFENSE. (a) Reports Required.--On an annual basis during the two-year period beginning on the date of the enactment of this Act, the Secretary of Defense shall submit to the congressional defense committees a report on the recommendations made by the National Security Commission on Artificial Intelligence with respect to the Department of Defense. Each such report shall include-- (1) for each such recommendation, a determination of whether the Secretary of Defense intends to implement the recommendation; (2) in the case of a recommendation the Secretary intends to implement, the intended timeline for implementation, a description of any additional resources or authorities required for such implementation, and the plan for such implementation; (3) in the case of a recommendation the Secretary determines is not advisable or feasible, the analysis and justification of the Secretary in making that determination; and (4) in the case of a recommendation the Secretary determines the Department is already implementing through a separate line of effort, the analysis and justification of the Secretary in making that determination. (b) Briefings Required.--Not less frequently than once each year during the two-year period beginning on the date of the enactment of this Act, the Secretary of Defense shall provide to the congressional defense commit",https://www.congress.gov/bill/117th-congress/senate-bill/1605/text,en,"Strategies: Disclosure, Strategies: Government study or report, Applications: Government: military and public safety"
212,"National Defense Authorization Act for Fiscal Year 2022, Section 216 (""Improvements relating to steering committee on emerging technology and national security threats"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-12-27,2021,12,positive,0.9866,low,0.0,218,1.0,Enacted,"SEC. 216. IMPROVEMENTS RELATING TO STEERING COMMITTEE ON EMERGING TECHNOLOGY AND NATIONAL SECURITY THREATS. Section 236 of the William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021 (Public Law 116-283) , is amended-- (1) in subsection (a), by striking may'' and inserting and the Director of National Intelligence may jointly''; (2) in subsection (b), by-- (A) by striking paragraphs (3) through (8); and (B) by inserting after paragraph (2) the following: ``(3) The Principal Deputy Director of National Intelligence. ``(4) Such other officials of the Department of Defense and intelligence community as the Secretary of Defense and the Director of National Intelligence jointly determine appropriate.''; (3) by redesignating subsections (c) through (e) as subsections (d) through (f), respectively; (4) by inserting after subsection (b) the following: ``(c) Leadership.--The Steering Committee shall be chaired by the Deputy Secretary of Defense, the Vice Chairman of the Joint Chiefs of Staff, and the Principal Deputy Director of National Intelligence jointly.''; (5) in subsection (d), as redesignated by paragraph (3)-- (A) in paragraph (1)-- (i) by striking a strategy'' and inserting strategies''; (ii) by inserting and intelligence community'' after United States military''; and (iii) by inserting and National Intelligence Strategy, and consistent with the National Security Strategy'' after National Defense Strategy''; (B) in paragraph (3)-- (i) in the matt",https://www.congress.gov/bill/117th-congress/senate-bill/1605/text,en,"Strategies: Convening, Strategies: New institution, Applications: Government: military and public safety"
213,"National Defense Authorization Act for Fiscal Year 2022, Section 557 (""United States Naval Community College"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-12-27,2021,12,positive,0.9799,low,0.0,213,1.0,Enacted,"SEC. 557. UNITED STATES NAVAL COMMUNITY COLLEGE. (a) Establishment.--Chapter 859 of title 10, United States Code, is amended by adding at the end the following new section: ``Sec. 8595. United States Naval Community College: establishment and degree granting authority ``(a) Establishment and Function.--There is a United States Naval Community College. The primary function of such College shall be to provide-- ``(1) programs of academic instruction and professional and technical education for individuals described in subsection (b) in-- ``(A) academic and technical fields of the liberal arts and sciences which are relevant to the current and future needs of the Navy and Marine Corps, including in designated fields of national and economic importance such as cybersecurity, artificial intelligence, machine learning, data science, and software engineering; and ``(B) their practical duties; ``(2) remedial, developmental, or continuing education programs, as prescribed by the Secretary of the Navy, which are necessary to support, maintain, or extend programs under paragraph (1); ``(3) support and advisement services for individuals pursuing such programs; and ``(4) continuous monitoring of the progress of such individuals. ``(b) Individuals Eligible for Programs.--Subject to such other eligibility requirements as the Secretary of the Navy may prescribe, the following individuals are eligible to participate in programs and services under subsection (a): ``(1) Enlisted members of the",https://www.congress.gov/bill/117th-congress/senate-bill/1605/text,en,"Strategies: Government support, Strategies: Government support: AI workforce-related, Applications: Government: military and public safety"
214,"National Defense Authorization Act for Fiscal Year 2022, Section 909 (""Digital talent recruiting officer"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-12-27,2021,12,positive,0.983,low,0.0,219,1.0,Enacted,"SEC. 909. DIGITAL TALENT RECRUITING OFFICER. (a) Digital Talent Recruiting for the Department of Defense.-- (1) In general.--Not later than 270 days after the date of the enactment of this Act, the Secretary of Defense shall designate a chief digital recruiting officer within the office of the Under Secretary of Defense for Personnel and Readiness to carry out the responsibilities set forth in paragraph (2). (2) Responsibilities.--The chief digital recruiting officer shall be responsible for-- (A) identifying Department of Defense needs for, and skills gaps in, specific types of civilian digital talent; (B) recruiting individuals with the skills that meet the needs and skills gaps identified under subparagraph (A), in partnership with the military departments and other organizations and elements of the Department; (C) ensuring Federal scholarship for service programs are incorporated into civilian recruiting strategies; (D) when appropriate and within authority granted under other Federal law, offering recruitment and referral bonuses; and (E) partnering with human resource teams in the military departments and other organizations and elements of the Department to help train all Department of Defense human resources staff on the available hiring flexibilities to accelerate the hiring of individuals with the skills that fill the needs and skills gaps identified under subparagraph (A). (3) Resources.--The Secretary of Defense shall ensure that the chief digital recruiting offic",https://www.congress.gov/bill/117th-congress/senate-bill/1605/text,en,"Strategies: Government support, Strategies: Government support: AI workforce-related, Applications: Government: military and public safety"
215,"National Defense Authorization Act for Fiscal Year 2022, Section 1509 (""Assessment of cyber posture and operational assumptions and development of targeting strategies and supporting capabilities"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-12-27,2021,12,positive,0.9625,low,0.1111,217,1.0,Enacted,"SEC. 1509. ASSESSMENT OF CYBER POSTURE AND OPERATIONAL ASSUMPTIONS AND DEVELOPMENT OF TARGETING STRATEGIES AND SUPPORTING CAPABILITIES. (a) Assessment of Cyber Posture of Adversaries and Operational Assumptions of United States Government.-- (1) In general.--Not later than one year after the date of the enactment of this Act, the Commander of United States Cyber Command, the Under Secretary of Defense for Policy, and the Under Secretary of Defense for Intelligence and Security, shall jointly sponsor or conduct an assessment, including, if appropriate, a war-game or tabletop exercise, of the current and emerging offensive and defensive cyber posture of adversaries of the United States and the current operational assumptions and plans of the Armed Forces for offensive cyber operations during potential crises or conflict. (2) Elements.--The assessment required under paragraph (1) shall include consideration of the following: (A) Changes to strategies, operational concepts, operational preparation of the environment, and rules of engagement. (B) Opportunities provided by armed forces in theaters of operations and other innovative alternatives. (C) Changes in intelligence community (as such term is defined in section 3 of the National Security Act of 1947 (50 U.S.C. 3003)) targeting and operations in support of the Department of Defense. (D) Adversary capabilities to deny or degrade United States activities in cyberspace. (E) Adversaries' targeting of United States critical infras",https://www.congress.gov/bill/117th-congress/senate-bill/1605/text,en,"Risk factors: Safety, Harms: Harm to infrastructure, Strategies: Government study or report, Applications: Government: military and public safety"
216,"National Defense Authorization Act for Fiscal Year 2022, Section 1511 (""Comparative analysis of cybersecurity capabilities"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-12-27,2021,12,positive,0.9393,low,0.1667,210,1.0,Enacted,"SEC. 1511. COMPARATIVE ANALYSIS OF CYBERSECURITY CAPABILITIES. (a) Comparative Analysis Required.--Not later than 180 days after the date of the enactment of this Act, the Chief Information Officer and the Director of Cost Assessment and Program Evaluation (CAPE) of the Department of Defense, in consultation with the Principal Cyber Advisor to the Secretary of Defense and the Chief Information Officers of each of the military departments, shall jointly sponsor a comparative analysis, to be conducted by the Director of the National Security Agency and the Director of the Defense Information Systems Agency, of the following: (1) The cybersecurity tools, applications, and capabilities offered as options on enterprise software agreements for cloud-based productivity and collaboration suites, such as is offered under the Defense Enterprise Office Solution and Enterprise Software Agreement contracts with Department of Defense components, relative to the cybersecurity tools, applications, and capabilities that are currently deployed in, or required by, the Department to conduct-- (A) asset discovery; (B) vulnerability scanning; (C) conditional access (also known as ``comply-to-connect''); (D) event correlation; (E) patch management and remediation; (F) endpoint query and control; (G) endpoint detection and response; (H) data rights management; (I) data loss prevention; (J) data tagging; (K) data encryption; (L) security information and event management; and (M) security orchestratio",https://www.congress.gov/bill/117th-congress/senate-bill/1605/text,en,"Risk factors: Reliability, Risk factors: Security, Risk factors: Security: Cybersecurity, Strategies: Governance development, Applications: Government: military and public safety, Applications: Government: other applications/unspecified"
217,"National Defense Authorization Act for Fiscal Year 2022, Section 126 (""Acquisition, modernization, and sustainment plan for carrier air wings"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-12-27,2021,12,positive,0.9169,low,0.0,229,1.0,Enacted,"SEC. 126. ACQUISITION, MODERNIZATION, AND SUSTAINMENT PLAN FOR CARRIER AIR WINGS. (a) Plan Required.--Not later than April 1, 2022, the Secretary of the Navy shall submit to the congressional defense committees a 15-year acquisition, modernization, and sustainment plan for the carrier air wings of the Navy. (b) Elements.--The plan required by subsection (a) shall include the following: (1)(A) An assessment of whether and to what extent the capabilities, capacity, and composition of the carrier air wings in existence as of the date of plan meet the requirements of the National Defense Strategy; and (B) a plan to address any known shortfalls of such carrier wings, including shortfalls with respect to aerial refueling aircraft capacity and strike-fighter combat radius. (2) An operational risk assessment and risk mitigation plan regarding the nine carrier air wings that, as of the date of the plan, support combatant commander steady-state peacetime and potential major contingency requirements. (3) An explanation of when the Secretary of the Navy will field a minimum of 10 carrier air wings in accordance with section 8062(e) of title 10, United States Code. (4) An identification and explanation of the role of autonomous and remotely-piloted aircraft, including the MQ-25 aircraft, and other potential capabilities and platforms planned to be fielded in future carrier air wings. (5) A detailed deck and hangar space plan that supports realistic peacetime steady-state or contingency su",https://www.congress.gov/bill/117th-congress/senate-bill/1605/text,en,"Strategies: Government study or report, Applications: Government: military and public safety"
218,"National Defense Authorization Act for Fiscal Year 2022, Section 246 (""Report on autonomy integration in major weapon systems"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-12-27,2021,12,positive,0.6394,low,0.1667,228,1.0,Enacted,"SEC. 246. REPORT ON AUTONOMY INTEGRATION IN MAJOR WEAPON SYSTEMS. (a) Report Required.--Not later than one year after the date of the enactment of this Act, the Secretary of Defense shall submit to the congressional defense committees a report on activities to resource and integrate autonomy software into appropriate systems to enable the continued operational capability of such systems in GPS-denied environments by fiscal year 2025. (b) Elements.--The report required under subsection (a) shall include-- (1) a list of systems, to be selected by the Secretary of Defense, which can be integrated with autonomy software as described in subsection (a) by fiscal year 2025; (2) timelines for integrating autonomy software into the systems as identified under paragraph (1); (3) funding requirements related to the development, acquisition, and testing of autonomy software for such systems; (4) plans to leverage advanced artificial intelligence technologies, as appropriate, for such systems; (5) plans for ensuring the safety and security of such systems equipped with autonomy software, including plans for testing, evaluation, validation, and verification of such systems; and (6) a list of Department of Defense policies in effect as of the date of the report that would need to be modified or revoked in order to implement the software integration described in subsection (a). (c) Form.--The report required under subsection (a) shall be submitted in unclassified form, but may include a clas",https://www.congress.gov/bill/117th-congress/senate-bill/1605/text,en,"Risk factors: Safety, Risk factors: Security, Harms: Harm to health/safety, Strategies: Evaluation, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Government study or report, Applications: Government: military and public safety"
220,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title VIII, Section 801 (""Report on acquisition risk assessment and mitigation as part of Adaptive Acquisition Framework implementation"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,negative,-0.3885,low,0.0556,210,1.0,Enacted,"SEC. 801. REPORT ON ACQUISITION RISK ASSESSMENT AND MITIGATION AS PART OF ADAPTIVE ACQUISITION FRAMEWORK IMPLEMENTATION. (a) IN GENERAL.—Each service acquisition executive shall submit to the Secretary of Defense, the Under Secretary of Defense for Acquisition and Sustainment, the Under Secretary of Defense for Research and Engineering, and the Chief Information Officer of the Department of Defense a report on how such service acquisition executive is, with respect to the risks in acquisition programs described in subsection (b)— (1) assessing such risks; (2) mitigating such risks; and (3) reporting within the Department of Defense and to Congress on such risks. (b) ACQUISITION PROGRAM RISKS.—The risks in acquisition programs described in this subsection are the following: (1) Technical risks in engineering, software, manufacturing and testing. (2) Integration and interoperability risks, including complications related to systems working across multiple domains while using machine learning and artificial intelligence capabilities to continuously change and optimize system performance. (3) Operations and sustainment risks, including as mitigated by appropriate sustainment planning earlier in the lifecycle of a program, access to technical data, and intellectual property rights. (4) Workforce and training risks, including consideration of the role of contractors as part of the total workforce. (5) Supply chain risks, including cybersecurity, foreign control and ownership of key",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Risk factors: Reliability, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Government study or report, Applications: Government: military and public safety"
221,"William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Division A, Title LXII, Section 6211 (""Financial crimes tech symposium"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2021-01-01,2021,1,positive,0.7363,low,0.0,203,1.0,Enacted,"SEC. 6211. FINANCIAL CRIMES TECH SYMPOSIUM. (a) PURPOSE.—The purposes of this section are to— (1) promote greater international collaboration in the effort to prevent and detect financial crimes and suspicious activities; and (2) facilitate the investigation, development, and timely adoption of new technologies aimed at preventing and detecting financial crimes and other illicit activities. (b) PERIODIC MEETINGS.—The Secretary shall, in coordination with the Subcommittee on Innovation and Technology established under subsection (d) of section 1564 of the Annunzio-Wylie Anti-Money Laundering Act, as added by section 6207 of this division, periodically convene a global anti-money laundering and financial crime symposium focused on how new technology can be used to more effectively combat financial crimes and other illicit activities. (c) ATTENDEES.—Attendees at each symposium convened under this section shall include domestic and international financial regulators, senior executives from regulated firms, technology providers, representatives from law enforcement and national security agencies, academic and other experts, and other individuals that the Secretary determines are appropriate. (d) PANELS.—At each symposium convened under this section, the Secretary shall convene panels in order to review new technologies and permit attendees to demonstrate proof of concept. (e) IMPLEMENTATION AND REPORTS.—The Secretary shall, to the extent practicable and necessary, work to provide",https://www.congress.gov/116/plaws/publ283/PLAW-116publ283.pdf,en,"Strategies: Evaluation, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Government study or report, Strategies: Convening, Strategies: Governance development, Applications: Government: judicial and law enforcement"
223,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 557 (""Study and report on professional military education"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9382,low,0.0,230,1.0,Enacted,"SEC. 557. STUDY AND REPORT ON PROFESSIONAL MILITARY EDUCATION. (a) Report.--Not later than December 1, 2025, the Secretary of Defense, in coordination with the Chairman of the Joint Chiefs of Staff and the Secretaries of the military departments, shall submit to the Committees on Armed Services of the Senate and House of Representatives a report on the effectiveness of PME in educating officers of the Armed Forces. (b) Elements.--The Secretary of Defense shall include in the report the following elements: (1) Definitions; purpose statement.--In order to improve readiness and create a culture of lifelong learning for PME students and faculty-- (A) recommendations regarding whether to define PME, or to revise existing definitions in section 2151 of title 10, United States Code; and (B) a purpose statement for PME. (2) Course of study.--With regards to a course of study in PME-- (A) an analysis of, and legislative recommendations regarding, the existing three-phase approach to JPME under section 2154 of title 10, United States Code. (B) legislative recommendations regarding developing a statutory three-phase approach for PME other than JPME, similar to such approach for JPME; and (C) a proposed career learning plan, provided to an officer every two years, to track the progress of such officer in achieving PME and JPME outcomes and other career milestones. (3) Curriculum evaluation.--An evaluation of curricula of institutions of PME, including-- (A) compliance with subject matter",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Government support: AI workforce-related"
224,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 835 (""Curricula on software acquisitions and cybersecurity software or hardware acquisitions for covered individuals"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9042,low,0.0,189,1.0,Enacted,"SEC. 835. CURRICULA ON SOFTWARE ACQUISITIONS AND CYBERSECURITY SOFTWARE OR HARDWARE ACQUISITIONS FOR COVERED INDIVIDUALS. (a) Curricula.--The President of the Defense Acquisition University, shall supplement existing training curricula related to software acquisitions and cybersecurity software or hardware acquisitions and offer such curricula to covered individuals to increase digital literacy related to such acquisitions by developing the ability of such covered individuals to use technology to identify, critically evaluate, and synthesize data and information related to such acquisitions. (b) Elements.--Curricula developed pursuant to subsection (a) shall provide information on-- (1) cybersecurity, information technology systems, computer networks, cloud computing, artificial intelligence, machine learning, distributed ledger technologies, and quantum technologies; (2) cybersecurity threats and capabilities; (3) activities that encompass the full range of threat reduction, vulnerability reduction, deterrence, incident response, resiliency, and recovery policies and activities, including activities relating to computer network operations, information assurance, military missions, and intelligence missions to the extent such activities relate to the security and stability of cyberspace; and (4) the industry best practices relating to software acquisitions and cybersecurity software or hardware acquisitions. (c) Such plan shall include a list of resources required for and cos",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Government support: AI workforce-related, Applications: Government: military and public safety"
225,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 861 (""Strategy for increasing competitive opportunities for certain critical technologies"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.981,low,0.0,216,1.0,Enacted,"SEC. 861. STRATEGY FOR INCREASING COMPETITIVE OPPORTUNITIES FOR CERTAIN CRITICAL TECHNOLOGIES. (a) Strategy.--Not later than one year after the date of the enactment of this Act, the Secretary of Defense shall submit to the congressional defense committees a comprehensive strategy to-- (1) increase competitive opportunities available for appropriate United States companies to transition critical technologies into major weapon systems and other programs of record; and (2) enhance the integrity and diversity of the defense industrial base. (b) Elements.--The strategy required under subsection (a) shall include the following: (1) A description of methods to increase opportunities for appropriate United States companies to develop end items of critical technologies for major weapon systems, rapidly prototype such end items, and conduct activities that would support the transition of such end items into major weapon systems and programs of record, including-- (A) continuous experimentation or military utility assessments to improve such end items; (B) evaluation of how to integrate existing commercial capabilities relating to such end items of appropriate United States companies or entities in the defense industrial base into major weapon systems and programs of record in the Department of Defense; (C) efforts that improve the ability of appropriate United States companies or entities in the defense industrial base to maintain, afford, or manufacture major weapon systems or compon",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Government study or report, Applications: Government: military and public safety"
226,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 911 (""Updates to management reform framework"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.875,low,0.0,130,1.0,Enacted,"SEC. 911. UPDATES TO MANAGEMENT REFORM FRAMEWORK. Section 125a of title 10, United States Code, is amended-- (1) in subsection (c)-- (A) in paragraph (1), by striking 2022'' and inserting 2023''; and (B) in paragraph (3), by inserting the Director for Administration and Management of the Department of Defense,'' after the Chief Information Officer of the Department of Defense,''; and (2) in subsection (d)-- (A) by redesignating paragraph (6) as paragraph (9); and (B) by inserting after paragraph (5) the following new paragraphs: ``(6) Development and implementation of a uniform methodology for tracking and assessing cost savings and cost avoidance from reform initiatives. ``(7) Implementation of reform-focused research to improve management and administrative science. ``(8) Tracking and implementation of technological approaches to improve management decision-making, such as artificial intelligence tools.''.",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Government study or report, Strategies: Governance development, Applications: Government: military and public safety, Applications: Government: other applications/unspecified"
227,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 916 (""Strategic management dashboard demonstration"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.963,low,0.0,228,1.0,Enacted,"SEC. 916. STRATEGIC MANAGEMENT DASHBOARD DEMONSTRATION. (a) In General.--Not later than one year after the date of the enactment of this Act, the Secretary of Defense shall conduct a demonstration of a strategic management dashboard to automate the data collection and data visualization of the primary management goals of the Department of Defense. (b) Elements.--The Secretary of Defense shall ensure that the strategic management dashboard demonstrated under subsection (a) includes the following: (1) The capability for real-time monitoring of the performance of the Department of Defense in meeting the management goals of the Department. (2) An integrated analytics capability, including the ability to dynamically add or upgrade new capabilities when needed. (3) Integration with the framework required by subsection (c) of section 125a of title 10, United States Code, for measuring the progress of the Department toward covered elements of reform (as defined in subsection (d) of that section). (4) Incorporation of the elements of the strategic management plan required by section 904(d) of the National Defense Authorization Act of Fiscal Year 2008 (Public Law 110- 181; 10 U.S.C. note prec. 2201), as derived from automated data feeds from existing information systems and databases. (5) Incorporation of the elements of the most recent annual performance plan of the Department required by section 1115(b) of title 31, United States Code, and the most recent update on performance of the",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Evaluation, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Pilots and testbeds, Strategies: Performance requirements, Applications: Government: military and public safety"
228,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 1092 (""National Commission on the Future of the Navy"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.8807,low,0.0,234,1.0,Enacted,"SEC. 1092. NATIONAL COMMISSION ON THE FUTURE OF THE NAVY. (a) Establishment.-- (1) In general.--There is established an independent commission in the legislative branch to be known as the Commission on the Future of the Navy'' (in this section referred to as the Commission''). (2) Duties of commission.-- (A) Study on naval force structure.-- (i) In general.--The Commission shall undertake a comprehensive study of the structure of the Navy and policy assumptions related to the size and force mixture of the Navy, in order-- (I) to make recommendations on the size and force mixture of ships; and (II) to make recommendations on the size and force mixture of naval aviation.(ii) Considerations.--In undertaking the study required by this subsection, the Commission shall carry out each of the following: (I) An evaluation and identification of a structure for the Navy that-- (aa) has the depth and scalability to meet current and anticipated requirements of the combatant commands; (bb) assumes four different funding levels of: fiscal year 2023 appropriated plus inflation; fiscal year 2023 appropriated with 3-5 percent real growth; such as is necessary to build, man, maintain and modernize the fleet required by section 1025 of the National Defense Authorization Act for 2018 (Public Law 115- 91); and notionally unconstrained to meet the needs of the National Defense Strategy including a particular focus on the areas of responsibility of United States Indo-Pacific Command and United State",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Evaluation, Strategies: Government study or report, Strategies: New institution, Applications: Government: military and public safety"
229,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 1535 (""Department of Defense Cyber and Digital Service Academy"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9364,low,0.0,205,1.0,Enacted,"SEC. 1535. DEPARTMENT OF DEFENSE CYBER AND DIGITAL SERVICE ACADEMY. (a) Establishment.-- (1) In general.--The Secretary of Defense, in consultation with the Secretary of Homeland Security and the Director of the Office of Personnel and Management, shall establish a program to provide financial support for pursuit of programs of education at institutions of high education in covered disciplines. (2) Covered disciplines.--For purposes of the Program, a covered discipline is a discipline that the Secretary of Defense determines is critically needed and is cyber- or digital technology-related, including the following: (A) Computer-related arts and sciences. (B) Cyber-related engineering. (C) Cyber-related law and policy. (D) Applied analytics related sciences, data management, and digital engineering, including artificial intelligence and machine learning. (E) Such other disciplines relating to cyber, cybersecurity, digital technology, or supporting functions as the Secretary of Defense considers appropriate. (3) Designation.--The program established under paragraph (1) shall be known as the Department of Defense Cyber and Digital Service Academy'' (in this section referred to as the Program''). (b) Program Description and Components.--The Program shall-- (1) provide scholarships through institutions of higher education to students who are enrolled in programs of education at such institutions leading to degrees or specialized program certifications in covered disciplines; and (2",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Government support, Strategies: Government support: AI workforce-related, Strategies: New institution, Applications: Government: military and public safety"
230,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 6504 (""Annual report on concentrated reeducation camps in the Xinjiang Uyghur Autonomous Region of the People's Republic of China"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,negative,-0.296,low,0.1667,220,1.0,Enacted,"SEC. 6504. ANNUAL REPORT ON CONCENTRATED REEDUCATION CAMPS IN THE XINJIANG UYGHUR AUTONOMOUS REGION OF THE PEOPLE'S REPUBLIC OF CHINA. (a) Definitions.--In this section: (1) Appropriate committees of congress.--The term ``appropriate committees of Congress'' means-- (A) the congressional intelligence committees; (B) the Committee on Foreign Relations, the Committee on Banking, Housing, and Urban Affairs, and the Committee on Appropriations of the Senate; and (C) the Committee on Foreign Affairs, the Committee on Financial Services, and the Committee on Appropriations of the House of Representatives. (2) Covered camp.--The term covered camp'' means a detention camp, prison, forced labor camp, or forced labor factory located in the Xinjiang Uyghur Autonomous Region of the People's Republic of China, referred to by the Government of the People's Republic of China as concentrated reeducation camps'' or ``vocational training centers''. (b) Annual Report Required.--Not later than 120 days after the date of the enactment of this Act, and annually thereafter for 5 years, the Director of National Intelligence, in consultation with such heads of elements of the intelligence community as the Director considers appropriate, shall submit to the appropriate committees of Congress a report on the status of covered camps. (c) Elements.--Each report required by subsection (b) shall include the following: (1) An identification of the number and geographic location of covered camps and an estim",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Harms: Harm to health/safety, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Government study or report, Applications: Government: judicial and law enforcement"
231,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 6505 (""Assessments of production of semiconductors by the People's Republic of China"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9371,low,0.1667,214,1.0,Enacted,"SEC. 6505. ASSESSMENTS OF PRODUCTION OF SEMICONDUCTORS BY THE PEOPLE'S REPUBLIC OF CHINA. (a) Definitions.--In this section: (1) Appropriate committees of congress.--The term ``appropriate committees of Congress'' means-- (A) the congressional intelligence committees; (B) the Committee on Armed Services, the Committee on Foreign Relations, the Committee on Banking, Housing, and Urban Affairs, the Committee on Commerce, Science, and Transportation, the Committee on Homeland Security and Governmental Affairs, and the Committee on Appropriations of the Senate; and (C) the Committee on Armed Services, the Committee on Foreign Affairs, the Committee on Financial Services, the Committee on Science, Space, and Technology, the Committee on Energy and Commerce, the Committee on Homeland Security, and the Committee on Appropriations of the House of Representatives. (2) Legacy semiconductor.--The term ``legacy semiconductor'' has the meaning given such term in section 9902(a)(6)(A) of the William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021 (15 U.S.C. 4652(a)(6)(A)). (b) In General.--Not later than 60 days after the date of the enactment of this Act, and annually thereafter for 3 years, the Director of National Intelligence shall submit to the appropriate committees of Congress an assessment of progress by the People's Republic of China in global competitiveness in the production of semiconductors by Chinese firms, including any subsidiary, affiliate, or s",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Risk factors: Reliability, Risk factors: Security, Risk factors: Transparency, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure: In standard form, Strategies: Government study or report, Strategies: Convening, Applications: Manufacturing and process automation, Applications: Energy and utilities"
232,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 6812 (""Increased intelligence-related engineering, research, and development capabilities of minority institutions"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9942,low,0.0,188,1.0,Enacted,"SEC. 6812. INCREASED INTELLIGENCE-RELATED ENGINEERING, RESEARCH, AND DEVELOPMENT CAPABILITIES OF MINORITY INSTITUTIONS. (a) Plan.-- (1) Requirement.--The Director of National Intelligence shall develop a plan to promote intelligence-related engineering, research, and development activities at covered institutions for the purpose of contributing toward the research necessary to achieve the intelligence advantage of the United States. (2) Elements.--The plan under paragraph (1) shall include the following: (A) An assessment of opportunities to support engineering, research, and development at covered institutions in computer sciences, including artificial intelligence, quantum computing, and machine learning, and synthetic biology and an assessment of opportunities to support the associated workforce and physical research infrastructure of such institutions. (B) An assessment of opportunities to enhance the ability of covered institutions-- (i) to participate in intelligence-related engineering, research, and development activities; and(ii) to effectively compete for intelligence- related engineering, research and development contracts in support of the most urgent research requirements of the intelligence community. (C) An assessment of the activities and investments the Director determines necessary-- (i) to expand opportunities for covered institutions to partner with other research organizations and educational institutions that the intelligence community frequently partner",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Strategies: Convening, Strategies: Governance development, Applications: Government: military and public safety"
233,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 9218 (""Report on changes to the Foreign Service Officer Test"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.4767,low,0.0,126,1.0,Enacted,"SEC. 9218. REPORT ON CHANGES TO THE FOREIGN SERVICE OFFICER TEST. Not later than December 1, 2023, the Secretary shall submit a report to the appropriate congressional committees describing and justifying any changes made during fiscal years 2022 and 2023 to the Foreign Service entry process, including-- (1) the use of artificial intelligence, including deep textual analysis, in any portion of the entry process and its impacts on recruitment into the Foreign Service; (2) the use of virtual formats for any portion of the entry process and its impacts on recruitment into the Foreign Service; and (3) the entities, groups, or individuals informed of or consulted on any changes to the Foreign Service entry process during the 1-year period immediately preceding the implementation of such changes.",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About evaluation, Strategies: Government study or report, Applications: Business services and analytics, Applications: Government: other applications/unspecified"
234,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 9506 (""Cybersecurity recruitment and retention"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9843,low,0.0,211,1.0,Enacted,"SEC. 9506. CYBERSECURITY RECRUITMENT AND RETENTION. (a) Sense of Congress.--It is the sense of Congress that improving computer programming language proficiency will improve-- (1) the cybersecurity effectiveness of the Department; and (2) the ability of foreign service officers to engage with foreign audiences on cybersecurity matters. (b) Technology Talent Acquisition.-- (1) Establishment.--The Secretary shall establish positions within the Bureau of Global Talent Management that are solely dedicated to the recruitment and retention of Department personnel with backgrounds in cybersecurity, engineering, data science, application development, artificial intelligence, critical and emerging technology, and technology and digital policy. (2) Goals.--The goals of the positions described in paragraph (1) shall be-- (A) to fulfill the critical need of the Department to recruit and retain employees for cybersecurity, digital, and technology positions; (B) to actively recruit relevant candidates from academic institutions, the private sector, and related industries; (C) to work with the Office of Personnel Management and the United States Digital Service to develop and implement best strategies for recruiting and retaining technology talent; and (D) to inform and train supervisors at the Department on the use of the authorities listed in subsection (c)(1). (3) Implementation plan.--Not later than 180 days after the date of the enactment of this Act, the Secretary shall submit a plan",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Government support: AI workforce-related"
235,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 11504 (""At-sea recovery operations pilot program"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9169,medium,0.3889,216,1.0,Enacted,"SEC. 11504. AT-SEA RECOVERY OPERATIONS PILOT PROGRAM. (a) In General.--The Secretary shall conduct a pilot program to evaluate the potential use of remotely controlled or autonomous operation and monitoring of certain vessels for the purposes of-- (1) better understanding the complexities of such at-sea operations and potential risks to navigation safety, vessel security, maritime workers, the public, and the environment; (2) gathering observational and performance data from monitoring the use of remotely-controlled or autonomous vessels; and(3) assessing and evaluating regulatory requirements necessary to guide the development of future occurrences of such operations and monitoring activities. (b) Duration and Effective Date.--The duration of the pilot program established under this section shall be not more than 5 years beginning on the date on which the pilot program is established, which shall be not later than 180 days after the date of enactment of this Act. (c) Authorized Activities.--The activities authorized under this section include-- (1) remote over-the-horizon monitoring operations related to the active at-sea recovery of spaceflight components on an unmanned vessel or platform; (2) procedures for the unaccompanied operation and monitoring of an unmanned spaceflight recovery vessel or platform; and (3) unmanned vessel transits and testing operations without a physical tow line related to space launch and recovery operations, except within 12 nautical miles of a p",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Risk factors: Reliability, Risk factors: Safety, Risk factors: Security, Risk factors: Security: Cybersecurity, Harms: Harm to health/safety, Harms: Harm to property, Harms: Ecological harm, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Government study or report, Strategies: Pilots and testbeds, Strategies: Convening"
236,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 862 (""Key advanced system development industry days"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9695,low,0.0,209,1.0,Enacted,"SEC. 862. KEY ADVANCED SYSTEM DEVELOPMENT INDUSTRY DAYS. (a) In General.--Not later than March 1, 2023, and every 180 days thereafter, the each Secretary of a military department shall ensure that such military department conducts an outreach event to-- (1) collaborate with the private sector on present current and future opportunities with respect to key advanced system development areas; (2) raise awareness within the private sector of-- (A) key advanced system development areas; and (B) capability needs and existing and potential requirements related to the key advanced system development areas; and (3) raise awareness within such military department of potential material solutions for capability needs and existing and potential requirements related to key advanced system development areas. (b) Responsibilities.-- (1) Service chiefs.--For each event a military department conducts under subsection (a), the Service Chief concerned shall, for each key advanced system development area, perform the following: (A) Identify related and potentially related existing, planned, or potential military requirements, including urgent and emergent operational needs. (B) Identify and describe related and potentially related needs or gaps in the capabilities of the military department to carry out the missions of the military department, including warfighting and combat support capabilities. (C) Identify and describe related and potentially related exercise, demonstration, or experimentatio",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Convening, Applications: Government: military and public safety"
237,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 6513 (""Lead intelligence community coordinator for countering and neutralizing proliferation of Iran-origin unmanned aircraft systems"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9793,low,0.1111,211,1.0,Enacted,"SEC. 6513. LEAD INTELLIGENCE COMMUNITY COORDINATOR FOR COUNTERING AND NEUTRALIZING PROLIFERATION OF IRAN-ORIGIN UNMANNED AIRCRAFT SYSTEMS. (a) Definitions.--In this section: (1) Appropriate committees of congress.--The term ``appropriate committees of Congress'' means-- (A) the congressional intelligence committees; (B) the Committee on Armed Services, the Committee on Foreign Relations, and the Subcommittee on Defense of the Committee on Appropriations of the Senate; and (C) the Committee on Armed Services, the Committee on Foreign Affairs, and the Subcommittee on Defense of the Committee on Appropriations of the House of Representatives. (2) Five eyes partnership.--The term ``Five Eyes Partnership'' means the intelligence alliance comprising Australia, Canada, New Zealand, the United Kingdom, and the United States. (3) Unmanned aircraft system.--The term ``unmanned aircraft system'' includes an unmanned powered aircraft (including communication links and the components that control the unmanned aircraft), that-- (A) does not carry a human operator; (B) may fly autonomously or be piloted remotely; (C) may be expendable or recoverable; and (D) may carry a lethal payload or explode upon reaching a designated location. (b) Coordinator.-- (1) Designation.--Not later than 30 days after the date of enactment of this Act, the Director of National Intelligence shall designate an official from an element of the intelligence community to serve as the lead intelligence community coordi",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Risk factors: Safety, Harms: Harm to health/safety, Strategies: Government study or report, Strategies: Convening, Applications: Government: military and public safety"
238,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 10305 (""Modifications to the ocean exploration program of the National Oceanic and Atmospheric Administration"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.8567,low,0.0,211,1.0,Enacted,"SEC. 10305. MODIFICATIONS TO THE OCEAN EXPLORATION PROGRAM OF THE NATIONAL OCEANIC AND ATMOSPHERIC ADMINISTRATION. (a) Purpose.--Section 12001 of the Omnibus Public Land Management Act of 2009 (33 U.S.C. 3401) is amended by striking ``and the national undersea research program''. (b) Program Established.--Section 12002 of such Act (33 U.S.C. 3402) is amended-- (1) in the first sentence, by striking ``and undersea''; and (2) in the second sentence, by striking and undersea research and exploration'' and inserting research and ocean exploration and characterization efforts''. (c) Powers and Duties of the Administrator.-- (1) In general.--Section 12003(a) of such Act (33 U.S.C. 3403(a)) is amended-- (A) in the matter preceding paragraph (1), by inserting , in consultation with the Ocean Policy Committee established under section 8932 of title 10, United States Code,'' after Administration''; (B) in paragraph (1)-- (i) by striking voyages'' and inserting expeditions''; (ii) by striking Federal agencies'' and all that follows through and survey'' and inserting ``Federal and State agencies, Tribal Governments, private industry, academia (including secondary schools, community colleges, and universities), and nongovernmental organizations, to map, explore, and characterize''; and (iii) by inserting characterize,'' after observe,''; (C) in paragraph (2), by inserting of the exclusive economic zone'' after deep ocean regions''; (D) in paragraph (3), by striking voyages'' and inserting",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Government support, Strategies: Government support: For R&D"
239,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 11225 (""Establishment of unmanned system program and autonomous control and computer vision technology project"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9364,low,0.0,215,1.0,Enacted,"SEC. 11225. ESTABLISHMENT OF UNMANNED SYSTEM PROGRAM AND AUTONOMOUS CONTROL AND COMPUTER VISION TECHNOLOGY PROJECT. (a) In General.--Section 319 of title 14, United States Code, is amended to read as follows: ``Sec. 319. Unmanned system program and autonomous control and computer vision technology project ``(a) Unmanned System Program.--Not later than 2 years after the date of enactment of this section, the Secretary shall establish, under the control of the Commandant, an unmanned system program for the use by the Coast Guard of land-based, cutter-based, and aircraft-based unmanned systems for the purpose of increasing effectiveness and efficiency of mission execution. ``(b) Autonomous Control and Computer Vision Technology Project.-- ``(1) In general.--The Commandant shall conduct a project to retrofit 2 or more existing Coast Guard small boats deployed at operational units with-- ``(A) commercially available autonomous control and computer vision technology; and ``(B) such sensors and methods of communication as are necessary to control, and technology to assist in conducting, search and rescue, surveillance, and interdiction missions. ``(2) Data collection.--As part of the project required under paragraph (1), the Commandant shall collect and evaluate field-collected operational data from the retrofit described in such paragraph to inform future requirements. ``(3) Briefing.--Not later than 180 days after the date on which the project required under paragraph (1) is compl",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Strategies: Evaluation, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Government study or report, Strategies: Government support, Strategies: Pilots and testbeds, Applications: Government: military and public safety"
240,"National Defense Authorization Act for Fiscal Year 2024, Section 224 (""Next Generation Air Dominance family of systems development program accountability matrices"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.9175,low,0.0556,218,1.0,Enacted,"SEC. 224. NEXT GENERATION AIR DOMINANCE FAMILY OF SYSTEMS DEVELOPMENT PROGRAM ACCOUNTABILITY MATRICES. (a) Submittal of Matrices.--Concurrent with the submission of the budget of the President to Congress pursuant to section 1105(a) of title 31, United States Code, for fiscal year 2025-- (1) the Secretary of the Air Force shall submit to the congressional defense committees and the Comptroller General of the United States the matrices described in subsection (b) relating to the Next Generation Air Dominance piloted fighter aircraft and the autonomous, uncrewed Collaborative Combat Aircraft programs of the Air Force; and (2) the Secretary of the Navy shall submit to the congressional defense committees and the Comptroller General of the United States the matrices described in subsection (b) relating to the Next Generation Air Dominance piloted fighter aircraft and the autonomous, uncrewed Collaborative Combat Aircraft programs of the Navy and the Marine Corps. (b) Matrices Described.--The matrices described in this subsection are the following: (1) Engineering manufacturing and development goals.--A matrix that identifies, in six month increments, key milestones, development and testing events, and specific performance goals for the engineering manufacturing and development phase (referred to in this section as the ``EMD phase'') of the programs described in subsection (a), and which shall be subdivided, at a minimum, according to the following: (A) Technology readiness levels",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Risk factors: Transparency, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Applications: Government: military and public safety"
241,"National Defense Authorization Act for Fiscal Year 2024, Section 1090 (""Conduct of weather reconnaissance in the United States"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2023-12-22,2023,12,positive,0.9158,low,0.0,208,1.0,Enacted,"SEC. 1090. CONDUCT OF WEATHER RECONNAISSANCE IN THE UNITED STATES. (a) Conduct of Reconnaissance.-- (1) In general.--Subject to the availability of appropriations, the 53rd Weather Reconnaissance Squadron of the Air Force Reserve Command and the Administrator of the National Oceanic and Atmospheric Administration may use aircraft, personnel, and equipment necessary to meet the mission requirements of-- (A) the National Hurricane Operations Plan; and (B) the National Winter Seasons Operation plan, as long as aircraft are able to fully meet needs for hurricane monitoring response. (2) Activities.--If the 53rd Weather Reconnaissance Squadron of the Air Force Reserve Command exercises the authority under paragraph (1), such Squadron, in consultation with the Administrator of the National Oceanic and Atmospheric Administration and appropriate line offices of the National Oceanic and Atmospheric Administration, shall use such authority to-- (A) improve the accuracy and timeliness of observations of storms that result in large amounts of precipitation, such as tropical cyclones and atmospheric rivers, to support the forecast and warning services of the National Weather Service of the United States; (B) collect data in data-sparse regions where conventional observations are lacking; (C) support water management decision-making and flood forecasting through the execution of targeted in- situ measurements, airborne dropsondes, buoys, autonomous platform observations, satellite observat",https://www.congress.gov/bill/118th-congress/house-bill/2670/text,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Performance requirements, Applications: Government: military and public safety"
244,"An Act Concerning Artificial Intelligence, Automated Decision-Making and Personal Data Privacy",Connecticut,United States,State governments,U.S. state and local documents,Law/Act,2023-06-07,2023,6,positive,0.9778,low,0.1667,224,1.0,Enacted,"AN ACT CONCERNING ARTIFICIAL INTELLIGENCE, AUTOMATED DECISION-MAKING AND PERSONAL DATA PRIVACY. Be it enacted by the Senate and House of Representatives in General Assembly convened: Section 1. (NEW) (Effective July 1, 2023) (a) For the purposes of this section: (1) ""Artificial intelligence"" means (A) an artificial system that (i) performs tasks under varying and unpredictable circumstances without significant human oversight or can learn from experience and improve such performance when exposed to data sets, (ii) is developed in any context, including, but not limited to, software or physical hardware, and solves tasks requiring human-like perception, cognition, planning, learning, communication or physical action, or (iii) is designed to (I) think or act like a human, including, but not limited to, a cognitive architecture or neural network, or (II) act rationally, including, but not limited to, an intelligent software agent or embodied robot that achieves goals using perception, planning, reasoning, learning, communication, decision-making or action, or (B) a set of techniques, including, but not limited to, machine learning, that is designed to approximate a cognitive task; and (2) ""State agency"" has the same meaning as provided in section 4d-1 of the general statutes. (b) (1) Not later than December 31, 2023, and annually thereafter, the Department of Administrative Services shall conduct an inventory of all systems that employ artificial intelligence and are in use by a",https://www.cga.ct.gov/2023/ACT/PA/PDF/2023PA-00016-R00SB-01103-PA.PDF,en,"Risk factors: Bias, Risk factors: Transparency, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Government study or report, Strategies: Convening, Strategies: Governance development, Strategies: New institution, Applications: Government: judicial and law enforcement, Applications: Government: other applications/unspecified"
247,"An act to amend Chapter 12 of Title 31 of the Official Code of Georgia Annotated, relating to the control of hazardous conditions, preventable diseases, and metabolic disorders [...]",Georgia,United States,State governments,U.S. state and local documents,Law/Act,2023-05-02,2023,5,positive,0.4648,low,0.1111,236,0.7,Enacted,"House Bill 203 (AS PASSED HOUSE AND SENATE) By: Representatives Newton of the 127th, Beverly of the 143rd, Hawkins of the 27th, Stephens of the 164th, and Cooper of the 45th A BILL TO BE ENTITLED AN ACT To amend Chapter 12 of Title 31 of the Official Code of Georgia Annotated, relating to the control of hazardous conditions, preventable diseases, and metabolic disorders, so as to revise provisions relating to restrictions on the sale and dispensing of contact lenses with respect to physicians; to revise definitions; to provide requirements for assessment mechanisms; to provide for rules and regulations; to provide for statutory construction; to provide for violations and penalties; to provide for related matters; to repeal conflicting laws; and for other purposes. BE IT ENACTED BY THE GENERAL ASSEMBLY OF GEORGIA: SECTION 1. Chapter 12 of Title 31 of the Official Code of Georgia Annotated, relating to the control of hazardous conditions, preventable diseases, and metabolic disorders, is amended by revising Code Section 31-12-12, relating to restrictions on the sale or dispensing of contact lenses, as follows: ""31-12-12. (a) As used in this Code section, the term: (1) 'Assessment mechanism' means automated or virtual equipment, application, or technology designed to be used on a telephone, a computer, or an internet accessible device that may be used either in person or via telemedicine to conduct an eye assessment, and includes artificial intelligence devices and any equipment",https://www.legis.ga.gov/api/legislation/document/20232024/213440,en,"Harms: Harm to health/safety, Harms: Financial loss, Strategies: Disclosure, Strategies: Disclosure: In standard form, Strategies: Performance requirements, Strategies: Licensing, registration, and certification, Incentives: Fines, Applications: Medicine, life sciences and public health"
266,Internet Information Service Algorithmic Recommendation Management Provisions,Chinese central government,China,China,Chinese law and policy,Other,2022-03-01,2022,3,positive,0.9612,medium,0.6667,196,1.0,Enacted,"Internet Information Service Algorithmic Recommendation Management Provisions Chapter I: General Provisions Article 1: In order to standardize Internet information service algorithmic recommendation activities, carry forward the Socialist core value view, safeguard national security and the social and public interest, protect the lawful rights and interests of citizens, legal persons, and other organizations, and stimulate the healthy development of Internet information services; and on the basis of the “Cybersecurity Law of the People’s Republic of China,"" the “Data Security Law of the People’s Republic of China,"" the “Personal Information Protection Law of the People’s Republic of China,"" the “Internet Information Service Management Rules,” and other such laws and administrative regulations; these Provisions are formulated. Article 2: These Provisions apply to the use of algorithmic recommendation technology to provide Internet information services (hereafter abbreviated as algorithmic recommendation services) within the mainland territory of the People’s Republic of China. Where laws and administrative regulations contain other provisions, those provisions are to be followed. The use of algorithmic recommendation technology as mentioned in the previous Paragraph refers to the use of generative or synthetic–type, personalized recommendation–type, ranking and selection–type, search filter–type, dispatching and decision-making–type, and other such algorithmic technologies to",https://digichina.stanford.edu/work/translation-internet-information-service-algorithmic-recommendation-management-provisions-effective-march-1-2022/,en,"Applications: Networking and telecommunications, Risk factors: Security, Harms: Detrimental content, Strategies: Evaluation, Strategies: Evaluation: Post-market monitoring, Risk factors: Privacy, Strategies: Disclosure, Harms: Harm to health/safety, Strategies: Governance development, Harms: Discrimination, Strategies: Tiering, Strategies: Tiering: Tiering based on impact, Strategies: Tiering: Tiering based on domain of application, Harms: Violation of civil or human rights, including privacy, Applications: Security"
274,"An Act concerning discrimination and automated decision systems and supplementing P.L.1945, c.169 (C.10:5-1 et seq.).",New Jersey,United States,State governments,U.S. state and local documents,Law/Act,2022-02-10,2022,2,positive,0.9696,low,0.1111,217,0.7,Proposed,"An Act concerning discrimination and automated decision systems and supplementing P.L.1945, c.169 (C.10:5-1 et seq.). Be It Enacted by the Senate and General Assembly of the State of New Jersey: 1. As used in this act: “Automated decision system” means a computational process, including one derived from machine learning, statistics, or other data processing or artificial intelligence techniques, that makes a decision or facilitates human decision making. “Health care provider"" means an individual or entity, which, acting within the scope of its licensure or certification, provides health care services, and includes, but is not limited to, a physician, dentist, nurse, or other health care professional whose professional practice is regulated pursuant to Title 45 of the Revised Statutes, and a health care facility licensed pursuant to P.L.1971, c.136 (C.26:2H-1 et seq.). “Member of a protected class” means an individual who has one or more characteristics, including race, creed, color, national origin, nationality, ancestry, age, marital status, civil union status, domestic partnership status, affectional or sexual orientation, genetic information, pregnancy, sex, gender identity or expression, disability or atypical hereditary cellular or blood trait of any individual, or liability for service in the armed forces, for which the individual is provided protections against discriminatory practices pursuant to section 11 of P.L.1945, c.169 (C.10:5-12). 2. A person, bank, banking o",https://www.njleg.state.nj.us/bill-search/2022/S1402/bill-text?f=S1500&n=1402_I1,en,"Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Governance development, Incentives: Criminal liability, Incentives: Civil liability, Incentives: Fines, Applications: Medicine, life sciences and public health, Applications: Finance and investment"
275,Block Nuclear Launch by Autonomous Artificial Intelligence Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.9587,low,0.3333,235,1.0,Defunct,"A BILL To prohibit the use of Federal funds to launch a nuclear weapon using an autonomous weapons system that is not subject to meaningful human control, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Block Nuclear Launch by Autonomous Artificial Intelligence Act of 2023”. SEC. 2. Findings. Congress finds the following: (1) Department of Defense Directive 3000.09 (relating to Autonomy in Weapons Systems), dated November 21, 2012, defines “autonomous weapons system” as a weapons system that, once activated, can select and engage targets without further intervention by an operator. (2) Article 3, clause 8 of the Convention on Prohibitions or Restrictions on the Use of Certain Conventional Weapons Which may be Deemed to be Excessively Injurious or to Have Indiscriminate Effects, signed at Geneva October 10, 1980 (commonly known as the“ Convention on Certain Conventional Weapons”) prohibits the indiscriminate use of weapons, which is defined in the Convention on Certain Conventional Weapons as “any placement of such weapons…which may be expected to cause incidental loss of civilian life, injury to civilians, damage to civilian objects, or a combination thereof, which would be excessive in relation to the concrete and direct military advantage anticipated”. (3) Section 5.10 of the Department of Defense Law of War Manual states that “[c]omm",https://www.congress.gov/bill/118th-congress/senate-bill/1394/text,en,"Risk factors: Safety, Harms: Harm to health/safety, Harms: Financial loss, Harms: Harm to property, Harms: Harm to infrastructure, Harms: Ecological harm, Applications: Government: military and public safety"
276,"State of Arizona Senate Bill 1565, An Act Amending Sections 16-442, 16-552 and 16-621, Arizona Revised Statutes; Relating to Conduct of Elections.",Arizona,United States,State governments,U.S. state and local documents,Law/Act,2023-04-18,2023,4,positive,0.9153,low,0.0556,259,1.0,Defunct,"Be it enacted by the Legislature of the State of Arizona: Section 1. Section 16-442, Arizona Revised Statutes, is amended to read: 16-442. Committee approval; adoption of vote tabulating equipment; experimental use; emergency certification A. The secretary of state shall appoint a committee of three persons, to consist of a member of the engineering college at one of the universities, a member of the state bar of Arizona and one person familiar with voting processes in the state, not more than two of whom shall be of the same political party, and at least one of whom shall have at least five years of experience with and shall be able to render an opinion based on knowledge of, training in or education in electronic voting systems, procedures and security. The committee shall investigate and test the various types of vote recording or tabulating machines or devices that may be used under this article. The committee shall submit its recommendations to the secretary of state who shall make final adoption of the type or types, make or makes, model or models to be certified for use in this state. The committee shall serve without compensation. B. Machines or devices used at any election for federal, state or county offices may only be certified for use in this state and may only be used in this state if they comply with the help America vote act of 2002 and if those machines or devices have been tested and approved by a laboratory that is accredited pursuant to the help America vo",https://www.azleg.gov/legtext/56leg/1R/bills/SB1565S.htm,en,"Harms: Violation of civil or human rights, including privacy, Strategies: Performance requirements, Applications: Government: other applications/unspecified"
277,An Act relating to the creation of the artificial intelligence advisory council,Texas,United States,State governments,U.S. state and local documents,Law/Act,2023-06-13,2023,6,positive,0.9848,medium,0.4444,212,1.0,Enacted,"H.B. No. 2060 AN ACT relating to the creation of the artificial intelligence advisory council. BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF TEXAS: SECTION 1. Chapter 2054, Government Code, is amended by adding Subchapter S to read as follows: SUBCHAPTER S. ARTIFICIAL INTELLIGENCE ADVISORY COUNCIL Sec. 2054.621. DEFINITIONS. In this subchapter: (1) ""Algorithm"" means a computerized procedure consisting of a set of steps used to accomplish a determined task. (2) ""Artificial intelligence systems"" means systems capable of: (A) perceiving an environment through data acquisition and processing and interpreting the derived information to take an action or actions or to imitate intelligent behavior given a specific goal; and (B) learning and adapting behavior by analyzing how the environment is affected by prior actions. (3) ""Automated decision system"" means an algorithm, including an algorithm incorporating machine learning or other artificial intelligence techniques, that uses data-based analytics to make or support governmental decisions, judgments, or conclusions. (4) ""Automated final decision system"" means an automated decision system that makes final decisions, judgments, or conclusions without human intervention. (5) ""Automated support decision system"" means an automated decision system that provides information to inform the final decision, judgment, or conclusion of a human decision maker. (6) ""Council"" means the artificial intelligence advisory council established under",https://capitol.texas.gov/tlodocs/88R/billtext/html/HB02060F.htm,en,"Risk factors: Bias, Risk factors: Privacy, Risk factors: Security, Risk factors: Security: Cybersecurity, Risk factors: Transparency, Harms: Financial loss, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About evaluation, Strategies: Disclosure: About inputs"
278,"An Act to amend the general business law, in relation to the management and oversight of personal data (Section 7)",New York,United States,State governments,U.S. state and local documents,Law/Act,2023-02-03,2023,2,positive,0.9702,low,0.2222,224,0.7,Proposed,"1. AUTOMATED DECISION-MAKING. (A) WHENEVER A CONTROLLER MAKES AN AUTO- MATED DECISION INVOLVING SOLELY AUTOMATED PROCESSING THAT MATERIALLY CONTRIBUTES TO A DENIAL OF FINANCIAL OR LENDING SERVICES, HOUSING, PUBLIC ACCOMMODATION, INSURANCE, HEALTH CARE SERVICES, OR ACCESS TO BASIC NECESSITIES, SUCH AS FOOD AND WATER, THE CONTROLLER MUST: (I) DISCLOSE IN A CLEAR, CONSPICUOUS, AND CONSUMER-FRIENDLY MANNER THAT THE DECISION WAS MADE BY A SOLELY AUTOMATED PROCESS; (II) PROVIDE AN AVENUE FOR THE AFFECTED CONSUMER TO APPEAL THE DECI- SION, WHICH MUST AT MINIMUM ALLOW THE AFFECTED CONSUMER TO (A) FORMALLY CONTEST THE DECISION, (B) PROVIDE INFORMATION TO SUPPORT THEIR POSITION, AND (C) OBTAIN MEANINGFUL HUMAN REVIEW OF THE DECISION; AND (III) EXPLAIN THE PROCESS TO APPEAL THE DECISION. (B) A CONTROLLER MUST RESPOND TO A CONSUMER'S APPEAL WITHIN FORTY-FIVE DAYS OF RECEIPT OF THE APPEAL. THAT PERIOD MAY BE EXTENDED ONCE BY FORTY-FIVE ADDITIONAL DAYS WHERE REASONABLY NECESSARY, TAKING INTO ACCOUNT THE COMPLEXITY AND NUMBER OF APPEALS. THE CONTROLLER MUST INFORM THE CONSUMER OF ANY SUCH EXTENSION WITHIN FORTY-FIVE DAYS OF RECEIPT OF THE APPEAL, TOGETHER WITH THE REASONS FOR THE DELAY. (C) (I) A CONTROLLER OR PROCESSOR ENGAGED IN AUTOMATED DECISION-MAKING AFFECTING FINANCIAL OR LENDING SERVICES, HOUSING, PUBLIC ACCOMMODATION, INSURANCE, EDUCATION ENROLLMENT, EMPLOYMENT, HEALTH CARE SERVICES, OR ACCESS TO BASIC NECESSITIES, SUCH AS FOOD AND WATER, OR ENGAGED IN ASSISTING OTHERS IN AUTOMATED",https://www.nysenate.gov/legislation/bills/2023/A3593,en,"Harms: Harm to health/safety, Harms: Financial loss, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: External auditing, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About evaluation, Strategies: Disclosure: About inputs, Strategies: Governance development, Incentives: Civil liability, Incentives: Fines"
280,"An act to add Chapter 25 (commencing with Section 22756) to Division 8 of the Business and Professions Code, relating to artificial intelligence.",California,United States,State governments,U.S. state and local documents,Law/Act,2024-01-31,2024,1,positive,0.5572,medium,0.4444,216,1.0,Defunct,"SECTION 1. Chapter 25 (commencing with Section 22756) is added to Division 8 of the Business and Professions Code, to read: CHAPTER 25. Automated Decision Tools 1. As used in this chapter: (a) “Algorithmic discrimination” means the condition in which an automated decision tool contributes to unjustified differential treatment or impacts disfavoring people based on their actual or perceived race, color, ethnicity, sex, religion, age, national origin, limited English proficiency, disability, veteran status, genetic information, reproductive health, or any other classification protected by state law. (b) “Artificial intelligence” means a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing a real or virtual environment. (c) “Automated decision tool” means a system or service that uses artificial intelligence and has been specifically developed and marketed to, or specifically modified to, make, or be a controlling factor in making, consequential decisions. (d) “Consequential decision” means a decision or judgment that has a legal, material, or similarly significant effect on an individual’s life relating to the impact of, access to, or the cost, terms, or availability of, any of the following: (1) Employment, workers management, or self-employment, including, but not limited to, all of the following: (A) Pay or promotion. (B) Hiring or termination. (C) Automated task allocation. (2) Education and",https://leginfo.legislature.ca.gov/faces/billCompareClient.xhtml?bill_id=202320240AB331&showamends=false,en,"Risk factors: Bias, Risk factors: Reliability, Risk factors: Interpretability and explainability, Risk factors: Transparency, Harms: Harm to health/safety, Harms: Financial loss, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About evaluation"
281,"A Bill in the District of Columbia to prohibit users of algorithmic decision-making from utilizing algorithmic eligibility determinations in a discriminatory manner, to require corresponding notices to individuals whose personal information is used, and to provide for appropriate means of civil enfo",District of Columbia,United States,State governments,U.S. state and local documents,Law/Act,2023-02-10,2023,2,positive,0.8807,low,0.3333,225,1.0,Proposed,"A BILL IN THE COUNCIL OF THE DISTRICT OF COLUMBIA To prohibit users of algorithmic decision-making from utilizing algorithmic eligibility determinations in a discriminatory manner, to require corresponding notices to individuals whose personal information is used, and to provide for appropriate means of civil enforcement. BE IT ENACTED BY THE COUNCIL OF THE DISTRICT OF COLUMBIA, That this act may be cited as the “Stop Discrimination by Algorithms Act of 2023”. Sec. 2. Findings and declaration of policy. The Council of the District of Columbia makes the following findings: (a) It is the sense of the Council that technological advancements should support the dignity and well-being of the people of the District. (b) Computers and data-derived decision-making tools play ever larger roles in modern life. As of 2019, 90 percent of U.S. adults regularly used the internet. Approximately 76 percent of households in the District of Columbia have a broadband internet subscription, and many who lack a home internet connection use smartphones to go online. (c) When District residents engage in online activities like posting on social media, searching web-based listings for an apartment, or submitting electronic job applications, they generate personalized information that is harvested by data collectors. Data collectors can track hundreds of categories of data about specific individuals including age, gender, employment status and place of employment, income level, sexual orientation, nat",https://lims.dccouncil.gov/downloads/LIMS/52282/Introduction/B25-0114-Introduction.pdf?Id=155626,en,"Risk factors: Bias, Risk factors: Privacy, Risk factors: Transparency, Harms: Financial loss, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Evaluation: External auditing, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About evaluation, Strategies: Disclosure: About incidents"
284,An Act preventing a dystopian work environment.,Massachusetts,United States,State governments,U.S. state and local documents,Law/Act,2024-03-28,2024,3,negative,-0.0775,low,0.1667,207,0.7,Proposed,"SECTION 1. Chapter 149A of the General Laws, as appearing in the 2020 Official Edition, is hereby amended by adding the following chapter: Chapter 149B Section 1. Definitions (a) As used in this chapter, the following words shall, unless a different meaning is required by the context or is specifically prescribed, have the following meanings: “Authorized representative” , any person or organization appointed by the worker to serve as an agent of the worker. Authorized representative shall not include a worker’s employer. “Automated Decision System (ADS)” or “algorithm” , a computational process, including one derived from machine learning, statistics, or other data processing or artificial intelligence techniques, that makes or assists an employment-related decision. “Automated Decision System (ADS) output” , any information, data, assumptions, predictions, scoring, recommendations, decisions, or conclusions generated by an ADS. “Data,” or “worker data” , any information that identifies, relates to, describes, is reasonably capable of being associated with, or could reasonably be linked, directly or indirectly, with a particular worker, regardless of how the information is collected, inferred, or obtained. Data includes, but is not limited to, the following: (i) Personal identity information, including the individual’s name, contact information, government-issued identification number, financial information, criminal background, or employment history. (ii) Biometric informati",https://malegislature.gov/Bills/193/H1873,en,"Harms: Financial loss, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Evaluation: External auditing, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About evaluation, Strategies: Disclosure: About inputs, Strategies: Disclosure: In standard form, Strategies: Convening, Strategies: Governance development"
285,An Act concerning the use of automated tools to assist with hiring decisions and supplementing Title 34 of the Revised Statutes.,New Jersey,United States,State governments,U.S. state and local documents,Law/Act,2023-01-19,2023,1,positive,0.8657,low,0.1667,231,1.0,Proposed,"An Act concerning the use of automated tools to assist with hiring decisions and supplementing Title 34 of the Revised Statutes. Be It Enacted by the Senate and General Assembly of the State of New Jersey: a. a. As used in P.L. , c. (C. ) (pending before the Legislature as this bill): “Automated employment decision tool” means any system the function of which is governed by statistical theory, or systems the parameters of which are defined by systems, including inferential methodologies, linear regression, neural networks, decision trees, random forests, and other learning algorithms, which automatically filters candidates or prospective candidates for hire or for any term, condition or privilege of employment in a way that establishes a preferred candidate or candidates. “Bias audit” means an impartial evaluation, including but not limited to testing, of an automated employment decision tool to assess its predicted compliance with the provisions of the “Law Against Discrimination,” P.L. 1945, c. 169 (C. 10:5-1 et seq.), and any other applicable law relating to discrimination in employment. “Commissioner” means the Commissioner of Labor and Workforce Development. “Department” means Department of Labor and Workforce Development. “Employment decision” means to screen candidates for employment or otherwise to help to decide compensation or any other terms, conditions or privileges of employment in the State. b. It shall be unlawful to sell or offer for sale in the State an autom",https://www.njleg.state.nj.us/bill-search/2022/A4909/bill-text?f=A5000&n=4909_I1,en,"Risk factors: Bias, Risk factors: Transparency, Harms: Violation of civil or human rights, including privacy, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Evaluation: External auditing, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About evaluation, Incentives: Civil liability, Incentives: Fines, Applications: Business services and analytics"
286,"An act to amend the labor law, in relation to establishing criteria for the use of automated employment decision tools",New York,United States,State governments,U.S. state and local documents,Law/Act,2024-01-08,2024,1,positive,0.2738,low,0.1111,221,0.7,Proposed,"AN ACT to amend the labor law, in relation to establishing criteria for the use of automated employment decision tools THE PEOPLE OF THE STATE OF NEW YORK, REPRESENTED IN SENATE AND ASSEM- BLY, DO ENACT AS FOLLOWS: Section 1. The labor law is amended by adding a new section 203-f to read as follows: § 203-F. USE OF AUTOMATED EMPLOYMENT DECISION TOOLS. 1. FOR PURPOSES OF THIS SECTION, THE FOLLOWING TERMS SHALL HAVE THE FOLLOWING MEANINGS: A. ""AUTOMATED EMPLOYMENT DECISION TOOL"" MEANS ANY SYSTEM USED TO FILTER EMPLOYMENT CANDIDATES OR PROSPECTIVE CANDIDATES FOR HIRE IN A WAY THAT ESTABLISHES A PREFERRED CANDIDATE OR CANDIDATES WITHOUT RELYING ON CANDIDATE-SPECIFIC ASSESSMENTS BY INDIVIDUAL DECISION-MAKERS. AUTOMATED EMPLOYMENT DECISION TOOLS SHALL INCLUDE PERSONALITY TESTS, COGNITIVE ABILITY TESTS, RESUME SCORING SYSTEMS AND ANY SYSTEM WHOSE FUNCTION IS GOVERNED BY STATISTICAL THEORY, OR WHOSE PARAMETERS ARE DEFINED BY SUCH SYSTEMS, INCLUDING INFERENTIAL METHODOLOGIES, LINEAR REGRESSION, NEURAL NETWORKS, DECISION TREES, RANDOM FORESTS AND OTHER ARTIFICIAL INTELLI- GENCE OR MACHINE LEARNING ALGORITHMS. THE TERM ""AUTOMATED EMPLOYMENT DECISION TOOL"" DOES NOT INCLUDE A TOOL THAT DOES NOT AUTOMATE, SUPPORT, SUBSTANTIALLY ASSIST OR REPLACE DISCRETIONARY DECISION-MAKING PROCESSES AND THAT DOES NOT MATERIALLY IMPACT NATURAL PERSONS. B. ""DISPARATE IMPACT ANALYSIS"" MEANS AN IMPARTIAL ANALYSIS, INCLUDING BUT NOT LIMITED TO TESTING OF THE EXTENT TO WHICH USE OF AN AUTOMATED EMPLOYMENT DECI",https://www.nysenate.gov/legislation/bills/2023/S5641/amendment/original,en,"Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About evaluation, Incentives: Civil liability, Applications: Business services and analytics"
287,"An Act to amend the labor law, in relation to automated employment decision tools",New York,United States,State governments,U.S. state and local documents,Law/Act,2024-01-03,2024,1,positive,0.5602,low,0.0556,221,1.0,Proposed,"AN ACT to amend the labor law, in relation to automated employment deci- sion tools THE PEOPLE OF THE STATE OF NEW YORK, REPRESENTED IN SENATE AND ASSEM- BLY, DO ENACT AS FOLLOWS: Section 1. The labor law is amended by adding a new section 203-f to read as follows: § 203-F. AUTOMATED EMPLOYMENT DECISION TOOLS. 1. DEFINITIONS. FOR THE PURPOSES OF THIS SECTION, THE FOLLOWING TERMS SHALL HAVE THE FOLLOWING MEANINGS: (A) ""AUTOMATED EMPLOYMENT DECISION TOOL"" MEANS ANY COMPUTATIONAL PROC- ESS, DERIVED FROM MACHINE LEARNING, STATISTICAL MODELING, DATA ANALYT- ICS, OR ARTIFICIAL INTELLIGENCE, THAT ISSUES SIMPLIFIED OUTPUT, INCLUD- ING A SCORE, CLASSIFICATION, OR RECOMMENDATION, THAT IS USED TO SUBSTANTIALLY ASSIST OR REPLACE DISCRETIONARY DECISION MAKING FOR MAKING EMPLOYMENT DECISIONS THAT IMPACT NATURAL PERSONS. ""AUTOMATED EMPLOYMENT DECISION TOOL"" DOES NOT INCLUDE A TOOL THAT DOES NOT AUTOMATE, SUPPORT, SUBSTANTIALLY ASSIST, OR REPLACE DISCRETIONARY DECISION-MAKING PROCESSES AND THAT DOES NOT MATERIALLY IMPACT NATURAL PERSONS, INCLUDING, BUT NOT LIMITED TO, A JUNK EMAIL FILTER, FIREWALL, ANTIVIRUS SOFTWARE, CALCULA- TOR, SPREADSHEET, DATABASE, DATA SET, OR OTHER COMPILATION OF DATA. (B) ""EMPLOYMENT DECISION"" MEANS TO SCREEN CANDIDATES FOR EMPLOYMENT.2. NOTICES REQUIRED. (A) ANY EMPLOYER OR EMPLOYMENT AGENCY THAT USES AN AUTOMATED EMPLOYMENT DECISION TOOL TO SCREEN CANDIDATES WHO HAVE APPLIED FOR A POSITION FOR AN EMPLOYMENT DECISION SHALL NOTIFY EACH SUCH CANDIDATE OF THE FOLLOWIN",https://www.nysenate.gov/legislation/bills/2023/A7859,en,"Risk factors: Transparency, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About inputs, Applications: Business services and analytics"
288,"A Bill to prohibit certain uses of automated decision systems by employers, and for other purposes.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7987,medium,0.3889,206,1.0,Defunct,"SECTION 1. Short title. This Act may be cited as the “No Robot Bosses Act”. SEC. 2. Definitions. For purposes of this Act: (1) AUTOMATED DECISION SYSTEM.— (A) IN GENERAL.—The term “automated decision system” means a system, software, or process that— (i) uses computation, in whole or in part, to determine outcomes, make or aid decisions (including through evaluations, metrics, or scoring), inform policy implementation, or collect data or observations, including such a system, software, or process derived from machine learning, statistics, or other data processing or artificial intelligence techniques; and (ii) is not passive computing infrastructure. (B) PASSIVE COMPUTING INFRASTRUCTURE.—For purposes of this paragraph, the term “passive computing infrastructure” means any intermediary technology that does not influence or determine the outcome of a decision, make or aid in a decision (including through evaluations, metrics, or scoring), inform policy implementation, or collect data or observations, including web hosting, domain registration, networking, caching, data storage, or cybersecurity. (2) AUTOMATED DECISION SYSTEM OUTPUT.—The term “automated decision system output” means any information, assumption, prediction, score, recommendation, decision, evaluation, metric, conclusion, inference, or profile generated by an automated decision system. (3) CANDIDATE.—The term “candidate”, with respect to an employer, means an individual who applies, or applied, to be employed by,",https://www.congress.gov/bill/118th-congress/senate-bill/2419/text/is?format=xml,en,"Risk factors: Bias, Risk factors: Reliability, Risk factors: Interpretability and explainability, Risk factors: Transparency, Harms: Financial loss, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Evaluation: External auditing, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About evaluation, Strategies: Disclosure: About incidents, Strategies: Disclosure: About inputs"
290,An Act regulating the use of artificial intelligence (AI) in providing mental health services.,Massachusetts,United States,State governments,U.S. state and local documents,Law/Act,2023-06-29,2023,6,positive,0.7865,low,0.1667,218,1.0,Proposed,"SECTION 1. Chapter 123 of the General Laws, as appearing in the 2020 Official Edition, is hereby amended by inserting after section 36C the following section: Section 1: Purpose The purpose of this act is to regulate the use of Artificial Intelligence (AI) in providing mental health services in the Commonwealth of Massachusetts in order to ensure the safety and well-being of individuals seeking mental health treatment, while also allowing for the responsible use of AI in mental health services. Section 2: Definitions (a) ""Artificial Intelligence"" or ""AI"" means any technology that can simulate human intelligence, including but not limited to, natural language processing, training language models, reinforcement learning from human feedback and machine learning systems. (b) ""Mental health services"" means any service provided by a licensed mental health professional for the purpose of diagnosing, treating, or preventing mental illness or emotional or behavioral disorders. (c) ""Licensed mental health professional"" means any individual who is licensed by the state of Massachusetts to provide mental health services, including but not limited to, psychiatrists, psychologists, licensed mental health counselors (LMHCs), licensed independent clinical social workers (LICSWs) and other professional counselors. Section 3: Regulation of AI in Mental Health Services (a) Any licensed mental health professional who wishes to provide mental health services through the use of AI shall first seek",https://malegislature.gov/Bills/193/H1974/BillHistory,en,"Risk factors: Safety, Risk factors: Transparency, Harms: Harm to health/safety, Strategies: Evaluation, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Licensing, registration, and certification, Applications: Medicine, life sciences and public health"
292,Artificial Intelligence for California Research Act,California,United States,State governments,U.S. state and local documents,Law/Act,2024-02-01,2024,2,positive,0.9371,low,0.0556,214,0.7,Defunct,"Date Published: 04/17/2023 02:00 PM Amended IN Senate April 17, 2023 Amended IN Senate March 22, 2023 CALIFORNIA LEGISLATURE— 2023–2024 REGULAR SESSION Senate Bill No. 398 Introduced by Senator Wahab (Coauthor: Senator Limón) February 09, 2023 An act to add and repeal Chapter 4 (commencing with Section 15210) of Part 6 of Division 3 of Title 2 Section 11546.8 of the Government Code, relating to technology. LEGISLATIVE COUNSEL'S DIGEST SB 398, as amended, Wahab. Department of Justice: Technology: advanced technology: research. Existing law establishes the state Department of Justice under the direction and control of the Attorney General, and among other things, requires the department to control and eradicate organized crime within the state. Existing law establishes the Department of Technology, within the Government Operations Agency, under the supervision of the Director of Technology. Existing law requires the director to, among other things, provide technology direction to agency and department chief information officers to ensure the integration of statewide technology initiatives, compliance with information technology policies and standards, and the promotion of the alignment and effective management of information technology services. Under existing law, the department is responsible for the approval and oversight of information technology projects. Existing law requires the department to submit various reports to the Legislature, including an annual information tech",https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB398,en,"Harms: Violation of civil or human rights, including privacy, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Post-market monitoring, Strategies: Government study or report, Strategies: Governance development, Applications: Government: benefits and welfare"
293,"An act to add Chapter 5.9 (commencing with Section 11549.80) to Part 1 of Division 3 of Title 2 of, the Government Code, relating to state government.",California,United States,State governments,U.S. state and local documents,Law/Act,2024-02-01,2024,2,positive,0.9866,low,0.0556,239,1.0,Proposed,"SECTION 1. Chapter 5.9 (commencing with Section 11549.80) is added to Part 1 of Division 3 of Title 2 of the Government Code, to read: CHAPTER 5.9. Artificial Intelligence 11549.80. This chapter shall be known, and may be cited, as the California AI-ware Act.11549.81. In enacting this chapter, the Legislature finds and declares: (a) The Legislature recognizes the tremendous potential of artificial intelligence (AI) to improve the lives of its citizens and the functioning of government. However, the Legislature also recognizes that the use of AI must be guided by principles of fairness, transparency, and accountability to ensure that the rights and opportunities of all Californians are protected in the age of artificial intelligence. (b) The Legislature declares that no individual or group should be discriminated against on the basis of race, gender, age, religion, sexual orientation, or any other protected characteristic in the design, development, deployment, or use of AI systems. (c) The Legislature affirms the importance of transparency in the use of AI systems. The public has the right to know when they are interacting with AI being used by the state, and to have a clear and conspicuous identification of that interaction. (d) The Legislature recognizes that the use of AI systems must be consistent with the protection of privacy and civil liberties and must be guided by a commitment to equity and social justice. It is the intent of the Legislature in enacting this legislat",https://leginfo.legislature.ca.gov/faces/billCompareClient.xhtml?bill_id=202320240SB313&showamends=false,en,"Harms: Violation of civil or human rights, including privacy, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: New institution, Applications: Government: other applications/unspecified"
294,An act relating to state affairs and government -- commission to monitor the use of artificial intelligence in state government.,Rhode Island,United States,State governments,U.S. state and local documents,Law/Act,2023-05-25,2023,5,positive,0.9608,low,0.1111,212,0.7,Defunct,"SECTION 1. Title 42 of the General Laws entitled ""STATE AFFAIRS AND GOVERNMENT"" is hereby amended by adding thereto the following chapter: CHAPTER COMMISSION TO MONITOR THE USE OF ARTIFICIAL INTELLIGENCE IN STATE GOVERNMENT42-165-1. Definitions. As used in this chapter, the following words shall have the following meanings unless the context clearly requires otherwise: (1) ""Algorithm"" means a specific procedure, set of rules, or order of operations designed to solve a problem or make a calculation, classification, or recommendation. (2) ""Artificial intelligence"" means computerized methods and tools, including, but not limited to, machine learning and natural language processing, that act in a way that resembles human cognitive abilities when it comes to solving problems or performing certain tasks. (3) ""Automated decision system"" means any computer program, method, statistical model, or process that aims to aid or replace human decision-making using algorithms or artificial intelligence. These systems can include analyzing complex datasets about human populations and government services or other activities to generate scores, predictions, classifications, or recommendations used by agencies to make decisions that impact human welfare. (4) ""Office,"" ""Rhode Island,"" or ""state"" means any agency, constitutional office, department, board, commission, bureau, division or authority of the State of Rhode Island, or of any political subdivision thereof, or of any authority established",https://webserver.rilegislature.gov/BillText/BillText23/SenateText23/S0117.pdf,en,"Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: External auditing, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About evaluation, Strategies: Disclosure: About inputs, Strategies: Government study or report, Strategies: Convening, Strategies: Governance development, Strategies: New institution, Strategies: Input controls, Strategies: Input controls: Data circulation"
299,"An act to amend the executive law, in relation to creating the office of algorithmic innovation",New York,United States,State governments,U.S. state and local documents,Law/Act,2024-01-03,2024,1,positive,0.9962,low,0.0556,251,0.7,Proposed,"S T A T E O F N E W Y O R K ________________________________________________________________________ 7501 2023-2024 Regular Sessions I N A S S E M B L Y May 25, 2023 ___________ Introduced by M. of A. RAJKUMAR -- read once and referred to the Commit- tee on Science and Technology AN ACT to amend the executive law, in relation to creating the office of algorithmic innovation THE PEOPLE OF THE STATE OF NEW YORK, REPRESENTED IN SENATE AND ASSEM- BLY, DO ENACT AS FOLLOWS: Section 1. The executive law is amended by adding a new article 38-A to read as follows: ARTICLE 38-A OFFICE OF ALGORITHMIC INNOVATION SECTION 860. OFFICE OF ALGORITHMIC INNOVATION. § 860. OFFICE OF ALGORITHMIC INNOVATION. 1. THERE IS HEREBY CREATED A STATE OFFICE OF ALGORITHMIC INNOVATION. THE OFFICE SHALL BE HEADED BY A DIRECTOR WHO SHALL BE APPOINTED BY THE GOVERNOR. THE OFFICE SHALL HAVE AS ITS PRIMARY PURPOSE THE CREATION OF POLICIES AND STANDARDS TO ENSURE ALGORITHMS ARE SAFE, EFFECTIVE, FAIR, AND ETHICAL, AND THAT THE STATE IS CONDUCIVE TO PROMOTING ALGORITHMIC INNOVATION. THE OFFICE SHALL HAVE THE POWER TO SET STANDARDS FOR ALGORITHMS USED IN ANY TECHNOLOGY, BE ABLE TO AUDIT ALL ALGORITHMS, AND SET STATEWIDE POLICY ON THE USE OF ALGORITHMS AND PROMOTION OF INNOVATION. THE DIRECTOR SHALL APPOINT STAFF AND PERFORM SUCH OTHER FUNCTIONS TO ENSURE THE EFFICIENT OPERATION OF THE OFFICE WITHIN THE AMOUNTS MADE AVAILABLE THEREFOR BY APPROPRIATION.1. FOR THE PURPOSE OF THIS ARTICLE, ""ALGORITHM"" SHALL MEAN ANY SET","https://www.nysenate.gov/legislation/bills/2023/A7501#:~:text=2023%2DA7501%20(ACTIVE)%20%2D%20Summary,conducive%20to%20promoting%20algorithmic%20innovation.",en,"Harms: Violation of civil or human rights, including privacy, Strategies: Evaluation, Strategies: Evaluation: External auditing, Strategies: Governance development, Strategies: New institution"
300,An act relating to a study on the establishment of a program administered by the Texas Workforce Commission to train individuals in certain skills related to artificial intelligence systems.,Texas,United States,State governments,U.S. state and local documents,Law/Act,2023-04-27,2023,4,positive,0.9049,low,0.0,161,0.7,Defunct,"A BILL TO BE ENTITLED AN ACT relating to a study on the establishment of a program administered by the Texas Workforce Commission to train individuals in certain skills related to artificial intelligence systems. BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF TEXAS: SECTION 1. (a) The standing committee of the house of representatives having jurisdiction over workforce development shall conduct a study on whether to establish a program administered by the Texas Workforce Commission to train individuals currently in the workforce in skills related to the use, operation, and creation of artificial intelligence systems. (b) Not later than December 1, 2024, the committee shall report the results of the study conducted under Subsection (a) of this section to the governor, the lieutenant governor, the speaker of the house of representatives, and the standing committee of the senate with jurisdiction over workforce development. (c) This section expires September 1, 2025. SECTION 2. This Act takes effect September 1, 2023.",https://capitol.texas.gov/tlodocs/88R/billtext/html/HB03633I.htm,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Government support: AI workforce-related, Strategies: Governance development"
301,"A bill to amend the South Carolina Code of Laws by adding Section 63-5-380 so as to prohibit operators of internet-based applications from using ""automated decision systems"" to place content on social media platforms for users under the age of eighteen who are residents of the State of South Carolin",South Carolina,United States,State governments,U.S. state and local documents,Law/Act,2023-01-18,2023,1,negative,-0.8256,low,0.0,241,0.7,Proposed,"A bill TO AMEND THE SOUTH CAROLINA CODE OF LAWS BY ADDING SECTION 63-5-380 SO AS TO PROHIBIT OPERATORS OF INTERNET-BASED APPLICATIONS FROM USING ""AUTOMATED DECISION SYSTEMS"" TO PLACE CONTENT ON SOCIAL MEDIA PLATFORMS FOR USERS UNDER THE AGE OF EIGHTEEN WHO ARE RESIDENTS OF THE STATE OF SOUTH CAROLINA, TO REQUIRE OPERATORS TO PERFORM AGE-VERIFICATION PRACTICES FOR CERTAIN USERS, TO ESTABLISH THAT A VIOLATION IS AN UNFAIR OR DECEPTIVE ACT OR PRACTICE UNDER THE SOUTH CAROLINA UNFAIR TRADE PRACTICES ACT, AND FOR OTHER PURPOSES. Be it enacted by the General Assembly of the State of South Carolina: SECTION 1. Article 3, Chapter 5, Title 63 of the S.C. Code is amended by adding: Section 63-5-380. (A)(1) It is unlawful for any operator of a website, an online service, or an online or mobile application, including any social media platform, to utilize an automated decision system for content placement, including feeds, posts, advertisements, or product offerings, for a user under the age of eighteen who is a resident of the State of South Carolina. (2) An operator that utilizes an automated decision system for content placement for residents of South Carolina who are eighteen years or older shall perform an age verification through an independent, third-party age-verification service that compares information available from public records to the personal information entered by the user to create an account to establish the individual is eighteen years of age or older, unless the opera",https://www.scstatehouse.gov/sess125_2023-2024/bills/404.htm,en,"Strategies: Tiering, Incentives: Civil liability, Applications: Broadcasting and media production, Applications: Arts, sports, leisure, travel, and lifestyle"
302,An Act Establishing the Alabama Commission on Artificial Intelligence and Associated Technologies.,Alabama,United States,State governments,U.S. state and local documents,Law/Act,2019-05-28,2019,5,positive,0.9803,low,0.0,224,0.7,Enacted,"ENROLLED, SJR71, ESTABLISHING THE ALABAMA COMMISSION ON ARTIFICIAL INTELLIGENCE AND ASSOCIATED TECHNOLOGIES. WHEREAS, technology and artificial intelligence have the capacity to improve the lives of the citizens of this state; and WHEREAS, the resources that are invested into Alabama's technology industry and artificial intelligence are critical to creating the industries of the future, including autonomous cars, industrial robots, and algorithms for disease diagnosis; and WHEREAS, maintaining the nation's global leadership helps insure that technology is developed in a manner that is consistent with the nation T s values, policies, and priorities; and it is important to have skilled workers and businesses in Alabama who are on the forefront in leading the country' s development of technology and artificial intelligence; and WHEREAS, as technological innovations take place, the quality of life improves; and WHEREAS, in 2018, net technology related employment in Alabama increased by nearly 1, 900 new workers, a 1.3 percent increase over 2017; since 2010, net technology employment has grown by over 10,000 new jobs with more than 147,000 workers; technology jobs account for approximately .1 percent of Alabama's workforce; and the technology sector had an estimated direct economic irnpact of $13.4 billion, which is about 6.8 percent of Alabama's total economy; and WHEREAS, tens of thousands of people rely on technology in the Alabama workplace; and the broad—based impact of the t",https://arc-sos.state.al.us/ucp/B19148AA.AEM.pdf,en,"Strategies: New institution, Applications: Medicine, life sciences and public health, Applications: Transportation, Applications: Manufacturing and process automation, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Government study or report, Applications: Education, Strategies: Convening, Strategies: Disclosure, Strategies: Disclosure: In standard form"
303,"Senate Resolution requesting the State to convene an Artificial Intelligence Advisory Committee to investigate how to implement, develop, and regulate artificial intelligence in the State.",Hawaii,United States,State governments,U.S. state and local documents,Resolution,2019-04-03,2019,4,positive,0.9903,low,0.0,213,1.0,Enacted,"WHEREAS, artificial intelligence is on track to be one of history's most impactful scientific advances; and WHEREAS, artificial intelligence is intelligence demonstrated by machines, wherein machines mimic human cognitive functions like learning and problem solving; and WHEREAS, the benefits of artificial intelligence currently outweigh its costs; and WHEREAS, advances in artificial intelligence are being used to benefit fields as diverse as trucking, medical diagnosis, and finance; and WHEREAS, however, many experts warn of artificial intelligence's dangers, such as autonomous weapons, social manipulation, and invasion of personal privacy; and WHEREAS, other states, like Vermont, have already created groups to investigate and manage the impact of artificial intelligence on their economies and state operations; and WHEREAS, Hawai‘i should follow suit by examining the best ways to integrate and approach artificial intelligence to leverage its advantages and prepare against potential harm; now, therefore, BE IT RESOLVED by the Senate of the Thirtieth Legislature of the State of Hawaii, Regular Session of 2019, that the State is requested to convene an artificial intelligence advisory committee to investigate how to implement, develop, and regulate artificial intelligence in the State; and BE IT FURTHER RESOLVED that the artificial intelligence advisory committee be composed of the following: (1) The Director of Business, Economic Development, and Tourism, or the Director's desi",https://www.capitol.hawaii.gov/sessions/session2019/bills/SR142_.HTM,en,"Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Government study or report, Strategies: Convening, Strategies: Governance development, Strategies: New institution"
304,Artificial Intelligence Video Interview Act,Illinois,United States,State governments,U.S. state and local documents,Law/Act,2019-08-09,2019,8,positive,0.9615,low,0.1111,222,1.0,Enacted,"AN ACT concerning employment. Be it enacted by the People of the State of Illinois, represented in the General Assembly: Section 1. Short title. This Act may be cited as the Artificial Intelligence Video Interview Act. Section 5. Disclosure of the use of artificial intelligence analysis. An employer that asks applicants to record video interviews and uses an artificial intelligence analysis of the applicant-submitted videos shall do all of the following when considering applicants for positions based in Illinois before asking applicants to submit video interviews: (1) Notify each applicant before the interview that artificial intelligence may be used to analyze the applicant's video interview and consider the applicant's fitness for the position. (2) Provide each applicant with information before the interview explaining how the artificial intelligence works and what general types of characteristics it uses to evaluate applicants. (3) Obtain, before the interview, consent from the applicant to be evaluated by the artificial intelligence program as described in the information provided. An employer may not use artificial intelligence to evaluate applicants who have not consented to the use of artificial intelligence analysis. Section 10. Sharing videos limited. An employer may not share applicant videos, except with persons whose expertise or technology is necessary in order to evaluate an applicant's fitness for a position. Section 15. Destruction of videos. Upon request from",https://www.ilga.gov/legislation/fulltext.asp?DocName=&SessionId=108&GA=101&DocTypeId=HB&DocNum=2557&GAID=15&LegID=&SpecSess=&Session=,en,"Risk factors: Security, Risk factors: Transparency, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Input controls, Strategies: Input controls: Data circulation, Applications: Business services and analytics"
307,"Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence",Executive Office of the President,United States,Federal government,Editors' Picks,Executive Order,2025-01-20,2025,1,positive,0.9888,high,0.8333,233,0.7,Defunct,"October 30, 2023 Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence By the authority vested in me as President by the Constitution and the laws of the United States of America, it is hereby ordered as follows: Section 1. Purpose. Artificial intelligence (AI) holds extraordinary potential for both promise and peril. Responsible AI use has the potential to help solve urgent challenges while making our world more prosperous, productive, innovative, and secure. At the same time, irresponsible use could exacerbate societal harms such as fraud, discrimination, bias, and disinformation; displace and disempower workers; stifle competition; and pose risks to national security. Harnessing AI for good and realizing its myriad benefits requires mitigating its substantial risks. This endeavor demands a society-wide effort that includes government, the private sector, academia, and civil society. My Administration places the highest urgency on governing the development and use of AI safely and responsibly, and is therefore advancing a coordinated, Federal Government-wide approach to doing so. The rapid speed at which AI capabilities are advancing compels the United States to lead in this moment for the sake of our security, economy, and society. In the end, AI reflects the principles of the people who build it, the people who use it, and the data upon which it is built. I firmly believe that the power of our ideals; the foundations of our so",https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/,en,"Risk factors: Bias, Risk factors: Safety, Harms: Detrimental content, Harms: Violation of civil or human rights, including privacy, Harms: Financial loss, Risk factors: Reliability, Risk factors: Reliability: Robustness, Risk factors: Security, Risk factors: Security: Cybersecurity, Strategies: Evaluation, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure: In deployment, Strategies: Disclosure, Applications: Medicine, life sciences and public health, Harms: Discrimination"
308,"An act to amend the general business law, in relation to requiring advertisements to disclose the use of synthetic media",New York,United States,State governments,U.S. state and local documents,Law/Act,2024-03-03,2024,3,positive,0.9403,low,0.1111,240,0.7,Proposed,"AN ACT to amend the general business law, in relation to requiring advertisements to disclose the use of synthetic media THE PEOPLE OF THE STATE OF NEW YORK, REPRESENTED IN SENATE AND ASSEM- BLY, DO ENACT AS FOLLOWS: Section 1. Section 396-b of the general business law, as added by chapter 1031 of the laws of 1965, is amended to read as follows: § 396-b. Advertisements. 1. FOR PURPOSES OF THIS SECTION, ""SYNTHETIC MEDIA"" MEANS ANY HUMAN VOICE, PHOTOGRAPH, IMAGE, VIDEO OR OTHER HUMAN LIKENESS CREATED, REPRODUCED, OR MODIFIED BY COMPUTER, USING ARTIFICIAL INTELLIGENCE OR SOFTWARE ALGORITHM, TO BE INDISTINGUISHABLE TO A REASON- ABLE VIEWER FROM A NATURAL PERSON.2. Any person, firm, corporation or association, or agent or employee thereof, hereinafter called person, who, being engaged in the business of dealing in any property, makes, publishes, disseminates, circulates or places before the public or causes, directly or indirectly, to be made, published, disseminated, circulated or placed before the public, in this state, any advertisement respecting any such property, in any newspaper, magazine, or other publication, or over any radio station or television station, unless it is stated in any such advertisement that the advertiser is a dealer in such property or from the context of any such advertisement, it plainly appears that such person is a dealer in such property so offered for sale in any such advertisement; or when placing or causing any such advertisement to appear in any",https://www.nysenate.gov/legislation/bills/2023/A216/amendment/A,en,"Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content, Strategies: Disclosure, Strategies: Disclosure: In deployment, Incentives: Civil liability, Incentives: Fines, Applications: Sales, retail, and customer relations"
309,"An Act amending Title 18 (Crimes and Offenses) of the Pennsylvania Consolidated Statutes, in sexual offenses, providing for the offense of unlawful dissemination of artificially generated depiction; and, in minors, further providing for the offense of sexual abuse of children and for the offense of",Pennsylvania,United States,State governments,U.S. state and local documents,Law/Act,2023-04-28,2023,4,negative,-0.9875,low,0.0556,218,0.7,Proposed,"PRINTER'S NO. 1077 THE GENERAL ASSEMBLY OF PENNSYLVANIA HOUSE BILL No. 1063 Session of 2023 INTRODUCED BY R. MACKENZIE, FLICK, KAUFFMAN, KENYATTA, LEADBETER, M. MACKENZIE, PICKETT, SCIALABBA, SHUSTERMAN AND STAATS, APRIL 28, 2023 REFERRED TO COMMITTEE ON JUDICIARY, APRIL 28, 2023 AN ACT Amending Title 18 (Crimes and Offenses) of the Pennsylvania Consolidated Statutes, in sexual offenses, providing for the offense of unlawful dissemination of artificially generated depiction; and, in minors, further providing for the offense of sexual abuse of children and for the offense of transmission of sexually explicit images by minor. The General Assembly of the Commonwealth of Pennsylvania hereby enacts as follows:Section 1. Title 18 of the Pennsylvania Consolidated Statutes is amended by adding a section to read: § 3131.1. Unlawful dissemination of artificially generated depiction. (a) Offense defined.--Except as provided in sections 5903 (relating to obscene and other sexual materials and performances), 6312 (relating to sexual abuse of children) and 6321 (relating to transmission of sexually explicit images by minor), a person commits the offense of unlawful dissemination of an artificially generated depiction if, with intent to harass, annoy or alarm an individual, the person disseminates an artificially generated depiction of the individual.(b) Defense.--It is a defense to a prosecution under this section that the actor disseminated the artificially generated depiction with the co",https://www.legis.state.pa.us/CFDOCS/Legis/PN/Public/btCheck.cfm?txtType=DOC&sessYr=2023&sessInd=0&billBody=H&billTyp=B&billNbr=1063&pn=1077,en,"Harms: Detrimental content, Strategies: Performance requirements, Incentives: Criminal liability, Applications: Broadcasting and media production"
310,An Act requiring the Commissioner of Labor and Workforce Development to conduct a study and issue a report on the impact of artificial intelligence on the growth of the State's economy.,New Jersey,United States,State governments,U.S. state and local documents,Law/Act,2022-01-11,2022,1,positive,0.9744,low,0.0,227,0.7,Proposed,"Bill A168 Session 2022 - 2023 ASSEMBLY, No. 168 STATE OF NEW JERSEY 220th LEGISLATURE PRE-FILED FOR INTRODUCTION IN THE 2022 SESSION Sponsored by: Assemblywoman LINDA S. CARTER District 22 (Middlesex, Somerset and Union) Assemblyman ROBERT J. KARABINCHAK District 18 (Middlesex) Assemblyman CLINTON CALABRESE District 36 (Bergen and Passaic) SYNOPSIS Requires Commissioner of Labor and Workforce Development to conduct study and issue report on impact of artificial intelligence on growth of State’s economy. CURRENT VERSION OF TEXT Introduced Pending Technical Review by Legislative Counsel. An Act requiring the Commissioner of Labor and Workforce Development to conduct a study and issue a report on the impact of artificial intelligence on the growth of the State's economy. Be It Enacted by the Senate and General Assembly of the State of New Jersey: a. The Commissioner of Labor and Workforce Development, in consultation with the New Jersey Commission on Science, Innovation and Technology, shall conduct a study on the impact of artificial intelligence-powered technology and automation on the growth of the State's economy and shall prepare and submit a written report, within one year of the effective date of this act, to the Governor and, pursuant to section 2 of P.L.1991, c.164 (C.52:14-19.1), to the Legislature, the chairperson of the Assembly Science, Innovation and Technology Committee and the chairperson of the Senate Economic Growth Committee, or their successor committees, whi",https://www.njleg.state.nj.us/bill-search/2022/A168,en,
311,"An act creating a temporary state commission to study and investigate how to regulate artificial intelligence, robotics and automation; and providing for the repeal of such provisions upon expiration thereof",New York,United States,State governments,U.S. state and local documents,Law/Act,2023-11-17,2023,11,positive,0.9773,low,0.0,229,0.7,Defunct,"S T A T E O F N E W Y O R K ________________________________________________________________________ 4969 2023-2024 Regular Sessions I N A S S E M B L Y February 27, 2023 ___________ Introduced by M. of A. VANEL -- read once and referred to the Committee on Science and Technology AN ACT creating a temporary state commission to study and investigate how to regulate artificial intelligence, robotics and automation; and providing for the repeal of such provisions upon expiration thereof THE PEOPLE OF THE STATE OF NEW YORK, REPRESENTED IN SENATE AND ASSEM- BLY, DO ENACT AS FOLLOWS: Section 1. A temporary state commission, to be known as the New York state artificial intelligence, robotics and automation commission (here- inafter ""commission""), is hereby created to study and make determi- nations on issues including but not limited to: (a) current law within this state addressing artificial intelligence, robotics and automation; (b) comparative state policies that have aided in creating a regulato- ry structure for artificial intelligence, robotics and automation, and whether such measures would be similarly effective in this state; (c) criminal and civil liability regarding violations of law caused by entities equipped with artificial intelligence, robotics and automation; (d) the impact of artificial intelligence, robotics and automation on employment in this state; (e) the impact of artificial intelligence, robotics and automation on the acquiring and disclosure of confidential",https://www.nysenate.gov/legislation/bills/2023/A4969,en,"Strategies: Government study or report, Strategies: Convening, Strategies: Governance development, Strategies: New institution, Applications: Government: military and public safety"
314,Illinois HB53 2021,Illinois,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2021-01-13,2021,1,positive,0.9094,low,0.1667,193,1.0,Enacted,"AN ACT concerning employment. Be it enacted by the People of the State of Illinois, represented in the General Assembly: Section 5. The Artificial Intelligence Video Interview Act is amended by adding Section 20 as follows: Sec. 20. Report of demographic data. (a) An employer that relies solely upon an artificial intelligence analysis of a video interview to determine whether an applicant will be selected for an in-person interview must collect and report the following demographic data: (1) the race and ethnicity of applicants who are and are not afforded the opportunity for an in-person interview after the use of artificial intelligence analysis; and (2) the race and ethnicity of applicants who are hired. (b) The demographic data collected under subsection (a) must be reported to the Department of Commerce and Economic Opportunity annually by December 31. The report shall include the data collected in the 12-month period ending on November 30 preceding the filing of the report. (c) The Department must analyze the data reported and report to the Governor and General Assembly by July 1 of each year whether the data discloses a racial bias in the use of artificial intelligence.",https://www.ilga.gov/legislation/fulltext.asp?DocName=&SessionId=110&GA=102&DocTypeId=HB&DocNum=53&GAID=16&LegID=127865&SpecSess=&Session=,en,"Harms: Financial loss, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: External auditing, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Applications: Business services and analytics"
315,Artificial Intelligence and Biosecurity Risk Assessment Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.1531,low,0.1667,207,1.0,Defunct,"A BILL To require the Assistant Secretary for Preparedness and Response shall conduct risk assessments and implement strategic initiatives or activities to address threats to public health and national security due to technical advancements in artificial intelligence or other emerging technology fields. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Artificial Intelligence and Biosecurity Risk Assessment Act”. SEC. 2. Regular assessment of emerging risks. Section 2811 of the Public Health Service Act (42 U.S.C. 300hh–10) is amended by adding at the end the following: “(h) Assessment of emerging risks.—In carrying out subsection (b)(4)(I), the Assistant Secretary for Preparedness and Response shall conduct risk assessments and implement strategic initiatives or activities to address whether technical advancements in artificial intelligence, such as open-source artificial intelligence models and large language models, can be used intentionally or unintentionally to develop novel pathogens, viruses, bioweapons, or chemical weapons. Such initiatives and activities may include— “(1) regularly monitoring and researching potential global biological catastrophic risks in which biological agents could lead to sudden, extraordinary loss of life and sustained damage to national governments, international relationships, economies, societal stability, or global security;",https://www.congress.gov/bill/118th-congress/house-bill/4704,en,"Harms: Harm to health/safety, Harms: Financial loss, Harms: Harm to infrastructure, Strategies: Evaluation, Strategies: Government study or report, Strategies: Governance development, Applications: Medicine, life sciences and public health"
316,Supercomputing for Safer Chemicals Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9744,low,0.0556,222,1.0,Defunct,"A BILL To direct the Administrator of the Environmental Protection Agency to establish a consortium relating to exposures to toxic substances and identifying chemicals that are safe to use. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Supercomputing for Safer Chemicals Act” or the “SUPERSAFE Act”. SEC. 2. Supercomputing for Safer Chemicals (SUPERSAFE) consortium. (a) Establishment.— (1) IN GENERAL.—The Administrator of the Environmental Protection Agency (referred to in this section as the “Administrator”), in consultation with the heads of relevant Federal agencies (including the Secretary of Health and Human Services and the Secretary of Energy), shall form a consortium, to be known as the “Supercomputing for Safer Chemicals (SUPERSAFE) Consortium” (referred to in this section as the “Consortium”). The Consortium shall include the National Laboratories of the Department of Energy, academic and other research institutions, and other entities, as determined by the Administrator, to carry out the activities described in subsection (b). (2) INCLUSION OF STATE AGENCIES.—The Administrator shall allow the head of a relevant State agency to join the Consortium on request of the State agency. (b) Consortium activities.— (1) IN GENERAL.—The Consortium shall use supercomputing, machine learning, and other similar capabilities— (A) to establish rapid approaches for l",https://www.congress.gov/bill/118th-congress/house-bill/3457,en,"Harms: Harm to health/safety, Strategies: Government study or report, Strategies: Government support, Strategies: Convening, Strategies: New institution, Applications: Medicine, life sciences and public health"
320,Land Grant Research Prioritization Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9852,low,0.0,216,1.0,Defunct,"A BILL To amend the Food, Agriculture, Conservation, and Trade Act of 1990 to include additional priorities as research and extension initiatives, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Land Grant Research Prioritization Act of 2023”. SEC. 2. Additional research and extension priorities. Section 1672(d) of the Food, Agriculture, Conservation, and Trade Act of 1990 (7 U.S.C. 5925(d)) is amended by adding at the end the following: “(21) ADVANCED MECHANIZED HARVESTER TECHNOLOGIES RESEARCH AND EXTENSION.— “(A) IN GENERAL.—Research and extension grants may be made under this section for the purpose of developing and evaluating technologies to mechanize agricultural processes. “(B) EMPHASIS.—In awarding grants under subparagraph (A), the Secretary may place emphasis on mechanizing the process for harvesting specialty crops. “(22) AGRICULTURAL APPLICATION OF ARTIFICIAL INTELLIGENCE RESEARCH AND EXTENSION.— “(A) IN GENERAL.—Research and extension grants may be made under this section for the purpose of developing and evaluating agricultural uses of artificial intelligence. “(B) EMPHASIS.—In awarding grants under subparagraph (A), the Secretary may place emphasis on uses of artificial intelligence that improve specialty crop production. “(23) INVASIVE SPECIES RESEARCH AND EXTENSION.—Research and extension grants may be made under this s",https://www.congress.gov/bill/118th-congress/house-bill/4162,en,"Strategies: Government support, Strategies: Government support: For R&D, Applications: Agriculture and resource extraction"
322,No CCP Consultants Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.969,low,0.0,246,1.0,Defunct,"A BILL To prohibit certain contractors who have previously consulted for certain foreign entities or who fail to make disclosures relating to conflicts of interest that relate to national security or foreign policy from receiving contracts from the Department of State, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “No CCP Consultants Act”. SEC. 2. Organizational conflict of interests relating to national security and foreign policy. (a) Prohibition related certain contracts or grants.— (1) IN GENERAL.—The Secretary may not, after the date of the enactment of this Act, enter into, renew, or extend a contract with, or award a grant to, a covered consultancy. (2) DISCLOSURE.—Any individual or entity that submits an offer or bid for a contract to provide consulting services to the Department of State shall disclose in such offer or bid any information relevant to the individual or entity with respect to the prohibition under paragraph (1), including— (A) whether the individual or entity has entered into a contract with, or received grants or other financial awards from a covered entity in the five years prior to submitting the offer or bid; and (B) at the time the contract to provide consulting services to the Department will be entered into, whether— (i) any contract entered into by the individual or entity with a covered entity will stil",https://www.congress.gov/bill/118th-congress/house-bill/6146,en,
323,Drone Safety and Efficiency Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9729,low,0.1111,223,1.0,Defunct,"A BILL To direct the Administrator of the Federal Aviation Administration to adopt a performance- and risk-based approach in reviewing requests for certain certificates of waiver, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Drone Safety and Efficiency Act”. SEC. 2. 14 CFR part 107 waiver improvements. (a) In general.—The Administrator of the Federal Aviation Administration shall adopt a performance- and risk-based approach in reviewing requests for certificates of waiver under section 107.200 of title 14, Code of Federal Regulations. (b) Standardization of waiver application.— (1) IN GENERAL.—In carrying out subsection (a), the Administrator shall improve the the process established to submit requests for certificates of waiver described in subsection (a). (2) FORMAT.—In carrying out paragraph (1), the Administrator may not require the use of open-ended descriptive prompts that are required to be filled out by an applicant, except to provide applicants the ability to provide the Administration with information for an unusual or irregular operation. (3) DATA.— (A) IN GENERAL.—In carrying out paragraph (1), the Administrator shall leverage data gathered from previous requests for certificates of waivers. (B) CONSIDERATIONS.—In carrying out subparagraph (A), the Administrator shall safely use— (i) big data analytics; and (ii) machine l",https://www.congress.gov/bill/118th-congress/house-bill/3983,en,"Harms: Harm to health/safety, Harms: Harm to property"
326,"Sensible Classification Act of 2023, Sec. 7: Implementation of Technology for Classification and Declassification",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9833,low,0.0,216,0.7,Defunct,"SEC. 7. Implementation of technology for classification and declassification. (a) In general.—Not later than 1 year after the date of the enactment of this Act, the Administrator of the Office of Electronic Government of the Office of Management and Budget (in this section referred to as the “Administrator”), in consultation with the Secretary of Defense, the Director of the Central Intelligence Agency, the Director of National Intelligence, the Director of the Information Security Oversight Office, the head of the National Declassification Center of the National Archives and Records Administration, and the Public Interest Declassification Board, shall— (1) research a technology-based solution— (A) using machine learning and artificial intelligence to support efficient and effective systems for classification and declassification; and (B) to be implemented on an interoperable and federated basis across the Federal Government; and (2) submit to the President a recommendation regarding a technology-based solution described in paragraph (1) that should be adopted by the Federal Government. (b) Staff.—The Administrator may hire sufficient staff to carry out subsection (a). (c) Report.— (1) SUBMISSION.—Not later than 540 days after the date of the enactment of this Act, the President shall submit to Congress a report on the technology-based solution recommended by the Administrator under subsection (a)(2) and the determination of the President regarding its adoption. (2) FORM.—The",https://www.congress.gov/bill/118th-congress/house-bill/5977,en,"Strategies: Government study or report, Strategies: Government support: For R&D, Strategies: Convening, Strategies: New institution, Applications: Security, Applications: Government: military and public safety"
327,"Sec. 2412. Duty of Care, Digital Consumer Protection Commission Act of 2023",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7102,low,0.2222,214,0.7,Defunct,"SEC. 2412. Duty of care. “(a) In general.—A covered entity may not design or employ services or algorithms, or process, collect, store, or transfer personal data, in a manner that causes or is likely to cause any of the following: “(1) Physical, economic, relational, or reputational injury to a person. “(2) Psychological injuries that would be highly offensive to a reasonable person. “(3) Discrimination on the basis of a person’s or class of persons’ actual or perceived race, color, ethnicity, sex (including sexual orientation, gender identity, and sex characteristics), religion, national origin, familial status, biometric information, or disability status. “(4) Discrimination regarding a decision that produces a legal effect or similarly significant effect concerning a person. “(b) Definition.—For purposes of subsection (a)(4), the term ‘decision that produces a legal effect or similarly significant effect concerning a person’ includes denial or degradation of consequential services or support, such as financial or lending services, housing, insurance, educational enrollment, criminal justice, employment opportunities, health care services, and access to basic necessities, such as food and water. “(c) Exceptions.—Subsection (a) shall not apply to— “(1) the design or employment of services or algorithms, or the processing, collecting, storing, or transferring of personal data, for the purpose of— “(A) a covered entity’s self-testing to prevent or mitigate unlawful discriminat",https://www.congress.gov/bill/118th-congress/senate-bill/2597,en,"Harms: Harm to health/safety, Harms: Financial loss, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Performance requirements, Strategies: Input controls, Strategies: Input controls: Data circulation, Strategies: Input controls: Data use, Applications: Finance and investment, Applications: Business services and analytics"
328,"Sec. 2501. Corporate Citizenship and Ownership, Digital Consumer Protection Commission Act of 2023",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9716,low,0.0,239,0.7,Defunct,"SEC. 2501. Corporate citizenship and ownership. “(a) Definition.—In this section, the term ‘foreign adversary’ has the meaning given the term in section 8(c) of the Secure and Trusted Communications Networks Act of 2019 (47 U.S.C. 1607(c)). “(b) Corporate citizenship.— “(1) IN GENERAL.—An operator of a dominant platform shall— “(A) be a citizen of the United States; or “(B) own a subsidiary corporation— “(i) that is a citizen of the United States; and “(ii) the number of directors of which who are noncitizens is less than half of the number of directors necessary to constitute a quorum. “(2) DIRECTORS.—No director of a subsidiary corporation described in paragraph (1)(B) may be a citizen of a foreign adversary. “(c) Ownership.—If more than 10 percent of the owners of an operator of a dominant platform are citizens of a foreign adversary, the operator of the dominant platform shall sequester any back-end data, algorithm, or information about United States users on the dominant platform so that the back-end data, algorithm, or information is inaccessible to any subsidiary, affiliate, director, employee, or agent of the operator of the dominant platform that is based outside of the United States. “(d) Review by Committee on Foreign Investment in the United States.— “(1) IN GENERAL.—The Committee on Foreign Investment in the United States shall— “(A) treat the application of a foreign person (as defined in section 800.224 of title 31, Code of Federal Regulations (or a successor r",https://www.congress.gov/bill/118th-congress/senate-bill/2597,en,"Strategies: Input controls, Strategies: Input controls: Data circulation, Applications: Broadcasting and media production"
329,"An Act to amend the general business law, the executive law, the state finance law and the education law, in relation to enacting the ""digital fairness act"" - Sections 7-9 (""AUTOMATED DECISION SYSTEM IMPACT ASSESSMENTS,"" etc.)",New York,United States,State governments,U.S. state and local documents,Law/Act,2024-01-03,2024,1,positive,0.9378,high,0.7222,230,0.7,Proposed,"§ 7. Section 165 of the state finance law is amended by adding two new subdivisions 9 and 10 to read as follows: 9. AUTOMATED DECISION SYSTEM IMPACT ASSESSMENTS. A. FOR THE PURPOSE OF THIS SUBDIVISION, THE FOLLOWING TERMS SHALL HAVE THE FOLLOWING MEANINGS: (I) ""AUTOMATED DECISION SYSTEM"" SHALL MEAN ANY SOFTWARE, SYSTEM, OR PROCESS THAT IS DESIGNED TO AID OR REPLACE HUMAN DECISION MAKING. SUCH TERM MAY INCLUDE ANALYZING COMPLEX DATASETS TO GENERATE SCORES, PREDIC- TIONS, CLASSIFICATIONS, OR SOME RECOMMENDED ACTION OR ACTIONS, WHICH ARE USED BY AGENCIES TO MAKE DECISIONS THAT IMPACT HUMAN WELFARE. (II) ""AUTOMATED DECISION SYSTEM IMPACT ASSESSMENT"" SHALL MEAN A STUDY EVALUATING AN AUTOMATED DECISION SYSTEM AND THE AUTOMATED DECISION SYSTEM'S DEVELOPMENT PROCESSES, INCLUDING THE DESIGN AND TRAINING DATA OF THE AUTOMATED DECISION SYSTEM, FOR STATISTICAL IMPACTS ON CLASSES PROTECTED UNDER SECTION TWO HUNDRED NINETY-SIX OF THE EXECUTIVE LAW, AS WELL AS FOR IMPACTS ON PRIVACY, AND SECURITY THAT INCLUDES AT A MINIMUM: (A) A DETAILED DESCRIPTION OF THE AUTOMATED DECISION SYSTEM, ITS DESIGN, ITS TRAINING, ITS DATA, AND ITS PURPOSE; (B) AN ASSESSMENT OF THE RELATIVE BENEFITS AND COSTS OF THE AUTOMATED DECISION SYSTEM IN LIGHT OF ITS PURPOSE, TAKING INTO ACCOUNT RELEVANT FACTORS, INCLUDING DATA MINIMIZATION PRACTICES, THE DURATION FOR WHICH PERSONAL INFORMATION AND THE RESULTS OF THE AUTOMATED DECISION SYSTEM ARE STORED, WHAT INFORMATION ABOUT THE AUTOMATED DECISION SYSTEM ARE AVAILABLE T",https://www.nysenate.gov/legislation/bills/2023/S2277,en,"Risk factors: Privacy, Risk factors: Security, Risk factors: Bias, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Applications: Government: benefits and welfare, Harms: Financial loss, Harms: Harm to health/safety, Harms: Harm to property, Harms: Discrimination, Harms: Violation of civil or human rights, including privacy, Applications: Finance and investment, Applications: Business services and analytics, Applications: Government: judicial and law enforcement"
356,Texas HB 4695,Texas,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-06-16,2024,6,positive,0.9782,low,0.0556,216,0.7,Defunct,"88R14274 EAS-F By: Jetton H.B. No. 4695 A BILL TO BE ENTITLED AN ACT relating to the provision of artificial intelligence mental health services. BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF TEXAS: SECTION 1. Subtitle E, Title 7, Health and Safety Code, is amended by adding Chapter 616 to read as follows: CHAPTER 616. PROVISION OF ARTIFICIAL INTELLIGENCE MENTAL HEALTH SERVICES Sec. 616.001. DEFINITIONS. In this chapter: (1) ""Artificial intelligence mental health services"" means the use of artificial intelligence technology to provide counseling, therapy, or other mental health services. (2) ""Artificial intelligence technology"" means computer software that is designed to simulate human intelligence through machine learning and perform tasks that would normally require human involvement. (3) ""Licensed mental health professional"" means an individual licensed by this state to provide counseling, therapy, or other mental health services, including: (A) a physician licensed under Subtitle B, Title 3, Occupations Code, who specializes in psychiatry; (B) a psychologist licensed under Chapter 501, Occupations Code; (C) a marriage and family therapist licensed under Chapter 502, Occupations Code; (D) a licensed professional counselor licensed under Chapter 503, Occupations Code; and (E) a social worker licensed under Chapter 505, Occupations Code. Sec. 616.002. REQUIREMENTS FOR ARTIFICIAL INTELLIGENCE MENTAL HEALTH SERVICES. (a) A person may not provide artificial intelligence ment",https://capitol.texas.gov/tlodocs/88R/billtext/html/HB04695I.htm,en,"Applications: Medicine, life sciences and public health, Strategies: Disclosure: In deployment, Strategies: Disclosure, Strategies: Pilots and testbeds, Strategies: Evaluation, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure: About evaluation, Risk factors: Bias, Incentives: Civil liability"
357,New Jersey Bill A537,New Jersey,United States,State governments,U.S. state and local documents,Law/Act,2024-06-16,2024,6,positive,0.7226,low,0.0,225,0.5,Defunct,"AN ACT concerning discrimination in automobile insurance underwriting and supplementing P.L.1997, c.151. (C.17:29A3 46.1 et al.). BE IT ENACTED by the Senate and General Assembly of the State of New Jersey: 1. a. An automobile insurer using an automated or predictive underwriting system shall annually provide documentation and analysis to the Department of Banking and Insurance to demonstrate that there is no discriminatory outcome in the pricing on the basis of race, ethnicity, sexual orientation, or religion, that is determined by the use of the insurer’s automated or predictive underwriting system. Additionally, an insurer shall demonstrate to the commissioner that each pricing segment is balanced and not disproportionate to the overall policyholder population. b. As used in this act, “automated or predictive underwriting system” means a computer-generated process that is used to evaluate the risk of a policyholder and determine an insurance rate. An automated or predictive underwriting system may include, but is not limited to, the use of robotic process automation, artificial intelligence, or other specialized technology in its underwriting process. 1. The Commissioner of Banking and Insurance shall adopt rules and regulations pursuant to the “Administrative procedure Act,” P.L.1968, c.410 (C.52:14B-1 et seq.), to effectuate the purposes of this act. 2. This act shall take effect on the first day of the sixth month next following enactment and shall apply to automobile i",https://pub.njleg.state.nj.us/Bills/2022/A1000/537_I1.PDF,en,
360,Massachusetts Bill H.64,Massachusetts,United States,State governments,U.S. state and local documents,Law/Act,2023-01-19,2023,1,positive,0.9371,low,0.2222,215,0.7,Proposed,"Bill H.64 SECTION 1. Chapter 7D of the General Laws, as amended by chapter 64 of the acts of 2017, is hereby further amended by inserting after section 10 the following new section:- Section 11. (a) As used in this section, the following words shall have the following meanings unless the context clearly requires otherwise: “Algorithm”, a specific procedure, set of rules, or order of operations designed to solve a problem or make a calculation, classification, or recommendation. “Artificial intelligence”, computerized methods and tools, including but not limited to machine learning and natural language processing, that act in a way that resembles human cognitive abilities when it comes to solving problems or performing certain tasks. “Automated decision system”, any computer program, method, statistical model, or process that aims to aid or replace human decision-making using algorithms or artificial intelligence. These systems can include analyzing complex datasets about human populations and government services or other activities to generate scores, predictions, classifications, or recommendations used by agencies to make decisions that impact human welfare. “Commonwealth of Massachusetts or “Massachusetts office”, any agency, constitutional office, department, board, commission, bureau, division or authority of the commonwealth, or of any political subdivision thereof, or of any authority established by the general court to serve a public purpose. “Identified group charact",https://malegislature.gov/Bills/193/H64/House/Bill/Text,en,"Risk factors: Safety, Harms: Discrimination, Harms: Violation of civil or human rights, including privacy, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Risk factors: Bias, Strategies: Governance development, Strategies: New institution, Strategies: Convening"
362,New Jersey SB 3876,New Jersey,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-06-16,2024,6,positive,0.951,low,0.0,214,0.5,Defunct,"SENATE, No. 3876 STATE OF NEW JERSEY 220th LEGISLATURE INTRODUCED MAY 22, 2023 Sponsored by: Senator TROY SINGLETON District 7 (Burlington) SYNOPSIS Concerns regulation of automated systems and artificial intelligence used by State agencies. CURRENT VERSION OF TEXT As introduced. An Act concerning automated systems and artificial intelligence, and supplementing Title 52 of the Revised Statutes. Be It Enacted by the Senate and General Assembly of the State of New Jersey: 1. As used in P.L. , c. (C. ) (pending before the Legislature as this bill): “Artificial intelligence” means: (1) any artificial system that performs tasks under varying and unpredictable circumstances without significant human oversight, or that can learn from experience and improve performance when exposed to data sets; (2) an artificial system developed in computer software, physical hardware, or other context that solves tasks requiring human-like perception, cognition, planning, learning, communication, or physical action; (3) an artificial system designed to think or act like a human, including cognitive architectures and neural networks; (4) a set of techniques, including machine learning, that is designed to approximate a cognitive task; or (5) an artificial system designed to act rationally, including an intelligent software agent or embodied robot that achieves goals using perception, planning, reasoning, learning, communicating, decision making, and acting. “Artificial Intelligence Implementation Of",https://pub.njleg.gov/Bills/2022/S4000/3876_I1.HTM,en,
363,New York Bill A5309,New York,United States,State governments,U.S. state and local documents,Law/Act,2023-03-07,2023,3,positive,0.7003,medium,0.3889,236,0.7,Proposed,"5309 2023-2024 Regular Sessions IN ASSEMBLY March 7, 2023 Introduced by M. of A. SOLAGES -- read once and referred to the Committee on Governmental Operations AN ACT to amend the state finance law, in relation to the purchase of products that are or contain an algorithmic decision system that adheres to responsible artificial intelligence standards; and to amend the executive law, in relation to the definition of ""unlawful discriminatory practice"" The People of the State of New York, represented in Senate and Assembly, do enact as follows: Section 1. Section 165 of the state finance law is amended by adding a new subdivision 9 to read as follows: 1. Algorithmic decision system purchase. a. As used in this subdivision: (i) ""algorithmic decision system"" means a computational process, including one derived from machine learning, statistics, or other data processing or artificial intelligence techniques, that makes a decision, or facilitates human decision making, in a manner that impacts individuals; and (ii) ""state unit"" means the state and any governmental agency or political subdivision or public benefit corporation of the state. b. When purchasing a product or service that is or contains an algorithmic decision system to be used by the state, a state unit shall purchase a product or service that adheres to responsible artificial intelligence standards, including: (i) the avoidance of harm, including the minimization of: (A) risks of physical or mental injury; (B) the unjusti",https://www.nysenate.gov/legislation/bills/2023/A5309,en,"Harms: Harm to health/safety, Harms: Violation of civil or human rights, including privacy, Harms: Ecological harm, Harms: Harm to infrastructure, Harms: Harm to property, Harms: Discrimination, Applications: Government: other applications/unspecified, Risk factors: Transparency"
365,Massachusetts Bill S. 31,Massachusetts,United States,State governments,U.S. state and local documents,Law/Act,2023-01-20,2023,1,positive,0.9869,low,0.0,226,0.5,Proposed,"Bill S.31 SECTION 1. The General Laws are hereby amended by inserting after chapter 93A the following chapter:- CHAPTER 93A½. Generative Artificial Intelligence Models Section 1. Purpose The purpose of this chapter is to regulate generative artificial intelligence models, such as ChatGPT, in order to protect the public’s safety, privacy and intellectual property rights. Section 2. Definitions For the purposes of this chapter, the following words shall have the following meanings, unless the context clearly requires otherwise: (a) A “large-scale generative artificial intelligence model” shall mean a machine learning model with a capacity of at least one billion parameters that generates text or other forms of output, such as ChatGPT. (b) “Parameter” shall mean any variable or value used to control the operation or output of a generative artificial intelligence model. Section 3. Operating Standards Any company operating a large-scale generative artificial intelligence model shall adhere to the following operating standards: (1) the model shall not be used to engage in discrimination or bias against any individual or group based on protected characteristics, as defined by state or federal law; (2) in order to prevent plagiarism, the model shall be programmed to generate all text with a distinctive watermark or offer an authentication process that allows a user to determine whether a particular output was generated by the model; (3) the company shall implement reasonable security",https://malegislature.gov/Bills/193/S31/Senate/Bill/Text,en,
366,New York A7106,New York,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2023-05-10,2023,5,positive,0.9291,low,0.0,231,0.5,Proposed,"7106--A 2023-2024 Regular Sessions IN ASSEMBLY May 10, 2023 Introduced by M. of A. BORES, WALKER, TAYLOR, CUNNINGHAM, McDONALD, ROZIC, LEE, L. ROSENTHAL, EPSTEIN, TAPIA, RIVERA, BURGOS, GIBBS, DAVILA, DINOWITZ, SILLITTI, CARROLL, SIMON -- read once and referred to the Committee on Election Law – committee discharged, bill amended, ordered reprinted as amended and recommitted to said committee AN ACT to amend the election law, in relation to the use and disclosure of synthetic media The People of the State of New York, represented in Senate and Assembly, do enact as follows: Section 1. Short title. This act shall be known and may be cited as the ""political artificial intelligence disclaimer (PAID) act"". § 2. Section 14-106 of the election law is amended by adding a new subdivision 2-a to read as follows: 2-a. (a) Any political communication covered by this section which was produced by or includes any synthetic media shall be required to disclose the use of such synthetic media. The disclosure on printed or digital political communications, including but not limited to brochures, flyers, posters, mailings, or internet advertising shall be printed or typed in an appropriate legible form to read as follows: ""This political communication was created with the assistance of artificial intelligence"". The disclosure on non-printed or digital political communications shall clearly and prominently display and/or speak the following statement: ""This political communication was created w",https://www.nysenate.gov/node/12010550,en,
367,New York S7422,New York,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2023-05-24,2023,5,positive,0.886,low,0.0556,246,0.7,Proposed,"7422--A 2023-2024 Regular Sessions IN SENATE May 24, 2023 Introduced by Sens. WEBB, COMRIE, RAMOS -- read twice and ordered printed, and when printed to be committed to the Committee on Investigations and Government Operations -- committee discharged, bill amended, ordered reprinted as amended and recommitted to said committee AN ACT to amend the tax law, in relation to excluding a production which uses artificial intelligence in a manner which results in the displacement of employees whose salaries are qualified expenses from the definition of qualified film for the purposes of the empire state film production credit The People of the State of New York, represented in Senate and Assembly, do enact as follows: Section 1. Paragraph 3 of subdivision (b) of section 24 of the tax law, as amended by section 9-a of part D of chapter 59 of the laws of 2023, is amended to read as follows: (3) ""Qualified film"" means a feature-length film, television film, relocated television production, television pilot or television series, regardless of the medium by means of which the film, pilot or series is created or conveyed. For the purposes of the credit provided by this section only, a ""qualified film"" whose majority of principal photography shooting days in the production of the qualified film are shot in Westchester, Rockland, Nassau, or Suffolk county or any of the five New York City boroughs shall have a minimum budget of one million dollars. A ""qualified film"", whose majority of princi",https://www.nysenate.gov/legislation/bills/2023/S7422/amendment/A,en,"Harms: Financial loss, Strategies: Governance development, Strategies: Tiering, Strategies: Tiering: Tiering based on impact, Applications: Broadcasting and media production"
368,Rhode Island HB 6286,Rhode Island,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-06-16,2024,6,positive,0.9898,medium,0.4444,216,0.7,Defunct,"STATE OF RHODE ISLAND IN GENERAL ASSEMBLY JANUARY SESSION, A.D. 2023 AN ACT RELATING TO COMMERCIAL LAW - GENERAL REGULATORY PROVISIONS -- GENERATIVE ARTIFICIAL INTELLIGENCE MODELS Introduced By: Representatives Carson, Baginski, and McNamara Date Introduced: April 19, 2023 Referred To: House Innovation, Internet, & Technology It is enacted by the General Assembly as follows: SECTION 1. Title 6 of the General Laws entitled ""COMMERCIAL LAW — GENERAL REGULATORY PROVISIONS"" is hereby amended by adding thereto the following chapter: CHAPTER 59 GENERATIVE ARTIFICIAL INTELLIGENCE MODELS 6-59-1. Purpose. The purpose of this chapter is to regulate generative artificial intelligence models, such as ChatGPT, in order to protect the public’s safety, privacy, and intellectual property rights. 6-59-2. Definition. For the purposes of this chapter, the following words shall have the following meanings, unless the context clearly requires otherwise: (1) “Large-scale generative artificial intelligence model” means a machine learning model with a capacity of at least one billion (1,000,000,000) parameters that generates text or other forms of output, such as ChatGPT. (2) “Parameter” means any variable or value used to control the operation or output of a generative artificial intelligence model. 6-59-3. Operating standards. Any company operating a large-scale generative artificial intelligence model shall adhere to the following operating standards: (1) The model shall not be used to engage in",https://webserver.rilegislature.gov/BillText23/HouseText23/H6286.pdf,en,"Strategies: Tiering, Risk factors: Bias, Risk factors: Privacy, Risk factors: Safety, Risk factors: Security, Risk factors: Transparency, Harms: Harm to health/safety, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Disclosure, Strategies: Governance development, Strategies: Disclosure: About inputs, Strategies: Disclosure: In deployment"
371,Illinois HB 3563,Illinois,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2023-08-04,2023,8,positive,0.9524,low,0.0,242,0.5,Enacted,"AN ACT concerning State government. Be it enacted by the People of the State of Illinois, represented in the General Assembly: Section 5. The Department of Innovation and Technology Act is amended by adding Section 1-80 as follows: (20 ILCS 1370/1-80 new) Sec. 1-80. Generative AI and Natural Language Processing Task Force. (a) As used in this Section, ""Task Force"" means the Generative AI and Natural Language Processing Task Force established by this Section. (b) The Department shall establish the Generative AI and Natural Language Processing Task Force. The Task Force shall investigate and provide a report on generative artificial intelligence software and natural language processing software. (c) The Task Force shall be composed of all of the following members: (1) One member appointed by the Speaker of the House of Representatives, who shall serve as a co-chairperson. (2) One member appointed by the Minority Leader of the House of Representatives. (3) One member appointed by the President of the Senate, who shall serve as a co-chairperson. (4) One member appointed by the Minority Leader of the Senate. (5) The Secretary of the Department of Innovation and Technology or his or her designee. (6) The State Superintendent of Education or his or her designee. (7) The Executive Director of the Illinois Community College Board or his or her designee. (8) The Executive Director of the Board of Higher Education or his or her designee. (9) Two teachers recommended by a statewide assoc",https://ilga.gov/legislation/103/HB/PDF/10300HB3563lv.pdf,en,
374,New York A7838,New York,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2023-07-07,2023,7,positive,0.743,low,0.0,232,0.7,Proposed,"7838 2023-2024 Regular Sessions IN ASSEMBLY July 7, 2023 Introduced by M. of A. CUNNINGHAM -- read once and referred to the Committee on Labor AN ACT in relation to requiring the department of labor to study the long-term impact of artificial intelligence on the state workforce THE PEOPLE OF THE STATE OF NEW YORK, REPRESENTED IN SENATE AND ASSEMBLY, DO ENACT AS FOLLOWS: Section 1. 1. No later than six months after the effective date of this act, the department of labor, in consultation with the department of civil service and the office of information technology services, shall begin a study on the long-term impact of artificial intelligence on the state workforce including but not limited to job performance, productivity, training, education requirements, privacy and security. The department shall issue an interim report on its current findings and recommendations for legislative action every five years and shall issue a final report and recommendations for legislative action no later than January 1, 2035. The department shall issue its reports and recommendations to the governor, the speaker of the assembly, the minority leader of the assembly, the temporary president of the senate, and the minority leader of the senate. 1. Until the final report and recommendations are received pursuant to subdivision 1 of this section, every state department, board, bureau, division, commission, committee, public authority, public corporation, council, office or other governmental entity",https://www.nysenate.gov/legislation/bills/2023/A7838,en,"Strategies: Government study or report, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Applications: Government: other applications/unspecified"
375,North Carolina SB 460,North Carolina,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2023-03-30,2023,3,positive,0.2048,low,0.0,218,0.5,Proposed,"GENERAL ASSEMBLY OF NORTH CAROLINA SESSION 2023 SENATE BILL DRS35175-LR-26 Short Title: Study Automation and the Workforce Sponsors: Senators Salvador, Lowe, and Murdock (Primary Sponsors) A BILL TO BE ENTITLED AN ACT TO ESTABLISH THE STUDY COMMITTEE ON AUTOMATION AND THE WORKFORCE. The General Assembly of North Carolina enacts: SECTION 1. The General Assembly finds that: (1) Automation during the twentieth century resulted in new job opportunities for some, but it also rendered other jobs obsolete, affecting many low-income workers. (2) Continued automation into the twenty-first century has resulted in the further diminishment of employment opportunities for some workers, especially workers who lack computer skills or are disadvantaged by social inequities or the digital divide. (3) A comprehensive review of the current and future effects of automation on the State's workforce will provide government officials, and education and business leaders, with the information and insight necessary to guide the State toward mitigating negative effects of automation on workers. This is especially true in the case of low-income and minority workers. SECTION 2. (a) Committee Established. – There is established the Study Committee on Automation and the Workforce (Committee). The Committee shall include 11 voting members, as follows: (1) Two persons representing labor organizations or nonprofit organizations engaged in workforce development efforts in this State, appointed by the Governor.",https://webservices.ncleg.gov/ViewBillDocument/2023/2915/0/DRS35175-LR-26,en,
376,Pennsylvania HB 49,Pennsylvania,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2023-03-07,2023,3,positive,0.93,low,0.0,212,0.5,Proposed,"THE GENERAL ASSEMBLY OF PENNSYLVANIA HOUSE BILL No. 49 Session of 2023 INTRODUCED BY MERCURI, ARMANINI, COOK, SCHLEGEL CULVER, FLICK, JAMES, JOZWIAK, PICKETT AND SMITH, MARCH 7, 2023 REFERRED TO COMMITTEE ON COMMERCE, MARCH 7, 2023 AN ACT Amending the act of April 9, 1929 (P.L.177, No.175), entitled ""An act providing for and reorganizing the conduct of the executive and administrative work of the Commonwealth by the Executive Department thereof and the administrative departments, boards, commissions, and officers thereof, including the boards of trustees of State Normal Schools, or Teachers Colleges; abolishing, creating, reorganizing or authorizing the reorganization of certain administrative departments, boards, and commissions; defining the powers and duties of the Governor and other executive and administrative officers, and of the several administrative departments, boards, commissions, and officers; fixing the salaries of the Governor, Lieutenant Governor, and certain other executive and administrative officers; providing for the appointment of certain administrative officers, and of all deputies and other assistants and employes in certain departments, boards, and commissions; providing for judicial administration; and prescribing the manner in which the number and compensation of the deputies and all other assistants and employes of certain departments, boards and commissions shall be determined,"" in powers and duties of the Department of State and its departmental ad",https://www.legis.state.pa.us/CFDOCS/Legis/PN/Public/btCheck.cfm?txtType=PDF&sessYr=2023&sessInd=0&billBody=H&billTyp=B&billNbr=0049&pn=0038,en,
377,Pennsylvania HR 170,Pennsylvania,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2023-06-29,2023,6,positive,0.9393,low,0.1111,221,0.7,Proposed,"THE GENERAL ASSEMBLY OF PENNSYLVANIA HOUSE RESOLUTION No. 170 Session of 2023 INTRODUCED BY MERSKI, PIELLI, MADDEN, NEILSON, GREEN, VENKAT, FRIEL, GERGELY, B. MILLER, SCHLOSSBERG, SANCHEZ, MALAGARI, JAMES, HOWARD, GALLAGHER, BRENNAN, HILL-EVANS, HARKINS, KHAN, DONAHUE, O'MARA, D. WILLIAMS AND CIRESI, JUNE 29, 2023 REFERRED TO COMMITTEE ON STATE GOVERNMENT, JUNE 29, 2023 A RESOLUTION Directing the Joint State Government Commission to establish an advisory committee to conduct a study on the field of artificial intelligence and its impact and potential future impact in Pennsylvania. WHEREAS, Artificial intelligence (AI) means models and systems performing functions generally associated with human intelligence, including reasoning and learning; and WHEREAS, Recent news stories and reports have shown the rapid acceleration of AI utilization across many different industries in this Commonwealth; and WHEREAS, While AI has the potential to be a tool to improve a variety of industries, many experts in the artificial intelligence field have been warning that we may be moving too quickly for comfort; and WHEREAS, The ""godfather of AI"" Geoffrey Hinton left his job at Google, where he developed AI programs, to ""blow the whistle"" on the dangers that artificial intelligence possess; and WHEREAS, It is important for the Commonwealth to take measures to study artificial intelligence's effect and impact; and WHEREAS, The automation of manufacturing and other jobs by artificial intelligence po",https://legiscan.com/PA/text/HR170/2023,en,"Strategies: Government study or report, Strategies: Governance development, Strategies: New institution, Strategies: Convening, Strategies: Evaluation, Harms: Detrimental content, Strategies: Government support, Strategies: Government support: AI workforce-related, Harms: Financial loss"
379,Pennsylvania HB 1380,Pennsylvania,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2023-06-12,2023,6,positive,0.9169,low,0.0,221,0.5,Proposed,"THE GENERAL ASSEMBLY OF PENNSYLVANIA HOUSE BILL No. 1380 Session of 2023 INTRODUCED BY GROVE, GREINER, KEEFER, FLICK, MOUL AND STRUZZI, JUNE 12, 2023 REFERRED TO COMMITTEE ON HUMAN SERVICES, JUNE 12, 2023 AN ACT Amending the act of June 13, 1967 (P.L.31, No.21), entitled ""An act to consolidate, editorially revise, and codify the public welfare laws of the Commonwealth,"" in public assistance, further providing for administration of assistance programs. The General Assembly of the Commonwealth of Pennsylvania hereby enacts as follows: Section 1. Section 403.1 of the act of June 13, 1967 (P.L.31, No.21), known as the Human Services Code, is amended to read: Section 403.1. Administration of Assistance Programs. (a) The department is authorized to establish rules, regulations, procedures and standards consistent with law as to the administration of programs providing assistance, including regulations promulgated under subsection (d), that do any of the following: (1) Establish standards for determining eligibility and the nature and extent of assistance. (2) Authorize providers to condition the delivery of care or services on the payment of applicable copayments. (3) Modify existing benefits, establish benefit limits and exceptions to those limits, establish various benefit packages and offer different packages to different recipients, to meet the needs of the recipients. (4) Establish or revise provider payment rates or fee schedules, reimbursement models or payment methodologies",https://www.legis.state.pa.us/CFDOCS/Legis/PN/Public/btCheck.cfm?txtType=PDF&sessYr=2023&sessInd=0&billBody=H&billTyp=B&billNbr=1380&pn=1540,en,
380,Rhode Island SB 146,Rhode Island,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-06-16,2024,6,positive,0.9239,low,0.1111,221,0.7,Defunct,"2023 -- S0146 STATE OF RHODE ISLAND IN GENERAL ASSEMBLY JANUARY SESSION, A.D. 2023 AN ACT RELATING TO STATE AFFAIRS AND GOVERNMENT -- VIDEO LOTTERY GAMES, TABLE GAMES AND SPORTS WAGERING -- THE RHODE ISLAND CONSUMER PROTECTION GAMING ACT Introduced By: Senators DiPalma, Felag, Gu, Acosta, Zurier, and Valverde Date Introduced: February 01, 2023 Referred To: Senate Special Legislation and Veterans Affairs It is enacted by the General Assembly as follows: SECTION 1. Chapter 42-61.2 of the General Laws entitled ""Video Lottery Games, Table Games and Sports Wagering"" is hereby amended by adding thereto the following section: 42-61.2-17. Prohibition on use of certain technology with video-lottery terminals and sports betting applications. (a) As used in this section, the following words shall have the following meanings unless the context clearly requires otherwise: (1) ""Algorithm"" means a specific procedure, set of rules, or order of operations designed to solve a problem or make a calculation, classification, or recommendation. (2) ""Artificial intelligence"" means computerized methods and tools, including, but not limited to, machine learning and natural language processing, that act in a way that resembles human cognitive abilities when it comes to solving problems or performing certain tasks. (3) ""Automated decision system"" means any computer program, method, statistical model, or process that aims to aid or replace human decision-making using algorithms or artificial intelligenc",https://legiscan.com/RI/text/S0146/2023,en,"Applications: Arts, sports, leisure, travel, and lifestyle, Risk factors: Privacy, Harms: Financial loss"
381,Alabama SB 78,Alabama,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2021-04-29,2021,4,positive,0.9799,low,0.0,232,0.5,Enacted,"SB78 ENROLLED, An Act, To establish the Alabama Council on Advanced Technology and Artificial Intelligence to review and advise the Governor, the Legislature, and other interested parties on the use and development of advanced technology and artificial intelligence in this state. BE IT ENACTED BY THE LEGISLATURE OF ALABAMA: Section 1. (a) There is established the Alabama Council on Advanced Technology and Artificial Intelligence. (b) The council shall review and advise the Governor and the Legislature on all aspects of the use and development of advanced technology and artificial intelligence in this state. (c) The council shall be composed of the following members: (1) Fourteen members appointed by the Governor. (2) The Secretary of Commerce, or his or her designee. (3) The Secretary of Information Technology, or his or her designee. (4) Two members appointed by the Lieutenant Governor, at least one of whom shall be an employee, board member, or trustee of an Alabama public community college or a four-year public institution of higher education. (5) Two members of the Alabama House of Representatives appointed by the Speaker of the House. (6) Two members of the Alabama Senate appointed by the Senate President Pro Tempore. (d) All persons appointed to the council other than legislators shall have one or more of the following qualifications: Expertise in matters relating to artificial intelligence, workforce development, technology, ethics, privacy, or computer science. (e) Me",https://alison.legislature.state.al.us/files/pdf/SearchableInstruments/2021RS/PrintFiles/SB78-Enr.pdf,en,
384,Arkansas SB 656,Arkansas,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2019-04-17,2019,4,positive,0.9714,low,0.0,228,0.7,Enacted,"State of Arkansas 92nd General Assembly Regular Session, 2019 By: Senator J. English For An Act To Be Entitled AN ACT TO CREATE THE DATA-SHARING AND DATA-DRIVEN DECISION-MAKING TASK FORCE; AND FOR OTHER PURPOSES. Subtitle TO CREATE THE DATA-SHARING AND DATA14 DRIVEN DECISION-MAKING TASK FORCE. BE IT ENACTED BY THE GENERAL ASSEMBLY OF THE STATE OF ARKANSAS: SECTION 1. TEMPORARY LANGUAGE. DO NOT CODIFY. Data-Sharing and Data20 Driven Decision-Making Task Force – Creation – Duties. (a) As used in this section, “state agency” means a cabinet, agency, institution, authority, department, board, commission, bureau, council, or other agency of the State of Arkansas supported by cash funds or an appropriation of state or federal funds. (b) The General Assembly finds that: (1) State agencies contain great amounts of valuable information and reports regarding all aspects of life for the citizens of this state, including without limitation health, business, public safety, labor, and transportation data; (2) The tremendous amount of data maintained by state agencies can result in the duplication of efforts, data, records, and parts of data and records that may result in the maintenance of inconsistent data and records concerning the same citizen; (3) The lack of a quick and efficient data-driven delivery system that would enable up-to-the-moment responses to legislative branch and executive branch inquiries impedes the policy-making process and ultimately costs the taxpayers money; (4) Pr",https://www.arkleg.state.ar.us/Home/FTPDocument?path=%2FACTS%2F2019R%2FPublic%2FACT943.pdf,en,"Strategies: New institution, Strategies: Convening, Strategies: Evaluation, Strategies: Government study or report, Applications: Government: benefits and welfare, Applications: Government: other applications/unspecified"
385,California SJR 6,California,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2019-07-09,2019,7,positive,0.9911,low,0.0,220,0.5,Enacted,"Senate Joint Resolution No. 6 CHAPTER 112 Relative to artificial intelligence. [Filed with Secretary of State July 09, 2019.] LEGISLATIVE COUNSEL'S DIGEST SJR 6, Chang. Artificial intelligence. This measure would urge the President and the Congress of the United States to develop a comprehensive Artificial Intelligence Advisory Committee and to adopt a comprehensive artificial intelligence policy. Fiscal Committee: no WHEREAS, Today, only 15 percent of enterprises use artificial intelligence but 31 percent said artificial intelligence is on the agenda for adoption within the next 12 months; and WHEREAS, Seventy-seven percent of consumers use an artificial intelligence-powered service or device; and WHEREAS, One-half of the leading 10 artificial intelligence startups are companies located in the United States; and WHEREAS, Artificial intelligence is expected to have a dramatic impact on the United States workforce; and WHEREAS, A study conducted by the Pew Research Center of over 1,800 experts found that nearly one-half of the experts envision “a future in which robots and digital agents [will] have displaced significant numbers of both blue- and white-collar workers”; and WHEREAS, The federal government has a role in protecting the nation’s workforce by planning for the future changes that will be brought on by emerging artificial intelligence technologies; and WHEREAS, Over one dozen countries, including Canada, China, France, and the United Kingdom, are already developing a",https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200SJR6,en,
389,Illinois HB 0645,Illinois,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2021-08-19,2021,8,positive,0.7793,low,0.0,232,0.7,Enacted,"AN ACT concerning State government. Be it enacted by the People of the State of Illinois, represented in the General Assembly: Section 1. Short title. This Act may be cited as the Illinois Future of Work Act. Section 5. Findings and declaration of policy. The General Assembly hereby finds, determines, and declares the following: (1) The future of work is a critically important conversation for those currently in the workforce as well as those looking to reenter or enter it as Illinois contemplates an equitable economic recovery from the coronavirus pandemic. (2) Policymakers at every level of government will be required to deal with the concurrent crises of the pandemic recovery, systemic inequities, and creating good-paying jobs. Policymakers must be able to anticipate the workforce policies and programs needed in the future to combat poverty, inequality, and climate change. (3) Rapid advancements in technology, specifically the automation of jobs and expanded artificial intelligence capability, have had and will continue to have a profound impact on the type, quality, and number of jobs available in our 21st century economy. (4) Automation and the rise of artificial intelligence and predictive analytics will have major impacts on industries and their jobs; from the service sector to white collar positions, the impacts will be felt by millions of workers in the United States. (5) Despite the opportunities and challenges presented by rapid advancements in technology, Illinois",https://www.ilga.gov/legislation/publicacts/fulltext.asp?Name=102-0407,en,"Strategies: New institution, Strategies: Government support: For R&D, Strategies: Government support, Strategies: Government support: AI workforce-related, Strategies: Disclosure"
390,New Jersey S 2723,New Jersey,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2022-01-18,2022,1,positive,0.7351,low,0.0,219,0.5,Enacted,"CHAPTER 392 AN ACT concerning the modernization of State government websites, supplementing Title 52 of the Revised Statutes, and amending P.L.2007, c.56. BE IT ENACTED by the Senate and General Assembly of the State of New Jersey: C.52:18A-233.1 Short title. 1. This act shall be known and may be cited as the “21st Century Integrated Digital Experience Act.” C.52:18A-233.2 Findings and declarations. 1. The Legislature finds and declares that: a. Ensuring New Jersey’s global leadership position in technology and electronic government requires an approach that narrows the growing gap between the digital demands of citizens and the methods by which the government provides digital services to New Jersey. b. The enhancement of citizen-facing digital experiences can change the paradigm for the delivery of government services and dramatically reduce the cost of government operations. c. Many State websites are not equipped to provide an enhanced experience to the growing number of citizens who access government services through a mobile device. d. Government lags far behind the private sector in providing a modern, seamless, personalized, and consistent digital experience that provides useful information and services to citizens, businesses, and other stakeholders. e. The implementation of modern customer service experiences, such as citizen-centric design, comprehensive self-service capabilities, and uniform mobile rendering will be key to facilitating the transition to from an ana",https://pub.njleg.state.nj.us/Bills/2020/PL21/392_.PDF,en,
392,Virginia HB 2154,Virginia,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2021-03-18,2021,3,positive,0.9753,low,0.0556,227,0.7,Enacted,"CHAPTER 219 An Act to amend and reenact § 32.1-127 of the Code of Virginia, relating to hospitals, nursing homes, and certified nursing facilities; regulations; patient access to intelligent personal assistant. Approved March 18, 2021 Be it enacted by the General Assembly of Virginia: 1. That § 32.1-127 of the Code of Virginia is amended and reenacted as follows: § 32.1-127. Regulations. A. The regulations promulgated by the Board to carry out the provisions of this article shall be in substantial conformity to the standards of health, hygiene, sanitation, construction and safety as established and recognized by medical and health care professionals and by specialists in matters of public health and safety, including health and safety standards established under provisions of Title XVIII and Title XIX of the Social Security Act, and to the provisions of Article 2 (§ 32.1-138 et seq.). B. Such regulations: 1. Shall include minimum standards for (i) the construction and maintenance of hospitals, nursing homes and certified nursing facilities to ensure the environmental protection and the life safety of its patients, employees, and the public; (ii) the operation, staffing and equipping of hospitals, nursing homes and certified nursing facilities; (iii) qualifications and training of staff of hospitals, nursing homes and certified nursing facilities, except those professionals licensed or certified by the Department of Health Professions; (iv) conditions under which a hospital or",https://lis.virginia.gov/cgi-bin/legp604.exe?212+ful+CHAP0219,en,"Applications: Medicine, life sciences and public health, Harms: Harm to health/safety"
394,Artificial Intelligence Bug Bounty Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9836,low,0.1111,216,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Artificial Intelligence Bug Bounty Act of 2023”. SEC. 2. ARTIFICIAL INTELLIGENCE BUG BOUNTY PROGRAMS. (a) Program For Foundational Artificial Intelligence Products Being Incorporated By Department Of Defense.— (1) DEVELOPMENT REQUIRED.—Not later than 180 days after the date of the enactment of this Act, the Chief Data and Artificial Intelligence Officer of the Department of Defense shall develop a bug bounty program for foundational artificial intelligence products being incorporated by the Department of Defense. (2) COLLABORATION.—In developing the program required by paragraph (1), the Chief may collaborate with the heads of other government agencies that have expertise in cybersecurity and artificial intelligence. (3) IMPLEMENTATION AUTHORIZED.—The Chief may carry out the program developed pursuant to subsection (a). (4) CONTRACTS.—The Secretary of Defense shall ensure that whenever the Department of Defense enters into any contract, the contract allows for participation in the bug bounty program developed pursuant to paragraph (1). (5) RULE OF CONSTRUCTION.—Nothing in this subsection shall be construed to require— (A) the use of any foundational artificial intelligence product; or (B) the implementation of the program developed pursuant to paragraph (1) in order for the Department to incorporate a foundational artificial intelligence product.(b) Briefing.—Not later than one year after the date of the enactment of this",https://www.congress.gov/bill/118th-congress/senate-bill/2502/text,en,"Strategies: Evaluation, Strategies: Government support, Strategies: Government support: For R&D, Risk factors: Reliability, Strategies: Evaluation: Adversarial testing, Risk factors: Reliability: Robustness, Strategies: Convening, Strategies: Disclosure, Strategies: Disclosure: About evaluation"
395,"Artificial Intelligence Research, Innovation, and Accountability Act of 2023",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9922,low,0.3333,206,1.0,Defunct,"A BILL To provide a framework for artificial intelligence innovation and accountability, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Artificial Intelligence Research, Innovation, and Accountability Act of 2023”. SEC. 2. Table of contents. The table of contents for this Act is as follows: Sec. 1. Short title. Sec. 2. Table of contents. TITLE I—ARTIFICIAL INTELLIGENCE RESEARCH AND INNOVATION Sec. 101. Open data policy amendments. Sec. 102. Online content authenticity and provenance standards research and development. Sec. 103. Standards for detection of emergent and anomalous behavior and AI-generated media. Sec. 104. Comptroller General study on barriers and best practices to usage of AI in government. TITLE II—ARTIFICIAL INTELLIGENCE ACCOUNTABILITY Sec. 201. Definitions. Sec. 202. Generative artificial intelligence transparency. Sec. 203. Transparency reports for high-impact artificial intelligence systems. Sec. 204. Recommendations to Federal agencies for risk management of high-impact artificial intelligence systems. Sec. 205. Office of Management and Budget oversight of recommendations to agencies. Sec. 206. Risk management assessment for critical-impact artificial intelligence systems. Sec. 207. Certification of critical-impact artificial intelligence systems. Sec. 208. Enforcement. Sec. 209. Artificial intelligence consumer edu",https://www.congress.gov/bill/118th-congress/senate-bill/3312,en,"Strategies: Government support: For R&D, Strategies: Pilots and testbeds, Strategies: Convening, Strategies: Government study or report, Strategies: Disclosure: In standard form, Risk factors: Interpretability and explainability, Applications: Government: military and public safety, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Risk factors: Security, Risk factors: Transparency, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About inputs, Risk factors: Safety"
396,Artificial Intelligence Accountability Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9925,low,0.1667,200,1.0,Defunct,"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE. This Act may be cited as the ``Artificial Intelligence Accountability Act'' or the ``AI Accountability Act''.SEC. 2. STUDY ON ACCOUNTABILITY MEASURES FOR ARTIFICIAL INTELLIGENCE SYSTEMS.(a) Study.--The Assistant Secretary of Commerce for Communications and Information shall conduct a study on accountability measures for artificial intelligence systems, which shall include an analysis of the following: (1) How accountability measures are being incorporated into artificial intelligence systems used by communications networks (including telecommunications networks and social media platforms) and electromagnetic spectrum sharing applications. (2) How accountability measures for artificial intelligence systems can facilitate the closing of the digital divide and assist the promotion of digital inclusion in the United States. (3) How accountability measures may reduce risks related to artificial intelligence systems, including cybersecurity risks. (4) How the term ``trustworthy'' is used and defined in the context of artificial intelligence, including how the term may be applied in various contexts related to artificial intelligence. (5) The relationship, with respect to artificial intelligence, between the term ``trustworthy'' and other terms such as ``responsible'' and ``human-centric''.(b) Stakeholder Consultation.--In carrying out the study requ",https://www.congress.gov/bill/118th-congress/house-bill/3369/text?format=txt,en,"Strategies: Government study or report, Risk factors: Security, Risk factors: Security: Cybersecurity, Applications: Broadcasting and media production, Applications: Networking and telecommunications, Strategies: Convening, Strategies: Governance development, Strategies: Evaluation, Strategies: Evaluation: External auditing, Strategies: Licensing, registration, and certification, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Risk factors: Reliability, Strategies: Disclosure"
397,Federal Artificial Intelligence Risk Management Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9364,low,0.2222,207,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Federal Artificial Intelligence Risk Management Act of 2023”.SEC. 2. AGENCY USE OF ARTIFICIAL INTELLIGENCE. (a) Definitions.—In this section: (1) ADMINISTRATOR.—The term “Administrator” means the Administrator of Federal Procurement Policy. (2) AGENCY.—The term “agency” means any department, independent establishment, Government corporation, or other agency of the executive branch of the Federal Government. (3) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence” has the meaning given the term in section 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401). (4) DIRECTOR.—The term “Director” means the Director of the National Institute of Standards and Technology. (5) FRAMEWORK.—The term “framework” means document number NIST AI 100–1 of the National Institute of Standards and Technology entitled “Artificial Intelligence Risk Management Framework”, or any successor document. (6) PLAYBOOK.—The term “playbook” means the AI RMF Playbook developed by the National Institute of Standards and Technology. (7) PROFILE.—The term “profile” means an implementation of the artificial intelligence risk management functions, categories, and subcategories for a specific setting or application based on the requirements, risk tolerance, and resources of the framework user. (b) Requirements For Agency Use Of Artificial Intelligence.— (1) OMB GUIDANCE.—Not later than 180 days after the date on which the Di",https://www.congress.gov/bill/118th-congress/senate-bill/3205/text,en,"Risk factors: Safety, Risk factors: Security, Risk factors: Security: Cybersecurity, Strategies: Governance development, Risk factors: Transparency, Strategies: Evaluation, Strategies: Evaluation: External auditing, Strategies: Disclosure, Strategies: Disclosure: About inputs, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: AI workforce-related, Strategies: Convening"
398,A bill to waive immunity under section 230 of the Communications Act of 1934 for claims and charges related to generative artificial intelligence.,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.2808,low,0.0,232,0.7,Defunct,"S. 1993 To waive immunity under section 230 of the Communications Act of 1934 for claims and charges related to generative artificial intelligence. IN THE SENATE OF THE UNITED STATES June 14, 2023Mr. Hawley (for himself and Mr. Blumenthal) introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To waive immunity under section 230 of the Communications Act of 1934 for claims and charges related to generative artificial intelligence.Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. NO SECTION 230 IMMUNITY FOR CLAIMS AND CHARGES RELATED TO GENERATIVE ARTIFICIAL INTELLIGENCE. Section 230 of the Communications Act of 1934 (47 U.S.C. 230) is amended— (1) in subsection (e), by adding at the end the following: “(6) NO EFFECT ON CLAIMS RELATED TO GENERATIVE ARTIFICIAL INTELLIGENCE.—Nothing in this section (other than subsection (c)(2)(A)) shall be construed to impair or limit any claim in a civil action or charge in a criminal prosecution brought under Federal or State law against the provider of an interactive computer service if the conduct underlying the claim or charge involves the use or provision of generative artificial intelligence by the interactive computer service.”; and (2) in subsection (f), by adding at the end the following: “(5) GENERATIVE ARTIFICIAL INTELLIGENCE.—The term ‘generative artificial intelligence’ means an artifi",https://www.congress.gov/bill/118th-congress/senate-bill/1993/text,en,
399,Artificial Intelligence Advancement Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9883,low,0.1667,219,0.7,Defunct,"S. 3050 To require a report on artificial intelligence regulation in the financial services industry, to establish artificial intelligence bug bounty programs, to require a vulnerability analysis study for artificial intelligence-enabled military applications, and to require a report on data sharing and coordination, and for other purposes.IN THE SENATE OF THE UNITED STATES October 17, 2023 Mr. Rounds (for himself, Mr. Schumer, Mr. Young, and Mr. Heinrich) introduced the following bill; which was read twice and referred to the Committee on Armed Services A BILL To require a report on artificial intelligence regulation in the financial services industry, to establish artificial intelligence bug bounty programs, to require a vulnerability analysis study for artificial intelligence-enabled military applications, and to require a report on data sharing and coordination, and for other purposes.Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Artificial Intelligence Advancement Act of 2023”. SEC. 2. DEFINITIONS. In this Act: (1) CONGRESSIONAL DEFENSE COMMITTEES.—The term “congressional defense committees” has the meaning given such term in section 101 of title 10, United States Code. (2) FOUNDATIONAL ARTIFICIAL INTELLIGENCE MODEL.—The term “foundational artificial intelligence model” means an adaptive generative model that is trained on a broad set of unlabeled data",https://www.congress.gov/bill/118th-congress/senate-bill/3050/text,en,"Strategies: Government study or report, Strategies: New institution, Strategies: Evaluation, Applications: Government: military and public safety, Applications: Finance and investment, Strategies: Evaluation: Impact assessment, Applications: Government: other applications/unspecified, Risk factors: Security: Cybersecurity, Strategies: Evaluation: Adversarial testing, Strategies: Government support, Risk factors: Privacy, Risk factors: Security, Strategies: Evaluation: External auditing, Strategies: Convening"
400,Artificial Intelligence Environmental Impacts Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9852,low,0.0556,200,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Artificial Intelligence Environmental Impacts Act of 2024”.SEC. 2. FINDINGS. Congress finds the following: (1) Multiple estimates indicate that the amount of computational power being used for artificial intelligence applications has increased rapidly over the last decade. A 2022 estimate suggested that the number of computational operations being used to create each of the largest artificial intelligence models is currently doubling every 10 months. (2) Accelerating use of artificial intelligence has the potential to greatly increase energy consumption due to the power utilization of computer hardware required for training and operating artificial intelligence models, despite ongoing efficiency gains in both artificial intelligence models and hardware. (3) Rapid growth in data center infrastructure, including cooling systems and backup power equipment, supporting artificial intelligence and other computing-intensive technologies contributes to pollution, water consumption, and land-use changes. (4) Resource and energy-intensive manufacturing processes are required for the hardware that runs artificial intelligence and other computing-intensive technologies, leading to significant environmental impacts. (5) Yearly increases in electronic waste (known as “e-waste”) pose increasing environmental and health risks, and will likely be exacerbated by outdated and discarded hardware used for artificial intelligence and other comp",https://www.congress.gov/bill/118th-congress/house-bill/7197/text,en,"Strategies: Disclosure, Strategies: Disclosure: About inputs, Harms: Ecological harm, Strategies: Evaluation: Impact assessment, Strategies: Evaluation, Strategies: Government study or report, Strategies: Convening, Strategies: Disclosure: About evaluation"
401,Closing Loopholes for the Overseas Use and Development of Artificial Intelligence Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.765,low,0.0,223,1.0,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Closing Loopholes for the Overseas Use and Development of Artificial Intelligence Act” or the “CLOUD AI Act”.SEC. 2. FINDINGS. Congress makes the following findings: (1) The People’s Republic of China, the Russian Federation, and other adversarial countries have taken actions to undermine global stability as well as the United States national security and foreign policy objectives. (2) China has used commercially available civilian technology to modernize its military forces in a policy known as military-civil fusion. (3) As part of its policy of military-civil fusion, China is working to modernize its nuclear, chemical, missile, and biological weapons capacity. (4) The United States and its allies have long regulated items and activities that support the development, production, or use of otherwise commercial items if those items are aid in the development, production, or use of nuclear, chemical, missile, or biological weapons. (5) Artificial intelligence tools could be used to support the development, production, or use of nuclear, chemical, missile, or biological weapons or enhance the destructive capabilities of those weapons. (6) Advanced semiconductors and supercomputer components such as graphics processing units can be used to develop or train artificial intelligence tools and models. (7) In October 2022, the Department of Commerce promulgated export control rules to prevent the export of advanced semiconductors a",https://www.congress.gov/bill/118th-congress/house-bill/4683/text,en,"Strategies: Government study or report, Applications: Security, Applications: Government: military and public safety"
402,Creating Resources for Every American To Experiment with Artificial Intelligence Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,neutral,0.0,low,0.0,0,0.5,Defunct,,https://www.congress.gov/bill/118th-congress/house-bill/5077/text#H4A9FC8390DA3413D9CE17B855C2C9933,,
403,"A bill to specify control and management of Department of Defense data and to establish the Chief Digital and Artificial Intelligence Officer Governing Council, and for other purposes.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9668,low,0.0,229,0.7,Defunct,"S. 3004 To specify control and management of Department of Defense data and to establish the Chief Digital and Artificial Intelligence Officer Governing Council, and for other purposes. IN THE SENATE OF THE UNITED STATES October 3, 2023 Mr. Manchin (for himself and Mr. Rounds) introduced the following bill; which was read twice and referred to the Committee on Armed Services A BILL To specify control and management of Department of Defense data and to establish the Chief Digital and Artificial Intelligence Officer Governing Council, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. CONTROL AND MANAGEMENT OF DEPARTMENT OF DEFENSE DATA AND ESTABLISHMENT OF CHIEF DIGITAL AND ARTIFICIAL INTELLIGENCE OFFICER GOVERNING COUNCIL. (a) Control And Management Of Department Of Defense Data.—The Chief Digital and Artificial Intelligence Officer of the Department of Defense shall maintain the authority, but not the requirement, to access and control, on behalf of the Secretary of Defense, of all data collected, acquired, accessed, or utilized by Department of Defense components consistent with section 1513 of the James M. Inhofe National Defense Authorization Act for Fiscal Year 2023 (Public Law 117–263; 10 U.S.C. 4001 note). (b) Chief Digital And Artificial Intelligence Officer Governing Council.—Section 238(d) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Publ",https://www.congress.gov/bill/118th-congress/senate-bill/3004/text,en,"Strategies: New institution, Applications: Government: military and public safety, Strategies: Governance development, Strategies: Government study or report"
405,"To direct the Secretary of Defense to establish a working group to develop and coordinate an artificial intelligence initiative among the Five Eyes countries, and for other purposes.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.982,low,0.0556,233,0.7,Defunct,"H. R. 6425 To direct the Secretary of Defense to establish a working group to develop and coordinate an artificial intelligence initiative among the Five Eyes countries, and for other purposes. IN THE HOUSE OF REPRESENTATIVES November 15, 2023 Mr. Gallagher (for himself and Mr. Khanna) introduced the following bill; which was referred to the Committee on Foreign Affairs, and in addition to the Committees on Armed Services, and Intelligence (Permanent Select), for a period to be subsequently determined by the Speaker, in each case for consideration of such provisions as fall within the jurisdiction of the committee concerned A BILL To direct the Secretary of Defense to establish a working group to develop and coordinate an artificial intelligence initiative among the Five Eyes countries, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. ESTABLISHMENT OF WORKING GROUP FOR ARTIFICIAL INTELLIGENCE INITIATIVE AMONG FIVE EYES COUNTRIES. (a) Establishment.—Not later than 90 days after the date of the enactment of this Act, the Secretary of Defense, in coordination with the Director of National Intelligence, shall establish a working group to be known as the “Five AIs Strategic Artificial Intelligence Working Group” (in this section referred to as the “Working Group”). (b) Purpose.—The purpose of the Working Group shall be to develop and coordinate an artificial intelligence initiative am",https://www.congress.gov/bill/118th-congress/house-bill/6425/text,en,"Strategies: New institution, Strategies: Convening, Strategies: Evaluation, Strategies: Evaluation: Post-market monitoring, Applications: Government: military and public safety, Strategies: Governance development, Risk factors: Security, Strategies: Government study or report"
406,Artificial Intelligence Literacy Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9655,low,0.0,225,0.7,Defunct,"H. R. 6791 To amend the Digital Equity Act of 2021 to facilitate artificial intelligence literacy opportunities, and for other purposes. IN THE HOUSE OF REPRESENTATIVES December 14, 2023 Ms. Blunt Rochester (for herself and Mr. Bucshon) introduced the following bill; which was referred to the Committee on Energy and Commerce A BILL To amend the Digital Equity Act of 2021 to facilitate artificial intelligence literacy opportunities, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Artificial Intelligence Literacy Act of 2023”. SEC. 2. FINDINGS. The Congress finds the following: (1) Artificial intelligence (AI) is a transformative technology that affects nearly every aspect of the United States economy. (2) As AI becomes increasingly ubiquitous, AI literacy will become as important as digital literacy is today. (3) Technological leadership in AI is an economic and national security imperative. Maintaining this leadership requires a sufficient workforce to research and develop AI capabilities. Such a workforce must contain both technical talent, such as computer engineers and data scientists, and nontechnical talent, such as product managers and sales engineers, who understand AI. (4) Effective AI literacy initiatives encompass not only technical training but also include comprehensive education about the potential benefits and risks associ",https://www.congress.gov/bill/118th-congress/house-bill/6791/text,en,"Strategies: Government support, Strategies: Government support: AI workforce-related, Applications: Education, Strategies: Government support: For R&D, Strategies: Government study or report"
408,Strategy for Public Health Preparedness and Response to Artificial Intelligence Threats,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9222,low,0.0,224,0.5,Defunct,"S. 2346 To require the Secretary of Health and Human Services to develop a strategy for public health preparedness and response to artificial intelligence threats, and for other purposes. IN THE SENATE OF THE UNITED STATES July 18, 2023 Mr. Budd (for himself and Mr. Markey) introduced the following bill; which was read twice and referred to the Committee on Health, Education, Labor, and Pensions A BILL To require the Secretary of Health and Human Services to develop a strategy for public health preparedness and response to artificial intelligence threats, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Strategy for Public Health Preparedness and Response to Artificial Intelligence Threats”. SEC. 2. STRATEGY FOR PUBLIC HEALTH PREPAREDNESS AND RESPONSE TO ARTIFICIAL INTELLIGENCE THREATS. (a) Definitions.—In this section: (1) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence” has the meaning given the term in section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (10 U.S.C. note prec. 4061; Public Law 115–232). (2) PHSA DEFINITIONS.—The terms “qualified countermeasure”, “security countermeasure”, and “qualified pandemic or epidemic product” have the meanings given the terms in sections 319F–1(a)(2), 319F–2(c)(1)(B), and 319F–3(i), respectively, of the Public Health Service Act (42 U.S.C. 247d–",https://www.congress.gov/bill/118th-congress/senate-bill/2346/text,en,
410,"To direct the Director of the National Institutes of Health to establish a grant program to facilitate research regarding the use of generative artificial intelligence in health care, and for other purposes.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.996,low,0.0,231,0.5,Defunct,"H. R. 7381 To direct the Director of the National Institutes of Health to establish a grant program to facilitate research regarding the use of generative artificial intelligence in health care, and for other purposes. IN THE HOUSE OF REPRESENTATIVES February 15, 2024 Mr. Lieu introduced the following bill; which was referred to the Committee on Energy and Commerce A BILL To direct the Director of the National Institutes of Health to establish a grant program to facilitate research regarding the use of generative artificial intelligence in health care, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Healthcare Enhancement And Learning Through Harnessing Artificial Intelligence Act” or the “HEALTH AI Act”. SEC. 2. GRANTS TO PERFORM RESEARCH REGARDING THE USE OF GENERATIVE ARTIFICIAL INTELLIGENCE IN HEALTH CARE. (a) In General.—The Director of the National Institutes of Health shall establish a grant program to award grants to eligible entities to perform research regarding the use of generative artificial intelligence in health care. (b) Permissible Research.—Research funded pursuant to a grant under this section may include research regarding the use of generative artificial intelligence to— (1) improve the ability of health care practitioners to record comprehensive notes or ask medically relevant questions during an appointment with a",https://www.congress.gov/bill/118th-congress/house-bill/7381/text,en,
411,A bill to promote United States leadership in technical standards by directing the National Institute of Standards and Technology and the Department of State to take certain actions to encourage and enable United States participation in developing standards and specifications for artificial intellig,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9901,low,0.0,219,0.5,Defunct,"S. 3849 To promote United States leadership in technical standards by directing the National Institute of Standards and Technology and the Department of State to take certain actions to encourage and enable United States participation in developing standards and specifications for artificial intelligence and other critical and emerging technologies, and for other purposes.IN THE SENATE OF THE UNITED STATES February 29, 2024 Mr. Warner (for himself and Mrs. Blackburn) introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To promote United States leadership in technical standards by directing the National Institute of Standards and Technology and the Department of State to take certain actions to encourage and enable United States participation in developing standards and specifications for artificial intelligence and other critical and emerging technologies, and for other purposes.Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Promoting United States Leadership in Standards Act of 2024”.SEC. 2. DEFINITIONS. In this Act: (1) ARTIFICIAL INTELLIGENCE AND OTHER CRITICAL AND EMERGING TECHNOLOGIES.—The term “artificial intelligence and other critical and emerging technologies” means a subset of artificial intelligence and other critical and emerging technologies included in the list of such",https://www.congress.gov/bill/118th-congress/senate-bill/3849/text,en,
414,Eliminating Bias in Algorithmic Systems Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8669,low,0.1111,235,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Eliminating Bias in Algorithmic Systems Act of 2023”.SEC. 2. DEFINITIONS. In this Act: (1) AGENCY.—The term “agency” has the meaning given the term in section 3502 of title 44, United States Code. (2) COVERED AGENCY.—The term “covered agency” means an agency that— (A) uses, funds, or procures a covered algorithm, or funds or otherwise participates in the development of a covered algorithm; or (B) oversees, regulates, or advises on the development or use of a covered algorithm. (3) COVERED ALGORITHM.—The term “covered algorithm” means a process that—(A) is— (i) a computational process that uses machine learning, natural language processing, artificial intelligence techniques, or other computational processing techniques of similar or greater complexity; or (ii) a computational process derived from a process described in clause (i); and (B) has the potential to have a material effect on the impact of, access to, availability of, eligibility for, cost of, terms of, or conditions of— (i) a program operated or funded by an agency; (ii) an economic opportunity regulated by an agency; or (iii) rights protected by an agency.SEC. 3. CIVIL RIGHTS OFFICES AND REPORTING ON AI BIAS, DISCRIMINATION, AND OTHER HARMS. (a) Offices Of Civil Rights.—The head of each covered agency shall ensure that the covered agency has an office of civil rights that employs experts and technologists focused on bias, discrimination, and other harms resultin",https://www.congress.gov/bill/118th-congress/senate-bill/3478/text,en,"Applications: Government: other applications/unspecified, Risk factors: Bias, Harms: Violation of civil or human rights, including privacy, Strategies: New institution, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Disclosure, Strategies: Convening"
415,Preventing Algorithmic Collusion Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,neutral,0.0,low,0.0,222,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Preventing Algorithmic Collusion Act of 2024”.SEC. 2. DEFINITIONS. In this Act: (1) ANTITRUST LAWS.—The term “antitrust laws”— (A) has the meaning given that term in subsection (a) of the first section of the Clayton Act (15 U.S.C. 12); and (B) includes section 5 of the Federal Trade Commission Act (15 U.S.C. 45). (2) COMMERCIAL TERMS.—The term “commercial terms” means— (A) level of service; (B) availability; (C) output, including quantities of products produced or distributed or the amount or level of service provided; or (D) rebates or discounts made available. (3) COMMISSION.—The term “Commission” means the Federal Trade Commission. (4) DISTRIBUTE; DISTRIBUTION; DISTRIBUTING.—The terms “distribute”, “distribution”, and “distributing” include selling, licensing, providing access to, or otherwise making available by any means, including through a subscription or the sale of a service. (5) NONPUBLIC COMPETITOR DATA.—The term “nonpublic competitor data”— (A) means nonpublic data that is derived from or otherwise provided by another person that competes in the same market as a person, or a related market; and (B) does not include information distributed, reported, or otherwise communicated in a way that does not reveal any underlying data from a competitor, such as narrative industry reports, news reports, business commentaries, or generalized industry survey results. (6) NONPUBLIC DATA.—The term “nonpublic data” means infor",https://www.congress.gov/bill/118th-congress/senate-bill/3686/text,en,
416,Justice in Forensic Algorithms Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.5719,low,0.3333,218,0.7,Defunct,"A BILL To prohibit the use of trade secrets privileges to prevent defense access to evidence in criminal proceedings, provide for the establishment of Computational Forensic Algorithm Testing Standards and a Computational Forensic Algorithm Testing Program, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Justice in Forensic Algorithms Act of 2024”.SEC. 2. Computational forensic algorithm testing standards. (a) In general.—Not later than 1 year after the date of enactment of this Act, the Director of the National Institute of Standards and Technology shall establish a program to provide for creation and maintenance of standards for testing computational forensic software, to be known as the Computational Forensic Algorithm Testing Standards, consistent with the following: (1) Testing standards shall include an assessment for the potential for disparate impact, on the basis of race, ethnicity, socioeconomic status, gender, and other demographic features. (2) Testing standards shall address— (A) the underlying scientific principles and methods implemented in computational forensic software; and(B) requirements for testing the software including the conditions under which it needs to be tested, types of testing data to be used, testing environments, testing methodologies, and system performance statistics required to be reported including—",https://www.congress.gov/bill/118th-congress/house-bill/7394/text,en,"Strategies: New institution, Strategies: Governance development, Strategies: Pilots and testbeds, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Risk factors: Bias, Risk factors: Reliability, Risk factors: Reliability: Robustness, Risk factors: Transparency, Strategies: Evaluation, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure: About inputs"
418,Algorithmic Accountability Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,neutral,-0.0,low,0.0,224,0.5,Defunct,"S. 2892 To direct the Federal Trade Commission to require impact assessments of automated decision systems and augmented critical decision processes, and for other purposes. IN THE SENATE OF THE UNITED STATES September 21, 2023 Mr. Wyden (for himself, Mr. Booker, Mr. Heinrich, Mr. Peters, Mr. Casey, Mr. Luján, Ms. Baldwin, Mr. Merkley, Mr. Whitehouse, Mr. Schatz, Ms. Hirono, and Ms. Warren) introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To direct the Federal Trade Commission to require impact assessments of automated decision systems and augmented critical decision processes, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Algorithmic Accountability Act of 2023”. SEC. 2. DEFINITIONS. In this Act: (1) AUGMENTED CRITICAL DECISION PROCESS.—The term “augmented critical decision process” means a process, procedure, or other activity that employs an automated decision system to make a critical decision. (2) AUTOMATED DECISION SYSTEM.—The term “automated decision system” means any system, software, or process (including one derived from machine learning, statistics, or other data processing or artificial intelligence techniques and excluding passive computing infrastructure) that uses computation, the result of which serves as a basis for a decision or judgment.",https://www.congress.gov/bill/118th-congress/senate-bill/2892/text,en,
420,"To establish a Joint Autonomy Office in the Department of Defense, and for other purposes.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9153,low,0.1667,215,0.7,Defunct,"SECTION 1. ESTABLISHMENT OF THE JOINT AUTONOMY OFFICE. (a) Establishment.—Not later than 120 days after the date of the enactment of this Act, the Secretary of Defense, in consultation with the Chief Digital and Artificial Intelligence Officer, shall establish an Office in the Department of Defense to coordinate and accelerate the delivery of all-domain autonomous systems to operational users. (b) Designation.—The office established under subsection (a) shall be known as the “Joint Autonomy Office” (in this Act referred to as the “Office”). (c) Head Of Office.—The head of the Office shall be a Director appointed by the Secretary of Defense from among individuals with management experience and technical expertise in all-domain autonomous system technologies.(d) Duties.—The duties of the Joint Autonomy Office are following: (1) Utilize commercial and defense best practices and existing investments in defense cloud infrastructure to accelerate the delivery of autonomous systems to the operational user. (2) Implement an all-domain enterprise autonomous systems software development and testing platform across classification levels of the Department of Defense. (3) Provide access to defense programs with autonomy requirements to accelerate the development and testing of all-domain autonomous systems. (4) Implement an enterprise all-domain data acquisition and curation process to build, manage, and sustain datasets from all available autonomy programs of the Department in order to d",https://www.congress.gov/bill/118th-congress/house-bill/3168/text,en,"Strategies: New institution, Applications: Government: military and public safety, Strategies: Government support: AI workforce-related, Risk factors: Security: Cybersecurity, Strategies: Input controls: Data use, Strategies: Input controls: Data circulation, Strategies: Licensing, registration, and certification, Strategies: Government study or report, Strategies: Evaluation, Risk factors: Reliability, Risk factors: Reliability: Robustness"
422,To require a briefing on the national security threats associated with Chinese autonomous ground vehicles operating in the United States.,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9727,low,0.0,187,0.5,Defunct,"SECTION 1. BRIEFING ON NATIONAL SECURITY THREATS ASSOCIATED WITH CHINESE AUTONOMOUS GROUND VEHICLES OPERATING IN THE UNITED STATES. (a) In General.—The Secretary of Defense, acting through Under Secretary of Defense for Policy and in coordination with the Under Secretary of Defense for Acquisitions and Sustainment and other United States Government agencies as appropriate, to provide a briefing to the Committees on Armed Services of the House of Representatives and the Senate not later than March 30, 2024, on the national security threats associated with Chinese autonomous ground vehicles operating in the United States, especially those with access to or operating in the vicinity of Department of Defense military bases and installations and other sensitive United States Government facilities, and potentially sharing geospatial and other data with the Chinese Communist Party (CCP).(b) Matters To Be Included.—The briefing required by subsection (a) should include the type of data that can be collected, the dual-use implications of autonomous ground vehicle technologies and their enabling factors, and how the CCP or People’s Liberation Army could potentially use the data it collects in the United States to support its military operational planning.",https://www.congress.gov/bill/118th-congress/house-bill/6896/text,en,
428,Basic Allowance for Housing Calculation Improvement Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9559,low,0.0,203,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Basic Allowance for Housing Calculation Improvement Act of 2023”.SEC. 2. BASIC ALLOWANCE FOR HOUSING: PILOT PROGRAM TO OUTSOURCE RATE CALCULATION. (a) In General.—Not later than September 30, 2024, the Secretary of Defense shall seek to enter into an agreement with a covered entity pursuant to which the covered entity shall calculate, using industry standard machine learning and artificial intelligence algorithms, the monthly rates of BAH for not fewer than 15 MHAs.(b) Report.—Not later than two years after the date of the enactment of this Act, the Secretary shall submit to the Committees on Armed Services of the Senate and House of Representatives a report containing the evaluation of the Secretary of the rates calculated by a covered entity pursuant to an agreement under subsection (a).(c) Definitions.—In this section: (1) The term “BAH” means the basic allowance for housing for members of the uniformed services under section 403 of title 37, United States Code. (2) The term “covered entity” means a nationally recognized entity in the field of single-family housing that has data on local rental rates in real estate markets across the United States. (3) The term “MHA” means military housing area.a",https://www.congress.gov/bill/118th-congress/house-bill/5230/text,en,"Strategies: Pilots and testbeds, Applications: Government: benefits and welfare, Strategies: Government study or report"
429,Healthy Technology Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8788,low,0.0,99,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Healthy Technology Act of 2023”.SEC. 2. PRESCRIPTION OF DRUGS BY ARTIFICIAL INTELLIGENCE OR MACHINE LEARNING TECHNOLOGIES. Section 503(b) of Federal Food, Drug, and Cosmetic Act (21 U.S.C. 353(b)) is amended by adding at the end the following: “(6) In this subsection, the term ‘practitioner licensed by law to administer such drug’ includes artificial intelligence and machine learning technology that are— “(A) authorized pursuant to a statute of the State involved to prescribe the drug involved; and “(B) approved, cleared, or authorized under section 510(k), 513, 515, or 564.”.",https://www.congress.gov/bill/118th-congress/house-bill/206/text,en,"Applications: Medicine, life sciences and public health, Strategies: Evaluation"
431,“Managing Active and Reserve Tech Talent Effectively Act of 2023”,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9628,low,0.0,200,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Managing Active and Reserve Tech Talent Effectively Act of 2023” or the “MARTTE Act of 2023”.SEC. 2. DEFINITIONS. In this Act: (1) COMPUTER PROGRAMMING OCCUPATIONAL AREA.—The term “computer programming occupational area” means a technical or nontechnical occupational position that supports computer programming, coding, and artificial intelligence operations and development, including the following positions: (A) Data scientists. (B) Data engineers. (C) Data analysts. (D) Software developers. (E) Machine learning engineers. (F) Program managers. (G) Acquisition professionals. (2) DIGITAL PLATFORM OR APPLICATION.—The term “digital platform or application” means an online integrated personnel management system or human capital solution. (3) HUMAN CAPITAL INFRASTRUCTURE.—The term “human capital infrastructure” means the policies and processes that support development, training, evaluating, and tracking of personnel with specific occupational skills, experiences, and positions, including— (A) career and talent management strategy and policies; and (B) personnel software and databases for tracking and identifying members of the Armed Forces with specific capabilities.(4) QUALIFICATION PROCESS.—The term “qualification process”— (A) means the process, modeled on a streamlined version of the process for obtaining joint qualifications, for training and verifying members of the Armed Forces to receive career field or occupational cod",https://www.congress.gov/bill/118th-congress/senate-bill/1123/text,en,
432,AI Leadership Training Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9375,low,0.0,227,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Artificial Intelligence Leadership Training Act” or the “AI Leadership Training Act”.SEC. 2. ARTIFICIAL INTELLIGENCE LEADERSHIP TRAINING PROGRAM. (a) Definitions.—In this section: (1) AI.—The term “AI” has the meaning given the term “artificial intelligence” in section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal year 2019 (10 U.S.C. 2358 note). (2) COVERED EMPLOYEE.—The term “covered employee” means— (A) a management official; (B) a supervisor; or (C) any other employee of an executive agency— (i) as determined appropriate by the Director for the purposes of this section; or (ii) who is designated by the head of that executive agency to participate in the Program. (3) DIRECTOR.—The term “Director” means the Director of the Office of Personnel Management. (4) EXECUTIVE AGENCY.—The term “executive agency” has the meaning given the term in section 133 of title 41, United States Code. (5) MANAGEMENT OFFICIAL; SUPERVISOR.—The terms “management official” and “supervisor” have the meanings given those terms in section 7103(a) of title 5, United States Code. (6) PROGRAM.—The term “Program” means the AI leadership training program established and implemented (or the provision of which is otherwise ensured) by the Director under subsection (b)(1).(b) Program.— (1) IN GENERAL.— (A) ESTABLISHMENT OF PROGRAM.—Not later than 18 months after the date of enactment of this Act, the Director, in consultation w",https://www.congress.gov/bill/118th-congress/senate-bill/1564/text,en,
433,Preventing Deep Fake Scams Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8986,low,0.2222,236,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Preventing Deep Fake Scams Act”.SEC. 2. FINDINGS. The Congress finds the following: (1) Artificial intelligence is being used in new and innovative ways by the financial services sector. (2) Artificial intelligence may provide benefits to banks, credit unions, and banking consumers. (3) Artificial intelligence poses unique threats to the safety and security of customer accounts. (4) Voice banking is offered by many banks for security and convenience reasons. (5) The popularity of social media has made video and audio of potential targets easier to obtain for bad actors. These materials can be exploited to replicate the voices and appearances of other people in pursuit of data theft, identity theft, or fraud. (6) Bad actors could utilize “deep fakes”, including voice and audio manipulation, to compromise and access a consumer’s financial accounts.SEC. 3. TASK FORCE ON ARTIFICIAL INTELLIGENCE IN THE FINANCIAL SERVICES SECTOR. (a) Establishment.—There is established a Task Force on Artificial Intelligence in the Financial Services Sector (in this section referred to as the “Task Force”).(b) Membership.—The Task Force shall consist of the following: (1) The Secretary of the Treasury, or a designee, who shall serve as Chair of the Task Force. (2) The Comptroller of the Currency, or a designee. (3) The Chairman of the Board of Governors of the Federal Reserve System, or a designee. (4) The Chairperson of the Federal Deposit Insu",https://www.congress.gov/bill/118th-congress/house-bill/5808/text,en,"Strategies: Governance development, Applications: Business services and analytics, Strategies: Convening, Strategies: Government study or report, Risk factors: Safety, Risk factors: Security, Risk factors: Security: Cybersecurity, Harms: Financial loss, Applications: Government: other applications/unspecified"
435,Advanced Weather Model Computing Development Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9722,low,0.0,217,0.7,Defunct,"H. R. 1715 IN THE SENATE OF THE UNITED STATES May 10, 2023 Received; read twice and referred to the Committee on Commerce, Science, and Transportation AN ACT To direct the Department of Energy and the National Oceanic and Atmospheric Administration to conduct collaborative research in order to advance numerical weather and climate prediction in the United States, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Advanced Weather Model Computing Development Act”. SEC. 2. DEFINITIONS. In this Act: (1) DEPARTMENT.—The term “Department” means the Department of Energy. (2) NATIONAL LABORATORY.—The term “National Laboratory” has the meaning given such term in section 2 of the Energy Policy Act of 2005 (42 U.S.C. 15801). (3) SECRETARY.—The term “Secretary” means the Secretary of Energy. (4) ADMINISTRATOR.—The term “Administrator” means the Administrator of the National Oceanic and Atmospheric Administration. SEC. 3. DEPARTMENT OF ENERGY AND NATIONAL OCEANIC AND ATMOSPHERIC ADMINISTRATION RESEARCH AND DEVELOPMENT COORDINATION. (a) In General.—The Secretary and Administrator shall carry out collaborative research and development activities in artificial intelligence and high performance computing focused on the advancement of climate models and operational numerical weather prediction relevant to agency missions. (b) Memorandum Of Understanding.—T",https://www.congress.gov/bill/118th-congress/house-bill/1715/text,en,"Strategies: Government support, Strategies: Government support: For R&D, Strategies: Convening, Strategies: Government study or report, Strategies: Governance development, Strategies: Evaluation"
436,AI Foundation Model Transparency Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8979,low,0.2222,239,0.7,Defunct,"H. R. 6881 To direct the Federal Trade Commission to establish standards for making publicly available information about the training data and algorithms used in artificial intelligence foundation models, and for other purposes. IN THE HOUSE OF REPRESENTATIVES December 22, 2023 Mr. Beyer (for himself and Ms. Eshoo) introduced the following bill; which was referred to the Committee on Energy and Commerce A BILL To direct the Federal Trade Commission to establish standards for making publicly available information about the training data and algorithms used in artificial intelligence foundation models, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “AI Foundation Model Transparency Act of 2023”.SEC. 2. FINDINGS. Congress finds the following: (1) With the increase in public access to artificial intelligence, there has been an increase in lawsuits and public concerns about copyright infringement, including in court cases such as the following: (A) Doe 1 v. GitHub, Inc., No. 22–cv–06823, 2023 WL 3449131, at *1 (N.D. Cal. May 11, 2023). (B) Amended Complaint, Getty Images, Inc. v. Stability AI, Ltd., No. 23–cv–00135 (D. Del. Mar. 29, 2023). (C) Andersen v. Stability AI Ltd., No. 23–cv–00201, 2023 WL 7132064, at *1 (N.D. Cal. Oct. 30, 2023). (2) Public use of foundation models has led to countless instances of the public being presented with i",https://www.congress.gov/bill/118th-congress/house-bill/6881/text,en,"Risk factors: Transparency, Strategies: Disclosure, Strategies: Governance development, Strategies: Disclosure: About inputs, Strategies: Convening, Strategies: Disclosure: About evaluation, Strategies: Disclosure: In standard form, Strategies: Government support, Incentives: Civil liability, Risk factors: Safety, Risk factors: Security, Risk factors: Security: Cybersecurity"
437,AI LEAD Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9903,low,0.2778,223,0.7,Defunct,"S. 2293 To establish the Chief Artificial Intelligence Officers Council, Chief Artificial Intelligence Officers, and Artificial Intelligence Governance Boards, and for other purposes. IN THE SENATE OF THE UNITED STATES July 13, 2023 Mr. Peters introduced the following bill; which was read twice and referred to the Committee on Homeland Security and Governmental Affairs A BILL To establish the Chief Artificial Intelligence Officers Council, Chief Artificial Intelligence Officers, and Artificial Intelligence Governance Boards, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “AI Leadership To Enable Accountable Deployment Act” or the “AI LEAD Act”. SEC. 2. DEFINITIONS. In this Act: (1) AGENCY.—The term “agency” has the meaning given the term in section 3502 of title 44, United States Code. (2) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence” has the meaning given the term in section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (10 U.S.C. note prec. 4061; Public Law 115–232). (3) CHIEF ARTIFICIAL INTELLIGENCE OFFICER.—The term “Chief Artificial Intelligence Officer” means an official appointed or designated by the head of an agency pursuant to section 4(b)(1). (4) COUNCIL.—The term “Council” means the Chief Artificial Intelligence Officers Council established under section 3(a). (5) DIRECTOR",https://congress.gov/bill/118th-congress/senate-bill/2293/text,en,"Strategies: Convening, Applications: Government: military and public safety, Applications: Government: benefits and welfare, Strategies: Government support, Strategies: Government support: For R&D, Risk factors: Privacy, Risk factors: Transparency, Risk factors: Bias, Risk factors: Reliability, Strategies: Evaluation: Impact assessment, Risk factors: Safety, Strategies: Government study or report"
438,DOE and NSF Interagency Research Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9725,low,0.0,217,0.5,Defunct,"H. R. 2980 IN THE SENATE OF THE UNITED STATES December 5, 2023 Received; read twice and referred to the Committee on Commerce, Science, and Transportation AN ACT To provide for Department of Energy and National Science Foundation research and development coordination, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “DOE and NSF Interagency Research Act”. SEC. 2. DEPARTMENT OF ENERGY AND NATIONAL SCIENCE FOUNDATION RESEARCH AND DEVELOPMENT COORDINATION. (a) In General.—The Secretary of Energy (in this section referred to as the “Secretary”) and the Director of the National Science Foundation (in this section referred to as the “Director”) shall carry out cross-cutting and collaborative research and development activities focused on the joint advancement of Department of Energy and National Science Foundation mission requirements and priorities. (b) Memorandum Of Understanding.—The Secretary and the Director shall coordinate the activities under subsection (a) through the establishment of a memorandum of understanding, or other appropriate interagency agreement. Such memorandum or agreement, as the case may be, shall require the use of a competitive, merit-reviewed process, which considers applications from Federal agencies, National Laboratories, institutions of higher education, non-profit institutions, and other appropriate entities. (c",https://www.congress.gov/bill/118th-congress/house-bill/2980/text,en,
439,No AI FRAUD Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8902,low,0.0,246,0.5,Defunct,"H. R. 6943 To provide for individual property rights in likeness and voice. IN THE HOUSE OF REPRESENTATIVES January 10, 2024 Ms. Salazar (for herself, Ms. Dean of Pennsylvania, Mr. Moran, Mr. Morelle, and Mr. Wittman) introduced the following bill; which was referred to the Committee on the Judiciary A BILL To provide for individual property rights in likeness and voice. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “No Artificial Intelligence Fake Replicas And Unauthorized Duplications Act of 2024” or as the “No AI FRAUD Act”. SEC. 2. FINDINGS. Congress finds that recent advancements in artificial intelligence (AI) technology and the development of deepfake software have adversely affected individuals’ ability to protect their voice and likeness from misappropriation, including: (1) On or around April 4, 2023, AI technology was used to create the song titled “Heart on My Sleeve,” emulating the voices of recording artists Drake and The Weeknd. It reportedly received more than 11 million views. (2) On or around October 1, 2023, AI technology was used to create a false endorsement featuring Tom Hanks’ face in an advertisement for a dental plan. (3) From October 16 to 20, 2023, AI technology was used to create false, nonconsensual intimate images of high school girls in Westfield, New Jersey. (4) In fall 2023, AI technology was used to create the song titled “De",https://www.congress.gov/bill/118th-congress/house-bill/6943/text,en,
440,ASSESS AI Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9874,low,0.1667,242,0.7,Defunct,"S. 1356 To establish a task force on organizational structure for artificial intelligence governance and oversight. IN THE SENATE OF THE UNITED STATES April 27, 2023 Mr. Bennet introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To establish a task force on organizational structure for artificial intelligence governance and oversight. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Assuring Safe, Secure, Ethical, and Stable Systems for AI Act” or the “ASSESS AI Act”. SEC. 2. TASK FORCE ON ARTIFICIAL INTELLIGENCE GOVERNANCE AND OVERSIGHT. (a) Establishment.—Not later than 90 days after the date of enactment of this Act, the President shall appoint a task force to assess the privacy, civil rights, and civil liberties implications of artificial intelligence (referred to in this section as the “AI Task Force”). (b) Membership Of AI Task Force.— (1) IN GENERAL.—The AI Task Force shall include— (A) the Director of the Office of Management and Budget or his or her designee; (B) the Director of the National Institute of Standards and Technology or his or her designee; (C) the Director of the Office of Science and Technology Policy or his or her designee; (D) the Assistant Director of the Directorate for Technology, Innovation, and Partnerships at the National Science Foundation; (E) the Secr",https://www.congress.gov/bill/118th-congress/senate-bill/1356/text,en,"Risk factors: Privacy, Harms: Violation of civil or human rights, including privacy, Strategies: Convening, Applications: Government: other applications/unspecified, Risk factors: Security, Strategies: Evaluation, Strategies: Evaluation: Adversarial testing, Strategies: Governance development, Strategies: Government study or report"
441,Political BIAS Emails Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.3885,low,0.0556,250,0.7,Defunct,"H. R. 5495 To prohibit providers of email services from using filtering algorithms to flag emails from political campaigns that consumers have elected to receive as spam. IN THE HOUSE OF REPRESENTATIVES September 14, 2023 Mrs. Lesko (for herself, Ms. Van Duyne, Mr. Steube, Mr. Pfluger, Mr. Duncan, Mr. Higgins of Louisiana, Mr. Issa, and Ms. Stefanik) introduced the following bill; which was referred to the Committee on Energy and Commerce A BILL To prohibit providers of email services from using filtering algorithms to flag emails from political campaigns that consumers have elected to receive as spam. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Political Bias In Algorithm Sorting Emails Act of 2023” or the “Political BIAS Emails Act of 2023”. SEC. 2. UNFAIR AND DECEPTIVE ACTS AND PRACTICES RELATING TO FILTERING POLITICAL EMAILS THAT A CONSUMER HAS ELECTED TO RECEIVE. (a) Conduct Prohibited.— (1) IN GENERAL.—It shall be unlawful for an operator of an email service to use a filtering algorithm to apply a label to an email sent to an email account from a political campaign unless the owner or user of the account took action to apply such a label. (2) EFFECTIVE DATE.—The prohibition under paragraph (1) shall take effect on the date that is 3 months after the date of enactment of this Act. (b) Quarterly Transparency Report.— (1) IN GENERAL.—Beginning with the",https://www.congress.gov/bill/118th-congress/house-bill/5495/text,en,"Risk factors: Transparency, Strategies: Disclosure, Strategies: Disclosure: About incidents, Strategies: Disclosure: About evaluation, Strategies: Disclosure: In standard form, Strategies: Disclosure: In deployment, Incentives: Civil liability"
442,ASK Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8934,low,0.1667,231,1.0,Defunct,"S. 1626 To require the Federal Communications Commission, in consultation with the Federal Trade Commission, to issue rules prohibiting entities from offering minor consumers artificial intelligence features in the products of those entities without parental consent, and for other purposes. IN THE SENATE OF THE UNITED STATES May 16, 2023 Mr. Scott of Florida introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To require the Federal Communications Commission, in consultation with the Federal Trade Commission, to issue rules prohibiting entities from offering minor consumers artificial intelligence features in the products of those entities without parental consent, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE. This Act may be cited as the “AI Shield for Kids Act” or the “ASK Act”. SEC. 2. ISSUANCE OF RULES. (a) Definitions.—In this section: (1) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence” has the meaning given the term in section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (10 U.S.C. 2358 note). (2) MINOR.—The term “minor” means an individual who is younger than 18 years of age. (3) PRODUCT.—The term “product” includes a program, service, application, or other product. (4) USER.—The term “user” means an individual who is a user or cus",https://www.congress.gov/bill/118th-congress/senate-bill/1626/text,en,"Risk factors: Safety, Harms: Harm to health/safety, Harms: Detrimental content, Applications: Consumer goods, Incentives: Civil liability"
443,Water Quality and Environmental Innovation Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9686,low,0.0556,229,0.7,Defunct,"H. R. 873 To authorize the Administrator of the Environmental Protection Agency to award grants and contracts for projects that use emerging technologies to address threats to water quality, and for other purposes. IN THE HOUSE OF REPRESENTATIVES February 8, 2023 Mr. Donalds (for himself and Mr. Gottheimer) introduced the following bill; which was referred to the Committee on Transportation and Infrastructure, and in addition to the Committees on Energy and Commerce, and Science, Space, and Technology, for a period to be subsequently determined by the Speaker, in each case for consideration of such provisions as fall within the jurisdiction of the committee concerned A BILL To authorize the Administrator of the Environmental Protection Agency to award grants and contracts for projects that use emerging technologies to address threats to water quality, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Water Quality and Environmental Innovation Act”. SEC. 2. FINDINGS. Congress finds the following: (1) Science, technology, and innovation are major cornerstones of the economy of the United States. (2) Throughout the United States, there is a growing momentum to address traditional and emerging threats to the Nation’s water resources through innovative technological approaches. (3) Water quality continues to negatively impact communities in th",https://www.congress.gov/bill/118th-congress/house-bill/873/text,en,"Harms: Ecological harm, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Disclosure, Strategies: Government study or report, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Post-market monitoring"
444,CREATE AI Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.993,low,0.0,218,0.5,Defunct,"A BILL To establish the National Artificial Intelligence Research Resource, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Creating Resources for Every American To Experiment with Artificial Intelligence Act of 2023” or the “CREATE AI Act of 2023”. SEC. 2. Findings. Congress finds the following: (1) Cutting-edge artificial intelligence research relies on access to computational resources and large datasets. (2) Access to the computational resources and datasets necessary for artificial intelligence research and development is often limited to very large technology companies. (3) The lack of access to computational and data resources has resulted in insufficient diversity in the artificial intelligence research and development community. (4) Engaging the full and diverse talent of the United States is critical for maintaining United States leadership in artificial intelligence and ensuring that artificial intelligence is developed in a manner that benefits all people of the United States. (5) The National Artificial Intelligence Research Resource Task Force, authorized under section 5106 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401 et seq.), recommended the establishment of a National Artificial Intelligence Research Resource in a report entitled “Strengthening and Democratizing the U.S. Artificial Inte",https://www.congress.gov/bill/118th-congress/senate-bill/2714,en,
447,REAL Political Advertisements Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9022,low,0.0556,235,0.7,Defunct,"H. R. 3044 To amend the Federal Election Campaign Act of 1971 to provide further transparency and accountability for the use of content that is generated by artificial intelligence (generative AI) in political advertisements by requiring such advertisements to include a statement within the contents of the advertisements if generative AI was used to generate any image or video footage in the advertisements, and for other purposes. IN THE HOUSE OF REPRESENTATIVES May 2, 2023 Ms. Clarke of New York introduced the following bill; which was referred to the Committee on House Administration A BILL To amend the Federal Election Campaign Act of 1971 to provide further transparency and accountability for the use of content that is generated by artificial intelligence (generative AI) in political advertisements by requiring such advertisements to include a statement within the contents of the advertisements if generative AI was used to generate any image or video footage in the advertisements, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Require the Exposure of AI–Led Political Advertisements Act” or the “REAL Political Advertisements Act”. SEC. 2. SENSE OF CONGRESS. It is the sense of Congress that— (1) the revolutionary innovations in generative artificial intelligence (generative AI) and the potential for their use in exacerbating and spre",https://www.congress.gov/bill/118th-congress/house-bill/3044/text,en,"Applications: Government: other applications/unspecified, Applications: Broadcasting and media production, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: In standard form, Strategies: Governance development, Strategies: Government study or report, Risk factors: Transparency"
448,AI Disclosure Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9186,low,0.0,224,0.7,Defunct,"H. R. 3831 To require generative artificial intelligence to disclose that their output has been generated by artificial intelligence, and for other purposes. IN THE HOUSE OF REPRESENTATIVES June 5, 2023 Mr. Torres of New York introduced the following bill; which was referred to the Committee on Energy and Commerce A BILL To require generative artificial intelligence to disclose that their output has been generated by artificial intelligence, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “AI Disclosure Act of 2023”. SEC. 2. REQUIREMENT TO DISCLOSE USE OF GENERATIVE ARTIFICIAL INTELLIGENCE. (a) Disclaimer Required.—Generative artificial intelligence shall include on any output generated by such artificial intelligence the following: “Disclaimer: this output has been generated by artificial intelligence.”. (b) Enforcement By Federal Trade Commission.— (1) UNFAIR OR DECEPTIVE ACTS OR PRACTICES.—A violation of subsection (a) or a regulation promulgated under such subsection shall be treated as a violation of a regulation under section 18(a)(1)(B) of the Federal Trade Commission Act (15 U.S.C. 57a(a)(1)(B)) regarding unfair or deceptive acts or practices. (2) POWERS OF COMMISSION.—The Federal Trade Commission shall enforce subsection (a) and the regulations promulgated under such subsection in the same manner, by the same means, and with the",https://www.congress.gov/bill/118th-congress/house-bill/3831/text,en,"Strategies: Disclosure, Strategies: Disclosure: In deployment, Incentives: Fines, Incentives: Civil liability"
449,FAIRR Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9835,low,0.0,232,0.5,Defunct,"S. 3554 To amend the Financial Stability Act of 2010 to provide the Financial Stability Oversight Council with duties regarding artificial intelligence in the financial sector, and for other purposes. IN THE SENATE OF THE UNITED STATES December 18, 2023 Mr. Warner (for himself and Mr. Kennedy) introduced the following bill; which was read twice and referred to the Committee on Banking, Housing, and Urban Affairs A BILL To amend the Financial Stability Act of 2010 to provide the Financial Stability Oversight Council with duties regarding artificial intelligence in the financial sector, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Financial Artificial Intelligence Risk Reduction Act” or the “FAIRR Act”. SEC. 2. DEFINITIONS. In this Act, the term “artificial intelligence” has the meaning given the term in section 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401). SEC. 3. SPECIAL PROVISIONS REGARDING ARTIFICIAL INTELLIGENCE IN THE FINANCIAL SECTOR. (a) In General.—Subtitle A of the Financial Stability Act of 2010 (12 U.S.C. 5321 et seq.) is amended by adding at the end the following: “SEC. 126. SPECIAL PROVISIONS REGARDING ARTIFICIAL INTELLIGENCE IN THE FINANCIAL SECTOR. “(a) Coordination, Report, And Recommendations.—The Council shall coordinate with member agencies with regard to potential risks to th",https://www.congress.gov/bill/118th-congress/senate-bill/3554/text,en,
450,National AI Commission Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.973,low,0.0,231,0.7,Defunct,"H. R. 4223 To establish an artificial intelligence commission, and for other purposes. IN THE HOUSE OF REPRESENTATIVES June 20, 2023 Mr. Lieu (for himself, Mr. Buck, and Ms. Eshoo) introduced the following bill; which was referred to the Committee on Science, Space, and Technology A BILL To establish an artificial intelligence commission, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE. This Act may be cited as the “National AI Commission Act”. SEC. 2. SENSE OF CONGRESS. It is the sense of Congress that this Act shall not be intended to preclude any legislation Congress may deem necessary relating to Artificial Intelligence in the interim period before the reports of the Commission are released.SEC. 3. ARTIFICIAL INTELLIGENCE COMMISSION. (a) Location.—There is established in the legislative branch an independent commission relating to artificial intelligence (AI), to be known as the “National AI Commission” (in this section referred to as the “Commission”). (b) Composition.—The Commission shall be comprised of 20 commissioners, of whom 10 shall be appointed by each party to ensure bipartisanship. Members of the Commission shall elect two Members to serve as co-chairs. One co-chair shall be a Democratic appointee and one co-chair shall be a Republican appointee. Members shall be appointed as follows: (1) The President, in consultation with relevant cabinet secretaries,",https://www.congress.gov/bill/118th-congress/house-bill/4223/text,en,"Strategies: Government study or report, Strategies: Evaluation: Impact assessment, Strategies: New institution"
451,R U REAL Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9403,low,0.2778,234,1.0,Defunct,"H. R. 7120 To direct the Federal Trade Commission to revise the Telemarketing Sales Rule to require disclosures for telemarketing using artificial intelligence and to provide for enhanced penalties for violations involving artificial intelligence voice or text message impersonation, and for other purposes. IN THE HOUSE OF REPRESENTATIVES January 29, 2024 Ms. Schakowsky introduced the following bill; which was referred to the Committee on Energy and Commerce A BILL To direct the Federal Trade Commission to revise the Telemarketing Sales Rule to require disclosures for telemarketing using artificial intelligence and to provide for enhanced penalties for violations involving artificial intelligence voice or text message impersonation, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE. This Act may be cited as the “Restrictions on Utilizing Realistic Electronic Artificial Language Act” or the “R U REAL Act”. SEC. 2. DISCLOSURE REQUIRED FOR TELEMARKETING USING AI. (a) In General.—Not later than 180 days after the date of the enactment of this Act, the Federal Trade Commission shall revise the Telemarketing Sales Rule (part 310 of title 16, Code of Federal Regulations) so as to add a requirement that, if a person makes a call or sends a text message with respect to telemarketing and uses artificial intelligence in such call or text message to emulate a human being, such perso",https://www.congress.gov/bill/118th-congress/house-bill/7120/text,en,"Risk factors: Transparency, Harms: Financial loss, Harms: Detrimental content, Applications: Networking and telecommunications, Incentives: Fines, Incentives: Civil liability, Strategies: Disclosure, Strategies: Disclosure: In deployment, Harms: Harm to health/safety, Harms: Harm to property"
452,Jobs of the Future Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.99,low,0.0,236,0.5,Defunct,"H. R. 4498 To promote a 21st century artificial intelligence workforce. IN THE HOUSE OF REPRESENTATIVES July 6, 2023 Mr. Soto (for himself, Mrs. Chavez-DeRemer, Ms. Blunt Rochester, and Mr. Garbarino) introduced the following bill; which was referred to the Committee on Education and the Workforce, and in addition to the Committee on Science, Space, and Technology, for a period to be subsequently determined by the Speaker, in each case for consideration of such provisions as fall within the jurisdiction of the committee concerned A BILL To promote a 21st century artificial intelligence workforce. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE. This Act may be cited as the “Jobs of the Future Act of 2023”. SEC. 2. SENSE OF CONGRESS. It is the sense of Congress that— (1) while the field of artificial intelligence is evolving quickly and has potential to disrupt jobs, there are opportunities to prepare the American workforce to develop and work alongside this new technology and mitigate job displacement; and (2) to ensure these opportunities, it is imperative to identify the following: (A) Data and data access necessary to properly analyze the impact of artificial intelligence on the United States workforce. (B) Industries projected to be most impacted by artificial intelligence. (C) Opportunities for workers and other stakeholders to influence the impact of artificial intelligence across indu",https://www.congress.gov/bill/118th-congress/house-bill/4498/text,en,
453,QUIET Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9674,low,0.2222,228,0.7,Defunct,"H. R. 7123 To amend the Communications Act of 1934 to require disclosures with respect to robocalls using artificial intelligence and to provide for enhanced penalties for certain violations involving artificial intelligence voice or text message impersonation, and for other purposes. IN THE HOUSE OF REPRESENTATIVES January 29, 2024 Mr. Sorensen (for himself and Mr. Ciscomani) introduced the following bill; which was referred to the Committee on Energy and Commerce A BILL To amend the Communications Act of 1934 to require disclosures with respect to robocalls using artificial intelligence and to provide for enhanced penalties for certain violations involving artificial intelligence voice or text message impersonation, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE. This Act may be cited as the “Quashing Unwanted and Interruptive Electronic Telecommunications Act” or the “QUIET Act”.SEC. 2. DISCLOSURE REQUIRED FOR ROBOCALLS USING AI. Section 227 of the Communications Act of 1934 (47 U.S.C. 227) is amended by adding at the end the following: “(k) Disclosure Required For Robocalls Using AI.— “(1) IN GENERAL.—If a person making a robocall uses artificial intelligence to emulate a human being, such person shall disclose at the beginning of the call or text message the fact that artificial intelligence is being used. “(2) DEFINITIONS.—In this subsection: “(A) ROBOCALL.— “(",https://www.congress.gov/bill/118th-congress/house-bill/7123/text,en,"Risk factors: Transparency, Harms: Financial loss, Harms: Detrimental content, Harms: Violation of civil or human rights, including privacy, Applications: Networking and telecommunications, Incentives: Fines, Incentives: Civil liability"
456,Candidate Voice Fraud Prohibition Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.802,low,0.1111,226,0.7,Defunct,"H. R. 4611 To amend the Federal Election Campaign Act of 1971 to prohibit the distribution, with actual malice, of certain political communications that contain materially deceptive audio generated by artificial intelligence which impersonate a candidate’s voice and are intended to injure the candidate’s reputation or to deceive a voter into voting against the candidate, and for other purposes. IN THE HOUSE OF REPRESENTATIVES July 13, 2023 Mr. Espaillat introduced the following bill; which was referred to the Committee on House Administration A BILL To amend the Federal Election Campaign Act of 1971 to prohibit the distribution, with actual malice, of certain political communications that contain materially deceptive audio generated by artificial intelligence which impersonate a candidate’s voice and are intended to injure the candidate’s reputation or to deceive a voter into voting against the candidate, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Candidate Voice Fraud Prohibition Act”. SEC. 2. SENSE OF CONGRESS. It is the sense of Congress that the prohibitions on paid-for political communications contained within this Act serve the purpose of furthering a compelling government interest by serving the informational interest of voters by preventing voters from hearing materially deceptive and intentionally falsified renderings of c",https://www.congress.gov/bill/118th-congress/house-bill/4611/text,en,"Harms: Detrimental content, Harms: Violation of civil or human rights, including privacy, Strategies: Tiering, Applications: Broadcasting and media production, Incentives: Criminal liability, Incentives: Fines, Incentives: Imprisonment, Strategies: Governance development, Strategies: Government study or report"
457,Stop Spying Bosses Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.926,low,0.0,222,0.5,Defunct,"A BILL To prohibit, or require disclosure of, the surveillance, monitoring, and collection of certain worker data by employers, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Stop Spying Bosses Act”. SEC. 2. Definitions. For purposes of this Act: (1) ADMINISTRATOR.—The term “Administrator” means the Administrator of the Privacy and Technology Division established under section 5. (2) AGGREGATED DATA.—The term “aggregated data” means data with respect to covered individuals of an employer that the employer has combined or collected together in a summary or other form that prevents the identification of any specific individual. (3) APPLICANT.—The term “applicant”, with respect to an employer, means an individual who applies, or applied, to be employed by, or otherwise perform work for remuneration for, the employer. (4) AUTOMATED DECISION SYSTEM.— (A) IN GENERAL.—The term “automated decision system” means a system, software, or process that— (i) uses computation, in whole or in part, to determine outcomes, make or aid decisions (including through evaluations, metrics, or scoring), inform policy implementation, collect data or observations, or otherwise interact with individuals or communities, including such a system, software, or process derived from machine learning, statistics, or other data processing or artificial intelligence techn",https://www.congress.gov/bill/118th-congress/senate-bill/262,en,
460,Farm Tech Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9512,low,0.0556,216,0.7,Defunct,"H. R. 6806 To provide for the establishment of a program to certify artificial intelligence software used in connection with producing agricultural products. IN THE HOUSE OF REPRESENTATIVES December 14, 2023 Mr. Feenstra (for himself, Mr. Valadao, and Mr. Sorensen) introduced the following bill; which was referred to the Committee on Agriculture A BILL To provide for the establishment of a program to certify artificial intelligence software used in connection with producing agricultural products. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE. This Act may be cited as the “Farm Tech Act”.SEC. 2. CERTIFICATION OF ARTIFICIAL INTELLIGENCE SOFTWARE USED IN CONNECTION WITH PRODUCING AGRICULTURAL PRODUCTS. (a) In General.—The Secretary of Agriculture shall establish a program to certify software that uses artificial intelligence in the performing a task in connection with producing agricultural products. The program shall be based on the Artificial Intelligence Risk Management Framework published by the National Institute of Standards and Technology. (b) Certification.—The Secretary may only certify software under the program established under subsection (a) if, in the performing a task in connection with producing an agricultural product, the software— (1) performs accurately, and (2) consistently meets or exceeds the Federal and State licensure, certification, and permitting standards applicabl",https://www.congress.gov/bill/118th-congress/house-bill/6806/text,en,"Risk factors: Reliability, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Governance development, Applications: Agriculture and resource extraction"
461,Small Business Broadband and Emerging Information Technology Enhancement Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.971,low,0.0,226,0.5,Defunct,"S. 2677 To improve certain programs of the Small Business Administration to better assist small business customers in accessing broadband technology, and for other purposes. IN THE SENATE OF THE UNITED STATES July 27, 2023 Mrs. Shaheen (for herself, Mr. Kennedy, Mr. Markey, Mr. Risch, and Ms. Hirono) introduced the following bill; which was read twice and referred to the Committee on Small Business and Entrepreneurship A BILL To improve certain programs of the Small Business Administration to better assist small business customers in accessing broadband technology, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Small Business Broadband and Emerging Information Technology Enhancement Act of 2023”. SEC. 2. BROADBAND AND EMERGING INFORMATION TECHNOLOGY COORDINATOR. The Small Business Act (15 U.S.C. 631 et seq.) is amended— (1) by redesignating section 49 (15 U.S.C. 631 note) as section 50; and (2) by inserting after section 48 (15 U.S.C. 657u) the following: “SEC. 49. BROADBAND AND EMERGING INFORMATION TECHNOLOGY. “(a) Definitions.—In this section— “(1) the term ‘Associate Administrator’ means the Associate Administrator for the Office of Investment and Innovation; “(2) the term ‘broadband’ means— “(A) high-speed wired broadband internet; and “(B) high-speed wireless internet; “(3) the term ‘broadband and emerging information technology c",https://www.congress.gov/bill/118th-congress/senate-bill/2677/text,en,
462,TEST AI Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9912,low,0.2222,228,1.0,Defunct,"S. 3162 To improve the requirement for the Director of the National Institute of Standards and Technology to establish testbeds to support the development and testing of trustworthy artificial intelligence systems and to improve interagency coordination in development of such testbeds, and for other purposes. IN THE SENATE OF THE UNITED STATES October 30, 2023 Mr. Luján (for himself, Mr. Durbin, Mr. Thune, Mrs. Blackburn, and Mr. Risch) introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To improve the requirement for the Director of the National Institute of Standards and Technology to establish testbeds to support the development and testing of trustworthy artificial intelligence systems and to improve interagency coordination in development of such testbeds, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE. This Act may be cited as the “Testing and Evaluation Systems for Trusted Artificial Intelligence Act of 2023” or the “TEST AI Act of 2023”.SEC. 2. INTERAGENCY COORDINATION TO FACILITATE TESTBEDS. Subsection (g) of section 22A of the National Institute of Standards and Technology Act (15 U.S.C. 278h–1) is amended to read as follows: “(g) Testbeds.— “(1) DEFINITION OF ARTIFICIAL INTELLIGENCE.—In this subsection, the term ‘artificial intelligence’ has the meaning given such term in section",https://www.congress.gov/bill/118th-congress/senate-bill/3162/text,en,"Risk factors: Reliability, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Pilots and testbeds, Strategies: Convening, Applications: Government: other applications/unspecified, Risk factors: Security, Risk factors: Security: Cybersecurity, Harms: Harm to health/safety, Applications: Government: military and public safety, Strategies: Government support: AI workforce-related"
466,Promoting Precision Agriculture Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9504,low,0.0,223,0.5,Defunct,"H. R. 1697 To enhance the participation of precision agriculture in the United States, and for other purposes. IN THE HOUSE OF REPRESENTATIVES March 22, 2023 Mr. Davis of North Carolina (for himself and Mr. Mann) introduced the following bill; which was referred to the Committee on Agriculture A BILL To enhance the participation of precision agriculture in the United States, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Promoting Precision Agriculture Act of 2023”. SEC. 2. DEFINITIONS. In this Act: (1) ADVANCED WIRELESS COMMUNICATIONS TECHNOLOGY.—The term “advanced wireless communications technology” means advanced technology that contributes to mobile (5G or beyond) networks, next-generation Wi-Fi networks, or other future networks using other technologies, regardless of whether the network is operating on an exclusive licensed, shared licensed, or unlicensed frequency band. (2) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence” has the meaning given the term in section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Public Law 115–232; 10 U.S.C. note prec. 4061). (3) FOREIGN ADVERSARY.—The term “foreign adversary” means any foreign government or foreign nongovernment person engaged in a long-term pattern or serious instances of conduct significantly adverse to the national security of t",https://www.congress.gov/bill/118th-congress/house-bill/1697/text,en,
467,AI Training Expansion Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9633,low,0.2222,235,0.7,Defunct,"H. R. 4503 To amend the Artificial Intelligence Training for the Acquisition Workforce Act to expand AI training within the executive branch of the Federal Government, and for other purposes. IN THE HOUSE OF REPRESENTATIVES July 10, 2023 Ms. Mace (for herself and Mr. Connolly) introduced the following bill; which was referred to the Committee on Oversight and Accountability A BILL To amend the Artificial Intelligence Training for the Acquisition Workforce Act to expand AI training within the executive branch of the Federal Government, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “AI Training Expansion Act of 2023”. SEC. 2. EXPANSION OF AI TRAINING WITHIN THE EXECUTIVE BRANCH OF THE FEDERAL GOVERNMENT. (a) In General.—Section 2 of the Artificial Intelligence Training for the Acquisition Workforce Act (Public Law 117–207; 41 U.S.C. 1703 note) is amended— (1) in subsection (a)— (A) by redesignating paragraphs (1), (2), (3), (4), and (5), as (2), (3), (4), (6), and (7), respectively; (B) by inserting before paragraph (2), as so redesignated, the following: “(1) ACQUISITION POSITION.—The term ‘acquisition position’ means any position listed in subsection (g)(1)(A) of section 1703 of title 41, United States Code.”; (C) in paragraph (4), as so redesignated— (i) by striking subparagraph (A); (ii) by redesignating subparagraph (B) as subparagr",https://www.congress.gov/bill/118th-congress/house-bill/4503/text,en,"Strategies: Government support, Strategies: Government support: AI workforce-related, Applications: Government: other applications/unspecified, Risk factors: Reliability, Risk factors: Safety, Risk factors: Transparency, Harms: Violation of civil or human rights, including privacy, Strategies: Disclosure"
468,DOE and USDA Interagency Research Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9794,low,0.0,215,0.5,Defunct,"H. R. 1713 IN THE SENATE OF THE UNITED STATES December 5, 2023 Received; read twice and referred to the Committee on Energy and Natural Resources AN ACT To provide for Department of Energy and Department of Agriculture joint research and development activities, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “DOE and USDA Interagency Research Act”. SEC. 2. DEPARTMENT OF ENERGY AND DEPARTMENT OF AGRICULTURE JOINT RESEARCH AND DEVELOPMENT ACTIVITIES. (a) In General.—The Secretary of Energy and the Secretary of Agriculture (in this section referred to as the “Secretaries”) shall carry out cross-cutting and collaborative research and development activities focused on the joint advancement of Department of Energy and Department of Agriculture mission requirements and priorities. (b) Memorandum Of Understanding.—The Secretaries shall carry out and coordinate the activities under subsection (a) through the establishment of a memorandum of understanding, or other appropriate interagency agreement. Such memorandum or agreement shall require the use of a competitive, merit-reviewed process, which considers applications from Federal agencies, National Laboratories, institutions of higher education, nonprofit institutions, and other appropriate entities. (c) Coordination.—In carrying out the activities under subsection (a), the Secretaries may— (1)",https://www.congress.gov/bill/118th-congress/house-bill/1713/text,en,
471,Building Resilient Supply Chains Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9147,low,0.0,235,0.7,Defunct,"H. R. 762 To establish the Supply Chain Resiliency and Crisis Response Office in the Department of Commerce, and for other purposes. IN THE HOUSE OF REPRESENTATIVES February 2, 2023 Ms. Blunt Rochester (for herself, Mrs. Dingell, Ms. Kelly of Illinois, and Ms. Wild) introduced the following bill; which was referred to the Committee on Energy and Commerce A BILL To establish the Supply Chain Resiliency and Crisis Response Office in the Department of Commerce, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE. This Act may be cited as the “Building Resilient Supply Chains Act”.SEC. 2. CRITICAL SUPPLY CHAIN RESILIENCE PROGRAM. (a) Establishment.—There is established in the Office of the Secretary of Commerce a Supply Chain Resiliency and Crisis Response Office to carry out the Critical Supply Chain Resilience Program described in subsection (d). (b) Mission.—The mission of the Office shall be the following: (1) Help to promote the leadership of the United States with respect to critical industries and supply chains that— (A) strengthen the national security of the United States; and (B) have a significant effect on the economic security of the United States. (2) Encourage partnerships and collaboration with the Federal Government and the private sector, labor organizations, the governments of countries that are allies or key international partners of the United States, Sta",https://www.congress.gov/bill/118th-congress/house-bill/762/text,en,"Applications: Government: military and public safety, Strategies: Government support, Strategies: New institution, Applications: Manufacturing and process automation, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Applications: Government: other applications/unspecified, Strategies: Evaluation: Impact assessment"
473,Digital Platform Commission Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9106,low,0.2222,230,0.7,Defunct,"S. 1671 To establish a new Federal body to provide reasonable oversight and regulation of digital platforms. IN THE SENATE OF THE UNITED STATES May 18, 2023 Mr. Bennet (for himself and Mr. Welch) introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To establish a new Federal body to provide reasonable oversight and regulation of digital platforms. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE; TABLE OF CONTENTS. (a) Short Title.—This Act may be cited as the “Digital Platform Commission Act of 2023”. (b) Table Of Contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. Sec. 2. Findings; sense of Congress. Sec. 3. Definitions. Sec. 4. Establishment of Federal Digital Platform Commission. Sec. 5. Jurisdiction. Sec. 6. Organization and general powers. Sec. 7. Organization and functioning of the Commission. Sec. 8. Code Council. Sec. 9. Rulemaking authority, requirements, and considerations. Sec. 10. Systemically important digital platforms. Sec. 11. Inter-agency support. Sec. 12. Petitions. Sec. 13. Research. Sec. 14. Investigative authority. Sec. 15. HSR filings. Sec. 16. Enforcement by private persons and governmental entities. Sec. 17. Enforcement by Commission and Department of Justice. Sec. 18. Proceedings to enjoin, set aside, annul, or suspend orders of the Commission.",https://www.congress.gov/bill/118th-congress/senate-bill/1671/text,en,"Applications: Arts, sports, leisure, travel, and lifestyle, Strategies: New institution, Risk factors: Transparency, Risk factors: Bias, Risk factors: Safety, Strategies: Governance development, Risk factors: Interpretability and explainability, Strategies: Evaluation, Strategies: Evaluation: Post-market monitoring"
481,Protecting Kids on Social Media Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8893,low,0.1111,234,0.7,Defunct,"S. 1291 To require that social media platforms verify the age of their users, prohibit the use of algorithmic recommendation systems on individuals under age 18, require parental or guardian consent for social media users under age 18, and prohibit users who are under age 13 from accessing social media platforms. IN THE SENATE OF THE UNITED STATES April 26, 2023 Mr. Schatz (for himself, Mr. Cotton, Mr. Murphy, and Mrs. Britt) introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To require that social media platforms verify the age of their users, prohibit the use of algorithmic recommendation systems on individuals under age 18, require parental or guardian consent for social media users under age 18, and prohibit users who are under age 13 from accessing social media platforms. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Protecting Kids on Social Media Act”. SEC. 2. DEFINITIONS. In this Act: (1) ALGORITHMIC RECOMMENDATION SYSTEM.—The term “algorithmic recommendation system” means a fully or partially automated system that suggests, promotes, or ranks information for, or presents advertising to, an individual. (2) COMMISSION.—The term “Commission” means the Federal Trade Commission. (3) INDIVIDUAL.—The term “individual” means a social media platform user who habitually resides in",https://www.congress.gov/bill/118th-congress/senate-bill/1291/text,en,"Applications: Arts, sports, leisure, travel, and lifestyle, Incentives: Civil liability, Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content"
483,Supply Chain Mapping and Monitoring Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8556,low,0.0,216,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Supply Chain Mapping and Monitoring Act”.SEC. 2. SUPPLY CHAIN RESILIENCY AND CRISIS RESPONSE OFFICE. (a) Definitions.—In this section: (1) CRITICAL GOOD OR SERVICE.—The term “critical good or service” means any raw, in process, or manufactured material (including any mineral, metal, or advanced processed material), article, commodity, supply, product, or item of supply the absence of which would have a significant effect on— (A) the national security or economic security of the United States; and (B) critical infrastructure. (2) CRITICAL INDUSTRY.—The term “critical industry” means an industry that is critical for the national security or economic security of the United States, considering key technology focus areas under this section and critical infrastructure. (3) CRITICAL INFRASTRUCTURE.—The term “critical infrastructure” has the meaning given to that term in the Critical Infrastructures Protection Act of 2001 (42 U.S.C. 5195c). (4) DOMESTIC ENTERPRISE.—The term “domestic enterprise” means an enterprise that conducts business in the United States and procures a critical good or service. (5) DOMESTIC MANUFACTURER.—The term “domestic manufacturer” means a business that— (A) conducts in the United States the research and development, engineering, or production activities necessary or incidental to manufacturing; or (B) if provided financial assistance by the Federal Government, will conduct in the United States the resear",https://www.congress.gov/bill/118th-congress/house-bill/796/text,en,
484,AI for National Security Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8091,low,0.0556,106,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “AI for National Security Act”.SEC. 2. DEPARTMENT OF DEFENSE ENTERPRISE-WIDE PROCUREMENT OF CYBER DATA PRODUCTS AND SERVICES. Section 1521 of the National Defense Authorization Act for Fiscal Year 2022 (Public Law 117–81; 10 U.S.C. 2224 note) is amended— (1) in subsection (a)(5), by inserting “, including the use of artificial intelligence-based endpoint security that prevents cyber attacks and does not require constant internet connectivity to function,” after “services”; and (2) in subsection (b), by inserting “, including by enhancing the security of the software supply chain of the Department” after “best interests of the Department”.",https://www.congress.gov/bill/118th-congress/house-bill/1718/text,en,"Applications: Government: military and public safety, Risk factors: Security: Cybersecurity, Strategies: Government support"
485,RESTRICT Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9631,low,0.0,224,0.5,Defunct,"S. 686 To authorize the Secretary of Commerce to review and prohibit certain transactions between persons in the United States and foreign adversaries, and for other purposes. IN THE SENATE OF THE UNITED STATES March 7, 2023 Mr. Warner (for himself, Mr. Thune, Ms. Baldwin, Mrs. Fischer, Mr. Manchin, Mr. Moran, Mr. Bennet, Mr. Sullivan, Mrs. Gillibrand, Ms. Collins, Mr. Heinrich, Mr. Romney, and Mrs. Capito) introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To authorize the Secretary of Commerce to review and prohibit certain transactions between persons in the United States and foreign adversaries, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Restricting the Emergence of Security Threats that Risk Information and Communications Technology Act” or the “RESTRICT Act”. SEC. 2. DEFINITIONS. In this Act: (1) CLASSIFIED NATIONAL SECURITY INFORMATION.—The term “classified national security information” means information that has been determined pursuant to Executive Order 13526 (50 U.S.C. 3161 note; relating to classified national security information) or any predecessor or successor order, to require protection against unauthorized disclosure, and is marked to indicate such classified status if in documentary form. (2) CONTROLLING HOLDING.—The term “controlling",https://www.congress.gov/bill/118th-congress/senate-bill/686/text,en,
486,Next Generation Pipelines Research and Development Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9337,low,0.0,227,0.5,Defunct,"H. R. 7073 To improve public-private partnerships and increase Federal research, development, and demonstration related to the evolution of next generation pipeline systems, and for other purposes. IN THE HOUSE OF REPRESENTATIVES January 22, 2024 Mr. Weber of Texas (for himself, Ms. Caraveo, Mr. Lucas, and Mr. Obernolte) introduced the following bill; which was referred to the Committee on Science, Space, and Technology A BILL To improve public-private partnerships and increase Federal research, development, and demonstration related to the evolution of next generation pipeline systems, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE. This Act may be cited as the “Next Generation Pipelines Research and Development Act”.SEC. 2. DEFINITIONS. In this Act: (1) DEPARTMENT.—The term “Department” means the Department of Energy. (2) ELIGIBLE ENTITY.—The term “eligible entity” means— (A) an institution of higher education (as such term is defined in section 101(a) of the Higher Education Act of 1965 (20 U.S.C. 1001(a))), including historically Black colleges and universities (within the meaning of the term “part B institution” in section 322 of the Higher Education Act of 1965 (20 U.S.C. 1061)), Tribal colleges and universities (as such term is defined in section 316 of the Higher Education Act of 1965 (20 U.S.C. 1059c)), and minority serving institutions (including the entiti",https://www.congress.gov/bill/118th-congress/house-bill/7073/text,en,
487,Advanced Weather Model Computing Development Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9681,low,0.0,210,0.5,Defunct,"S. 3642 To direct the Secretary of Energy and the Administrator of the National Oceanic and Atmospheric Administration to conduct collaborative research to advance weather models in the United States, and for other purposes. IN THE SENATE OF THE UNITED STATES January 23, 2024 Mr. Luján (for himself and Mrs. Blackburn) introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To direct the Secretary of Energy and the Administrator of the National Oceanic and Atmospheric Administration to conduct collaborative research to advance weather models in the United States, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE. This Act may be cited as the “Advanced Weather Model Computing Development Act”.SEC. 2. DEFINITIONS. In this Act: (1) ADMINISTRATION.—The term “Administration” means the National Oceanic and Atmospheric Administration. (2) ADMINISTRATOR.—The term “Administrator” means the Administrator of the National Oceanic and Atmospheric Administration (3) ADVANCED COMPUTING TECHNIQUES.—The term “advanced computing techniques” includes the hardware, software, and computational methods necessary to develop and deploy advanced weather models, such as artificial intelligence, high-performance computing, cloud computing, numerical methods, machine learning, data assimilation, large scale data analytics, pr",https://www.congress.gov/bill/118th-congress/senate-bill/3642/text,en,
489,Technology Workforce Framework Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8591,low,0.0,217,0.5,Defunct,"S. 3792 To expand the functions of the National Institute of Standards and Technology to include workforce frameworks for critical and emerging technologies, to require the Director of the National Institute of Standards and Technology to develop an artificial intelligence workforce framework, and periodically review and update the National Initiative for Cybersecurity Education Workforce Framework for Cybersecurity, and for other purposes. IN THE SENATE OF THE UNITED STATES February 8 (legislative day, February 7), 2024 Mr. Peters (for himself and Mr. Schmitt) introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To expand the functions of the National Institute of Standards and Technology to include workforce frameworks for critical and emerging technologies, to require the Director of the National Institute of Standards and Technology to develop an artificial intelligence workforce framework, and periodically review and update the National Initiative for Cybersecurity Education Workforce Framework for Cybersecurity, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Technology Workforce Framework Act of 2024”. SEC. 2. WORKFORCE FRAMEWORKS FOR CRITICAL AND EMERGING TECHNOLOGIES. (a) Definitions.— (1) IN GENERAL.—In this section, the terms “competencies”, “workfor",https://www.congress.gov/bill/118th-congress/senate-bill/3792/text,en,
494,Investing in Tomorrow's Workforce Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,neutral,0.0,low,0.0,0,0.5,Defunct,,https://www.congress.gov/bill/118th-congress/senate-bill/2722/text,,
496,Investing in Tomorrow's Workforce Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8225,low,0.0556,236,0.7,Defunct,"A BILL To address the needs of workers in industries likely to be impacted by rapidly evolving technologies. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Investing in Tomorrow's Workforce Act of 2023”. SEC. 2. Findings. Congress makes the following findings: (1) A 2019 Government Accountability Office report found that while there are many Federal employment and training programs, their total funding levels remain at nearly $20,000,000,000, or less than 0.1 percent of the gross domestic product of the United States. (2) The number of workers receiving federally supported training has declined in the past 3 decades as advances in technology have simultaneously shifted labor market demand over time. (3) Job losses from automation are more likely to impact women, people of color, and workers making less than $40,000 annually. (4) The COVID–19 pandemic accelerated trends in automation, with 43 percent of businesses in the World Economic Forum’s Future of Jobs survey indicating they plan to reduce their workforce as a result of technology integration. (5) Strong Federal investment in expanding training services for workers whose jobs may be lost due to automation could prepare the United States workforce to better adapt to changes in the labor market and enter into skilled positions in technologically oriented occupations and industries. (6) A focus on preparing",https://www.congress.gov/bill/118th-congress/house-bill/5350,en,"Strategies: Government support, Harms: Financial loss, Strategies: Pilots and testbeds, Applications: Transportation, Applications: Manufacturing and process automation, Strategies: Government study or report"
497,FinCEN Modernization Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9869,low,0.0,209,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “FinCEN Modernization Act of 2023”.SEC. 2. MODERNIZING THE RESEARCH, DEVELOPMENT, INFORMATION SHARING, AND ACQUISITION PROCESS AUTHORITIES OF THE FINANCIAL CRIMES ENFORCEMENT NETWORK (FINCEN). Section 310 of title 31, United States Code, is amended by adding at the end the following: “(m) Modernizing The Research, Development, Information Sharing, And Acquisition Process.—“(1) IN GENERAL.—FinCEN shall establish and maintain research, development, and information sharing programs that further the purposes and objectives of the laws administered by FinCEN, including programs that— “(A) inform FinCEN of important technological advances and innovations like machine learning and data analytics that help safeguard financial systems and detect illicit activity; “(B) facilitate an environment where these technological advances and innovations may be explored by developers and FinCEN to evaluate potential benefits for the financial industry; “(C) identify areas where FinCEN should adapt to facilitate these technological advances and innovations, and encourage the development of novel tools that are currently not available for use by FinCEN that would benefit financial systems monitored by FinCEN; “(D) ensure that FinCEN has the necessary technology to monitor cryptocurrencies and other emerging financial technologies for their potential use in money laundering and cyber and data security breaches; and “(E) facilitate FinCEN’s abilit",https://www.congress.gov/bill/118th-congress/house-bill/370/text,en,Strategies: Government support: For R&D
499,Preventing PLA Acquisition of United States Technology Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9767,low,0.0,234,0.5,Defunct,"H. R. 2993 To counter the military-civil fusion strategy of the Chinese Communist Party and prevent United States contributions to the development of dual-use technology in China. IN THE HOUSE OF REPRESENTATIVES April 28, 2023 Mr. Banks introduced the following bill; which was referred to the Committee on Armed Services, and in addition to the Committees on Science, Space, and Technology, Energy and Commerce, and Education and the Workforce, for a period to be subsequently determined by the Speaker, in each case for consideration of such provisions as fall within the jurisdiction of the committee concerned A BILL To counter the military-civil fusion strategy of the Chinese Communist Party and prevent United States contributions to the development of dual-use technology in China. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Preventing PLA Acquisition of United States Technology Act of 2023”. SEC. 2. COUNTERING THE MILITARY-CIVIL FUSION STRATEGY OF THE CHINESE COMMUNIST PARTY. (a) Definitions.—In this section: (1) CHINESE ENTITY OF CONCERN.—The term “Chinese entity of concern” means— (A) any college or university in the People's Republic of China that is determined by the Secretary of Defense to be involved in the implementation of the military-civil fusion strategy, including— (i) any college or university known as the “Seven Sons of National Defense”; (ii)",https://www.congress.gov/bill/118th-congress/house-bill/2993/text,en,
500,MEANS Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9448,low,0.0,234,0.5,Defunct,"H. R. 774 To establish an Office of Manufacturing Security and Resilience in the Department of Commerce, and for other purposes. IN THE HOUSE OF REPRESENTATIVES February 2, 2023 Mrs. Dingell (for herself, Ms. Blunt Rochester, Ms. Kelly of Illinois, and Ms. Wild) introduced the following bill; which was referred to the Committee on Energy and Commerce A BILL To establish an Office of Manufacturing Security and Resilience in the Department of Commerce, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Manufacturing Economy And National Security Act” or the “MEANS Act”. SEC. 2. FINDINGS. Congress finds the following: (1) Resilient supply chains are paramount to our national security and economic security. (2) A coordinated and whole-of-Government approach to safeguarding supply chains will benefit all Americans and ensure disruptions are avoided or mitigated. (3) Establishing an Office of Manufacturing Security and Resilience in the Department of Commerce will serve as the cornerstone of the Federal Government’s supply chain mission. SEC. 3. UNITED STATES STRATEGY TO COUNTER THREATS TO SUPPLY CHAINS FOR CRITICAL GOODS. (a) In General.—In accordance with Executive Order 14017 (86 Fed. Reg. 11849; relating to America’s supply chains), the Under Secretary shall, not later than 180 days after enactment of this Act, develop and implement a strate",https://www.congress.gov/bill/118th-congress/house-bill/774/text,en,
504,Medicare Transaction Fraud Prevention Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8286,low,0.0,237,0.5,Defunct,"S. 3630 To amend title XI of the Social Security Act to establish a pilot program for testing the use of a predictive risk-scoring algorithm to provide oversight of payments for durable medical equipment and clinical diagnostic laboratory tests under the Medicare program. IN THE SENATE OF THE UNITED STATES January 18, 2024 Mr. Braun (for himself and Mr. Cassidy) introduced the following bill; which was read twice and referred to the Committee on Finance A BILL To amend title XI of the Social Security Act to establish a pilot program for testing the use of a predictive risk-scoring algorithm to provide oversight of payments for durable medical equipment and clinical diagnostic laboratory tests under the Medicare program. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Medicare Transaction Fraud Prevention Act”. SEC. 2. PILOT PROGRAM TESTING USE OF PREDICTIVE RISK-SCORING ALGORITHM TO PROVIDE OVERSIGHT OF PAYMENTS FOR DURABLE MEDICAL EQUIPMENT AND CLINICAL DIAGNOSTIC LABORATORY TESTS UNDER THE MEDICARE PROGRAM. Section 1128K of the Social Security Act (42 U.S.C. 1320a–7n) is amended— (1) in the section heading by inserting “; PILOT PROGRAM TESTING USE OF PREDICTIVE RISK-SCORING ALGORITHM TO PROVIDE OVERSIGHT OF PAYMENTS FOR DURABLE MEDICAL EQUIPMENT AND CLINICAL DIAGNOSTIC LABORATORY TESTS UNDER THE MEDICARE PROGRAM” after “ABUSE”; and (2) by adding at the end t",https://www.congress.gov/bill/118th-congress/senate-bill/3630/text,en,
508,STAND with Taiwan Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.991,low,0.0,248,0.5,Defunct,"S. 1027 To require the imposition of sanctions with respect to the People's Republic of China if the People's Liberation Army initiates a military invasion of Taiwan. IN THE SENATE OF THE UNITED STATES March 29, 2023 Mr. Sullivan introduced the following bill; which was read twice and referred to the Committee on Banking, Housing, and Urban Affairs A BILL To require the imposition of sanctions with respect to the People's Republic of China if the People's Liberation Army initiates a military invasion of Taiwan. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Sanctions Targeting Aggressors of Neighboring Democracies with Taiwan Act of 2023” or the “STAND with Taiwan Act of 2023”. SEC. 2. FINDINGS. Congress makes the following findings: (1) Taiwan is a free and prosperous democracy of nearly 24,000,000 people, an important contributor to peace and stability around the world, and continues to embody and promote democratic values, freedom, and human rights in Asia. (2) The policy of the United States toward Taiwan is guided by the Taiwan Relations Act (22 U.S.C. 3301 et seq.), the United States-People's Republic of China joint communiqués concluded in 1972, 1978, and 1982, and the Six Assurances that President Ronald Reagan communicated to Taiwan in 1982. (3) Under section 2 of the Taiwan Relations Act (22 U.S.C. 3301), it is the policy of the United States— (A) “",https://www.congress.gov/bill/118th-congress/senate-bill/1027/text,en,
510,Data Science and Literacy Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9463,low,0.0,242,0.5,Defunct,"H. R. 1050 To direct the Secretary of Education to make grants for the purpose of increasing access to data literacy education, and for other purposes. IN THE HOUSE OF REPRESENTATIVES February 14, 2023 Ms. Stevens (for herself, Mr. Baird, Mr. Beyer, and Mrs. Kim of California) introduced the following bill; which was referred to the Committee on Education and the Workforce A BILL To direct the Secretary of Education to make grants for the purpose of increasing access to data literacy education, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE; TABLE OF CONTENTS. (a) Short Title.—This Act may be cited as the “Data Science and Literacy Act of 2023”. (b) Table Of Contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. Sec. 2. Findings. TITLE I—DATA LITERACY EDUCATION GRANT PROGRAM Sec. 101. Grant program established. Sec. 102. Applications. Sec. 103. Use of funds. Sec. 104. Reporting and evaluation. Sec. 105. Definitions. Sec. 106. Authorization of appropriations. TITLE II—STATISTICS ON SECONDARY SCHOOL STEM TEACHERS Sec. 201. Amendments to the Education Sciences Reform Act of 2002. SEC. 2. FINDINGS. Congress finds the following: (1) Data science and literacy are vital for United States residents in an era of intense global competition and growing reliance on data. (2) The American people constantly interact with and are affect",https://www.congress.gov/bill/118th-congress/house-bill/1050/text,en,
511,"To establish in the National Oceanic and Atmospheric Administration a program to improve precipitation forecasts, and for other purposes.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9686,low,0.0,210,0.7,Defunct,"H. R. 4913 To establish in the National Oceanic and Atmospheric Administration a program to improve precipitation forecasts, and for other purposes. IN THE HOUSE OF REPRESENTATIVES July 26, 2023 Mr. Jackson of North Carolina introduced the following bill; which was referred to the Committee on Science, Space, and Technology A BILL To establish in the National Oceanic and Atmospheric Administration a program to improve precipitation forecasts, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. ESTABLISHMENT OF NOAA PRECIPITATION FORECASTS PROGRAM. (a) Establishment.—There is established in the National Oceanic and Atmospheric Administration (NOAA) a program to improve precipitation forecasts (in this section referred to as the “program”). (b) Goal.—The goal of the program shall be to improve precipitation forecasts across all timescales through the research, development, and operational implementation of fully coupled Earth System Models. The program shall carry out the following: (1) Improve the understanding and prediction of precipitation extremes from a wide variety of weather systems and climate patterns. (2) Improve the development, production, management, assimilation, integration, availability, and curation of datasets for precipitation prediction. (3) Identify and improve observations and analyses necessary for precipitation prediction, including relating to water vapor, oce",https://www.congress.gov/bill/118th-congress/house-bill/4913/text,en,"Strategies: Evaluation, Strategies: New institution, Strategies: Convening, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Governance development"
515,DOE and NASA Interagency Research Coordination Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9681,low,0.0,213,0.5,Defunct,"H. R. 2988 IN THE SENATE OF THE UNITED STATES December 5, 2023 Received; read twice and referred to the Committee on Commerce, Science, and Transportation AN ACT To provide for Department of Energy and National Aeronautics and Space Administration research and development coordination, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “DOE and NASA Interagency Research Coordination Act”. SEC. 2. DEPARTMENT OF ENERGY AND NATIONAL AERONAUTICS AND SPACE ADMINISTRATION RESEARCH AND DEVELOPMENT COORDINATION. (a) In General.—The Secretary of Energy (in this section referred to as the “Secretary”) and the Administrator of the National Aeronautics and Space Administration (in this section referred to as the “Administrator”) may carry out, as practicable, cross-cutting and collaborative research and development activities to support the advancement of Department of Energy and National Aeronautics and Space Administration mission requirements and priorities. The Secretary and Administrator, in accordance with subsection (e), may make competitive awards to carry out such activities. (b) Memoranda Of Understanding.—The Secretary and the Administrator shall coordinate the activities under subsection (a) through memoranda of understanding, or other appropriate interagency agreements. (c) Coordination.—In carrying out the activities under subsection (a),",https://www.congress.gov/bill/118th-congress/house-bill/2988/text,en,
517,Protect Elections from Deceptive AI Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8807,low,0.1111,220,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Protect Elections from Deceptive AI Act”.SEC. 2. PROHIBITION ON DISTRIBUTION OF MATERIALLY DECEPTIVE AI-GENERATED AUDIO OR VISUAL MEDIA PRIOR TO ELECTION. (a) In General.—Title III of the Federal Election Campaign Act of 1971 (52 U.S.C. 30101 et seq.) is amended by adding at the end the following new section: “SEC. 325. PROHIBITION ON DISTRIBUTION OF MATERIALLY DECEPTIVE AI-GENERATED AUDIO OR VISUAL MEDIA.“(a) Definitions.—In this section: “(1) COVERED INDIVIDUAL.—The term ‘covered individual’ means a candidate for Federal office. “(2) DECEPTIVE AI-GENERATED AUDIO OR VISUAL MEDIA.—The term ‘deceptive AI-generated audio or visual media’ means an image, audio, or video that— “(A) is the product of artificial intelligence technology that uses machine learning (including deep learning models, natural learning processing, or any other computational processing techniques of similar or greater complexity), that— “(i) merges, combines, replaces, or superimposes content onto an image, audio, or video, creating an image, audio, or video that appears authentic; or “(ii) generates an inauthentic image, audio, or video that appears authentic; and “(B) a reasonable person, having considered the qualities of the image, audio, or video and the nature of the distribution channel in which the image, audio, or video appears— “(i) would have a fundamentally different understanding or impression of the appearance, speech, or expressive conduct",https://www.congress.gov/bill/118th-congress/senate-bill/2770/all-actions?overview=closed#tabs,en,"Harms: Detrimental content, Risk factors: Reliability, Applications: Broadcasting and media production, Applications: Government: other applications/unspecified, Incentives: Civil liability, Incentives: Fines"
519,Weather Information for Agriculture Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8807,low,0.0,225,0.5,Defunct,"H. R. 4373 To reauthorize the National Integrated Drought Information System, maintain a National Coordinated Soil Moisture Monitoring Network, and for other purposes. IN THE HOUSE OF REPRESENTATIVES June 27, 2023 Mr. Collins (for himself, Mr. Baird, and Mr. Miller of Ohio) introduced the following bill; which was referred to the Committee on Science, Space, and Technology A BILL To reauthorize the National Integrated Drought Information System, maintain a National Coordinated Soil Moisture Monitoring Network, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Weather Information for Agriculture Act.” SEC. 2. NATIONAL INTEGRATED DROUGHT INFORMATION SYSTEM. (a) In General.—Section 3 of the National Integrated Drought Information System Act of 2006 (15 U.S.C. 313d) is amended— (1) in subsection (b)— (A) in paragraph (5), by striking “and” after the semicolon; (B) in paragraph (6), by striking the period and inserting a semicolon; and (C) by adding at the end the following new paragraphs: “(7) advance and deploy next generation technologies related to drought and related publicly available data, such as forecasting capabilities utilizing artificial intelligence, machine learning, and cloud technologies; and “(8) strengthen observational networks and drought indicators across a variety of spatial and temporal scales by optimizing data and reso",https://www.congress.gov/bill/118th-congress/house-bill/4373/text,en,
520,Integrating New Technologies to Empower Law Enforcement at Our Borders Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9881,low,0.0,227,0.7,Defunct,"H. R. 6391 To require the Department of Homeland Security to develop a comprehensive plan to identify, deploy, and integrate emerging technologies to achieve greater situational awareness along the northern and southern borders of the United States. IN THE HOUSE OF REPRESENTATIVES November 13, 2023 Ms. Slotkin (for herself, Ms. Spanberger, Mr. Garbarino, and Mr. Duarte) introduced the following bill; which was referred to the Committee on Homeland Security A BILL To require the Department of Homeland Security to develop a comprehensive plan to identify, deploy, and integrate emerging technologies to achieve greater situational awareness along the northern and southern borders of the United States. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Integrating New Technologies to Empower Law Enforcement at Our Borders Act”. SEC. 2. FINDINGS. Congress finds the following: (1) Our border security is directly tied to our national security. (2) U.S. Customs and Border Protection faces a daunting challenge in maintaining situational awareness along the United States northern and southern borders. (3) The United States northern border is the longest common non-militarized border between two countries. (4) The United States southern border is nearly 2,000 miles long, stretching across rugged and varied terrain. (5) Emerging technologies present an opportunity to reduce c",https://www.congress.gov/bill/118th-congress/house-bill/6391/text,en,"Strategies: Government study or report, Applications: Government: judicial and law enforcement, Strategies: Evaluation"
522,National Critical Capabilities Defense Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8986,low,0.0,233,0.7,Defunct,"H. R. 3136 To require notification and review of United States investment in foreign countries that may threaten the national security of the United States, and for other purposes. IN THE HOUSE OF REPRESENTATIVES May 9, 2023 Ms. DeLauro (for herself, Mr. Pascrell, and Mr. Fitzpatrick) introduced the following bill; which was referred to the Committee on Ways and Means A BILL To require notification and review of United States investment in foreign countries that may threaten the national security of the United States, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “National Critical Capabilities Defense Act of 2023”. SEC. 2. PROTECTION OF NATIONAL CRITICAL CAPABILITIES. The Trade Act of 1974 (19 U.S.C. 2101 et seq.) is amended by adding at the end the following: “TITLE X—PROTECTION OF NATIONAL CRITICAL CAPABILITIES “SEC. 1001. DEFINITIONS. “In this title: “(1) APPROPRIATE CONGRESSIONAL COMMITTEES.—The term ‘appropriate congressional committees’ means— “(A) the Committee on Finance, the Committee on Banking, Housing, and Urban Affairs, the Select Committee on Intelligence, and the Committee on Foreign Relations of the Senate; and “(B) the Committee on Ways and Means, the Committee on Financial Services, the Permanent Select Committee on Intelligence, and the Committee on Foreign Affairs of the House of Representatives. “(2) COUNTRY OF CO",https://www.congress.gov/bill/118th-congress/house-bill/3136/text,en,"Strategies: New institution, Strategies: Convening, Strategies: Disclosure, Strategies: Government study or report, Strategies: Governance development, Incentives: Civil liability, Incentives: Fines"
523,Digital Defense Content Provenance Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9578,low,0.0556,236,0.7,Defunct,"S. 3504 To establish a course of education and pilot program on authentication of digital content provenance for certain Department of Defense media content, and for other purposes. IN THE SENATE OF THE UNITED STATES December 13, 2023 Mr. Peters introduced the following bill; which was read twice and referred to the Committee on Armed Services A BILL To establish a course of education and pilot program on authentication of digital content provenance for certain Department of Defense media content, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Digital Defense Content Provenance Act of 2023”. SEC. 2. COURSE OF EDUCATION AND PILOT PROGRAM ON AUTHENTICATION OF DIGITAL CONTENT PROVENANCE FOR CERTAIN DEPARTMENT OF DEFENSE MEDIA CONTENT. (a) Course Of Education.— (1) IN GENERAL.—Not later than one year after the date of the enactment of this Act, the Secretary of Defense, acting through the Director of the Defense Media Activity, shall establish a course of education at the Defense Information School, the purpose of which shall be to provide instruction on the practical concepts and skills needed by public affairs, audiovisual, visual information, and records management specialists to understand the following: (A) Digital content provenance for applicable Department media content. (B) The challenges posed to missions and operations of the De",https://www.congress.gov/bill/118th-congress/senate-bill/3504/text,en,"Strategies: Government support, Strategies: Government support: AI workforce-related, Harms: Detrimental content, Strategies: Governance development, Applications: Government: military and public safety, Strategies: Government study or report, Strategies: Pilots and testbeds, Strategies: Convening"
524,Digital Defense Content Provenance Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9112,low,0.0,241,0.5,Defunct,"S. 2222 To require the Director of the Defense Media Activity to establish a course of education on digital content provenance and to carry out a pilot program on implementing digital content provenance standards, and for other purposes. IN THE SENATE OF THE UNITED STATES July 10, 2023 Mr. Peters introduced the following bill; which was read twice and referred to the Committee on Armed Services A BILL To require the Director of the Defense Media Activity to establish a course of education on digital content provenance and to carry out a pilot program on implementing digital content provenance standards, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Digital Defense Content Provenance Act of 2023”. SEC. 2. DEPARTMENT OF DEFENSE DIGITAL CONTENT PROVENANCE. (a) Briefing.— (1) IN GENERAL.—Not later than 90 days after the date of the enactment of this Act, the Director of the Defense Media Activity (DMA) shall provide to the Committee on Armed Services of the Senate and the Committee on Armed Services of the House of Representatives a briefing on developing a course of education at the Defense Information School (DINFOS) to teach the practical concepts and skills needed by Department of Defense public affairs, audiovisual, visual information, and records management specialists. (2) ELEMENTS.—The briefing provided pursuant to paragraph (1) s",https://www.congress.gov/bill/118th-congress/senate-bill/2222/text,en,
525,Advancing Nuclear Regulatory Oversight Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.4466,low,0.0,232,0.5,Defunct,"H. R. 6346 To update oversight and inspection practices of the Nuclear Regulatory Commission, and for other purposes. IN THE HOUSE OF REPRESENTATIVES November 9, 2023 Mrs. Lesko introduced the following bill; which was referred to the Committee on Energy and Commerce A BILL To update oversight and inspection practices of the Nuclear Regulatory Commission, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Advancing Nuclear Regulatory Oversight Act”. SEC. 2. IMPLEMENTING LESSONS LEARNED FROM THE COVID–19 HEALTH EMERGENCY. (a) In General.—Not later than 180 days after the date of enactment of this Act, the Commission shall submit to the appropriate committees of Congress a report on actions taken by the Commission during the public health emergency declared by the Secretary of Health and Human Services under section 319 of the Public Health Service Act (42 U.S.C. 247d) on January 31, 2020, with respect to COVID–19. (b) Contents.—The report submitted under subsection (a) shall— (1) identify any processes, procedures, and other regulatory policies that the Commission revised or temporarily suspended during the public health emergency described in subsection (a); (2) examine how any revision or temporary suspension of a process, procedure, or other regulatory policy identified under paragraph (1) affected the ability of the Commission to licens",https://www.congress.gov/bill/118th-congress/house-bill/6346/text,en,
529,Autonomous Vehicle Accessibility Act/AV Accessibility Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7506,low,0.0,219,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Autonomous Vehicle Accessibility Act” or the “AV Accessibility Act”.SEC. 2. DEFINITIONS. In this Act: (1) DISABILITY.—The term “disability” has the meaning given the term in section 12102 of title 42, United States Code. (2) PUBLIC TRANSPORTATION.—The term “public transportation” has the meaning given the term in section 5302 of title 49, United States Code. (3) RIDE-HAIL ADS-EQUIPPED VEHICLE.—The term “ride-hail ADS-equipped vehicle” means an ADS-equipped vehicle that is— (A) offered for pre-arranged transportation services for compensation, using an online-enabled application or electronic platform to connect passengers with vehicles; and (B) dispatched in driverless operation. (4) SECRETARY.—The term “Secretary” means the Secretary of Transportation. (5) SAE-DEFINED TERMS.—The terms “ADS-equipped vehicle”, “dispatch”, “Level 4”, “Level 5”, and “driverless operation” have the meanings given such terms in the document titled SAE International Recommended Practice J3016, published in April 2021, or by a revision of that such document subsequently adopted by the Secretary.SEC. 3. LICENSING. In accordance with title II of the Americans with Disabilities Act (42 U.S.C. 12132), a State shall not issue a motor vehicle operator’s license for the operation or use of an ADS-equipped vehicle operating at Level 4 or Level 5 in a manner that discriminates on the basis of disability against a qualified individual with a disability.SEC",https://www.congress.gov/bill/118th-congress/house-bill/7126/text,en,
530,Shifting Forward Vehicle Technologies Research and Development Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9524,low,0.0,214,0.5,Defunct,"H. R. 5090 To support research, development, demonstration, and other activities to develop innovative vehicle technologies, and for other purposes. IN THE HOUSE OF REPRESENTATIVES July 28, 2023 Ms. Stevens (for herself and Mrs. Dingell) introduced the following bill; which was referred to the Committee on Science, Space, and Technology A BILL To support research, development, demonstration, and other activities to develop innovative vehicle technologies, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Shifting Forward Vehicle Technologies Research and Development Act”. SEC. 2. DEFINITIONS. In this Act: (1) ALTERNATIVE FUEL.—The term “alternative fuel” means a fuel that results in a significant reduction in lifecycle greenhouse gas (GHG) and criteria air pollutant emissions compared to conventional fuel options. (2) EXTREME FAST CHARGING.—The term “extreme fast charging” means recharging up to 80 percent of battery capacity in approximately 10 minutes or less. (3) SUSTAINABLE MATERIALS.—The term “sustainable materials” means materials used throughout the consumer and industrial economy that can be produced in required volumes without depleting nonrenewable resources and without disrupting the established steady-state equilibrium of the environment and key natural resource systems. (4) DEPARTMENT.—The term “Department” means the Departme",https://www.congress.gov/bill/118th-congress/house-bill/5090/text,en,
531,Disrupt Explicit Forged Images And Non-Consensual Edits Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.6124,low,0.1667,217,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Disrupt Explicit Forged Images And Non-Consensual Edits Act of 2024” or the “DEFIANCE Act of 2024”.SEC. 2. CIVIL ACTION RELATING TO DISCLOSURE OF INTIMATE IMAGES. (a) Definitions.—Section 1309(a) of the Consolidated Appropriations Act, 2022 (15 U.S.C. 6851(a)) is amended— (1) in paragraph (2), by inserting “competent,” after “conscious,”; (2) by redesignating paragraphs (5) and (6) as paragraphs (6) and (7), respectively; (3) by redesignating paragraph (3) as paragraph (5); (4) by inserting after paragraph (2) the following:“(3) DIGITAL FORGERY.—The term ‘digital forgery’ means any intimate visual depiction of an identifiable individual created through the use of software, machine learning, artificial intelligence, or any other computer-generated or technological means, including by adapting, modifying, manipulating, or altering an authentic visual depiction, to appear to a reasonable person to be indistinguishable from an authentic visual depiction of the individual, regardless of whether the visual depiction indicates, through a label or some other form of information published with the visual depiction, that the visual depiction is not authentic.”; (5) in paragraph (5), as so redesignated— (A) by striking “(5) DEPICTED” and inserting “(5) IDENTIFIABLE”; and (B) by striking “depicted individual” and inserting “identifiable individual”; and (6) in paragraph (6)(A), as so redesignated— (A) in clause (i), by striking “; or”",https://www.congress.gov/bill/118th-congress/senate-bill/3696/text,en,"Harms: Detrimental content, Incentives: Civil liability, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination"
532,Disincentivizing Internet Service Censorship of Online Users and Restrictions on Speech and Expression Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.773,low,0.0,222,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Disincentivizing Internet Service Censorship of Online Users and Restrictions on Speech and Expression Act” or the “DISCOURSE Act”.SEC. 2. CONTENT MODERATION, CREATION AND DEVELOPMENT, AND DISTRIBUTION. (a) Treatment As Publisher Or Speaker Contingent On Content Management Practices.—Section 230 of the Communications Act of 1934 (47 U.S.C. 230) is amended— (1) in subsection (c)(1)— (A) by striking “No provider” and inserting the following: “(A) IN GENERAL.—Subject to subparagraph (B), no provider”; and (B) by adding at the end the following:“(B) NOTIFICATION OF PARENTAL CONTROL PROTECTIONS.—Subparagraph (A) shall not apply to a provider of an interactive computer service with a dominant market share that violates subsection (d).”; and (2) in subsection (f)— (A) in paragraph (3)— (i) by striking “The term” and inserting the following: “(A) IN GENERAL.—The term”; and (ii) by adding at the end the following:“(B) CONTENT MODERATION.—If an interactive computer service provider with a dominant market share— “(i) engages in a content moderation activity that reasonably appears to express, promote, or suppress a discernible viewpoint for a reason that is not protected from liability under subsection (c)(2), including reducing or eliminating the ability of an information content provider to earn revenue, with respect to any information, the interactive computer service provider shall be deemed to be an information content provider",https://www.congress.gov/bill/118th-congress/senate-bill/921/text,en,Incentives: Civil liability
533,Promoting Digital Privacy Technologies Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9813,low,0.0,210,0.5,Defunct,"S. 3325 To support research on privacy enhancing technologies and promote responsible data use, and for other purposes. IN THE SENATE OF THE UNITED STATES November 15, 2023 Ms. Cortez Masto (for herself and Mrs. Fischer) introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To support research on privacy enhancing technologies and promote responsible data use, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Promoting Digital Privacy Technologies Act”. SEC. 2. PROMOTING PRIVACY ENHANCING TECHNOLOGIES. (a) Definition Of Privacy Enhancing Technology.—In this section the term “privacy enhancing technology” means any software or hardware solution, technical processes, or other technological means of protecting an individual’s privacy and the confidentiality of data, which may include— (1) de-identification, anonymization and pseudonymization technologies or techniques, filtering tools, anti-tracking technology, differential privacy tools, synthetic data generation tools, cryptographic techniques (such as secure multi-party computation and homomorphic encryption), and systems for federated learning; and (2) any other software or hardware solution, technical processes, or other technological means that the Director of the National Science Foundation, in consultation wi",https://www.congress.gov/bill/118th-congress/senate-bill/3325/text,en,
534,Sensible Classification Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9744,low,0.0,209,0.7,Defunct,"SECTION 1. SHORT TITLE; TABLE OF CONTENTS. (a) Short Title.—This Act may be cited as the “Sensible Classification Act of 2023”. (b) Table Of Contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. Sec. 2. Definitions. Sec. 3. Findings and sense of the Senate. Sec. 4. Classification authority. Sec. 5. Promoting efficient declassification review. Sec. 6. Training to promote sensible classification. Sec. 7. Improvements to Public Interest Declassification Board. Sec. 8. Implementation of technology for classification and declassification. Sec. 9. Studies and recommendations on necessity of security clearances.SEC. 2. DEFINITIONS. In this Act: (1) AGENCY.—The term “agency” has the meaning given the term “Executive agency” in section 105 of title 5, United States Code. (2) CLASSIFIED INFORMATION.—The term “classified information” means information that has been determined pursuant to Executive order 12958 (50 U.S.C. 3161 note; relating to classified national security information), or successor order, to require protection against unauthorized disclosure and is marked to indicate its classified status when in documentary form. (3) CLASSIFICATION.—The term “classification” means the act or process by which information is determined to be classified information. (4) DECLASSIFICATION.—The term “declassification” means the authorized change in the status of information from classified information to unclassified information. (5) DOCUMENT.—The",https://www.congress.gov/bill/118th-congress/senate-bill/1518/text,en,"Strategies: Government support, Strategies: Government support: For R&D, Strategies: Government study or report, Applications: Government: other applications/unspecified"
539,Computer Science for All Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8964,low,0.0,233,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Computer Science for All Act of 2023”.SEC. 2. FINDINGS. Congress finds the following: (1) Computer science is transforming industry, creating new fields of commerce, driving innovation, and bolstering productivity. By 2029, computer science and information jobs are expected to grow by 11 percent, faster than the average of any other occupation. (2) However, as of 2019, the more than 900,000 computing and tech jobs unfilled in the United States suggests that our students are not being prepared to meet the demands of a 21st century economy. It is projected that there will be 8,000,000 new jobs in the technology sector by 2028 and 3,500,000 computing-related jobs by 2026, however, the current state of computer science education will only prepare enough computer science professionals to fill 19 percent of these jobs. (3) Knowledge of computer science and use of technology is increasingly essential for all individuals, not just those working or planning to work in the technology sector. (4) Providing students with computer science education in elementary school and secondary school is critical for student success, and strengthening the workforce of a 21st century economy. (5) While an estimated 90 percent of parents want computer science taught in their children’s schools, just 45 percent of all elementary schools and secondary schools offer high-quality computer science instruction that includes programming and coding. (6) Bla",https://www.congress.gov/bill/118th-congress/house-bill/4174/text,en,
540,Tornado Observations Research and Notification Assessment for Development of Operations Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.7845,low,0.0,226,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Tornado Observations Research and Notification Assessment for Development of Operations Act” or the “TORNADO Act”.SEC. 2. DEFINITIONS. In this Act: (1) HAZARDOUS WEATHER AND WATER EVENTS.—The term “hazardous weather and water events” means weather and water events that have a high risk of loss of life or property, including— (A) severe storms, such as hurricanes and short-fused, small-scale hazardous weather or hydrologic events produced by thunderstorms, including large hail, damaging winds, tornadoes, and flash floods; (B) winter storms, such as freezing or frozen precipitation (including freezing rain, sleet, and snow), or combined effects of freezing or frozen precipitation and strong winds; and (C) other weather hazards, such as extreme heat or cold, wildfire, drought, dense fog, high winds, river flooding, and lakeshore flooding. (2) HISTORICALLY BLACK COLLEGE OR UNIVERSITY.—The term “historically Black college or university” has the meaning given the term “part B institution” in section 322 of the Higher Education Act of 1965 (20 U.S.C. 1061). (3) INDIAN TRIBE.—The term “Indian Tribe” has the meaning given the term in section 4 of the Indian Self-Determination and Education Assistance Act (25 U.S.C. 5304). (4) INSTITUTION OF HIGHER EDUCATION.—The term “institution of higher education” has the meaning given the term in section 101(a) of the Higher Education Act of 1965 (20 U.S.C. 1001(a)). (5) NATIONAL LABORATORY.—Th",https://www.congress.gov/bill/118th-congress/senate-bill/1284/all-actions,en,"Applications: Government: other applications/unspecified, Strategies: Government support"
541,Exploitative Workplace Surveillance and Technologies Task Force Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9106,low,0.0,226,0.5,Defunct,"S. 2440 To establish an interagency task force on employer surveillance and workplace technologies, and for other purposes. IN THE SENATE OF THE UNITED STATES July 20, 2023 Mr. Casey (for himself, Mr. Schatz, Mr. Fetterman, and Mr. Booker) introduced the following bill; which was read twice and referred to the Committee on Health, Education, Labor, and Pensions A BILL To establish an interagency task force on employer surveillance and workplace technologies, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Exploitative Workplace Surveillance and Technologies Task Force Act of 2023”. SEC. 2. DEFINITIONS. In this Act: (1) APPLICANT.—The term “applicant”, with respect to an employer, means an individual who applies, or applied, to be employed by, or otherwise perform work for remuneration for, the employer. (2) AUTOMATED DECISION SYSTEM.— (A) IN GENERAL.—The term “automated decision system” means a system, software, or process that— (i) uses computation, in whole or in part, to determine outcomes, make or aid decisions (including through evaluations, metrics, or scoring), inform policy implementation, collect data or observations, or otherwise interact with individuals or communities, including such a system, software, or process derived from machine learning, statistics, or other data processing or artificial intelligence techniques; and (",https://www.congress.gov/bill/118th-congress/senate-bill/2440/text,en,
546,Deceptive Experiences To Online Users Reduction Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9565,low,0.0,241,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Deceptive Experiences To Online Users Reduction Act” or the “DETOUR Act”.SEC. 2. DEFINITIONS. In this Act: (1) AFFIRMATIVE EXPRESS CONSENT.—The term “affirmative express consent”— (A) means an affirmative act by a user that— (i) clearly communicates the user's authorization for a specific act or practice for which the user's consent is sought to proceed; (ii) is freely taken by the user; and (iii) is taken after the user is informed about the act or practice for which consent is sought, including through the presentation to the user of a clear and conspicuous description of the act or practice; and (B) does not include— (i) the consent of a child or teen; or (ii) the consent to a provision contained in a general contract or service agreement. (2) AGGREGATED DATA.—The term “aggregated data” means data that have been combined or collected together in summary or other form such that the data is not linked or reasonably linkable to any individual. (3) AUTO-PLAY.—The term “auto-play” means the automatic playing of content selected by a personalized recommendation system for a user. (4) CHILD.—The term “child” has the meaning given such term in section 1302 of the Children's Online Privacy Protection Act of 1998 (15 U.S.C. 6501). (5) COMMISSION.—The term “Commission” means the Federal Trade Commission. (6) COMPULSIVE USAGE.—The term “compulsive usage” means any response stimulated by external factors that causes an individual to",https://www.congress.gov/bill/118th-congress/senate-bill/2708,en,
554,AI Labeling Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9406,low,0.0556,227,0.7,Defunct,"S. 2691 To require disclosures for AI-generated content, and for other purposes. IN THE SENATE OF THE UNITED STATES July 27, 2023 Mr. Schatz (for himself and Mr. Kennedy) introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To require disclosures for AI-generated content, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “AI Labeling Act of 2023”. SEC. 2. DISCLOSURES FOR AI-GENERATED CONTENT. (a) Consumer Disclosures.— (1) IMAGE, VIDEO, AUDIO, OR MULTIMEDIA AI-GENERATED CONTENT.— (A) IN GENERAL.—Each generative artificial intelligence system that, using any means or facility of interstate or foreign commerce, produces image, video, audio, or multimedia AI-generated content shall include on such AI-generated content a clear and conspicuous disclosure that meets the requirements of subparagraph (B). (B) DISCLOSURE REQUIREMENTS.—A disclosure required under subparagraph (A) shall meet each of the following criteria: (i) The disclosure shall include a clear and conspicuous notice, as appropriate for the medium of the content, that identifies the content as AI-generated content. (ii) The output's metadata information shall include an identification of the content as being AI-generated content, the identity of the tool used to create the content, and the date and time th",https://www.congress.gov/bill/118th-congress/senate-bill/2691/text,en,"Risk factors: Transparency, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: In standard form, Strategies: Governance development, Strategies: Licensing, registration, and certification, Incentives: Civil liability, Strategies: New institution, Strategies: Convening, Strategies: Government study or report"
556,National Strategy to Utilize Microreactors for Natural Disaster Response Efforts Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.91,low,0.0,228,0.5,Defunct,"H. R. 1009 To require the President develop a national strategy for utilizing microreactors to assist with natural disaster response efforts, and for other purposes. IN THE HOUSE OF REPRESENTATIVES February 14, 2023 Mr. Donalds (for himself, Mr. Fleischmann, Mr. Feenstra, Mr. Obernolte, and Ms. Mace) introduced the following bill; which was referred to the Committee on Transportation and Infrastructure, and in addition to the Committees on Energy and Commerce, and Armed Services, for a period to be subsequently determined by the Speaker, in each case for consideration of such provisions as fall within the jurisdiction of the committee concerned A BILL To require the President develop a national strategy for utilizing microreactors to assist with natural disaster response efforts, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “National Strategy to Utilize Microreactors for Natural Disaster Response Efforts Act”. SEC. 2. FINDINGS; SENSE OF CONGRESS. (a) Findings.—Congress finds that— (1) natural disasters often cause loss of life, human suffering, loss of income, and property loss and damage; (2) natural disasters often disrupt the normal functioning of governments and communities and adversely affect individuals and families with great severity; and (3) special measures, designed to assist with and supplement natural disaster response e",https://www.congress.gov/bill/118th-congress/house-bill/1009/text,en,
557,Promoting Resilient Supply Chains Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7672,low,0.0,226,0.5,Defunct,"H. R. 6571 IN THE SENATE OF THE UNITED STATES May 16, 2024 Received; read twice and referred to the Committee on Commerce, Science, and Transportation AN ACT To establish a critical supply chain resiliency and crisis response program in the Department of Commerce, and to secure American leadership in deploying emerging technologies, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE; TABLE OF CONTENTS. (a) Short Title.—This Act may be cited as the “Promoting Resilient Supply Chains Act of 2023”. (b) Table Of Contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. Sec. 2. Additional responsibilities of Assistant Secretary of Commerce for Industry and Analysis. Sec. 3. Critical supply chain resiliency and crisis response program. Sec. 4. Critical supply chain innovation and best practices. Sec. 5. Department of Commerce capability assessment. Sec. 6. Definitions.SEC. 2. ADDITIONAL RESPONSIBILITIES OF ASSISTANT SECRETARY OF COMMERCE FOR INDUSTRY AND ANALYSIS. (a) Additional Responsibilities.—In addition to the responsibilities of the Assistant Secretary on the day before the date of the enactment of this Act, the Assistant Secretary shall have the following responsibilities: (1) Promote the leadership of the United States with respect to critical industries, critical supply chains, and emerging technologies that— (A) strengthen th",https://www.congress.gov/bill/118th-congress/house-bill/6571/text,en,
560,DATA Privacy Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8986,medium,0.4444,231,0.7,Defunct,"S. 3337 To establish national data privacy standards in the United States, and for other purposes. IN THE SENATE OF THE UNITED STATES November 15, 2023 Ms. Cortez Masto introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To establish national data privacy standards in the United States, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Digital Accountability and Transparency to Advance Privacy Act” or the “DATA Privacy Act”. SEC. 2. DEFINITIONS. (a) In General.—In this Act: (1) COLLECT.—The term “collect” means taking any operation or set of operations to obtain covered data, including by automated means, including purchasing, leasing, assembling, recording, gathering, acquiring, or procuring. (2) COMMISSION.—The term “Commission” means the Federal Trade Commission. (3) COVERED DATA.—The term “covered data”— (A) means any information that is— (i) collected, processed, stored, or disclosed by a covered entity; (ii) collected over the internet or other digital network; and (iii) (I) linked to an individual or device associated with an individual; or (II) practicably linkable to an individual or device associated with an individual, including by combination with separate information, by the covered entity or any potential recipient of the data; and (B) does not inc",https://www.congress.gov/bill/118th-congress/senate-bill/3337/text,en,"Risk factors: Privacy, Harms: Discrimination, Harms: Harm to health/safety, Risk factors: Safety, Harms: Financial loss, Harms: Violation of civil or human rights, including privacy, Strategies: Input controls, Strategies: Input controls: Data circulation, Strategies: Input controls: Data use, Applications: Medicine, life sciences and public health, Applications: Arts, sports, leisure, travel, and lifestyle, Strategies: Disclosure, Strategies: Disclosure: About inputs, Strategies: Performance requirements, Strategies: Evaluation"
566,Do Not Disturb Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7689,low,0.0,226,0.5,Defunct,"H. R. 7116 To strengthen certain provisions relating to restrictions on robocalls and telemarketing, and for other purposes. IN THE HOUSE OF REPRESENTATIVES January 29, 2024 Mr. Pallone (for himself, Ms. Matsui, Ms. Schakowsky, Mr. Sorensen, and Mr. Soto) introduced the following bill; which was referred to the Committee on Energy and Commerce A BILL To strengthen certain provisions relating to restrictions on robocalls and telemarketing, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE; TABLE OF CONTENTS. (a) Short Title.—This Act may be cited as the “Do Not Disturb Act”. (b) Table Of Contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. TITLE I—FEDERAL COMMUNICATIONS COMMISSION Sec. 101. Robocall restrictions. Sec. 102. Text message authentication and trace back study. Sec. 103. Annual robocall report. Sec. 104. Disclosure required for robocalls using AI. Sec. 105. Enhanced penalties for violations involving AI voice or text message impersonation. Sec. 106. Certain requirements for VoIP service providers. Sec. 107. Tracking of top 100 illegal robocall campaigns. Sec. 108. Offering of robocall-blocking service at no charge to customer. Sec. 109. Telephone solicitation. Sec. 110. Commission defined. TITLE II—FEDERAL TRADE COMMISSION Sec. 201. Addition of text message to the definition of telemarketing. Sec. 202. Adoption of",https://www.congress.gov/bill/118th-congress/house-bill/7116/text,en,
568,Protect Working Musicians Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9813,low,0.0,233,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Protect Working Musicians Act of 2023”.SEC. 2. FINDINGS. Congress finds the following: (1) Music is a cultural treasure and a unique source of spiritual inspiration, emotional comfort, community connection, and joy. It is also a powerful economic driver that directly and indirectly supports nearly 2 million American jobs and almost $150 billion in annual economic activity. (2) A healthy music ecosystem is a fundamental bedrock for a healthy society. (3) Fair and competitive markets for the use and licensing of recorded music are integral to a healthy music ecosystem. (4) As music distribution has moved online, the market for use and licensing has become distorted and imbalanced. The largest Dominant Online Music Distribution Platforms use their market power to distort legal requirements and force music creators into licensing agreements that do not reflect market value. Those agreements essentially dictate a price to music creators. If music creators do not agree to licensing terms, the online platforms profit from unlicensed uploads of music anyway. (5) These platforms game the system created by the Digital Millennium Copyright Act, which allows dominant online platforms to ignore and profit from unlicensed use of music and places the responsibility for finding each and every instance of unlicensed use of music on music creators. This “notice and takedown” scheme has been described as a gigabit-speed game of whack-a-mole.",https://www.congress.gov/bill/118th-congress/house-bill/5576/text,en,
571,Transparent Automated Governance Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.5371,low,0.2222,221,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Transparent Automated Governance Act” or the “TAG Act”. SEC. 2. DEFINITIONS. In this Act: (1) AGENCY.—The term “agency” has the meaning given the term in section 3502 of title 44, United States Code. (2) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence” has the meaning given the term in section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (10 U.S.C. note prec. 4061; Public Law 115–232). (3) AUGMENTED CRITICAL DECISION PROCESS.—The term “augmented critical decision process” means the use by an agency, or by a third party on behalf of the agency, of an automated system to determine or substantially influence the outcomes of critical decisions. (4) AUTOMATED SYSTEM.—The term “automated system”— (A) means a set of computational processes derived from statistics or artificial intelligence techniques, or that otherwise rely on data about specific individuals or groups, to substantially influence the outcome of critical decisions, including computational processes that stand alone or are embedded within another process, system, or application, including paper-based processes; and (B) does not include computational processes or infrastructure the function of which is not directly related to influencing or determining the outcome of critical decisions. (5) CRITICAL DECISION.—The term “critical decision” means an agency determination, including the assignment of a score or classifica",https://www.congress.gov/bill/118th-congress/senate-bill/1865/text,en,"Strategies: Governance development, Risk factors: Privacy, Harms: Violation of civil or human rights, including privacy, Strategies: Disclosure, Strategies: Disclosure: About incidents, Strategies: Disclosure: In deployment, Strategies: Disclosure: In standard form, Risk factors: Reliability, Risk factors: Transparency, Strategies: Convening, Strategies: Government study or report"
572,"Novel, Advanced Spectrum and Communications Technology Networks Promotion Act",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9633,low,0.0,214,0.5,Defunct,"H. R. 4504 To direct the Assistant Secretary of Commerce for Communications and Information to take certain actions to improve the management of electromagnetic spectrum, and for other purposes. IN THE HOUSE OF REPRESENTATIVES July 10, 2023 Mr. Guthrie introduced the following bill; which was referred to the Committee on Energy and Commerce A BILL To direct the Assistant Secretary of Commerce for Communications and Information to take certain actions to improve the management of electromagnetic spectrum, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE. This Act may be cited as the “Novel, Advanced Spectrum and Communications Technology Networks Promotion Act”. SEC. 2. FINDINGS. Congress finds the following: (1) The National Telecommunications and Information Administration (NTIA) is the principal advisor to the President on all telecommunications and information issues. (2) The NTIA represents executive branch agencies on electromagnetic spectrum issues before the Federal Communications Commission. (3) Understanding radio frequency propagation characteristics is a critical component of making spectrum management and spectrum policy decisions. (4) The NTIA relies on expert engineering studies and analyses to make determinations about system relocations to make spectrum available, as well as to identify spectrum sharing opportunities. (5) Spectrum clearing, when feasibl",https://www.congress.gov/bill/118th-congress/house-bill/4504/text,en,
573,STOP HATE Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.8816,low,0.1667,244,0.7,Defunct,"H. R. 6463 To require the publication of the terms of service of certain social media company platforms. IN THE HOUSE OF REPRESENTATIVES November 21, 2023 Mr. Gottheimer (for himself and Mr. Bacon) introduced the following bill; which was referred to the Committee on Energy and Commerce, and in addition to the Permanent Select Committee on Intelligence, for a period to be subsequently determined by the Speaker, in each case for consideration of such provisions as fall within the jurisdiction of the committee concerned A BILL To require the publication of the terms of service of certain social media company platforms. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE. This Act may be cited as the “Stopping Terrorists Online Presence and Holding Accountable Tech Entities Act of 2023” or as the “STOP HATE Act of 2023”.SEC. 2. TERMS OF SERVICE PUBLICATION. (a) No later than 180 days after the date of enactment, a social media company shall post terms of service, or lack thereof, for each social media platform owned or operated by the company in a manner reasonably designed to inform all users of the social media platform of the existence and contents of the terms of service applicable to the following: (1) A foreign terrorist organization designated under section 219 of the Immigration and Nationality Act. (2) Individuals or entities designated as Specially Designated Global Terrorists under Execu",https://www.congress.gov/bill/118th-congress/house-bill/6463/text,en,"Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content, Strategies: Disclosure, Applications: Broadcasting and media production, Harms: Harm to health/safety, Strategies: Disclosure: In deployment, Incentives: Civil liability, Incentives: Fines, Strategies: Government study or report"
576,Cooper Davis Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9049,low,0.0,229,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Cooper Davis Act”.SEC. 2. REPORTING REQUIREMENTS OF ELECTRONIC COMMUNICATION SERVICE PROVIDERS AND REMOTE COMPUTING SERVICES FOR CERTAIN CONTROLLED SUBSTANCES VIOLATIONS.(a) Amendments To Controlled Substances Act.— IN GENERAL.—Part E of the Controlled Substances Act (21 U.S.C. 871 et seq.) is amended by adding at the end the following: “REPORTING REQUIREMENTS OF ELECTRONIC COMMUNICATION SERVICE PROVIDERS AND REMOTE COMPUTING SERVICES FOR CERTAIN CONTROLLED SUBSTANCES VIOLATIONS “Sec. 521. (a) Definitions.—In this section— “(1) the term ‘electronic communication service’ has the meaning given that term in section 2510 of title 18, United States Code; “(2) the term ‘electronic mail address’ has the meaning given that term in section 3 of the CAN-SPAM Act of 2003 (15 U.S.C. 7702); “(3) the term ‘Internet’ has the meaning given that term in section 1101 of the Internet Tax Freedom Act (47 U.S.C. 151 note); “(4) the term ‘provider’ means an electronic communication service provider or remote computing service; “(5) the term ‘remote computing service’ has the meaning given that term in section 2711 of title 18, United States Code; and “(6) the term ‘website’ means any collection of material placed in a computer server-based file archive so that it is publicly accessible, over the Internet, using hypertext transfer protocol or any successor protocol.“(b) Duty To Report.— “(1) GENERAL DUTY.—In order to reduce the proliferation of",https://www.congress.gov/bill/118th-congress/senate-bill/1080/text,en,"Strategies: Disclosure, Strategies: Disclosure: About incidents"
579,Oversee Emerging Technology Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9825,low,0.0,246,0.7,Defunct,"S. 1577 To require the appointment or designation of emerging technology leads in certain Federal agencies. IN THE SENATE OF THE UNITED STATES May 11, 2023 Mr. Bennet introduced the following bill; which was read twice and referred to the Committee on Homeland Security and Governmental Affairs A BILL To require the appointment or designation of emerging technology leads in certain Federal agencies. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Oversee Emerging Technology Act”. SEC. 2. EMERGING TECHNOLOGY LEADS. (a) Definitions.—In this section: (1) COVERED AGENCY.—The term “covered agency” means— (A) an agency listed in section 901(b) of title 31, United States Code; or (B) an element of the intelligence community, as defined in section 3 of the National Security Act of 1947 (50 U.S.C. 3003). (2) COVERED INDIVIDUAL.—The term “covered individual” means— (A) an individual serving in a Senior Executive Service position, as that term is defined in section 3132 of title 5, United States Code; (B) an individual who— (i) is serving in a position to which section 5376 of title 5, United States Code, applies; and (ii) has a significant amount of seniority and experience, as determined by the head of the applicable covered agency; and (C) another individual who is the equivalent of an individual described in subparagraph (A) or (B), as determined by the head of the ap",https://www.congress.gov/bill/118th-congress/senate-bill/1577/text,en,
580,Diversify Tech Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9287,low,0.0,243,0.5,Defunct,"H. R. 7314 To create a task force within the Department of Commerce to oversee and promote diversity, equity, inclusion, and accessibility in the tech industry. IN THE HOUSE OF REPRESENTATIVES February 9, 2024 Mr. Meeks (for himself and Ms. Lee of California) introduced the following bill; which was referred to the Committee on Energy and Commerce, and in addition to the Committee on Education and the Workforce, for a period to be subsequently determined by the Speaker, in each case for consideration of such provisions as fall within the jurisdiction of the committee concerned A BILL To create a task force within the Department of Commerce to oversee and promote diversity, equity, inclusion, and accessibility in the tech industry. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Diversify Tech Act”. SEC. 2. ESTABLISHMENT AND POWERS OF THE TASK FORCE. (a) Establishment.—Not later than 60 days after the date of enactment of this Act, the Secretary of Commerce shall establish, within the Office of Policy and Strategic Planning, the Tech Industry Diversity, Equity, Inclusion, and Accessibility Task Force (in this Act referred to as the “Task Force”). (b) Composition.— (1) MEMBERS.—The Task Force shall consist of the following members: (A) The Chief Diversity and Equity Officer of the Department of Labor. (B) The Chair of the Communications Equity and Diversity Coun",https://www.congress.gov/bill/118th-congress/house-bill/7314/text,en,
581,Countering Adversarial and Malicious Partnerships at Universities and Schools Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9236,low,0.0,224,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Countering Adversarial and Malicious Partnerships at Universities and Schools Act of 2023” or the “CAMPUS Act”.SEC. 2. IDENTIFICATION OF ENTITIES ENGAGED IN MILITARY-CIVIL FUSION IN THE PEOPLE'S REPUBLIC OF CHINA. (a) In General.—The Director of National Intelligence, in consultation with the Secretary of Defense, shall identify each institution of higher education domiciled in the People’s Republic of China that provides support to the People’s Liberation Army, including any such institution involved in the implementation of the Military-Civil Fusion strategy of the People’s Republic of China or that participates in the defense industrial base of the People’s Republic of China.(b) Submission Of List To Congress.—Not later than 180 days after the date of the enactment of this Act, and annually thereafter, the Director of National Intelligence shall submit to the appropriate committees of Congress a list of each entity identified under subsection (a).SEC. 3. PROHIBITION ON USE OF FUNDS FOR ENTITIES ENGAGED IN MILITARY-CIVIL FUSION. None of the funds authorized to be appropriated or otherwise made available for the Department of Defense for research, development, testing, and evaluation may be provided to an entity that maintains a contract with an institution identified under section 2.SEC. 4. LIMITATION ON ELIGIBILITY OF FACILITIES TO HOST OR STORE CLASSIFIED INFORMATION. The Director of the Defense Counterintelligence and",https://www.congress.gov/bill/118th-congress/senate-bill/2726/text,en,
582,Water Infrastructure Modernization Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9741,low,0.0,232,0.5,Defunct,"H. R. 3490 To amend the Federal Water Pollution Control Act and the Safe Drinking Water Act to authorize grants for smart water infrastructure technology, and for other purposes. IN THE HOUSE OF REPRESENTATIVES May 18, 2023 Mr. Gallego (for himself and Mr. Duarte) introduced the following bill; which was referred to the Committee on Transportation and Infrastructure, and in addition to the Committee on Energy and Commerce, for a period to be subsequently determined by the Speaker, in each case for consideration of such provisions as fall within the jurisdiction of the committee concerned A BILL To amend the Federal Water Pollution Control Act and the Safe Drinking Water Act to authorize grants for smart water infrastructure technology, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE; TABLE OF CONTENTS. (a) Short Title.—This Act may be cited as the “Water Infrastructure Modernization Act of 2023”. (b) Table Of Contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. Sec. 2. Purposes. TITLE I—WASTEWATER INFRASTRUCTURE Sec. 101. Smart wastewater infrastructure technology for treatment works. TITLE II—DRINKING WATER INFRASTRUCTURE Sec. 201. Smart water infrastructure technology for drinking water.SEC. 2. PURPOSES. The purposes of this Act are— (1) to upgrade and modernize the drinking water, wastewater, and stormwater systems of",https://www.congress.gov/bill/118th-congress/house-bill/3490/text,en,
583,HEARTS Act of 2022,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.848,low,0.0,244,0.5,Defunct,"H. R. 1024 To amend the Public Health Service Act to ensure that nonanimal methods are prioritized, where applicable and feasible, in proposals for all research to be conducted or supported by the National Institutes of Health, to provide for the establishment of the National Center for Alternatives to Animals in Research and Testing, and for other purposes. IN THE HOUSE OF REPRESENTATIVES February 14, 2023 Mr. Pappas (for himself and Mr. Calvert) introduced the following bill; which was referred to the Committee on Energy and Commerce A BILL To amend the Public Health Service Act to ensure that nonanimal methods are prioritized, where applicable and feasible, in proposals for all research to be conducted or supported by the National Institutes of Health, to provide for the establishment of the National Center for Alternatives to Animals in Research and Testing, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Humane and Existing Alternatives in Research and Testing Sciences Act of 2022” or the “HEARTS Act of 2022”. SEC. 2. FINDINGS. Congress finds the following: (1) The National Institutes of Health (NIH) has supported life-saving research that has greatly improved the health and well-being not only of Americans but also of people around the world. (2) Much of this research has relied on animals. It is estimated that between 17,000,000",https://www.congress.gov/bill/118th-congress/house-bill/1024/text,en,
590,Advisory for AI-Generated Content Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7672,low,0.1111,225,1.0,Defunct,"S. 2765 To require a watermark for AI-generated materials, and for other purposes. IN THE SENATE OF THE UNITED STATES September 12, 2023 Mr. Ricketts introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To require a watermark for AI-generated materials, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE. This Act may be cited as the “Advisory for AI-Generated Content Act”.SEC. 2. WATERMARKS ON AI-GENERATED MATERIALS. (a) In General.— (1) WATERMARK REQUIREMENT.—It shall be unlawful for an AI-generating entity to create covered AI-generated material unless such material includes a watermark that meets the standards established by the Commission under paragraph (2). (2) STANDARDS FOR AI WATERMARKS.—Not later than 180 days after the date of enactment of this section, the Commission, in consultation with the Federal Communications Commission, the Attorney General, and the Secretary of Homeland Security, shall issue regulations to establish standards for the watermarks required under paragraph (1). (3) EFFECTIVE DATE.—The requirement established under paragraph (1) shall take effect on the date that is 1 year after the date on which the Commission promulgates the regulations required under paragraph (2).(b) Enforcement.— (1) UNFAIR OR DECEPTIVE ACTS OR PRACTICES.—A violation of this section or a regul",https://www.congress.gov/bill/118th-congress/senate-bill/2765/text,en,"Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Governance development, Strategies: Convening, Risk factors: Transparency, Incentives: Civil liability, Incentives: Fines, Harms: Detrimental content"
591,Counseling for Career Choice Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9723,low,0.0,229,0.5,Defunct,"H. R. 7395 To amend the Elementary and Secondary Education Act of 1965 to expand career counseling opportunities within student support and academic enrichment grants. IN THE HOUSE OF REPRESENTATIVES February 15, 2024 Mr. Thompson of Pennsylvania (for himself and Ms. Bonamici) introduced the following bill; which was referred to the Committee on Education and the Workforce A BILL To amend the Elementary and Secondary Education Act of 1965 to expand career counseling opportunities within student support and academic enrichment grants. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Counseling for Career Choice Act”. SEC. 2. AMENDMENT. Section 4107(a)(3)(A) of the Elementary and Secondary Education Act of 1965 (20 U.S.C. 7117(a)(3)(A)) is amended to read as follows: “(A) career guidance and school counseling programs, such as— “(i) guidance for school career counseling programs, and school counselors and students who may be interested in such programs; “(ii) identifying and assessing school counseling activities and postsecondary options available within the State, and outside the State as applicable; “(iii) identifying regional workforce trends in collaboration with entities at the State and regional level with expertise in identifying such trends (such as State boards and local boards (as such terms are defined in section 3 of the Workforce Innovation and Oppo",https://www.congress.gov/bill/118th-congress/house-bill/7395/text,en,
592,Ensuring Safe and Ethical AI Development Through SAFE AI Research Grants,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9967,low,0.1667,245,0.7,Defunct,"H. R. 6088 To require the National Academy of Sciences to establish a grant program to develop safe AI models and safe AI research, and for other purposes. IN THE HOUSE OF REPRESENTATIVES October 26, 2023 Mr. Kiley (for himself and Ms. Garcia of Texas) introduced the following bill; which was referred to the Committee on Science, Space, and Technology A BILL To require the National Academy of Sciences to establish a grant program to develop safe AI models and safe AI research, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Ensuring Safe and Ethical AI Development Through SAFE AI Research Grants”. SEC. 2. GRANT PROGRAM TO DEVELOP SAFE AI MODELS AND SAFE AI RESEARCH. (a) Findings.—Congress finds the following: (1) The development and use of artificial intelligence (AI) have accelerated rapidly through all sectors of society opening the doors to untold benefit and innovation. (2) With this great potential also comes unknown risks. Research into the safety and risk reduction of AI development is urgently needed. (b) Statement Of Policy.—It is the policy of Congress to encourage research on AI safety and risk mitigation processes in order that AI is developed in a manner that ensures security, reliability, and consonance with human values. (c) Establishment Of Grant Program To Encourage Safe AI Models.— (1) IN GENERAL.—Subject to paragraph",https://www.congress.gov/bill/118th-congress/house-bill/6088/text,en,"Risk factors: Safety, Risk factors: Reliability, Harms: Violation of civil or human rights, including privacy, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Evaluation"
593,United States-Israel Health Technologies Cooperation Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.4019,low,0.0,242,0.7,Defunct,"H. R. 4076 To authorize funding for a bilateral cooperative program with Israel for the development of health technologies. IN THE HOUSE OF REPRESENTATIVES June 13, 2023 Mr. Pappas (for himself, Mr. Panetta, Ms. Salazar, Mr. Crenshaw, Mr. Graves of Louisiana, Ms. Mace, Mr. Van Drew, Mr. Waltz, Mr. Nunn of Iowa, Mr. Fitzpatrick, Mr. Gimenez, Mr. Ezell, Mr. Dunn of Florida, Mr. Moolenaar, Mr. Lawler, Mr. Lamborn, Mr. Mooney, Mr. Molinaro, Mr. Kim of New Jersey, Mr. Davis of North Carolina, Mr. Ciscomani, Mr. Arrington, Mrs. McClain, Mr. Bacon, Mr. Gottheimer, Mr. Moskowitz, Mr. Auchincloss, Mr. Lieu, Mr. Schiff, Ms. Tokuda, Mr. Kilmer, Ms. Stevens, Ms. Brownley, Mr. Sherman, Mr. Sorensen, Ms. Titus, Mr. Boyle of Pennsylvania, Mr. Levin, Mrs. Trahan, Ms. Meng, Mr. Mullin, Mr. Cohen, Ms. Craig, Mr. Fleischmann, Mr. Kean of New Jersey, Mr. Steube, Mr. Tony Gonzales of Texas, Mr. Bilirakis, Mr. Grothman, Mr. Bost, Mr. Miller of Ohio, Mr. Rutherford, Ms. Brown, Mr. Turner, Mr. Johnson of South Dakota, Mr. Wilson of South Carolina, and Mr. Kustoff) introduced the following bill; which was referred to the Committee on Energy and Commerce A BILL To authorize funding for a bilateral cooperative program with Israel for the development of health technologies. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE. This Act may be cited as the “United States-Israel Health Technologies Cooperation Act”.SEC. 2. BI",https://www.congress.gov/bill/118th-congress/house-bill/4076/text,en,"Strategies: Government support, Applications: Medicine, life sciences and public health, Strategies: Government support: For R&D, Strategies: New institution"
596,"Wildfire Technology Demonstration, Evaluation, Modernization, and Optimization Act",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8176,low,0.0,229,0.5,Defunct,"H. R. 4235 To direct the Secretary of Agriculture and the Secretary of the Interior to establish a wildfire technology testbed pilot program, and for other purposes. IN THE HOUSE OF REPRESENTATIVES June 21, 2023 Mrs. Kim of California (for herself and Mr. Crow) introduced the following bill; which was referred to the Committee on Natural Resources, and in addition to the Committee on Agriculture, for a period to be subsequently determined by the Speaker, in each case for consideration of such provisions as fall within the jurisdiction of the committee concerned A BILL To direct the Secretary of Agriculture and the Secretary of the Interior to establish a wildfire technology testbed pilot program, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Wildfire Technology Demonstration, Evaluation, Modernization, and Optimization Act” or the “Wildfire Technology DEMO Act”. SEC. 2. PUBLIC-PRIVATE WILDFIRE TECHNOLOGY TESTBED PARTNERSHIP. (a) Definitions.—In this Act, the term: (1) COVERED AGENCY.—The term “covered agency” means— (A) each Federal land management agency (as such term is defined in the Federal Lands Recreation Enhancement Act (16 U.S.C. 6801)); (B) the National Oceanic and Atmospheric Administration; (C) the United States Fire Administration; (D) the Federal Emergency Management Agency; (E) the National Aeronautics and Space Administ",https://www.congress.gov/bill/118th-congress/house-bill/4235/text,en,
597,CONSULT Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9813,low,0.1111,224,0.7,Defunct,"S. 2034 To require the Secretary of Defense to develop procurement policy and guidance to mitigate consulting company conflict of interests related to national security and foreign policy. IN THE SENATE OF THE UNITED STATES June 15, 2023 Ms. Ernst (for herself, Mr. Kelly, and Ms. Hassan) introduced the following bill; which was read twice and referred to the Committee on Homeland Security and Governmental Affairs A BILL To require the Secretary of Defense to develop procurement policy and guidance to mitigate consulting company conflict of interests related to national security and foreign policy. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,SECTION 1. SHORT TITLE. This Act may be cited as the “Combating Obstructive National Security Underreporting of Legitimate Threats Act of 2023” or the “CONSULT Act of 2023”.SEC. 2. ORGANIZATIONAL CONFLICT OF INTERESTS RELATING TO NATIONAL SECURITY AND FOREIGN POLICY. (a) Findings.—Congress makes the following findings: (1) The reliance by the Department of Defense on consultants for mission support services can create potential organizational conflicts of interest related to national security matters due to competing interests as a result of business relationships with foreign adversarial nations and entities. (2) It is imperative for consultants providing mission support services to the Department of Defense related to national security matters and foreign policy interests",https://www.congress.gov/bill/118th-congress/senate-bill/2034/text,en,"Risk factors: Security, Risk factors: Security: Dissemination, Strategies: Governance development, Incentives: Access to business opportunities, Applications: Government: military and public safety, Strategies: Disclosure"
601,Outbound Investment Transparency Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9191,low,0.0,233,0.5,Defunct,"S. 2678 To provide for an investment screening mechanism relating to covered sectors. IN THE SENATE OF THE UNITED STATES July 27, 2023 Mr. Cornyn (for himself and Mr. Casey) introduced the following bill; which was read twice and referred to the Committee on Banking, Housing, and Urban Affairs A BILL To provide for an investment screening mechanism relating to covered sectors. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Outbound Investment Transparency Act of 2023”. SEC. 2. PROTECTION OF COVERED SECTORS. The Defense Production Act of 1950 (50 U.S.C. 4501 et seq.) is amended by adding at the end the following: “TITLE VIII—PROTECTION OF COVERED SECTORS “SEC. 801. DEFINITIONS. “In this title: “(1) APPROPRIATE CONGRESSIONAL COMMITTEES.—The term ‘appropriate congressional committees’ means— “(A) the Committee on Armed Services, the Committee on Finance, the Committee on Banking, Housing, and Urban Affairs, the Select Committee on Intelligence, and the Committee on Foreign Relations of the Senate; and “(B) the Committee on Armed Services, the Committee on Ways and Means, the Committee on Financial Services, the Permanent Select Committee on Intelligence, and the Committee on Foreign Affairs of the House of Representatives. “(2) COUNTRY OF CONCERN.—The term ‘country of concern’ means, subject to such regulations as may be prescribed in accordance with section 806",https://www.congress.gov/bill/118th-congress/senate-bill/2678/text,en,
604,"Protecting the Information of our Vulnerable Adolescents, Children, and Youth Act",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7783,medium,0.5,237,0.7,Defunct,"SECTION 1. SHORT TITLE; TABLE OF CONTENTS. (a) Short Title.—This Act may be cited as the “Protecting the Information of our Vulnerable Adolescents, Children, and Youth Act” or the “Kids PRIVACY Act”. (b) Table Of Contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. Sec. 2. Definitions. Sec. 3. Requirements for processing of covered information of children or teenagers. Sec. 4. Repeal of safe harbors provision. Sec. 5. Administration and applicability of Act. Sec. 6. Review. Sec. 7. Private right of action. Sec. 8. Relationship to other law. Sec. 9. Additional conforming amendment. Sec. 10. Youth Privacy and Marketing Division. Sec. 11. Commission defined. Sec. 12. Effective date.SEC. 2. DEFINITIONS. Section 1302 of the Children’s Online Privacy Protection Act of 1998 (15 U.S.C. 6501) is amended— (1) by striking paragraphs (5) and (10); (2) by redesignating paragraphs (2), (3), (4), (6), (7), (8), and (9) as paragraphs (3), (5), (6), (7), (8), (9), and (10), respectively; (3) by inserting after paragraph (1) the following: “(2) TEENAGER.—The term ‘teenager’ means an individual over the age of 12 and under the age of 18.”; (4) by striking paragraph (3) (as so redesignated) and inserting the following: “(3) COVERED ENTITY.—The term ‘covered entity’ means— “(A) any person over which the Commission has authority under section 5(a)(2) of the Federal Trade Commission Act (15 U.S.C. 45(a)(2)); “(B) any organization not organized to carry",https://www.congress.gov/bill/118th-congress/house-bill/2801/text,en,"Risk factors: Privacy, Harms: Financial loss, Harms: Harm to health/safety, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Risk factors: Security, Strategies: Evaluation, Strategies: Disclosure, Strategies: Convening, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure: About evaluation, Strategies: Disclosure: About inputs, Strategies: Evaluation: Adversarial testing"
607,Forest Data Modernization Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8668,low,0.0,239,0.5,Defunct,"S. 1743 To amend the Forest and Rangeland Renewable Resources Research Act of 1978 to modify the forest inventory and analysis program. IN THE SENATE OF THE UNITED STATES May 18, 2023 Mr. Ossoff (for himself and Mr. Cassidy) introduced the following bill; which was read twice and referred to the Committee on Agriculture, Nutrition, and Forestry A BILL To amend the Forest and Rangeland Renewable Resources Research Act of 1978 to modify the forest inventory and analysis program. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Forest Data Modernization Act of 2023”. SEC. 2. FOREST INVENTORY AND ANALYSIS. (a) In General.—Section 3(e) of the Forest and Rangeland Renewable Resources Research Act of 1978 (16 U.S.C. 1642(e)) is amended— (1) in paragraph (1)— (A) by striking “their resources” and inserting “the resources of those forests, including forest carbon,”; (B) by striking “In compliance” and inserting the following: “(A) IN GENERAL.—In compliance”; and (C) by adding at the end the following: “(B) ADDITIONAL METHODS.—Under the program under this subsection, the Secretary shall carry out, as a data collection method— “(i) a timber products output study; and “(ii) a national woodland owner survey.”; (2) in paragraph (3)(C), by inserting “including with respect to available forest carbon data,” after “2 decades,”; (3) in paragraph (4)— (A) in the second sentence,",https://www.congress.gov/bill/118th-congress/senate-bill/1743/text,en,
611,Deploying American Blockchains Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8481,low,0.0,209,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Deploying American Blockchains Act of 2023”.SEC. 2. DEFINITIONS. In this Act: (1) BLOCKCHAIN TECHNOLOGY OR OTHER DISTRIBUTED LEDGER TECHNOLOGY.—The term “blockchain technology or other distributed ledger technology” means a distributed digital database where data is— (A) shared across a network of computers to create a ledger of verified information among network participants; (B) linked using cryptography to maintain the integrity of the ledger and to execute other functions; and (C) distributed among network participants in an automated fashion to concurrently update network participants on the state of the ledger and other functions. (2) COVERED NONGOVERNMENTAL REPRESENTATIVES.—The term “covered nongovernmental representatives” means representatives as specified in the second sentence of section 135(b)(1) of the Trade Act of 1974 (19 U.S.C. 2155(b)(1)), except that such term does not include representatives of non-Federal governments. (3) SECRETARY.—The term “Secretary” means the Secretary of Commerce. (4) STATE.—The term “State” means each of the several States, the District of Columbia, each commonwealth, territory, or possession of the United States, and each federally recognized Indian Tribe. (5) TOKEN.—The term “token” means a transferable, digital representation of information recorded on blockchain technology or other distributed ledger technology. (6) TOKENIZATION.—The term “tokenization” means the process of cr",https://www.congress.gov/bill/118th-congress/house-bill/6572/text,en,
614,SAFE from PRC Investments Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.948,low,0.0,237,0.5,Defunct,"H. R. 499 To amend the Securities Exchange Act of 1934 to require certain additional annual disclosures by public companies and exchange-traded funds investing in companies with ties to the People’s Republic of China, and for other purposes. IN THE HOUSE OF REPRESENTATIVES January 25, 2023 Mr. Fallon (for himself, Mr. Ellzey, Mr. Jackson of Texas, and Mr. Amodei) introduced the following bill; which was referred to the Committee on Financial Services A BILL To amend the Securities Exchange Act of 1934 to require certain additional annual disclosures by public companies and exchange-traded funds investing in companies with ties to the People’s Republic of China, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Securing American Families and Enterprises from People’s Republic of China Investments Act” or the “SAFE from PRC Investments Act”. SEC. 2. ADDITIONAL DISCLOSURES TO PROTECT AMERICAN INVESTORS AND BUSINESSES. Section 13 of the Securities Exchange Act of 1934 (15 U.S.C. 78m) is amended by adding at the end the following: “(s) Additional Disclosures To Protect American Investors And Businesses.— “(1) IN GENERAL.—Each covered issuer that is required to file an annual report under section 13(a) or 15(d) shall disclose in that report the following: “(A) Whether a senior official of the national- or provincial-level governments of the Peo",https://www.congress.gov/bill/118th-congress/house-bill/499/text,en,
615,Preventing Adversaries from Developing Critical Capabilities Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8189,low,0.0,228,0.5,Defunct,"H. R. 6349 To prohibit or require notification with respect to certain activities of United States persons involving countries of concern, and for other purposes. IN THE HOUSE OF REPRESENTATIVES November 9, 2023 Mr. McCaul (for himself and Mr. Meeks) introduced the following bill; which was referred to the Committee on Foreign Affairs A BILL To prohibit or require notification with respect to certain activities of United States persons involving countries of concern, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Preventing Adversaries from Developing Critical Capabilities Act”. SEC. 2. EXERCISE OF AUTHORITIES UNDER THE INTERNATIONAL EMERGENCY ECONOMIC POWERS ACT. (a) In General.—The President may exercise all authorities provided under the International Emergency Economic Powers Act (50 U.S.C. 1701 et seq.) necessary to carry out the provisions of this Act, including authorities to impose penalties under section 206 of such Act. (b) Delegation.—The President may delegate the authorities described in subsection (a) to the head of any Federal agency the President determines appropriate in order to carry out the provisions of this Act. SEC. 3. PROHIBITION ON COVERED ACTIVITIES IN COVERED SECTORS THAT POSE PARTICULARLY ACUTE THREATS TO UNITED STATES NATIONAL SECURITY. (a) Identification Of Categories Of Technologies And Products.— (1) IN",https://www.congress.gov/bill/118th-congress/house-bill/6349/text,en,
617,Strengthening Consumer Protections and Medical Debt Transparency Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.824,low,0.0,232,0.5,Defunct,"S. 2483 To amend the Public Health Service Act to provide additional transparency and consumer protections relating to medical debt collection practices. IN THE SENATE OF THE UNITED STATES July 25, 2023 Mr. Murphy (for himself and Mr. Braun) introduced the following bill; which was read twice and referred to the Committee on Health, Education, Labor, and Pensions A BILL To amend the Public Health Service Act to provide additional transparency and consumer protections relating to medical debt collection practices. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Strengthening Consumer Protections and Medical Debt Transparency Act”. SEC. 2. MEDICAL DEBT COLLECTIONS. (a) In General.—Part C of title XXVII of the Public Health Service Act (42 U.S.C. 300gg–91 et seq.) is amended by adding at the end the following: “SEC. 2796. MEDICAL DEBT COLLECTIONS. “(a) Definitions.— “(1) IN GENERAL.—In this section: “(A) DATABASE.—The term ‘database’ means the medical debt collection database established under subsection (e). “(B) DEBT COLLECTOR.—The term ‘debt collector’ has the meaning as defined under the Fair Debt Collection Practices Act. “(C) EXTRAORDINARY COLLECTION ACTION.—The term ‘extraordinary collection action’ is as defined for purposes of section 501(r) of the Internal Revenue Code of 1986 (as in effect on the date of enactment of this section). “(D) HEALTH CARE ENT",https://www.congress.gov/bill/118th-congress/senate-bill/2483/text,en,
637,Facial Recognition Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8934,low,0.2778,258,0.7,Defunct,"H. R. 6092 To regulate law enforcement use of facial recognition technology, and for other purposes. IN THE HOUSE OF REPRESENTATIVES October 26, 2023 Mr. Lieu (for himself, Ms. Jackson Lee, Ms. Clarke of New York, Mr. Gomez, Mr. Ivey, and Mr. Veasey) introduced the following bill; which was referred to the Committee on the Judiciary, and in addition to the Committee on Science, Space, and Technology, for a period to be subsequently determined by the Speaker, in each case for consideration of such provisions as fall within the jurisdiction of the committee concerned A BILL To regulate law enforcement use of facial recognition technology, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Facial Recognition Act of 2023”. SEC. 2. INELIGIBILITY FOR CERTAIN FUNDS. In the case of a State or unit of local government that received a grant award under subpart 1 of part E of title I of the Omnibus Crime Control and Safe Streets Act of 1968 (42 U.S.C. 3750 et seq.), if the State or unit of local government fails to substantially to comply with the requirements under this Act for a fiscal year, the Attorney General shall reduce the amount that would otherwise be awarded to that State or unit of local government under such grant program in the following fiscal year by 15 percent. SEC. 3. DEFINITIONS. In this Act: (1) ARREST PHOTO DATABASE.—The term “ar",https://www.congress.gov/bill/118th-congress/house-bill/6092/text,en,"Incentives: Civil liability, Applications: Government: judicial and law enforcement, Applications: Government: other applications/unspecified, Strategies: Governance development, Strategies: Performance requirements, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: In standard form, Risk factors: Transparency, Strategies: Tiering, Strategies: Tiering: Tiering based on domain of application, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Tiering: Tiering based on inputs, Strategies: Government study or report"
641,LISTOS Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9578,low,0.0,241,0.5,Defunct,"H. R. 3806 To ensure that large online platforms are addressing the needs of non-English users. IN THE HOUSE OF REPRESENTATIVES June 5, 2023 Mr. Cárdenas (for himself, Mr. Soto, Ms. Barragán, Mr. Costa, Mr. Espaillat, Mr. Vargas, Mr. García of Illinois, and Mr. Castro of Texas) introduced the following bill; which was referred to the Committee on Energy and Commerce, and in addition to the Committee on Foreign Affairs, for a period to be subsequently determined by the Speaker, in each case for consideration of such provisions as fall within the jurisdiction of the committee concerned A BILL To ensure that large online platforms are addressing the needs of non-English users. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE; TABLE OF CONTENTS. (a) Short Title.—This Act may be cited as the “Language-Inclusive Support and Transparency for Online Services Act of 2023” or the “LISTOS Act”. (b) Table Of Contents.—The table of contents of this Act is as follows: Sec. 1. Short title; table of contents. Sec. 2. Sense of Congress. Sec. 3. Duty to ensure consistent enforcement. Sec. 4. Disclosures on staffing and automated processes. Sec. 5. Consistent access to tools and documentation. Sec. 6. Advisory Group. Sec. 7. Enforcement. Sec. 8. Regulations. Sec. 9. Effective dates. Sec. 10. International online communication research activities pilot program. Sec. 11. Definitions. SEC. 2. SENSE OF CONGRESS. I",https://www.congress.gov/bill/118th-congress/house-bill/3806/text,en,
652,Stop Fentanyl at the Border Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9842,low,0.0,218,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Stop Fentanyl at the Border Act”.SEC. 2. FUNDING. (a) Enhancing Law Enforcement Capabilities At The Border.—There is appropriated, out of any money in the Treasury not otherwise appropriated, for the Department of Homeland Security for the fiscal year ending September 30, 2025, $3,409,000,000, to remain available until September 30, 2027, to support and enhance law enforcement capabilities at land borders of the United States, of which— (1) $300,000,000 shall be for additional civilian U.S. Border Patrol processing coordinators; (2) $1,750,000,000 shall be for additional U.S. Customs and Border Protection officers, U.S. Border Patrol agents, and mission support staff within the Office of Field Operations and U.S. Border Patrol; (3) $950,000,000 shall be for hiring bonuses, retention bonuses, and retention-focused support services, including mental health services, for U.S. Customs and Border Protection officers, U.S. Border Patrol agents, U.S. Border Patrol processing coordinators, and any other U.S. Customs and Border Protection staff whose work supports operations at the land borders of the United States; and (4) $409,000,000 shall be for “U.S. Citizenship and Immigration Services–Operations and Support” to contribute to improved operations along the land borders of the United States.(b) Increasing Fentanyl Interdiction And Enhancing Processing Capabilities At The Border.—There is appropriated, out of any money in the Tr",https://www.congress.gov/bill/118th-congress/senate-bill/3591/text,en,"Applications: Government: judicial and law enforcement, Strategies: Government support, Strategies: Government support: For R&D, Incentives: Fines, Incentives: Imprisonment"
655,National Mesonet Authorization Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9422,low,0.0,212,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “National Mesonet Authorization Act”.SEC. 2. NATIONAL MESONET PROGRAM. (a) In General.—Title I of the Weather Research and Forecasting Innovation Act of 2017 (15 U.S.C. 8501 et seq.) is amended by adding at the end the following new section:“SEC. 111. NATIONAL MESONET PROGRAM. “(a) Findings.—Congress finds the following: “(1) Since the initial establishment of the National Mesonet Program, a public-private partnership program, the Program has leveraged data collected by existing weather observation networks to— “(A) provide accurate, real-time observations to support weather forecasters, emergency response, and all-weather sensitive activities across the United States; “(B) address persistent impediments, identified in a 2009 National Academy of Sciences Report, From the Ground Up, to fulfill the need for broader and denser environmental observation networks to improve severe weather lead-times; “(C) help achieve major improvements for the National Oceanic and Atmospheric Administration and the broader American Weather Enterprise, as identified in the 2011 National Academy of Sciences Report, The National Weather Service Modernization and Associated Restructuring; “(D) increase the amount of non-Federal weather data available to the Federal Government by orders of magnitude; and “(E) improve understanding of the impact, size, and duration of mesoscale weather events. “(2) The National Mesonet Program is a critical component",https://www.congress.gov/bill/118th-congress/house-bill/2995/text,en,
657,Food and Agriculture Industry Cybersecurity Support Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9118,low,0.0,215,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Food and Agriculture Industry Cybersecurity Support Act”.SEC. 2. NTIA FOOD AND AGRICULTURE CYBERSECURITY CLEARINGHOUSE. (a) Definitions.—In this section: (1) ASSISTANT SECRETARY.—The term “Assistant Secretary” means the Assistant Secretary of Commerce for Communications and Information. (2) CYBERSECURITY RISK.—The term “cybersecurity risk” has the meaning given the term in section 2200 of the Homeland Security Act of 2002 (6 U.S.C. 650). (3) CYBERSECURITY THREAT.—The term “cybersecurity threat” has the meaning given the term in section 2200 of the Homeland Security Act of 2002 (6 U.S.C. 650). (4) FOOD AND AGRICULTURE INDUSTRY.—The term “food and agriculture industry” means— (A) equipment and systems utilized in the food and agriculture supply chain, such as computer vision algorithms for precision agriculture, grain silos, and related food and agriculture storage infrastructure; (B) food and agriculture goods processors, growers, and distributors; and (C) information technology systems of businesses engaged in farming, ranching, planting, harvesting, food and agriculture product storage, food or animal genetic modification, the design or production of agrochemicals, or the design or production of food and agriculture tools. (5) INCIDENT.—The term “incident” has the meaning given the term in section 2200 of the Homeland Security Act of 2002 (6 U.S.C. 650). (6) NTIA.—The term “NTIA” means the National Telecommunications and",https://www.congress.gov/bill/118th-congress/senate-bill/2393/text,en,
659,Know Your App Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.4069,low,0.0,217,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Know Your App Act”.SEC. 2. FINDINGS; SENSE OF CONGRESS. (a) Findings.—Congress finds the following: (1) Minors engaging with internet-linked applications face heightened susceptibility to privacy risks and potential exploitation through those applications. It is crucial for parents and guardians to possess comprehensive knowledge about the applications being accessed so that they can make informed decisions to protect their children. (2) Many users are unaware of the country of origin of the applications they download and use, as well as the data handling practices of the developers behind those applications. This lack of transparency can lead to potential risks for users, including exposure to foreign government surveillance, data breaches, and privacy violations. Users have a right to know baseline information on the country of origin so that they can personally make decisions to mitigate the threat to their personal and biometric information. (3) The potential for foreign governments to access user data through internet-linked applications presents national security risks. These risks may include the collection of sensitive information, espionage, and potential influence over critical infrastructure. (4) Increasing transparency and providing users with the necessary information to make informed decisions about the applications they download can help protect consumer privacy and security. (b) Sense Of Congress.—It is the",https://www.congress.gov/bill/118th-congress/senate-bill/1732/all-actions,en,
660,Advancing Automation Research and Development in Agriculture Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9209,low,0.0,200,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Advancing Automation Research and Development in Agriculture Act”.SEC. 2. MECHANIZATION AND AUTOMATION FOR SPECIALTY CROPS. The Agricultural Research, Extension, and Education Reform Act of 1998 (7 U.S.C. 7601 et seq.) is amended by inserting at the end the following: “SEC. 412A. MECHANIZATION AND AUTOMATION FOR SPECIALTY CROPS. “(a) Establishment.—The Secretary shall establish within the Department a stand-alone competitive research and extension grant program to increase the competitiveness of specialty crops in the United States through the advancement and acceleration of the mechanization and automation, including— “(1) Projects that create or improve cost-effective technologies to reduce a specialty crop grower’s manual labor requirements and increase the efficiency of crop production, resource management, harvesting, processing, post-harvest technologies, and packaging through mechanization, automation, and other innovations and technologies. “(2) Projects that increase adoption of mechanization and automation technologies by: “(A) Emphasizing adoption drivers that could include but are not limited to connectivity, autonomy, reliability, durability, in-field validation, and cost-effectiveness. “(B) Investing and developing human capital to increase the specialty crop sector’s capacity to work with new technologies, and to manage a more tech-focused farm workforce. “(3) Projects that accelerate automation and mechaniz",https://www.congress.gov/bill/118th-congress/house-bill/4173/text,en,"Incentives: Subsidies, Strategies: Government support, Strategies: Government support: For R&D, Applications: Agriculture and resource extraction, Strategies: Government support: AI workforce-related, Strategies: Convening, Strategies: Government study or report"
666,Combating Cartels on Social Media Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.4919,low,0.0,208,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Combating Cartels on Social Media Act of 2023”.SEC. 2. DEFINITIONS. In this Act: (1) APPROPRIATE CONGRESSIONAL COMMITTEES.—The term “appropriate congressional committees” means— (A) the Committee on Homeland Security and Governmental Affairs of the Senate; and (B) the Committee on Homeland Security of the House of Representatives. (2) COVERED OPERATOR.—The term “covered operator” means the operator, developer, or publisher of a covered service. (3) COVERED SERVICE.—The term “covered service” means— (A) a social media platform; (B) a mobile or desktop service with direct or group messaging capabilities, but not including text messaging services without other substantial social functionalities or electronic mail services, that the Secretary determines is, has been, or will be used by transnational criminal organizations in connection with matters described in section 3; and (C) a digital platform, or an electronic application utilizing the digital platform, involving real-time interactive communication between multiple individuals, including multi-player gaming services and immersive technology platforms or applications, that the Secretary determines is, has been, or will be used by transnational criminal organizations in connection with matters described in section 3. (4) DEPARTMENT.—The term “Department” means the Department of Homeland Security. (5) SECRETARY.—The term “Secretary” means the Secretary of Homeland Security.",https://www.congress.gov/bill/118th-congress/house-bill/2393/text,en,
672,Advanced Aviation Integration Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9625,low,0.0,208,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Advanced Aviation Integration Act”.SEC. 2. ADVANCED AVIATION LEADERSHIP. (a) Establishment.—Not later than 90 days after the date of enactment of this Act, the Secretary shall designate the Deputy Administrator of the Federal Aviation Administration as the executive responsible for leadership, coordination, and integration of advanced aviation in the national airspace system.(b) Responsibilities.—The responsibilities of the Deputy Administrator (including any designee of the Deputy Administrator) shall include the following: (1) Coordinate across relevant offices of the Administration to facilitate the necessary planning for policy, rulemaking, and approval processes on matters relating to the safe operation and integration of advanced aviation systems in the national airspace system. (2) Coordinate across relevant offices of the Administration on the development, assessment, and refinement of advanced aviation systems concepts to ensure feasibility and viability within the national airspace system, including coordination of research and conducting studies and demonstrations to prove concepts. (3) Coordinate workforce planning across relevant offices of the Administration to— (A) hire and recruit personnel to— (i) research, develop, test, and evaluate advanced aviation systems; and (ii) process hiring applications related to advanced aviation systems in a timely manner; and (B) develop and submit a biannual report to the S",https://www.congress.gov/bill/118th-congress/senate-bill/1888/text,en,
678,Solving the Border Crisis Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.9192,low,0.0,234,0.5,Defunct,"SECTION 1. SHORT TITLE; TABLE OF CONTENTS. (a) Short Title.—This Act may be cited as the “Solving the Border Crisis Act”. (b) Table Of Contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. Sec. 2. Findings. Sec. 3. Sense of Congress. Sec. 4. Definitions. Sec. 5. Termination of suspension of entries and imports from designated places related to the COVID–19 pandemic. Sec. 6. Resumption of border wall system construction. Sec. 7. Congressional resolution of disapproval regarding termination of the exclusive authority of immigration judges over asylum claims. Sec. 8. Treatment of aliens arriving from contiguous territory. Sec. 9. Minimum staffing levels. Sec. 10. Mandatory detention funding. Sec. 11. Report requirement.SEC. 2. FINDINGS. Congress finds the following: (1) The current situation at the southern border presents a border security and humanitarian crisis that threatens core national security interests and constitutes a national emergency. (2) The southern border is a major entry point for criminals, gang members, and illicit narcotics. (3) Recent years have seen sharp increases in the number of family units entering and seeking entry to the United States. (4) If not detained, such aliens are often released into the country and are often difficult to remove from the United States because they fail to appear for hearings, do not comply with orders of removal, or are otherwise difficult to locate.SEC. 3. SENSE OF CONGRESS. It",https://www.congress.gov/bill/118th-congress/senate-bill/716/text,en,
682,Air Tour and Sport Parachuting Safety Improvement Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9777,low,0.0,229,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Air Tour and Sport Parachuting Safety Improvement Act of 2023”.SEC. 2. DEFINITIONS. In this Act: (1) ADMINISTRATOR.—The term “Administrator” means the Administrator of the Federal Aviation Administration. (2) AIR CARRIER.—The term “air carrier” has the meaning given that term in section 40102 of title 49, United States Code. (3) COMMERCIAL AIR TOUR.—The term “commercial air tour” means a flight conducted for compensation or hire in an airplane or helicopter where a purpose of the flight is sightseeing. (4) COMMERCIAL AIR TOUR OPERATOR.—The term “commercial air tour operator” means any person who conducts a commercial air tour. (5) PARACHUTE OPERATION.—The term “parachute operation” has the meaning given that term in section 105.3 of title 14, Code of Federal Regulations (or any successor regulation).SEC. 3. SAFETY MANAGEMENT SYSTEM REQUIREMENTS FOR CERTAIN OPERATORS. Not later than 24 months after the date of enactment of this Act, the Administrator shall issue a final rule requiring each person holding a certificate under part 119 of title 14, Code of Federal Regulations, and authorized to conduct operations in accordance with the provisions of part 135 of title 14, Code of Federal Regulations, to implement a safety management system, as appropriate for the operations.SEC. 4. OTHER SAFETY REQUIREMENTS FOR COMMERCIAL OPERATORS. (a) Safety Reforms.— (1) AUTHORITY TO CONDUCT NONSTOP COMMERCIAL AIR TOURS.— (A) IN GENERAL.—Sub",https://www.congress.gov/bill/118th-congress/senate-bill/1032/text,en,
704,Advanced Aviation Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9743,low,0.0,212,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Advanced Aviation Act”.SEC. 2. OFFICE OF ADVANCED AVIATION; ASSOCIATE ADMINISTRATOR FOR ADVANCED AVIATION. (a) Establishment.—Not later than 1 year after the date of enactment of this Act, the Secretary shall redesignate the Office of NextGen as the Office of Advanced Aviation.(b) Appointment.—Not later than 1 year after the date of enactment of this Act, the Secretary shall appoint an Associate Administrator for Advanced Aviation to head the Office of Advanced Aviation designated under subsection (a).(c) Responsibilities.—The responsibilities of the Associate Administrator for Advanced Aviation shall include the following: (1) Coordinate rulemaking and approval processes on matters relating to the standardization and certification of advanced aviation systems for use in the national airspace system. (2) Coordinate rulemaking and approval processes on matters relating to the safe operation and integration of advanced aviation systems in the national airspace system. (3) Coordinate activities and establish policies related to the integration of aeronautical radio frequency spectrum designated by the National Telecommunications and Information Administration of the Department of Commerce for use in the national airspace system. (4) Coordinate workforce planning across relevant offices of the Administration to— (A) hire and recruit personnel to— (i) research, develop, test, and evaluate advanced aviation systems; and (ii) pro",https://www.congress.gov/bill/118th-congress/house-bill/220/text,en,
721,No ICBMs or Drones for Iran Act of 2023,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.802,low,0.0,219,1.0,Defunct,"SECTION 1. SHORT TITLE; TABLE OF CONTENTS. (a) Short Title.—This Act may be cited as the “No ICBMs or Drones for Iran Act of 2023”. (b) Table Of Contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. TITLE I—SANCTIONS AND REPORT ON IRANIAN SPACE-LAUNCH VEHICLES AND INTERCONTINENTAL BALLISTIC MISSILES Sec. 101. Findings; sense of Congress. Sec. 102. Determination and mandatory imposition of sanctions under Executive Order 13382. Sec. 103. Report on support for Iran's space, aerospace, and ballistic missile sectors and United States capacity to deny intercontinental ballistic missile attacks from Iran. Sec. 104. Report on senior officials of Government of Iran responsible for space-launch vehicle or ballistic missile tests. TITLE II—SANCTIONS AND REPORTS RELATING TO IRANIAN UNMANNED AERIAL SYSTEMS Sec. 201. Findings; sense of Congress. Sec. 202. Inclusion of unmanned aerial systems and cruise missiles under Comprehensive Iran Sanctions, Accountability, and Divestment Act of 2010. Sec. 203. Inclusion of unmanned aerial systems in enforcement of arms embargos under Countering America’s Adversaries Through Sanctions Act. Sec. 204. Inclusion of unmanned aerial systems under Iran-Iraq Arms Non-Proliferation Act of 1992. Sec. 205. Strategy to counter Iranian unmanned aerial systems. Sec. 206. Report on support for Iran’s unmanned aerial system program and related technology transfers. Sec. 207. Unmanned aerial system defined. TITLE III—EXP",https://www.congress.gov/bill/118th-congress/senate-bill/3334/text,en,"Applications: Government: military and public safety, Strategies: Governance development, Strategies: Government study or report, Strategies: Convening, Strategies: Evaluation"
757,"REGULATION (EU) 2024/1689 OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU) 2018/858, (EU) 2018/1139 and (EU) 2019/2144 and Directives 2014/90/EU, (",European Union,Multinational,Multinational,Editors' Picks,Regulation,2024-03-13,2024,3,positive,0.9891,high,0.8889,221,0.7,Enacted,"2024/1689 12.7.2024 REGULATION (EU) 2024/1689 OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU) 2018/858, (EU) 2018/1139 and (EU) 2019/2144 and Directives 2014/90/EU, (EU) 2016/797 and (EU) 2020/1828 (Artificial Intelligence Act) [Introductory recitals omitted.] CHAPTER I: GENERAL PROVISIONS Article 1: Subject matter 1. The purpose of this Regulation is to improve the functioning of the internal market and promote the uptake of human-centric and trustworthy artificial intelligence (AI), while ensuring a high level of protection of health, safety, fundamental rights enshrined in the Charter, including democracy, the rule of law and environmental protection, against the harmful effects of AI systems in the Union and supporting innovation. 2. This Regulation lays down: (a) harmonised rules for the placing on the market, the putting into service, and the use of AI systems in the Union; (b) prohibitions of certain AI practices; (c) specific requirements for high-risk AI systems and obligations for operators of such systems; (d) harmonised transparency rules for certain AI systems; (e) harmonised rules for the placing on the market of general-purpose AI models; (f) rules on market monitoring, market surveillance, governance and enforcement; (g) measures to support innovation, with a particular focus on SMEs, including start-ups. Art",https://eur-lex.europa.eu/eli/reg/2024/1689/oj,en,"Strategies: Disclosure, Strategies: Disclosure: About incidents, Strategies: Evaluation, Strategies: Governance development, Strategies: Government support, Incentives: Fines, Strategies: Government study or report, Applications: Government: judicial and law enforcement, Strategies: Input controls, Strategies: Input controls: Data use, Strategies: New institution, Strategies: Convening, Strategies: Disclosure: About inputs, Strategies: Disclosure: About evaluation, Strategies: Evaluation: Adversarial testing"
758,Voluntary Commitments from Leading Artificial Intelligence Companies,Private-sector companies,,,Corporate policies and commitments,Other,2023-07-21,2023,7,positive,0.9946,medium,0.5556,211,1.0,Enacted,"FACT SHEET: Biden-⁠Harris Administration Secures Voluntary Commitments from Leading Artificial Intelligence Companies to Manage the Risks Posed by AI Voluntary commitments – underscoring safety, security, and trust – mark a critical step toward developing responsible AI Biden-Harris Administration will continue to take decisive action by developing an Executive Order and pursuing bipartisan legislation to keep Americans safeSince taking office, President Biden, Vice President Harris, and the entire Biden-Harris Administration have moved with urgency to seize the tremendous promise and manage the risks posed by Artificial Intelligence (AI) and to protect Americans’ rights and safety. As part of this commitment, President Biden is convening seven leading AI companies at the White House today – Amazon, Anthropic, Google, Inflection, Meta, Microsoft, and OpenAI – to announce that the Biden-Harris Administration has secured voluntary commitments from these companies to help move toward safe, secure, and transparent development of AI technology. Companies that are developing these emerging technologies have a responsibility to ensure their products are safe. To make the most of AI’s potential, the Biden-Harris Administration is encouraging this industry to uphold the highest standards to ensure that innovation doesn’t come at the expense of Americans’ rights and safety. These commitments, which the companies have chosen to undertake immediately, underscore three principles that mus",https://www.whitehouse.gov/briefing-room/statements-releases/2023/07/21/fact-sheet-biden-harris-administration-secures-voluntary-commitments-from-leading-artificial-intelligence-companies-to-manage-the-risks-posed-by-ai/,en,"Risk factors: Safety, Risk factors: Transparency, Harms: Violation of civil or human rights, including privacy, Harms: Harm to health/safety, Risk factors: Security, Strategies: Evaluation: External auditing, Strategies: Evaluation: Conformity assessment, Strategies: Evaluation, Strategies: Disclosure, Strategies: Convening, Strategies: Disclosure: About incidents, Risk factors: Security: Cybersecurity, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure: In deployment, Risk factors: Bias"
759,AI Safety Summit - Enhancing Frontier AI Safety (Amazon),Private-sector companies,,,Corporate policies and commitments,Other,2023-10-01,2023,10,positive,0.9865,low,0.0,243,0.5,Enacted,"Amazon and AI Amazon’s perspectives on AI are informed by our dual role as a developer of AI technology and a deployer of AI tools and services. Artificial intelligence (AI) and Machine Learning (ML) have been a focus for Amazon for over 25 years, and many of the capabilities customers use with Amazon are driven by ML. Our e-commerce recommendations engine is driven by ML; the paths that optimize robotic picking routes in our fulfilment centers are driven by ML; and our supply chain, forecasting, and capacity planning are informed by ML. Prime Air (our drones) and the computer vision technology in Amazon Go (our retail experience that lets consumers select items off a shelf and leave the store without having to formally check out) use deep learning. Alexa, powered by more than 30 different machine learning systems, helps customers billions of times each week to manage smart homes, shop, get information and entertainment, and more. We have thousands of engineers at Amazon committed to ML, and it’s a big part of our heritage, current ethos, and future. Amazon Web Services (AWS) has played a key role in helping organisations across industry sectors leverage AI to improve their productivity, enhance their competitiveness, and better serve their customers. AWS offers the broadest and deepest portfolio of AI and ML services for cloud customers, empowering developers to build, train, and deploy their own ML models or easily incorporate pre-trained AI functionality. From the most per",https://aws.amazon.com/uki/cloud-services/uk-gov-ai-safety-summit/,en,
761,2023 UK AI Safety Summit Response (Google DeepMind),Private-sector companies,,,Corporate policies and commitments,Other,2023-10-27,2023,10,positive,0.9948,low,0.0,236,0.5,Proposed,"AI Safety Summit: An update on our approach to safety and responsibility In September, we were asked by the UK Secretary of State for the Department of Science, Innovation and Technology (DSIT) to share Google DeepMind’s approach to 7 areas of safety and responsibility for frontier AI. Our response is below. As the UK prepares to host the AI Safety Summit, we believe it’s important to have an inclusive conversation about AI safety practices, and how we can best build on them together. We hope this provides a useful snapshot of some of our priorities.Introduction At Google DeepMind, we aim to build AI responsibly to benefit humanity. At the heart of this mission is our commitment to act as responsible pioneers in the field of AI, in service of society’s needs and expectations. We believe applying AI across all sorts of domains – including scientific disciplines, economic sectors, and to improve and develop new products and services – will unlock new levels of human progress. However, we need to develop and deploy this technology thoughtfully and responsibly — our mission is only achievable with the responsible development and deployment of AI systems. We’ve already seen people use AI to address societal challenges, including by helping scientists better detect breast cancer, forecast floods, limit the warming effects of jet contrails, accelerate clean nuclear fusion, predict protein structures, and achieve healthcare breakthroughs. Vast potential remains to supercharge scienti",https://deepmind.google/public-policy/ai-summit-policies/,en,
762,Our Policy on Frontier Safety (Inflection),Private-sector companies,,,Corporate policies and commitments,Policy/Guidance,2023-10-30,2023,10,positive,0.979,low,0.0,233,0.5,Enacted,"Area 1: Responsible Capability Scaling Inflection believes that the promise of the latest generation of AI is tremendous. Given the global challenges facing society in this century, we believe that it is imperative to continue to make progress in this technology. This is a moment for seizing the massive opportunities on offer to boost global prosperity and wellbeing at a time when both are faltering. At the same time, Inflection recognizes that scaling these models must be done responsibly. It therefore believes in a disciplined, phased approach that steadily increases model scale while rigorously checking that it is safe at each step. This includes investments in (1) pre-deployment safety, (2) post-launch monitoring and mitigation, and (3) global governance efforts that attempt to standardize practices across the research community. This incorporates each of the AI Safety areas that will be discussed in further detail below: Pre-Deployment Safety: Frontier AI must pass a robust, continuously improved set of evaluations and third-party red-teaming in order to be cleared for any form of public launch (Area 2), and must conform to a set of rigorous internal restrictions on data use (Area 3). This work must be done under conditions of the highest security to avoid the risk of leaking “unauthorized” models or methodologies (Area 4). Post-Launch Monitoring and Mitigation: Safety is a continuous process that does not end with launch. We monitor and investigate concerning platform a",https://inflection.ai/frontier-safety,en,
763,2023 UK AI Safety Summit Response (Meta),Private-sector companies,,,Corporate policies and commitments,Other,2023-10-20,2023,10,positive,0.9942,medium,0.5,233,0.7,Proposed,"RESPONSIBLE CAPABILITY SCALING Meta has deep experience and commitment in building state of the art AI systems and products with responsibility and safety as a priority. Our Fundamental AI Research (FAIR) team has spent the past decade working to develop safer AI systems, and we continue to invest in our Responsible AI Team to support industry leading work around issues such as privacy, fairness, accountability, and transparency. We built upon this strong foundation when developing our approach for recent releases, including our ecosystem of Llama models and new generative AI experiences. We prioritised safety and responsibility throughout, and produced numerous artefacts (see Annex I) which we believe demonstrate how companies can build and release both innovative open source and consumer AI products with safety in mind. In relation to frontier AI systems, we have signed up to the White House Commitments. We believe the commitments are an important first step in ensuring responsible guardrails are established for AI as we look towards a future with increasingly capable systems. We joined these commitments because they represent an emerging industry-wide consensus around the things that we have been building into our products for years. Our five pillars of responsible AI have been core to our own development of AI for years, and the White House AI commitments’ themes of safety, security, and trust, reflect those same values. These commitments, built with input from leading AI",https://transparency.meta.com/en-gb/policies/ai-safety-policies-for-safety-summit/,en,"Risk factors: Privacy, Risk factors: Transparency, Risk factors: Safety, Risk factors: Security, Strategies: Disclosure, Strategies: Evaluation, Strategies: Evaluation: Adversarial testing, Strategies: Disclosure: About evaluation, Risk factors: Reliability, Risk factors: Reliability: Robustness, Strategies: Licensing, registration, and certification, Strategies: Governance development, Strategies: Convening, Risk factors: Security: Cybersecurity, Risk factors: Security: Dissemination"
764,2023 UK AI Safety Summit Response (Microsoft),Private-sector companies,,,Corporate policies and commitments,Other,2023-10-26,2023,10,positive,0.9919,low,0.0,213,0.5,Proposed,"Introduction Microsoft welcomes the opportunity to share information about how we are advancing responsible artificial intelligence (AI), including by implementing voluntary commitments that we and others made at the White House convening in July.[1] Visibility into our policies and how we put them into practice helps to inform and accelerate responsible technology development and deployment. It can also strengthen public-private partnerships driving progress on AI safety, security, and trust. As a developer and deployer of AI models, API services, and applications, Microsoft works to map, measure, and manage risk and apply multi-layered governance that embeds robust checks on processes and outcomes. For frontier models specifically, Microsoft works closely with OpenAI. Since 2019, Microsoft and OpenAI have been engaged in a long-term collaboration to develop advanced AI systems, underpinned by a shared commitment to responsible development and deployment practices. Microsoft’s efforts to deploy frontier models at scale build upon and complement OpenAI’s leading model development practices. For a comprehensive accounting of the model development and deployment practices that apply to OpenAI’s frontier models as deployed in Microsoft’s offerings, OpenAI’s and Microsoft’s responses to the UK Government’s AI Safety Policies Request should be read together. The UK Government has requested information about nine areas of practice and investment, many of which relate to the volunta",https://blogs.microsoft.com/on-the-issues/2023/10/26/microsofts-ai-safety-policies/,en,
765,OpenAI's Approach to Frontier Risk (An Update for the UK AI Safety Summit),Private-sector companies,,,Corporate policies and commitments,Other,2023-10-26,2023,10,negative,-0.3422,medium,0.6111,211,0.7,Enacted,"Preparedness Framework Frontier AI models have the potential to benefit all of humanity, but also pose increasingly severe risks. To manage these risks as AI models continue to improve, we are developing a Preparedness Framework, which deepens our proactive, risk-based approach to responsible frontier model development, especially in relation to catastrophic risks. The Preparedness Framework will detail our approach to developing rigorous frontier model capability evaluations and monitoring, as well as establishing a governance structure for accountability and oversight across the development process. The risks we plan to track as part of this policy span multiple categories including cybersecurity, persuasion, chemical and biological threats, and autonomy. The Preparedness Framework will also provide for a spectrum of actions to protect against catastrophic outcomes. The empirical understanding of catastrophic risk is nascent and developing rapidly. We will thus be dynamically updating our assessment of current frontier model risk levels to ensure we reflect our latest evaluation and monitoring understanding. We are standing up a dedicated team (Preparedness) that drives this effort, including performing necessary research and monitoring. The Preparedness Framework is meant to complement and extend our existing risk mitigation work, which contributes to the safety and alignment of new, highly capable systems, both before and after deployment. These existing efforts include t",https://openai.com/global-affairs/our-approach-to-frontier-risk/,en,"Risk factors: Security, Risk factors: Security: Cybersecurity, Risk factors: Safety, Harms: Harm to health/safety, Strategies: Evaluation, Strategies: Evaluation: Adversarial testing, Strategies: Evaluation: Impact assessment, Strategies: Convening, Strategies: Governance development, Strategies: New institution, Strategies: Evaluation: External auditing, Applications: Government: military and public safety, Risk factors: Transparency, Strategies: Disclosure, Strategies: Disclosure: In standard form"
766,OpenAI Preparedness Framework (Beta),Private-sector companies,,,Corporate policies and commitments,Other,2023-12-18,2023,12,positive,0.9041,medium,0.5556,221,0.7,Enacted,"OpenAI Preparedness Framework (Beta) We believe the scientific study of catastrophic risks from Al has fallen far short of where we need to be. To help address this gap, we are introducing our Preparedness Framework, a living document describing OpenAl's processes to track, evaluate, forecast, and protect against catastrophic risks posed by increasingly powerful models. December 18, 2023 Introduction Our practical experience with iterative deployment has enabled us to proactively improve our technical and procedural safety infrastructure. As our systems get closer to AGI, we are becoming even more careful about the development of our models, especially in the context of catastrophic risk. This Preparedness Framework is a living document that distills our latest learnings on how to best achieve safe development and deployment in practice. The processes laid out in each version of the Preparedness Framework will help us rapidly improve our understanding of the science and empirical texture of catastrophic risk, and establish the processes needed to protect against unsafe development. The central thesis behind our Preparedness Framework is that a robust approach to Al catastrophic risk safety requires proactive, science-based determinations of when and how it is safe to proceed with development and deployment. Our Preparedness Framework contains five key elements: 1. Tracking catastrophic risk level via evaluations. We will be building and continually improving suites of evaluat",https://cdn.openai.com/openai-preparedness-framework-beta.pdf,en,"Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Input controls, Risk factors: Security, Risk factors: Security: Dissemination, Strategies: Input controls: Data circulation, Strategies: Tiering, Strategies: Tiering: Tiering based on impact, Strategies: Tiering: Tiering based on domain of application, Strategies: Performance requirements, Risk factors: Bias, Harms: Violation of civil or human rights, including privacy"
767,OpenAI Charter,Private-sector companies,,,Corporate policies and commitments,Other,2018-04-09,2018,4,positive,0.9958,low,0.1667,235,0.7,Enacted,"OpenAI Charter Our Charter describes the principles we use to execute on OpenAI’s mission. This document reflects the strategy we’ve refined over the past two years, including feedback from many people internal and external to OpenAI. The timeline to AGI remains uncertain, but our Charter will guide us in acting in the best interests of humanity throughout its development. OpenAI’s mission is to ensure that artificial general intelligence (AGI)—by which we mean highly autonomous systems that outperform humans at most economically valuable work—benefits all of humanity. We will attempt to directly build safe and beneficial AGI, but will also consider our mission fulfilled if our work aids others to achieve this outcome. To that end, we commit to the following principles:Broadly distributed benefits We commit to use any influence we obtain over AGI’s deployment to ensure it is used for the benefit of all, and to avoid enabling uses of AI or AGI that harm humanity or unduly concentrate power. Our primary fiduciary duty is to humanity. We anticipate needing to marshal substantial resources to fulfill our mission, but will always diligently act to minimize conflicts of interest among our employees and stakeholders that could compromise broad benefit.Long-term safety We are committed to doing the research required to make AGI safe, and to driving the broad adoption of such research across the AI community. We are concerned about late-stage AGI development becoming a competitive rac",https://openai.com/charter,en,"Risk factors: Safety, Harms: Harm to health/safety, Risk factors: Security, Strategies: Disclosure, Strategies: Convening"
768,Anthropic Responsible Scaling Policy,Private-sector companies,,,Corporate policies and commitments,Policy/Guidance,2024-10-15,2024,10,positive,0.9738,medium,0.3889,217,0.7,Enacted,"[Introductory material omitted. Footnotes omitted throughout.] 1. Background AI Safety Level Standards (ASL Standards) are core to our risk mitigation strategy. An ASL Standard is a set of technical and operational measures for safely training and deploying frontier AI models. As model capabilities increase, so will the need for stronger safeguards, which are captured in successively higher ASL Standards. Deﬁnitions of ASL Standards and other key terms are available in Appendix A. The types of measures that compose an ASL Standard currently fall into two categories–Deployment Standards and Security Standards–which map onto the types of risks that frontier AI models may pose. - Deployment Standards: Deployment Standards are technical, operational, and policy measures to ensure the safe usage of AI models by external users (i.e., our users and customers) as well as internal users (i.e., our employees). Deployment Standards aim to strike a balance between enabling beneﬁcial use of AI technologies and mitigating the risks of potentially catastrophic cases of misuse. - Security Standards: Security Standards are technical, operational, and policy measures to protect AI models–particularly their weights and associated systems–from unauthorized access, theft, or compromise by malicious actors. Security Standards are intended to maintain the integrity and controlled use of AI models throughout their lifecycle, from development to deployment. We expect to continue reﬁning our framework",https://assets.anthropic.com/m/24a47b00f10301cd/original/Anthropic-Responsible-Scaling-Policy-2024-10-15.pdf,en,"Strategies: Tiering, Strategies: Tiering: Tiering based on impact, Strategies: Evaluation, Strategies: Evaluation: Adversarial testing, Risk factors: Reliability: Robustness, Strategies: Tiering: Tiering based on domain of application, Risk factors: Security, Risk factors: Reliability, Strategies: Evaluation: Post-market monitoring, Risk factors: Security: Dissemination, Risk factors: Security: Cybersecurity, Strategies: Evaluation: Conformity assessment, Strategies: Governance development, Strategies: Evaluation: Impact assessment, Strategies: Disclosure"
769,Google AI Principles,Private-sector companies,,,Corporate policies and commitments,Other,2018-01-01,2018,1,positive,0.9698,low,0.0,219,0.5,Enacted,"Responsibility: Our Principles While we are optimistic about the potential of AI, we recognize that advanced technologies can raise important challenges that must be addressed clearly, thoughtfully, and affirmatively. These AI Principles describe our commitment to developing technology responsibly and work to establish specific application areas we will not pursue. Objectives for AI applications 1. Be socially beneficial. The expanded reach of new technologies increasingly touches society as a whole. Advances in AI will have transformative impacts in a wide range of fields, including healthcare, security, energy, transportation, manufacturing, and entertainment. As we consider potential development and uses of AI technologies, we will take into account a broad range of social and economic factors, and will proceed where we believe that the overall likely benefits substantially exceed the foreseeable risks and downsides. AI also enhances our ability to understand the meaning of content at scale. We will strive to make high-quality and accurate information readily available using AI, while continuing to respect cultural, social, and legal norms in the countries where we operate. And we will continue to thoughtfully evaluate when to make our technologies available on a non-commercial basis. 2. Avoid creating or reinforcing unfair bias. AI algorithms and datasets can reflect, reinforce, or reduce unfair biases. We recognize that distinguishing fair from unfair biases is not alway",https://ai.google/responsibility/principles/,en,
771,"Microsoft Responsible AI Standard, v2",Private-sector companies,,,Corporate policies and commitments,Other,2024-06-01,2024,6,positive,0.9769,medium,0.6111,239,0.7,Enacted,"About this release When we embarked on our effort to operationalize Microsoft's six AI principles, we knew there was a policy gap. Laws and norms had not caught up with AI's unique risks or society's needs. Yet, our product development teams needed concrete and actionable guidance as to what our principles meant and how they could uphold them. We leveraged the expertise on our research, policy, and engineering teams to develop guidance on how to fill that gap. The Responsible AI Standard is the product of a multi-year effort to define product development requirements for responsible AI. We are making available this second version of the Responsible AI Standard to share what we have learned, invite feedback from others, and contribute to the discussion about building better norms and practices around AI. While our Standard is an important step in Microsoft's responsible AI journey, it is just one step. As we make progress with implementation, we expect to encounter challenges that require us to pause, reflect, and adjust. Our Standard will remain a living document, evolving to address new research, technologies, laws, and learnings from within and outside the company. There is a rich and active global dialog about how to create principled and actionable norms to ensure organizations develop and deploy AI responsibly. We have benefited from this discussion and will continue to contribute to it. We believe that industry, academia, civil society, and government need to collaborat",https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-Responsible-AI-Standard-v2-General-Requirements-3.pdf,en,"Strategies: Evaluation: Impact assessment, Strategies: Evaluation, Strategies: Disclosure, Strategies: Disclosure: In standard form, Strategies: Disclosure: About evaluation, Strategies: Tiering, Strategies: Tiering: Tiering based on impact, Risk factors: Reliability, Risk factors: Reliability: Robustness, Strategies: Performance requirements, Strategies: Governance development, Strategies: Disclosure: About inputs, Harms: Discrimination, Strategies: Evaluation: Conformity assessment, Risk factors: Transparency"
772,NIST AI Risk Management Framework 1.0,National Institute of Standards and Technology,United States,Federal government,Editors' Picks,Regulation,2023-01-26,2023,1,positive,0.9808,medium,0.6667,210,0.7,Enacted,"[Introductory material omitted. Figures omitted throughout.] Part 1: Foundational Information [Omitted.] 2. Audience [Omitted.] 3. AI Risks and Trustworthiness For AI systems to be trustworthy, they often need to be responsive to a multiplicity of criteria that are of value to interested parties. Approaches which enhance AI trustworthiness can reduce negative AI risks. This Framework articulates the following characteristics of trustworthy AI and offers guidance for addressing them. Characteristics of trustworthy AI systems include: valid and reliable, safe, secure and resilient, accountable and transparent, explainable and interpretable, privacy-enhanced, and fair with harmful bias managed. Creating trustworthy AI requires balancing each of these characteristics based on the AI system’s context of use. While all characteristics are socio-technical system attributes, accountability and transparency also relate to the processes and activities internal to an AI system and its external setting. Neglecting these characteristics can increase the probability and magnitude of negative consequences. Trustworthiness characteristics (shown in Figure 4) are inextricably tied to social and organizational behavior, the datasets used by AI systems, selection of AI models and algorithms and the decisions made by those who build them, and the interactions with the humans who provide insight from and oversight of such systems. Human judgment should be employed when deciding on the specific me",https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf,en,"Risk factors: Transparency, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Evaluation: Impact assessment, Strategies: Convening, Strategies: Performance requirements, Risk factors: Interpretability and explainability, Risk factors: Safety, Harms: Harm to health/safety, Harms: Ecological harm, Harms: Harm to property, Strategies: Governance development, Risk factors: Security, Risk factors: Security: Dissemination, Risk factors: Privacy"
785,"Frontier AI Safety Commitments, AI Seoul Summit 2024",Private-sector companies,,,Corporate policies and commitments,Other,2024-05-21,2024,5,positive,0.9769,low,0.3333,220,0.7,Proposed,"The UK and Republic of Korea governments announced that the following organisations have agreed to the Frontier AI Safety Commitments: Amazon Anthropic Cohere Google G42 IBM Inflection AI Meta Microsoft Mistral AI Naver OpenAI Samsung Electronics Technology Innovation Institute xAI Zhipu.ai The above organisations, in furtherance of safe and trustworthy AI, undertake to develop and deploy their frontier AI models and systems responsibly, in accordance with the following voluntary commitments, and to demonstrate how they have achieved this by publishing a safety framework focused on severe risks by the upcoming AI Summit in France. Given the evolving state of the science in this area, the undersigned organisations’ approaches (as detailed in paragraphs I-VIII) to meeting Outcomes 1, 2 and 3 may evolve in the future. In such instances, organisations will provide transparency on this, including their reasons, through public updates. The above organisations also affirm their commitment to implement current best practices related to frontier AI safety, including: internal and external red-teaming of frontier AI models and systems for severe and novel threats; to work toward information sharing; to invest in cybersecurity and insider threat safeguards to protect proprietary and unreleased model weights; to incentivize third-party discovery and reporting of issues and vulnerabilities; to develop and deploy mechanisms that enable users to understand if audio or visual content is AI-g",https://www.gov.uk/government/publications/frontier-ai-safety-commitments-ai-seoul-summit-2024/frontier-ai-safety-commitments-ai-seoul-summit-2024,en,"Risk factors: Safety, Risk factors: Security, Risk factors: Security: Cybersecurity, Risk factors: Transparency, Harms: Harm to health/safety, Strategies: Evaluation, Strategies: Evaluation: Adversarial testing, Strategies: Disclosure, Strategies: Disclosure: In deployment, Risk factors: Security: Dissemination, Strategies: Performance requirements, Strategies: Governance development"
787,"National Drone and Advanced Air Mobility Research and Development Act, Title II (""National Drone and Advanced Air Mobility Research Institutes"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9911,low,0.0,209,0.5,Defunct,"TITLE II—NATIONAL DRONE AND ADVANCED AIR MOBILITY RESEARCH INSTITUTES SEC. 201. NATIONAL DRONE AND ADVANCED AIR MOBILITY RESEARCH INSTITUTES. (a) In General.—The Administrator of the National Aeronautics and Space Administration shall establish a program to award financial assistance for the planning, establishment, and support of a network of Institutes (as described in subsection (b)(2)) in accordance with this section. (b) Financial Assistance To Establish And Support National Drone And Advanced Air Mobility Research Institutes.— (1) IN GENERAL.—The Director of the National Institute of Standards and Technology, the Director of the National Science Foundation, the Administrator of the National Aeronautics and Space Administration, and any other agency head may award financial assistance to an eligible entity, or consortia thereof, as determined by an agency head, to establish and support an Institute. (2) DRONE AND ADVANCED AIR MOBILITY INSTITUTES.—An Institute described in this subsection is an unmanned aircraft systems research institute that— (A) may focus on— (i) a particular economic or social sector, including education, manufacturing, transportation, agriculture, security, energy, environment, and public safety, and includes a component that addresses the ethical, societal, safety, and security implications relevant to the application of advanced air mobility and unmanned aircraft systems in that sector; or (ii) a cross-cutting challenge for research, development, t",https://www.congress.gov/bill/118th-congress/house-bill/3560/text,en,
788,"National Drone and Advanced Air Mobility Research and Development Act, Title IV (""National Science Foundation Activities"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9881,low,0.0,198,0.5,Defunct,"TITLE IV—NATIONAL SCIENCE FOUNDATION ACTIVITIES SEC. 401. NATIONAL SCIENCE FOUNDATION ACTIVITIES. (a) In General.—The Director of the National Science Foundation shall support research and STEM education and related activities in advanced air mobility and unmanned aircraft systems, components, and related technologies, including competitive awards or grants to institutions of higher education or eligible nonprofit organizations (or consortia thereof). (b) Use Of Funds.—In carrying out the activities under subsection (a), the Director of the National Science Foundation shall— (1) support fundamental research on the underlying technologies for advanced air mobility and unmanned aircraft systems, components, and related technologies, which may include— (A) improving the safety and reliability of operation systems; (B) developing and improving autonomous control systems, including real-time control and autonomous decisionmaking; (C) incorporating the use of artificial intelligence into systems; (D) improving or developing materials for advanced air mobility and unmanned aircraft systems; (E) understanding safety and sustainability of advanced air mobility and unmanned aircraft systems as a part of a transportation system, including the impacts of advanced air mobility and unmanned aircraft systems on ground transportation; (F) developing and improving communications systems, including multivehicle coordination and task and path planning; and (G) understanding the human-drone inte",https://www.congress.gov/bill/118th-congress/house-bill/3560/text,en,
789,"National Drone and Advanced Air Mobility Research and Development Act, Title VI (""Department of Energy Activities"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9903,low,0.0,209,0.5,Defunct,"TITLE VI—DEPARTMENT OF ENERGY ACTIVITIES SEC. 601. DEPARTMENT OF ENERGY RESEARCH PROGRAM. (a) In General.—The Secretary of Energy shall carry out a cross-cutting research, development, and demonstration program to advance unmanned aircraft system technologies, capabilities, and workforce needs and to improve the reliability of unmanned aircraft systems implementation methods relevant to the mission of the Department of Energy. In carrying out such program, the Secretary shall coordinate across all relevant offices and activities at the Department, including the Office of Science, the Office of Energy Efficiency and Renewable Energy, the Office of Nuclear Energy, the Office of Fossil Energy, the Office of Electricity, the Office of Cybersecurity, Energy Security, and Emergency Response, the Advanced Research Projects Agency–Energy, the Office of Environmental Management, the Office of Environment, Health, Safety and Security, the National Nuclear Security Administration, the Artificial Intelligence Technology Office, the UAS Research and Engineering Center, and any other relevant office or activity as determined appropriate by the Secretary. (b) Program Components.—In carrying out the program under subsection (a), the Secretary of Energy shall— (1) formulate goals for unmanned aircraft systems research activities to be supported by the Department of Energy, including in the research areas under subsection (c); (2) leverage the collective body of knowledge from existing unmanne",https://www.congress.gov/bill/118th-congress/house-bill/3560/text,en,
790,"National Drone and Advanced Air Mobility Research and Development Act, Title VII (""Department of Homeland Security Activities"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9907,low,0.0,196,0.5,Defunct,"TITLE VII—DEPARTMENT OF HOMELAND SECURITY ACTIVITIES SEC. 701. DEPARTMENT OF HOMELAND SECURITY ACTIVITIES. (a) In General.—The Secretary of Homeland Security, acting through the Under Secretary for Science and Technology of the Department of Homeland Security, shall— (1) support research, development, evaluation and testing for advanced air mobility, unmanned aircraft systems, counter-UAS systems, and detection systems capabilities, including for— (A) air domain awareness and advanced air mobility and unmanned aircraft systems traffic monitoring; (B) privacy, security, and cybersecurity of advanced air mobility systems, unmanned aircraft systems, and counter-UAS systems capabilities; (C) safety of advanced air mobility and unmanned aircraft systems; (D) safety of operations in the National Airspace System; and (E) testing and evaluation of unmanned aircraft systems and counter-UAS systems capabilities, performance systems engineering, and operational analysis; (2) coordinate with all relevant offices and programs of the Department of Homeland Security, including the Cybersecurity and Infrastructure Security Agency, U.S. Customs and Border Protection, the Federal Emergency Management Agency, the Federal Protective Service, the Transportation Security Administration, the United States Coast Guard, and the United States Secret Service; (3) produce curated, standardized, representative, secure, and privacy protected data sets for advanced air mobility systems, unmanned aircraft s",https://www.congress.gov/bill/118th-congress/house-bill/3560/text,en,
791,"Fair Trade with China Enforcement Act, Sec. 101 (""Establishment of list of certain products receiving support from government of People's Republic of China pursuant to Made in China 2025 policy"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9727,low,0.0,235,0.5,Defunct,"SEC. 101. ESTABLISHMENT OF LIST OF CERTAIN PRODUCTS RECEIVING SUPPORT FROM GOVERNMENT OF PEOPLE'S REPUBLIC OF CHINA PURSUANT TO MADE IN CHINA 2025 POLICY. (a) In General.—Chapter 8 of title I of the Trade Act of 1974 (19 U.S.C. 2241 et seq.) is amended by adding at the end the following: “SEC. 183. LIST OF CERTAIN PRODUCTS RECEIVING SUPPORT FROM GOVERNMENT OF PEOPLE'S REPUBLIC OF CHINA. “(a) In General.—Not later than 120 days after the date of the enactment of the Fair Trade with China Enforcement Act, and every year thereafter, the United States Trade Representative shall set forth a list of products manufactured or produced in, or exported from, the People's Republic of China that are determined by the Trade Representative to receive support from the Government of the People's Republic of China pursuant to the Made in China 2025 industrial policy of that Government. “(b) Criteria For List.— “(1) IN GENERAL.—The Trade Representative shall include in the list required by subsection (a) the following products: “(A) Any product specified in the following documents set forth by the Government of the People's Republic of China: “(i) Notice on Issuing Made in China 2025. “(ii) China Manufacturing 2025. “(iii) Notice on Issuing the 13th Five-year National Strategic Emerging Industries Development Plan. “(iv) Guiding Opinion on Promoting International Industrial Capacity and Equipment Manufacturing Cooperation. “(v) Any other document that expresses a national strategy or stated go",https://www.congress.gov/bill/118th-congress/senate-bill/153/text,en,
792,"Fair Trade with China Enforcement Act, Sec. 102 (""Prohibition on export to People's Republic of China of national security sensitive technology and intellectual property"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9956,low,0.0,216,0.5,Defunct,"SEC. 102. PROHIBITION ON EXPORT TO PEOPLE'S REPUBLIC OF CHINA OF NATIONAL SECURITY SENSITIVE TECHNOLOGY AND INTELLECTUAL PROPERTY. (a) In General.—The Secretary of Commerce shall prohibit the export to the People's Republic of China of any national security sensitive technology or intellectual property subject to the jurisdiction of the United States or exported by any person subject to the jurisdiction of the United States. (b) Definitions.—In this section: (1) INTELLECTUAL PROPERTY.—The term “intellectual property” includes patents, copyrights, trademarks, or trade secrets. (2) NATIONAL SECURITY SENSITIVE TECHNOLOGY OR INTELLECTUAL PROPERTY.—The term “national security sensitive technology or intellectual property” includes the following: (A) Technology or intellectual property that would make a significant contribution to the military potential of the People’s Republic of China that would prove detrimental to the national security of the United States. (B) Technology or intellectual property necessary to protect the economy of the United States from the excessive drain of scarce materials and to reduce the serious inflationary impact of demand from the People’s Republic of China. (C) Technology or intellectual property that is a component of the production of products included in the most recent list required under section 183 of the Trade Act of 1974, as added by section 101(a), determined in consultation with the United States Trade Representative. (3) TECHNOLOGY.—The te",https://www.congress.gov/bill/118th-congress/senate-bill/153/text,en,
793,"Kids Online Safety Act, Sec. 13 (""Filter Bubble Transparency Requirements"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.6652,low,0.1667,203,1.0,Defunct,"SEC. 13. FILTER BUBBLE TRANSPARENCY REQUIREMENTS. (a) Definitions.—In this section: (1) ALGORITHMIC RANKING SYSTEM.—The term “algorithmic ranking system” means a computational process, including one derived from algorithmic decision-making, machine learning, statistical analysis, or other data processing or artificial intelligence techniques, used to determine the selection, order, relative prioritization, or relative prominence of content from a set of information that is provided to a user on a covered internet platform, including the ranking of search results, the provision of content recommendations, the display of social media posts, or any other method of automated content selection. (2) APPROXIMATE GEOLOCATION INFORMATION.—The term “approximate geolocation information” means information that identifies the location of an individual, but with a precision of less than 5 miles. (3) COMMISSION.—The term “Commission” means the Federal Trade Commission. (4) CONNECTED DEVICE.—The term “connected device” means an electronic device that— (A) is capable of connecting to the internet, either directly or indirectly through a network, to communicate information at the direction of an individual; (B) has computer processing capabilities for collecting, sending, receiving, or analyzing data; and (C) is primarily designed for or marketed to consumers. (5) COVERED INTERNET PLATFORM.— (A) IN GENERAL.—The term “covered internet platform” means any public-facing website, internet applicat",https://www.congress.gov/bill/118th-congress/senate-bill/1409/text,en,"Strategies: Input controls, Strategies: Input controls: Data circulation, Strategies: Input controls: Data use, Risk factors: Privacy, Risk factors: Transparency, Harms: Discrimination, Strategies: Disclosure, Strategies: Disclosure: In standard form, Strategies: Disclosure: About inputs, Incentives: Civil liability"
795,"Simplify, Don't Amplify the IRS Act, Sec. 201 (""Tax Gap Projection"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.2023,low,0.0,221,0.5,Defunct,"SEC. 201. TAX GAP PROJECTION. (a) In General.—Not later than 180 days after the date of the enactment of this section, and no later than July 31 annually thereafter, the Commissioner of Internal Revenue shall submit to Congress a projection detailing the tax gap estimate for the most recent taxable year as is practicable using the most recently available data, and including identification and detailed descriptions of the data used for such projection and clear identification of the amount of the projected tax gap associated with nonfiling, underreporting, and underpayment (including identifying the amount subject to collection actions). (b) Use Of Artificial Intelligence.—To the extent practicable, for purposes of reducing the burden on taxpayers subject to National Research Program audits, the Commissioner shall use artificial intelligence, including neural machine learning, and other available data analysis tools, including commercial analytic data providers, to calculate a projection described in subsection (a). (c) National Research Program Audits.—In calculating a projection described in subsection (a), the Commissioner of Internal Revenue shall not undertake more National Research Program audits in any one fiscal year than are undertaken in fiscal year 2022. (d) Tax Gap.—For purposes of this section, the term “tax gap” means the difference between tax liabilities owed to the United States under the Internal Revenue Code of 1986 and those liabilities actually collected b",https://www.congress.gov/bill/118th-congress/house-bill/2556/text,en,
796,"FAA Research and Development Act of 2023, Sec. 210 (""Technology review of artificial intelligence and machine learning technologies"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9838,low,0.0,145,0.5,Defunct,"SEC. 210. TECHNOLOGY REVIEW OF ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING TECHNOLOGIES. (a) Review.—The Administrator shall conduct a review of current and planned artificial intelligence and machine learning technologies to improve airport efficiency and safety. (b) Summaries.—The review conducted under subsection (a) shall include examination of the application of artificial intelligence and machine learning technologies to the following: (1) Jet bridges. (2) Airport service vehicles on airport movement areas. (3) Aircraft taxi. (4) Any other areas the Administrator determines necessary to help improve airport efficiency and safety. (c) Report.—Not later than one year after the date of the enactment of this Act, the Administrator shall submit to the appropriate committees of Congress a report containing the results of the review conducted under subsection (a). The report shall also include an examination of China’s domestic application of artificial intelligence and machine learning technologies identified under subsection (b).",https://www.congress.gov/bill/118th-congress/house-bill/3559/text,en,
797,"FAA Research and Development Act of 2023, Sec. 215 (""Air Traffic Control Training"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.926,low,0.0,153,0.5,Defunct,"SEC. 215. AIR TRAFFIC CONTROL TRAINING. (a) Research.—Subject to the availability of appropriations for such purpose, the Administrator shall carry out a research program to evaluate opportunities to modernize, enhance, and streamline training time to become a Certified Professional Controller. (b) Requirements.—The research under subsection (a) shall— (1) assess the use of advanced technologies, such as artificial intelligence, machine learning, adaptive computer-based simulation, virtual reality, or augmented reality, to enhance controller knowledge retention, improve performance, and improve the effectiveness of training time; (2) develop a timeline to deploy proven advanced technologies and associated processes for accreditation in training programs and training facilities within the national airspace system; and (3) include collaboration with labor organizations and other stakeholders. (c) Report.—Not later than one year after the date of the enactment of this Act, the Administrator shall submit to the appropriate committees of Congress a report on the findings of the research under subsection (a).",https://www.congress.gov/bill/118th-congress/house-bill/3559/text,en,
798,"Weather Act Reauthorization Act of 2023, Sec. 108 (""Computing Resources Prioritization"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9153,low,0.0,206,0.5,Defunct,"SEC. 108. COMPUTING RESOURCES PRIORITIZATION. Section 108 of the Weather Research and Forecasting Innovation Act of 2017 (15 U.S.C. 8518) is amended by striking subsection (a)(3)(C) and all that follows through subsection (b)(7) and inserting the following new subsections: “(b) Computing Research Initiative.— “(1) IN GENERAL.—The Under Secretary, in collaboration with the Secretary of Energy, shall carry out an initiative, which may leverage Department of Energy high performance computers, cloud computing, or expertise, to run advanced coupled models in order to conduct proof of concept scenarios in comparison with current issued forecasts and models. The Under Secretary and Secretary of Energy shall carry out the initiative through a competitive, merit-reviewed process, and consider applications from Federal agencies, National Laboratories, institutions of higher education (as such term is defined in section 101 of the Higher Education Act of 1965 (20 U.S.C. 1001)), nonprofit institutions, and other appropriate entities (or a consortia thereof). “(2) COMPONENTS.—In carrying out the initiative under paragraph (1), the Under Secretary shall prevent duplication and coordinate research efforts in artificial intelligence, high performance computing, cloud computing, quantum computing, modeling and simulation, machine learning, data assimilation, large scale data analytics, and predictive analysis across the National Oceanic and Atmospheric Administration, and may— “(A) conduct re",https://www.congress.gov/bill/118th-congress/house-bill/6093/text,en,
799,"Weather Act Reauthorization Act of 2023, Sec. 116(f) (""National Harmful Algal Bloom and Hypoxia Observing Network"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7003,low,0.0,183,0.5,Defunct,"(f) National Harmful Algal Bloom And Hypoxia Observing Network.— (1) IN GENERAL.—Section 606 of the Harmful Algal Bloom and Hypoxia Research and Control Act of 1998 (33 U.S.C. 4005) is amended to read as follows: “SEC. 606. NATIONAL HARMFUL ALGAL BLOOM OBSERVING NETWORK. “(a) In General.—The Under Secretary, acting through the National Centers for Coastal Ocean Science (referred to in this section as ‘NCCOS’) and the Integrated Ocean Observing System (referred to in this section as ‘IOOS’) of the National Oceanic and Atmospheric Administration, shall integrate Federal, State, regional, and local observing capabilities to establish a national network of harmful algal bloom observing systems for the monitoring, detection, and forecasting of harmful algal blooms by leveraging the capacity of IOOS regional associations, including through the incorporation of emerging technologies and new data integration methods, such as artificial intelligence. “(b) Coordination.— In carrying out subsection (a), the IOOS Program Office shall— “(1) coordinate with NCCOS regarding observations, data integration, and information dissemination; and “(2) establish a Harmful Algal Bloom Data Assembly Center to integrate, disseminate, and provide a central architecture to support ecological forecasting.”.",https://www.congress.gov/bill/118th-congress/house-bill/6093/text,en,
800,"Weather Act Reauthorization Act of 2023, Sec. 304 (""Data Assimilation, Management, and Sharing Practices"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9871,low,0.0,206,0.5,Defunct,"SEC. 304. DATA ASSIMILATION, MANAGEMENT, AND SHARING PRACTICES. Title III of the Weather Research and Forecasting Innovation Act of 2017, as amended by section 303 of this Act, is further amended by adding at the end the following new section: “SEC. 305. DATA ASSIMILATION, MANAGEMENT, AND SHARING PRACTICES. “(a) Data Standards.—The Under Secretary, in collaboration with the weather enterprise, shall seek to establish consistent and open data and metadata standards to support open science, including simple cloud-optimized data formats and application programming interfaces that support findability, accessibility, usability, and preservability. “(b) Data Infrastructure.— “(1) IN GENERAL.—The Under Secretary, in consultation with the Chief Information Officer and appropriate program heads, shall consolidate and arrange data infrastructure needs to ensure efficient and effective data transfer between National Oceanic and Atmospheric Administration offices by considering the use of commercial cloud technologies, or similar hybrid structures, to host and transmit data and metadata. “(2) FEDERAL PARTNERSHIPS.—In carrying out paragraph (1), the Under Secretary may partner with the heads of other Federal departments and agencies, including the National Aeronautics and Space Administration, the Department of Energy, the United States Space Force, the United States Coast Guard, the United States Navy, the Federal Aviation Administration, the United States Forest Service, the Environment",https://www.congress.gov/bill/118th-congress/house-bill/6093/text,en,
801,"Weather Act Reauthorization Act of 2023, Sec. 402 (""Hazardous Weather or Water Event Risk Communication"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.6874,low,0.0,226,0.5,Defunct,"SEC. 402. HAZARDOUS WEATHER OR WATER EVENT RISK COMMUNICATION. (a) In General.—Section 406 of the Weather Research and Forecasting Innovation Act of 2017 (Public Law 115–25; 131 Stat. 109) is amended to read as follows: “SEC. 406. HAZARDOUS WEATHER OR WATER EVENT RISK COMMUNICATION. “(a) Definitions.—In this section: “(1) HAZARDOUS WEATHER OR WATER EVENTS.—The term ‘hazardous weather or water events’ means weather or water events that have a high risk of loss of life or property, including the following: “(A) Severe storms, such as hurricanes and short-fused, small-scale hazardous weather or hydrologic events produced by thunderstorms, including large hail, damaging winds, tornadoes, and flash floods. “(B) Winter storms, such as freezing or frozen precipitation (including freezing rain, sleet, and snow), or combined effects of freezing or frozen precipitation and strong winds. “(C) Other weather hazards, such as extreme heat or cold, wildfire, drought, dense fog, high winds, and river, coastal, or lakeshore flooding. “(2) INSTITUTION OF HIGHER EDUCATION.—The term ‘institution of higher education’ has the meaning given such term in section 101 of the Higher Education Act of 1965 (20 U.S.C. 1001). “(3) WATCH; WARNING.— “(A) IN GENERAL.—The terms ‘watch’ and ‘warning’, with respect to a hazardous weather or water event, mean products issued by the National Oceanic and Atmospheric Administration, intended for consumption by the general public, to alert the general public to the p",https://www.congress.gov/bill/118th-congress/house-bill/6093/text,en,
802,"Weather Act Reauthorization Act of 2023, Sec. 502 (""National Integrated Drought Information System"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7269,low,0.0,214,0.5,Defunct,"SEC. 502. NATIONAL INTEGRATED DROUGHT INFORMATION SYSTEM. (a) In General.—Section 3 of the National Integrated Drought Information System Act of 2006 (15 U.S.C. 313d) is amended— (1) in subsection (b)— (A) in paragraph (1)— (i) in subparagraph (A), by striking “and” after the semicolon; (ii) in subparagraph (B), by inserting “and” after the semicolon; and (iii) by adding at the end the following new subparagraph: “(C) incorporates flash drought research and tools to enhance timely response;”; (B) in paragraph (5), by striking “and” after the semicolon; (C) in paragraph (6)— (i) by inserting “(including ecological drought)” after “drought” each place it appears; and (ii) by striking the period and inserting a semicolon; and (D) by adding at the end the following new paragraphs: “(7) advance and deploy next generation technologies related to drought and related publicly available data, such as monitoring, preparedness, and forecasting capabilities utilizing artificial intelligence, machine learning, and cloud technologies; and “(8) utilize observational networks, including the National Weather Service cooperative observer program and State or regional hydrological monitoring projects, and refine drought indicators across a variety of spatial and temporal scales for decision-support products by optimizing data and resources from across the Federal Government, including snowpack, soil moisture, groundwater, and rapid intensification data.”; (2) in subsection (c)— (A) in paragraph",https://www.congress.gov/bill/118th-congress/house-bill/6093/text,en,
804,Research and Development Program on New Approaches to Data Analysis for Aviation Safety,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9325,low,0.0,215,0.5,Defunct,"SEC. 7. RESEARCH AND DEVELOPMENT PROGRAM ON NEW APPROACHES TO DATA ANALYSIS FOR AVIATION SAFETY.(a) In General.—The Secretary shall establish a new research and development program to be undertaken by the FAA’s Consortium in Aviation Operations Research (NEXTOR III) to investigate and develop new approaches to data analysis for understanding the factors in aviation safety incidents and identifying emerging risks of future safety incidents.(b) Approaches.—The approaches described in subsection (a) include the use of new algorithms for analyzing the text and audio of communications between flight crews and air traffic controllers and the use of machine learning or artificial intelligence methods for analyzing a variety of data sets, including, data on weather, performance of communication, navigation and surveillance equipment and facilities, flight delays, safety incidents, flight crew work schedules, and air traffic and crew member communications for detecting anomalies in the National Airspace System.(c) Collaboration.—In carrying out the research program established in this section, member institutions of the Consortium shall collaborate in the sharing of data for the purpose of testing and demonstrating the potential effectiveness of new approaches to analysis— (1) with each other; (2) with aviation industry partners; (3) with units within the FAA including groups within the Air Traffic Organization, NextGen Office, Office of Airports, and Aviation Safety; and (4) with the",https://www.congress.gov/bill/118th-congress/house-bill/6850/text,en,
805,"TORPEDO Act of 2023, Sec. 6 (Reporting requirements on efforts of the Department of State to implement the AUKUS partnership)",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8807,low,0.0,232,0.5,Defunct,"SEC. 6. REPORTING REQUIREMENTS. (a) Report On Department Of State Implementation Of Partnership.— (1) IN GENERAL.—Not later than 90 days after the date of the enactment of this Act, the Secretary of State, in coordination with the Secretary of Defense and, as appropriate, the Secretary of Commerce and the Secretary of Energy, shall submit to the appropriate congressional committees a report on efforts of the Department of State to implement the AUKUS partnership.(2) ELEMENTS.—The report required under paragraph (1) shall include the following elements: (A) Regarding the achievement of Phase One goals for of the Optimal Pathway for AUKUS Pillar One for each of calendar years 2023, 2024, 2025, 2026, and 2027, the following: (i) A description of progress by the Government of Australia in negotiating an Article 14 Arrangement with the International Atomic Energy Agency. (ii) A description of the status of efforts by the Government of Australia to build the supporting infrastructure to base conventionally armed nuclear powered attack submarines. (iii) Updates on the efforts by the Government of Australia to train a workforce that can build, sustain, and operate conventionally armed nuclear powered attack submarines. (iv) A description of progress by the Government of Australia in building a new submarine facility to support the basing and disposition of a nuclear attack submarine on the east coast of Australia. (v) The number of Australian personnel embedded on United States Navy",https://www.congress.gov/bill/118th-congress/senate-bill/1471/text,en,
806,"TORPEDO Act of 2023, Sec. 12 (Expedited release of advanced technologies to Australia, Canada, and the United Kingdom through the foreign military sales program)",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9418,low,0.0,218,0.5,Defunct,"SEC. 12. EXPEDITED RELEASE OF ADVANCED TECHNOLOGIES TO AUSTRALIA, CANADA, AND THE UNITED KINGDOM THROUGH THE FOREIGN MILITARY SALES PROGRAM. (a) Preclearance Of Certain Military Sales Items.— (1) IN GENERAL.—Not later than 90 days after the date of the enactment of this Act, and annually thereafter, the Secretary of State, in coordination with the Secretary of Defense, and in conjunction with coordinating entities such as the National Disclosure Policy Committee, the Arms Transfer and Technology Release Senior Steering Group, and other appropriate entities, shall compile a list of available and emerging military platforms, technologies, and equipment that are pre-cleared and prioritized for sale and release to Australia, Canada, and the United Kingdom through the Foreign Military Sales program.(2) RULES OF CONSTRUCTION REGARDING SELECTION OF ITEMS.— (A) NO LIMITATION ON FOREIGN MILITARY SALES PROGRAM ACTIVITIES.—The list compiled pursuant to paragraph (1) shall not be construed as limiting the type, timing, or quantity of items that may be requested by, or sold to, Australia, the United Kingdom, and Canada under the Foreign Military Sales program. (B) CONGRESSIONAL NOTIFICATION REQUIREMENTS.—Nothing in this Act shall be construed to supersede congressional notification requirements under the Arms Export Control Act (22 U.S.C. 2751 et. seq.).(b) Expedited Processing Of Foreign Military Sales Requests.—The Secretary of State and the Secretary of Defense shall expedite the proce",https://www.congress.gov/bill/118th-congress/senate-bill/1471/text,en,
807,"Black Maternal Health Omnibus Act, Sec. 904 (Report on the Use of Technology in Maternity Care)",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9957,medium,0.3889,231,0.7,Defunct,"SEC. 904. REPORT ON THE USE OF TECHNOLOGY IN MATERNITY CARE. (a) In General.—Not later than 60 days after the date of enactment of this Act, the Secretary of Health and Human Services shall seek to enter an agreement with the National Academies of Sciences, Engineering, and Medicine (referred to in this Act as the “National Academies”) under which the National Academies shall conduct a study on the use of technology and patient monitoring devices in maternity care.(b) Content.—The agreement entered into pursuant to subsection (a) shall provide for the study of the following: (1) The use of innovative technology (including artificial intelligence) in maternal health care, including the extent to which such technology has affected racial or ethnic biases in maternal health care. (2) The use of patient monitoring devices (including pulse oximeter devices) in maternal health care, including the extent to which such devices have affected racial or ethnic biases in maternal health care. (3) Best practices for reducing and preventing racial or ethnic biases in the use of innovative technology and patient monitoring devices in maternity care. (4) Best practices in the use of innovative technology and patient monitoring devices for pregnant and postpartum individuals from racial and ethnic minority groups. (5) Best practices with respect to privacy and security safeguards in such use.(c) Report.—The agreement under subsection (a) shall direct the National Academies to complete the stu",https://www.congress.gov/bill/118th-congress/house-bill/3305/text#toc-HBCD74E16B158450D8E4CCE07B0985BC5,en,"Strategies: Government study or report, Strategies: Evaluation, Strategies: Evaluation: Post-market monitoring, Harms: Discrimination, Harms: Violation of civil or human rights, including privacy, Harms: Harm to health/safety, Risk factors: Bias, Risk factors: Privacy, Risk factors: Security, Risk factors: Safety, Applications: Medicine, life sciences and public health, Applications: Security"
808,"National Quantum Initiative Reauthorization Act, Sec. 16 (""Department of Energy Quantum Information Science Research Program"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8816,low,0.0,199,0.5,Defunct,"SEC. 16. DEPARTMENT OF ENERGY QUANTUM INFORMATION SCIENCE RESEARCH PROGRAM. Section 401 of the National Quantum Initiative Act (15 U.S.C. 8851) is amended— (1) by amending subsection (a) to read as follows: “(a) In General.—The Secretary of Energy shall carry out a research, development, and demonstration program on quantum information science, engineering, and technology.”; (2) in subsection (b)— (A) in paragraph (1), by inserting “, engineering, and technology” after “science”; (B) by redesignating paragraphs (3), (4), and (5) as paragraphs (5), (6), and (7), respectively; (C) by inserting after paragraph (2) the following new paragraphs: “(3) operate National Quantum Information Science Research Centers to accelerate and scale up scientific and technical breakthroughs in quantum information science, engineering, and technology, and maintain state-of-the-art infrastructure for quantum researchers and industry partners, in accordance with section 202; “(4) conduct cooperative research with industry, National Laboratories, institutions of higher education, and other research institutions to facilitate the development and demonstration of quantum information science, engineering, and technology, including in the fields of— “(A) quantum information theory; “(B) quantum physics; “(C) quantum computational science, including hardware and software, including artificial intelligence, machine learning and data science; “(D) applied mathematics and algorithm development; “(E) quantum",https://www.congress.gov/bill/118th-congress/house-bill/6213/text,en,
809,"Intelligence Authorization Act for Fiscal Year 2024, Sec. 906 (""Programs for Next-Generation Microelectronics in Support of Artificial Intelligence"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9908,low,0.0,183,0.5,Defunct,"SEC. 906. PROGRAMS FOR NEXT-GENERATION MICROELECTRONICS IN SUPPORT OF ARTIFICIAL INTELLIGENCE. (a) Program Establishment.—The Director of National Intelligence, acting through the Director of the Intelligence Advanced Research Projects Activity, shall establish or otherwise oversee a program to advance microelectronics research. (b) Research Focus.—The Director of National Intelligence shall ensure that the research carried out under the program established under subsection (a) is focused on the following: (1) Advanced engineering and applied research into next-generation computing models, materials, devices, architectures, and algorithms to enable the advancement of artificial intelligence and machine learning. (2) Efforts to— (A) overcome challenges with engineering and applied research of microelectronics, including with respect to the physical limits on transistors, electrical interconnects, and memory elements; (B) promote long-term advancements in computing technologies, including by fostering a unified and multidisciplinary approach encompassing research and development into— (i) next-generation algorithm design; (ii) next-generation compute capability; (iii) generative and adaptive artificial intelligence for design applications; (iv) photonics-based microprocessors, including electrophotonics; (v) the chemistry and physics of new materials; (vi) optical communication networks, including electrophotonics; and (vii) safety and controls for generative artificial intelli",https://www.congress.gov/bill/118th-congress/house-bill/3932/text#toc-H962C63EA88374DDD96F0E4B2F0A87C4F,en,
810,"Intelligence Authorization Act for Fiscal Year 2024, Sec. 909 (""Requirement to Ensure Intelligence Community Directives Appropriately Account for Artificial Intelligence and Machine Learning Tools in Intelligence Products"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9968,low,0.0,202,0.5,Defunct,"SEC. 909. REQUIREMENT TO ENSURE INTELLIGENCE COMMUNITY DIRECTIVES APPROPRIATELY ACCOUNT FOR ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING TOOLS IN INTELLIGENCE PRODUCTS. (a) Requirement.—Not later than 120 days after the date of the enactment of this Act, the Director of National Intelligence shall provide to the congressional intelligence committees a briefing on whether intelligence community directives in effect as of the date such briefing is provided furnish intelligence community analysts with sufficient guidance and direction with respect to the use of artificial intelligence and machine learning tools in intelligence products produced by the intelligence community. (b) Elements.—The briefing required under subsection (a) shall include— (1) a determination by the Director as to— (A) whether Intelligence Community Directive 203, Analytic Standards, Intelligence Community Directive 206, Sourcing Requirements for Disseminated Analytic Products, and any other intelligence community directive related to the production and dissemination of intelligence products by the intelligence community in effect as of the date the briefing under subsection (a) is provided furnish intelligence community analysts with sufficient guidance and direction on how to properly use, provide sourcing information about, and otherwise provide transparency to customers regarding the use of artificial intelligence and machine learning tools in intelligence products produced by the intelligence communit",https://www.congress.gov/bill/118th-congress/house-bill/3932/text#toc-H91EED36F339C4F919BF57223383F9CF3,en,
811,"Federal Information Security Modernization Act of 2023, Sec. 14 (""Automation and Artificial Intelligence"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9762,low,0.0,229,0.5,Defunct,"SEC. 14. AUTOMATION AND ARTIFICIAL INTELLIGENCE. (a) Definition.—In this section, the term “information system” has the meaning given the term in section 3502 of title 44, United States Code. (b) Use Of Artificial Intelligence.— (1) IN GENERAL.—As appropriate, the Director shall issue guidance on the use of artificial intelligence by agencies to improve the cybersecurity of information systems. (2) CONSIDERATIONS.—The Director and head of each agency shall consider the use and capabilities of artificial intelligence systems wherever automation is used in furtherance of the cybersecurity of information systems. (3) REPORT.—Not later than 1 year after the date of enactment of this Act, and annually thereafter until the date that is 5 years after the date of enactment of this Act, the Director shall submit to the appropriate congressional committees a report on the use of artificial intelligence to further the cybersecurity of information systems. (c) Comptroller General Reports.— (1) IN GENERAL.—Not later than 2 years after the date of enactment of this Act, the Comptroller General of the United States shall submit to the appropriate congressional committees a report on the risks to the privacy of individuals and the cybersecurity of information systems associated with the use by Federal agencies of artificial intelligence systems or capabilities. (2) STUDY.—Not later than 2 years after the date of enactment of this Act, the Comptroller General of the United States shall perfor",https://www.congress.gov/bill/118th-congress/senate-bill/2251/text#toc-idbe8f7d937d1e4c7eb74a0874ce06d1ca,en,
813,"Intelligence Authorization Act for Fiscal Year 2024, Title V (""Matters Pertaining to United States Economic and Emerging Technology Competition with United States Adversaries""), Subtitle B (""Next Generation Energy, Biotechnology, and Artificial Intelligence"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.985,low,0.0,216,0.5,Defunct,"Subtitle B—Next-Generation Energy, Biotechnology, And Artificial Intelligence SEC. 511. EXPANDED ANNUAL ASSESSMENT OF ECONOMIC AND TECHNOLOGICAL CAPABILITIES OF THE PEOPLE'S REPUBLIC OF CHINA. Section 6503(c)(3) of the Intelligence Authorization Act for Fiscal Year 2023 (Public Law 117–263) is amended by adding at the end the following: “(I) A detailed assessment, prepared in consultation with all elements of the working group— “(i) of the investments made by the People’s Republic of China in— “(I) artificial intelligence; “(II) next-generation energy technologies, especially small modular reactors and advanced batteries; and “(III) biotechnology; and “(ii) that identifies— “(I) competitive practices of the People’s Republic of China relating to the technologies described in clause (i); “(II) opportunities to counter the practices described in subclause (I); “(III) countries the People’s Republic of China is targeting for exports of civil nuclear technology; “(IV) countries best positioned to utilize civil nuclear technologies from the United States in order to facilitate the commercial export of those technologies; “(V) United States vulnerabilities in the supply chain of these technologies; and “(VI) opportunities to counter the export by the People’s Republic of China of civil nuclear technologies globally. “(J) An identification and assessment of any unmet resource or authority needs of the working group that affect the ability of the working group to carry out this secti",https://www.congress.gov/bill/118th-congress/senate-bill/2103/text#toc-idb761845aa63b4209b7908c24909200db,en,
814,"Intelligence Authorization Act for Fiscal Year 2024, Sec. 758 (""Implementation of Technology for Classification and Declassification"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9803,low,0.0,204,0.5,Defunct,"SEC. 758. IMPLEMENTATION OF TECHNOLOGY FOR CLASSIFICATION AND DECLASSIFICATION. (a) In General.—Not later than 1 year after the date of the enactment of this Act, the Administrator of the Office of Electronic Government (in this section referred to as the “Administrator”) shall, in consultation with the Secretary of Defense, the Director of the Central Intelligence Agency, the Director of National Intelligence, the Public Interest Declassification Board, the Director of the Information Security Oversight Office, and the head of the National Declassification Center of the National Archives and Records Administration— (1) research a technology-based solution— (A) utilizing machine learning and artificial intelligence to support efficient and effective systems for classification and declassification; and (B) to be implemented on an interoperable and federated basis across the Federal Government; and (2) submit to the President a recommendation regarding a technology-based solution described in paragraph (1) that should be adopted by the Federal Government. (b) Staff.—The Administrator may hire sufficient staff to carry out subsection (a). (c) Report.—Not later than 540 days after the date of the enactment of this Act, the President shall submit to Congress a classified report on the technology-based solution recommended by the Administrator under subsection (a)(2) and the President’s decision regarding its adoption.",https://www.congress.gov/bill/118th-congress/senate-bill/2103/text#toc-idd641fdfa0ed943d898eac95ecaba7fdd,en,
815,"Department of State Authorization Act of 2023, Sec. 303 (""Task force to address artificial intelligence-enabled influence operations"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9867,low,0.0,206,0.5,Defunct,"SEC. 303. TASK FORCE TO ADDRESS ARTIFICIAL INTELLIGENCE-ENABLED INFLUENCE OPERATIONS. (a) Sense Of Congress.—It is the sense of Congress that— (1) the rapid development of publicly available, affordable generative artificial intelligence (AI) technology, including the use of large language models (LLM) to fuel natural language processing applications, has the potential to fundamentally alter the nature of disinformation and propaganda campaigns by enabling finely tailored, auto-generated disinformation swiftly, in any language, at scale, and at low-costs; (2) academia and private industry, including social media platforms, play a critical role in establishing safeguards for powerful, publicly available tools for producing AI-generated content, and it is in the United States national security interest to ensure that these technologies are not misused by foreign malign actors to enhance influence operations abroad; (3) the ability to identify, track, and label original text, audio, and visual content is becoming increasingly vital to United States national interests as sophisticated AI-generated content creation becomes increasingly available to the public at low costs; (4) coalitions such as the Content Authenticity Initiative (CAI) and the Coalition for Content Provenance and Authority (C2PA) play important roles in establishing open industry standards for content authenticity and digital content provenance, which will become increasingly vulnerable to manipulation and distor",https://www.congress.gov/bill/118th-congress/senate-bill/2043/text#toc-idf9806c6c3c2c458db1a68cc1196bdeb0,en,
816,"Department of State Authorization Act of 2023, Sec. 304 (""Establishment of the Chief Artificial Intelligence Officer of the Department of State"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9889,low,0.0,214,0.5,Defunct,"SEC. 304. ESTABLISHMENT OF THE CHIEF ARTIFICIAL INTELLIGENCE OFFICER OF THE DEPARTMENT OF STATE. Section 1 of the State Department Basic Authorities Act of 1956 (22 U.S.C. 2651a) is amended by adding at the end the following new subsection: “(n) Chief Artificial Intelligence Officer.— “(1) IN GENERAL.—There shall be within the Department of State a Chief Artificial Intelligence Officer, which may be dual-hatted as the Department’s Chief Data Officer, who shall be a member of the Senior Executive Service. “(2) DUTIES DESCRIBED.—The principal duties and responsibilities of the Chief Artificial Intelligence Officer shall be— “(A) to evaluate, oversee, and, if appropriate, facilitate the responsible adoption of artificial intelligence (AI) and machine learning applications to help inform decisions by policymakers and to support programs and management operations of the Department of State; and “(B) to act as the principal advisor to the Secretary of State on the ethical use of AI and advanced analytics in conducting data-informed diplomacy. “(3) QUALIFICATIONS.—The Chief Artificial Intelligence Officer should be an individual with demonstrated skill and competency in— “(A) the use and application of data analytics, AI, and machine learning; and “(B) transformational leadership and organizational change management, particularly within large, complex organizations. “(4) PARTNER WITH THE CHIEF INFORMATION OFFICER ON SCALING ARTIFICIAL INTELLIGENCE USE CASES.—To ensure alignment betw",https://www.congress.gov/bill/118th-congress/senate-bill/2043/text#toc-id15f169d6e303461994613dd5ee7587c1,en,
817,"Department of State Authorization Act of 2023, Sec. 931 (""Priority for Australia and the United Kingdom in Foreign Military Sales and Direct Commercial Sales"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9496,low,0.0,207,0.5,Defunct,"SEC. 931. PRIORITY FOR AUSTRALIA AND THE UNITED KINGDOM IN FOREIGN MILITARY SALES AND DIRECT COMMERCIAL SALES. (a) In General.—The President shall institute policies and procedures for letters of request from Australia and the United Kingdom to transfer defense articles and services under section 21 of the Arms Export Control Act (22 U.S.C. 2761) related to the AUKUS partnership to receive expedited consideration and processing relative to all other letters of request other than from Taiwan and Ukraine. (b) Technology Transfer Policy For Australia, Canada, And The United Kingdom.— (1) IN GENERAL.—The Secretary, in consultation with the Secretary of Defense, shall create an anticipatory release policy for the transfer of technologies described in paragraph (2) to Australia, the United Kingdom, and Canada through Foreign Military Sales and Direct Commercial Sales that are not covered by an exemption under the International Traffic in Arms Regulations. (2) CAPABILITIES DESCRIBED.—The capabilities described in this paragraph are— (A) Pillar One-related technologies associated with submarine and associated combat systems; and (B) Pillar Two-related technologies, including hypersonic missiles, cyber capabilities, artificial intelligence, quantum technologies, undersea capabilities, and other advanced technologies. (3) EXPEDITED DECISION-MAKING.—Review of a transfer under the policy established under paragraph (1) shall be subject to an expedited decision-making process. (c) Interag",https://www.congress.gov/bill/118th-congress/senate-bill/2043/text#toc-idede7821841af47e896be0d8ec8ea6dcf,en,
818,"Department of State Authorization Act of 2023, Sec. 941 (""Reporting Related to the AUKUS Partnership"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9524,low,0.0,227,0.5,Defunct,"SEC. 941. REPORTING RELATED TO THE AUKUS PARTNERSHIP. (a) Report On Instruments.— (1) IN GENERAL.—Not later than 30 days after the signature, conclusion, or other finalization of any non-binding instrument related to the AUKUS partnership, the President shall submit to the appropriate congressional committees the text of such instrument. (2) NON-DUPLICATION OF EFFORTS; RULE OF CONSTRUCTION.—To the extent the text of a non-binding instrument is submitted to the appropriate congressional committees pursuant to subsection (a), such text does not need to be submitted to Congress pursuant to section 112b(a)(1)(A)(ii) of title 1, United States Code, as amended by section 5947 of the James M. Inhofe National Defense Authorization Act for Fiscal Year 2023 (Public Law 117–263; 136 Stat. 3476). Paragraph (1) shall not be construed to relieve the executive branch of any other requirement of section 112b of title 1, United States Code, as amended so amended, or any other provision of law. (3) DEFINITIONS.—In this section: (A) IN GENERAL.—The term “text”, with respect to a non-binding instrument, includes— (i) any annex, appendix, codicil, side agreement, side letter, or any document of similar purpose or function to the aforementioned, regardless of the title of the document, that is entered into contemporaneously and in conjunction with the non-binding instrument; and (ii) any implementing agreement or arrangement, or any document of similar purpose or function to the aforementioned, re",https://www.congress.gov/bill/118th-congress/senate-bill/2043/text#toc-id36a67f0c2f3b4c71a0034717021f480f,en,
819,"Advanced Safe Testing at Residence Telehealth Act of 2023, Sec. 2 (""Coverage and Payment for Certain Tests and Assistive Telehealth Consultations; Demonstration Program Under Certain State Medicaid Programs"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9824,low,0.0,205,0.5,Defunct,SEC. 2. COVERAGE AND PAYMENT FOR CERTAIN TESTS AND ASSISTIVE TELEHEALTH CONSULTATIONS; DEMONSTRATION PROGRAM UNDER CERTAIN STATE MEDICAID PROGRAMS. (a) Tests And Assistive Telehealth Consultations Demonstration.—Part C of title XVIII of the Social Security Act is amended by inserting after section 1859 (42 U.S.C. 1395w–28) the following new subsection: “SEC. 1859A. TESTS AND ASSISTIVE TELEHEALTH CONSULTATIONS DEMONSTRATION. “(a) Establishment.— “(1) IN GENERAL.—The Secretary shall establish a Value-Based Insurance Design Model demonstration program (in this section referred to as the ‘VBID demonstration program’) to provide to eligible Medicare beneficiaries— “(A) an assistive telehealth consultation that is furnished via a telecommunications system by a physician or practitioner to an eligible telehealth individual enrolled under part B notwithstanding that the individual physician or practitioner ordering the test did not furnish the test or that the individual physician or practitioner providing the assistive telehealth consultation is not at the same location as the beneficiary; and “(B) home and community-based care. “(2) AGREEMENTS.—The Secretary shall enter into agreements with eligible MA organizations under which such organizations shall offer eligible MA plans under the VBID demonstration program to eligible Medicare beneficiaries. “(3) LIMITATIONS ON NUMBER OF PLANS FOR VBID DEMONSTRATION PROGRAM.—The VBID demonstration program shall be carried out with respect to,https://www.congress.gov/bill/118th-congress/house-bill/207/text#toc-H47D97BC723874386B2E67D926BD6F2D6,en,
820,"Coast Guard Authorization Act of 2023, Sec. 212 (""Report on Establishment of an Unmanned Systems Capabilities Office"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9442,low,0.0,214,0.5,Defunct,"SEC. 212. REPORT ON ESTABLISHMENT OF AN UNMANNED SYSTEMS CAPABILITIES OFFICE. (a) In General.—Not later than 1 year after the date of enactment of this Act, the Commandant shall submit to the Committee on Commerce, Science, and Transportation of the Senate and the Committee on Transportation and Infrastructure of the House of Representatives a report that outlines a plan for establishing an unmanned systems capabilities office within the Coast Guard responsible for the acquisition and development of unmanned system and counter-unmanned system technologies and to expand the capabilities of the Coast Guard with respect to such technologies (b) Contents.—The report required under subsection (a) shall include the following: (1) A management strategy for the acquisition, development, and deployment of unmanned system and counter-unmanned system technologies. (2) A service-wide coordination strategy to synchronize and integrate efforts across the Coast Guard in order to— (A) support the primary duties of the Coast Guard pursuant to section 102 of title 14, United States Code; and (B) pursue expanded research, development, testing, and evaluation opportunities and funding to expand and accelerate identification and transition of unmanned system and counter-unmanned system technologies. (3) The identification of contracting and acquisition authorities needed to expedite the development and deployment of unmanned system and counter-unmanned system technologies. (4) A detailed list of",https://www.congress.gov/bill/118th-congress/house-bill/2741/text#toc-H8D795C1808FF4DF99FC75A18E419A8E1,en,
821,"Pandemic and All-Hazards Preparedness and Response Act, Sec. 407 (""Assessment of Artificial Intelligence Threats to Health Security"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9317,low,0.0,215,0.5,Defunct,"SEC. 407. ASSESSMENT OF ARTIFICIAL INTELLIGENCE THREATS TO HEALTH SECURITY. (a) In General.—Not later than 45 days after the date of enactment of this Act, the Secretary of Health and Human Services (referred to in this section as the “Secretary”) shall seek to enter into a contract with the National Academies of Sciences, Engineering, and Medicine (referred to in this section as the “National Academies”) to conduct a study assessing the potential vulnerabilities to health security presented by the current or prospective use or misuse of artificial intelligence, including with respect to open-source artificial intelligence models, such as large language models. (b) Inclusions.—The study conducted pursuant to the contract under subsection (a) shall include— (1) an assessment of the potential vulnerabilities posed by technical advancements in artificial intelligence to health security, including any risks related to the development of, enhancement of, or protection from, chemical, biological, radiological, or nuclear threats; (2) a description of roles, responsibilities, and capabilities of agencies and offices of the Department of Health and Human Services, and, as applicable and appropriate, other Federal departments and agencies, with respect to the identification and mitigation of such potential vulnerabilities; (3) a summary of any ongoing Federal activities related to the identification, understanding, and mitigation of such potential risks; (4) the identification of any",https://www.congress.gov/bill/118th-congress/senate-bill/2333/text,en,
822,"NTIA Reauthorization Act of 2023, Sec. 203 (""Spectrum management improvements"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9849,low,0.0,188,0.5,Defunct,"SEC. 203. SPECTRUM MANAGEMENT IMPROVEMENTS. (a) Prototyping.—Consistent with subparagraphs (F), (L), (P), and (U) of section 103(b)(2) of the National Telecommunications and Information Administration Organization Act (47 U.S.C. 902(b)(2)), the Under Secretary, in coordination with the Commission and in consultation with other relevant Federal agencies, shall develop, establish, prototype, and support the implementation of common models, common methodologies, and common inputs to inform, with respect to frequencies assigned on a primary or co-primary basis to 1 or more Federal entities, electromagnetic spectrum management decisions relating to— (1) technologies and techniques to control radio frequency emissions and interference; (2) advanced antenna arrays, and artificial intelligence systems and technologies capable of operating advanced antenna arrays, including multiple-input, multiple-output antennas, beam forming and steering technology, antenna nulling technology, and conformal arrays; (3) network sensing and monitoring technologies; (4) advanced receivers that incorporate new technologies supporting new waveforms and multiple bands; (5) dynamic spectrum access technologies across wireless systems and frequencies, including local-to-the-radio and cognitive multidomain access; (6) novel spectrum access technologies; (7) artificial intelligence systems to enable dynamic spectrum access, Internet of Things networks, and other advanced communications technologies; and (8)",https://www.congress.gov/bill/118th-congress/house-bill/4510/text#toc-H59EDD2E863A54C788B1CFE86B649EC42,en,
823,"Atomic Energy Advancement Act, Sec. 123 (""Advancement of Nuclear Regulatory Oversight"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8979,low,0.0,226,0.5,Defunct,"SEC. 123. ADVANCEMENT OF NUCLEAR REGULATORY OVERSIGHT. (a) Implementing Lessons Learned From The COVID–19 Health Emergency.— (1) IN GENERAL.—Not later than 180 days after the date of enactment of this Act, the Commission shall submit to the appropriate committees of Congress a report on actions taken by the Commission during the public health emergency declared by the Secretary of Health and Human Services under section 319 of the Public Health Service Act (42 U.S.C. 247d) on January 31, 2020, with respect to COVID–19. (2) CONTENTS.—The report submitted under paragraph (1) shall— (A) identify any processes, procedures, and other regulatory policies that the Commission revised or temporarily suspended during the public health emergency described in paragraph (1); (B) examine how any revision or temporary suspension of a process, procedure, or other regulatory policy identified under subparagraph (A) affected the ability of the Commission to license and regulate the civilian use of radioactive materials in the United States to protect public health and safety, promote the common defense and security, and protect the environment; (C) discuss lessons learned from the matters described in subparagraph (B); (D) list actions that the Commission has taken or will take to incorporate into the licensing and oversight activities of the Commission, without compromising the mission of the Commission, the lessons described in subparagraph (C); and (E) describe when the actions listed under",https://www.congress.gov/bill/118th-congress/house-bill/6544/text#toc-H616B150FC502411F817DF8D1D6A6C2C7,en,
824,"Western Wildfire Support Act of 2023, Sec. 206 (""Study on Wildfire Detection Equipment and Integration of Artificial Intelligence Technologies"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9558,low,0.0,172,0.5,Defunct,"SEC. 206. STUDY ON WILDFIRE DETECTION EQUIPMENT AND INTEGRATION OF ARTIFICIAL INTELLIGENCE TECHNOLOGIES. (a) In General.—The Secretaries shall conduct a study on— (1) the effectiveness and limitations on the deployment and application of each wildfire detection equipment technology with respect to detection, confirmation, geolocation, predictability of wildfire spread, suppression resource management, post-fire forensics, and surface rehabilitation; (2) how each technology described in paragraph (1), with proper and timely deployment and use, can provide for the most effective and efficient means of dealing with the threat and the reality of wildland fires; (3) the integration of artificial intelligence with real-time imagery and weather data provided by wildfire detection equipment technology; and (4) how the integration of artificial intelligence described in paragraph (3) can enhance the value of each wildfire detection equipment technology, individually and collectively. (b) Submission And Public Availability.—Not later than 2 years after the date of enactment of this Act, the Secretaries shall submit to the congressional committees and make publicly available the results of the study conducted under subsection (a).",https://www.congress.gov/bill/118th-congress/senate-bill/1764/text#toc-id0cea417c784648eaab84cdd989d4c197,en,
826,"DEEPFAKES Accountability Act, Sec. 2 (""Transparency Requirements"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9647,low,0.2778,217,0.7,Defunct,"SEC. 2. TRANSPARENCY REQUIREMENTS. (a) In General.—Chapter 47 of title 18, United States Code, is amended by adding at the end the following: “§ 1041. Advanced technological false personation record “(a) In General.—Except as provided in subsection (j), any person who, using any means or facility of interstate or foreign commerce, produces an advanced technological false personation record with the intent to distribute such record over the internet or knowledge that such record shall be so distributed, shall ensure such record, complies with— “(1) the requirement under subsection (b); and “(2) (A) in the case of an audiovisual record, the disclosure requirements under subsection (c); “(B) in the case of a visual record, the disclosure requirements under subsection (d); or “(C) in the case of an audio record, the disclosure requirements under subsection (e). “(b) Content Provenance.—Any advanced technological false personation record which contains a moving visual element shall contain technologies, such as content provenance technologies, that clearly identify such record as containing altered audio or visual elements, or as having been entirely created through generative artificial intelligence or similar technologies. “(c) Audiovisual Disclosure.—Any advanced technological false personation records containing both an audio and a visual element shall include— “(1) not less than 1 clearly articulated verbal statement that identifies the record as containing altered audio and",https://www.congress.gov/bill/118th-congress/house-bill/5586/text,en,"Applications: Broadcasting and media production, Strategies: Disclosure, Harms: Detrimental content, Strategies: Disclosure: In deployment, Risk factors: Transparency, Strategies: Disclosure: In standard form, Harms: Harm to health/safety, Harms: Financial loss, Harms: Violation of civil or human rights, including privacy, Incentives: Civil liability, Incentives: Criminal liability, Incentives: Fines, Incentives: Imprisonment, Strategies: Tiering, Strategies: Tiering: Tiering based on domain of application"
828,"Tech to Save Moms Act, Sec. 5 (""Report on the Use of Technology in Maternity Care"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9961,low,0.0,233,0.5,Defunct,"SEC. 5. REPORT ON THE USE OF TECHNOLOGY IN MATERNITY CARE. (a) In General.—Not later than 60 days after the date of enactment of this Act, the Secretary of Health and Human Services shall seek to enter an agreement with the National Academies of Sciences, Engineering, and Medicine (referred to in this Act as the “National Academies”) under which the National Academies shall conduct a study on the use of technology and patient monitoring devices in maternity care. (b) Content.—The agreement entered into pursuant to subsection (a) shall provide for the study of the following: (1) The use of innovative technology (including artificial intelligence) in maternal health care, including the extent to which such technology has affected racial or ethnic biases in maternal health care. (2) The use of patient monitoring devices (including pulse oximeter devices) in maternal health care, including the extent to which such devices have affected racial or ethnic biases in maternal health care. (3) Best practices for reducing and preventing racial or ethnic biases in the use of innovative technology and patient monitoring devices in maternity care. (4) Best practices in the use of innovative technology and patient monitoring devices for pregnant and postpartum individuals from racial and ethnic minority groups. (5) Best practices with respect to privacy and security safeguards in such use. (c) Report.—The agreement under subsection (a) shall direct the National Academies to complete the stu",https://www.congress.gov/bill/118th-congress/house-bill/5066/text,en,
829,"AREA Act, Part B (""National Center for Education Research""), Sec. 133 (""Duties"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9682,low,0.0,213,0.5,Defunct,"SEC. 133. DUTIES. Section 133 (20 U.S.C. 9533) is amended— (1) by redesignating subsections (b) and (c) as subsections (c) and (g), respectively; (2) by striking subsection (a) and inserting the following: “(a) General Duties.—The Research Commissioner shall— “(1) maintain published peer-review standards and standards for the conduct and evaluation of all research and development carried out under the auspices of the Research Center, aligned with the principles of scientifically valid research and in accordance with this part; “(2) propose to the Director a research plan in accordance with subsection (b), and implement the research plan approved as part of the Institute's plan under section 115A; “(3) carry out specific, long-term research activities that are consistent with the priorities and mission of the Institute and the mission of the Research Center, and are approved by the Director; “(4) support scientifically valid research that seeks to improve educational opportunities and outcomes at the individual, classroom, program, school, institutional, education system, or other relevant research level; “(5) support the use of scientifically valid research within the Department and across the Federal Government; “(6) ensure that research conducted under the direction of the Research Center— “(A) supports the collaborative identification and development of research questions, designs, measurements, and methods among researchers, students, families, practitioners, education sy",https://www.congress.gov/bill/118th-congress/senate-bill/3392/text,en,
830,"Health Care Price Transparency Act of 2023, Sec. 301 (""Establishing Requirements With Respect to the Use of Prior Authorization Under Medicare Advantage Plans"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9655,low,0.0,228,0.5,Defunct,"SEC. 301. ESTABLISHING REQUIREMENTS WITH RESPECT TO THE USE OF PRIOR AUTHORIZATION UNDER MEDICARE ADVANTAGE PLANS. (a) In General.—Section 1852 of the Social Security Act (42 U.S.C. 1395w–22) is amended by adding at the end the following new subsection: “(o) Prior Authorization Requirements.— “(1) IN GENERAL.—In the case of a Medicare Advantage plan that imposes any prior authorization requirement with respect to any applicable item or service (as defined in paragraph (5)) during a plan year, such plan shall— “(A) beginning with the third plan year beginning after the date of the enactment of this subsection— “(i) establish the electronic prior authorization program described in paragraph (2); and “(ii) meet the enrollee protection standards specified pursuant to paragraph (4); and “(B) beginning with the fourth plan year beginning after the date of the enactment of this subsection, meet the transparency requirements specified in paragraph (3). “(2) ELECTRONIC PRIOR AUTHORIZATION PROGRAM.— “(A) IN GENERAL.—For purposes of paragraph (1)(A), the electronic prior authorization program described in this paragraph is a program that provides for the secure electronic transmission of— “(i) a prior authorization request from a provider of services or supplier to a Medicare Advantage plan with respect to an applicable item or service to be furnished to an individual and a response, in accordance with this paragraph, from such plan to such provider or supplier; and “(ii) any attachment",https://www.congress.gov/bill/118th-congress/house-bill/4822/text#toc-HCAC31962936245EAB91F32DFB9EE44F1,en,
832,"Harmful Algal Bloom and Hypoxia Research and Control Amendments Act of 2023, Sec. 2f (""National Harmful Algal Bloom and Hypoxia Observing Network"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7003,low,0.0,201,0.5,Defunct,"(f) National Harmful Algal Bloom And Hypoxia Observing Network.— (1) IN GENERAL.—The Harmful Algal Blooms and Hypoxia Research and Control Act of 1998 is amended by amending section 606 (33 U.S.C. 4005) to read as follows: “SEC. 606. NATIONAL HARMFUL ALGAL BLOOM OBSERVING NETWORK. “(a) In General.—The Under Secretary, acting through the National Centers for Coastal Ocean Science (NCCOS) and the Integrated Ocean Observing System (IOOS) of the National Oceanic and Atmospheric Administration, shall establish a national network of harmful algal bloom observing systems for the monitoring, detection, and forecasting of harmful algal blooms by leveraging the capacity of IOOS regional associations, including through the incorporation of emerging technologies and new data integration methods, such as artificial intelligence. “(b) Coordination.—In carrying out subsection (a), the IOOS Program Office shall— “(1) coordinate with NCCOS regarding observations, data integration, and information dissemination; and “(2) establish a Harmful Algal Bloom Data Assembly Center to integrate, disseminate, and provide a central architecture to support ecological forecasting.”. (2) CLERICAL AMENDMENT.—The table of contents in section 2 of the Coast Guard Authorization Act of 1998 is amended by amending the item relating to section 606 to read as follows: “Sec. 606. National harmful algal bloom observing network.”.",https://www.congress.gov/bill/118th-congress/house-bill/6235/text,en,
834,"Rail Worker and Community Safety Act, Sec. 13 (Equipment Inspections)",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8442,low,0.0,145,0.5,Defunct,"SEC. 13. EQUIPMENT INSPECTIONS. Not later than 12 months after the date of enactment of this Act, the Secretary of Transportation shall issue such regulations as are necessary to— (1) prohibit any train from being moved out of a switchyard before all required brake inspections of locomotives and rail cars have been completed; (2) allow only the Qualified Mechanical Inspector assigned to inspect a locomotive or rail car to sign off on the Form FRA F6180–49A (commonly known as the “blue card”) for locomotive inspections or the satisfactory Class I brake inspection or end of train device form relating to such locomotive or rail car related to rail car inspections; and (3) ensure that any inspection conducted under part 215 of title 49, Code of Federal Regulations, utilizing inspection technologies, including artificial intelligence or camera-based systems, require verification or validation by a Qualified Mechanical Inspector.",https://www.congress.gov/bill/118th-congress/house-bill/5871/all-actions,en,
836,"Communications, Video, and Technology Accessibility Act of 2023, Sec. 401 (""Emerging Technology"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.6369,low,0.0,215,0.5,Defunct,"SEC. 401. EMERGING TECHNOLOGY. Title VII of the Communications Act of 1934 (42 U.S.C. 601 et seq.) is amended by adding at the end the following: “SEC. 723. EMERGING TECHNOLOGY ACCESSIBILITY. “(a) Definitions.—In this section: “(1) AUGMENTATIVE AND ALTERNATIVE COMMUNICATION.—The term ‘augmentative and alternative communication’ means any tool, method, technology, strategy, service, training, coaching, or other support used to supplement or replace speech. “(2) DISABILITY.—The term ‘disability’ has the meaning given the term in section 3 of the Americans with Disabilities Act of 1990 (42 U.S.C. 12102). “(b) Reports To Congress.—Not later than 3 years after the date of enactment of this section, and every 5 years thereafter, the Commission shall, in consultation with the United States Access Board, submit to the Committee on Commerce, Science, and Transportation of the Senate and the Committee on Energy and Commerce of the House of Representatives a report assessing— “(1) the extent to which any accessibility barriers exist for individuals with disabilities, including individuals who are blind, deaf, or DeafBlind or have low vision, an auditory processing disorder, a cortical or cerebral visual impairment, a speech disability, including individuals who use augmentative and alternative communication, a mobility disability, or a cognitive disability, with respect to emerging communications and video programming technologies and services, including communication and video programm",https://www.congress.gov/bill/118th-congress/house-bill/4858/text#toc-H0BAC0341D19A439ABB8DD046E3739E3C,en,
837,"Online Privacy Act of 2023, Sec. 106 (""Right to individual autonomy"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.6941,low,0.0,220,0.5,Defunct,"SEC. 106. RIGHT TO INDIVIDUAL AUTONOMY. (a) In General.—A covered entity shall not collect, process, maintain, or disclose an individual’s personal information to— (1) create, improve upon, or maintain; (2) process with; or (3) otherwise link an individual with; an algorithm, model, or other means designed for behavioral personalization, without the affirmative express consent of that individual. (b) Consent.—A covered entity must obtain express affirmative consent from an individual before it may provide a behaviorally personalized version of a product or service, and not less than every calendar year thereafter. Where consent is denied, a covered entity must provide the product or service without behavioral personalization. (c) Exceptions To Providing Product Or Service.— (1) Where the offering of a substantially similar product or service without behavioral personalization is infeasible, a covered entity shall provide, to the greatest extent feasible, a core aspect or part of the product or service that can be offered without behavioral personalization. (2) Where no core aspect or part of the product or service can function in a substantially similar function without behavioral personalization, a covered entity may deny providing an individual use of such product or service if such individual does not consent to behavioral personalization as required in subsection (a). (d) Exception To Behavioral Processing.—Notwithstanding subsections (a) and (b), a covered entity may pro",https://www.congress.gov/bill/118th-congress/house-bill/2701/text#toc-H92725DAD9E9045BEA1E4D2A0AEE94B30,en,
838,"Securing Growth and Robust Leadership in American Aviation Act, Sec. 1024 (""Technology Review of Artificial Intelligence and Machine Learning Technologies"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2024-05-16,2024,5,positive,0.9908,low,0.0,187,1.0,Enacted,"SEC. 1024. TECHNOLOGY REVIEW OF ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING TECHNOLOGIES. (a) Review.—The Administrator shall conduct a review of current and planned artificial intelligence and machine learning technologies to improve airport efficiency and safety. (b) Considerations.—In conducting the review required under subsection (a), the Administrator may consider— (1) identifying best practices and lessons learned from both domestic and international artificial intelligence and machine learning technology applications to improve airport operations; and (2) coordinating with other relevant Federal agencies to identify China’s domestic application of artificial intelligence and machine learning technologies relating to airport operations. (c) Summaries.—The review conducted under subsection (a) shall include examination of the application of artificial intelligence and machine learning technologies to the following: (1) Jet bridges. (2) Airport service vehicles on airport movement areas. (3) Aircraft taxi. (4) Air traffic control operations. (5) Any other areas the Administrator determines necessary to help improve airport efficiency and safety. (d) Report.—Not later than 1 year after the date of enactment of this Act, the Administrator shall submit to the covered committees of Congress a report containing the results of the review conducted under subsection (a).",https://www.congress.gov/bill/118th-congress/house-bill/3935/text#toc-H7ED374E4041E474387FF34648AD054DC,en,"Applications: Transportation, Strategies: Evaluation, Strategies: Convening, Strategies: Government study or report"
839,"Securing Growth and Robust Leadership in American Aviation Act, Sec. 1028 (""Air Traffic Control Training"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2024-05-16,2024,5,positive,0.9623,low,0.0,209,1.0,Enacted,"SEC. 1028. AIR TRAFFIC CONTROL TRAINING. (a) Research.—Subject to the availability of appropriations, the Administrator shall carry out a research program to evaluate opportunities to modernize, enhance, and streamline on-the-job training and training time for individuals seeking to become certified professional controllers of the FAA, as required by the Administrator. (b) Requirements.—In carrying out the research program under subsection (a), the Administrator shall— (1) assess the benefits of deploying and using advanced technologies, such as artificial intelligence, machine learning, adaptive computer-based simulation, virtual reality, or augmented reality, or any other technology determined appropriate by the Administrator, to enhance air traffic controller knowledge retention and controller performance, strengthen safety, and improve the effectiveness of training time; and (2) include collaboration with labor organizations, including the exclusive bargaining representative of air traffic controllers of the FAA certified under section 7111 of title 5, United States Code, and other stakeholders. (c) Report.—Not later than 1 year after the date of enactment of this Act, the Administrator shall submit to the covered committees of Congress a report on the findings of the research under subsection (a). (d) Rule Of Construction.—Nothing in this section shall be construed to delay the installation of tower simulation systems by the Administrator at FAA air traffic facilities ac",https://www.congress.gov/bill/118th-congress/house-bill/3935/text#toc-HFE134C67415640189C642F62A6AB33C3,en,"Applications: Transportation, Strategies: Evaluation, Strategies: Government study or report, Strategies: Convening"
840,"Securing Growth and Robust Leadership in American Aviation Act, Sec. 908 (""Part 107 Waiver Improvements"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2024-05-16,2024,5,positive,0.9317,low,0.0,220,0.7,Enacted,"SEC. 908. PART 107 WAIVER IMPROVEMENTS. (a) In General.—The Administrator shall adopt a performance- and risk-based approach in reviewing requests for certificates of waiver under section 107.200 of title 14, Code of Federal Regulations. (b) Standardization Of Waiver Application.— (1) IN GENERAL.—In carrying out subsection (a), the Administrator shall improve the process to submit requests for certificates of waiver described in subsection (a). (2) FORMAT.—In carrying out paragraph (1), the Administrator may not require the use of open-ended descriptive prompts that are required to be filled out by an applicant, except to provide applicants the ability to provide the FAA with information for an unusual or irregular operation. (3) DATA.— (A) IN GENERAL.—In carrying out paragraph (1), the Administrator shall leverage data gathered from previous requests for certificates of waivers. (B) CONSIDERATIONS.—In carrying out subparagraph (A), the Administrator shall safely use— (i) big data analytics; and (ii) machine learning. (c) Consideration Of Property Access.— (1) IN GENERAL.—In determining whether to issue a certificate of waiver under section 107.200 of title 14, Code of Federal Regulations, the Administrator shall— (A) consider whether the waiver applicant has control over access to all real property on the ground within the area of operation; and (B) recognize and account for the safety enhancements of such controlled access. (2) RULE OF CONSTRUCTION.—Nothing in this subsecti",https://www.congress.gov/bill/118th-congress/house-bill/3935/text#toc-H25A9371BBE8648B09E7C94EBC7B3A544,en,Strategies: Governance development
841,"Lummis-Gillibrand Responsible Financial Innovation Act, Sec. 1001 (""Executive Office of the President Appropriations"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9393,low,0.0,215,0.5,Defunct,"SEC. 1001. EXECUTIVE OFFICE OF THE PRESIDENT APPROPRIATIONS. (a) Office Of Science And Technology Policy.—For the purposes of hiring specialist positions within the Office of Science and Technology Policy to coordinate Federal activities and advise the President on matters of research and development relating to crypto assets, distributed ledger technology, artificial intelligence and other innovative financial technologies, including funding the position created by section 10671 of 136 Stat. 1688 and coordinating the national research and development strategy required by section 5913 of 136 Stat. 2395, there is authorized to be appropriated to the Executive Office of the President the following: (1) $2,500,000 for fiscal year 2023, to remain available until September 30, 2024. (2) $2,500,000 for fiscal year 2024, to remain available until September 30, 2025. (3) $2,500,000 for fiscal year 2025, to remain available until September 30, 2026. (4) $2,500,000 for fiscal year 2026, to remain available until September 30, 2027. (5) $2,500,000 for fiscal year 2027, to remain available until September 30, 2028. (b) National Economic Council.—For the purposes of hiring specialist positions within the National Economic Council to coordinate Federal activities and advise the President on matters of financial and economic policy relating to crypto assets, distributed ledger technology, artificial intelligence and other innovative financial technologies, there is authorized to be appropri",https://www.congress.gov/bill/118th-congress/senate-bill/2281/text#toc-idef01ee42ae274e9b8e81c90f884f6475,en,
843,"HOME Act of 2024, Sec. 7 (Identification of Unfair Screening Practices)",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.7378,low,0.0,108,0.5,Defunct,"SEC. 7. IDENTIFICATION OF UNFAIR SCREENING PRACTICES. The Secretary, the Federal Trade Commission, and the Bureau of Consumer Financial Protection shall jointly— (1) carry out a program to collect information to identify practices that unfairly prevent applicants and tenants of rental housing from accessing or staying in housing, including the establishment and use of tenant or applicant background checks, the use of algorithms in tenant screenings, the provision of adverse action notices by landlords and property management companies, and the use of information regarding tenant income sources; and(2) submit a report to the Congress annually describing the information collected under the program carried out pursuant to paragraph (1).",https://www.congress.gov/bill/118th-congress/senate-bill/3561/text,en,
844,"PAID Act, Sec. 3 (Requirements for Private Passenger Automobile Insurers)",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.25,low,0.0,225,0.5,Defunct,"1. REQUIREMENTS FOR PRIVATE PASSENGER AUTOMOBILE INSURERS. (a) Use Of Certain Factors And Income Proxies Prohibited.—It shall be unlawful for a private passenger automobile insurer, or any of its affiliate insurers, to take into consideration any of the factors described in subsection (b) relating to a consumer in determining that consumer’s eligibility for automobile insurance or in calculating the rate for that consumer.(b) Factors.—The factors referred to in subsection (a) are— (1) gender; (2) level of education; (3) occupation; (4) employment status; (5) home ownership status; (6) ZIP Code or adjacent ZIP Codes; (7) census tract; (8) marital status; (9) credit score or credit-based insurance score; (10) consumer report; (11) previous insurer; or (12) prior purchase of insurance of a consumer from that automobile insurer.(c) Submissions To FTC Regarding Certain Business Practices.—Not later than 1 year after the date of the enactment of this Act, and every 2 years thereafter, each private passenger automobile insurer, and each of its affiliate insurers, shall submit to the Federal Trade Commission such information as the Commission may require to demonstrate that the marketing, underwriting, rating, claims handling, and fraud investigations of such private passenger automobile insurer or affiliate insurer (as the case may be), and any algorithm or model used by such private passenger automobile insurer or affiliate insurer (as the case may be) for such marketing, underwrit",https://www.congress.gov/bill/118th-congress/house-bill/3880/text,en,
845,NSF AI Education Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9402,low,0.0,231,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “NSF AI Education Act of 2024”. SEC. 2. DEFINITIONS. In this Act: (1) ESEA TERMS.—The terms “educational service agency”, “elementary school”, “high school”, “local educational agency”, “secondary school”, “State educational agency”, and “universal design for learning” have the meaning given those terms in section 8101 of the Elementary and Secondary Education Act of 1965 (20 U.S.C. 7801). (2) ARTIFICIAL INTELLIGENCE; AI.—The term “artificial intelligence” or “AI” has the meaning given such term in section 5002 of the William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021 (15 U.S.C. 9401). (3) COMMUNITY COLLEGE.—The term “community college” means— (A) an institution that is a junior or community college, as such term is defined in section 312(f) of the Higher Education Act of 1965 (20 U.S.C. 1058(f)); (B) a degree-granting public institution of higher education at which— (i) the highest degree awarded is an associate degree; or (ii) an associate degree is the most frequently awarded degree; (C) an eligible Tribal College or University; or (D) a branch campus of a four-year public institution of higher education, if, at such branch campus— (i) the highest degree awarded is an associate degree; or (ii) an associate degree is the most frequently awarded degree. (4) DIRECTOR.—The term “Director” means the Director of the National Science Foundation. (5) EMERGING RESEARCH INSTITUTION.—The term “emerg",https://www.congress.gov/bill/118th-congress/senate-bill/4394/text,en,
849,Preparing Election Administrators for AI Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9674,low,0.0,200,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Preparing Election Administrators for AI Act”.SEC. 2. VOLUNTARY GUIDELINES FOR ADMINISTRATION OF ELECTIONS THAT ADDRESS THE USE AND RISKS OF ARTIFICIAL INTELLIGENCE TECHNOLOGIES. (a) Report And Voluntary Guidelines.—Not later than 60 days after the date of the enactment of this Act, the Election Assistance Commission shall, in consultation with the National Institute of Standards and Technology, submit to Congress, issue to State and local election offices, and make available to the public a report with voluntary guidelines for election offices that address the use and risks of artificial intelligence technologies in the administration of elections. (b) Contents.—The report submitted and made available pursuant to subsection (a) shall include voluntary guidelines that address— (1) the risks and benefits associated with using artificial intelligence technologies to conduct election administration activities; (2) the cybersecurity risks of artificial intelligence technologies to election administration; (3) how information generated and distributed by artificial intelligence technologies can affect the sharing of accurate election information and how election offices should respond; and (4) how information generated and distributed by artificial intelligence technologies can affect the spreading of election disinformation that undermines public trust and confidence in elections.",https://www.congress.gov/bill/118th-congress/house-bill/8353/text,en,
850,Cybersecurity and Infrastructure Security Agency Securing AI Task Force Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9964,low,0.1667,215,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “CISA Securing AI Task Force Act”.SEC. 2. TASK FORCE ON SECURING ARTIFICIAL INTELLIGENCE. (a) In General.—Not later than 1 year after the date of enactment of this Act, the Director of the Cybersecurity and Infrastructure Security Agency of the Department of Homeland Security shall establish within the Agency a Task Force comprised of personnel from across its offices and divisions to coordinate the execution of directives pursuant to Executive Order 14110, or a subsequent Executive order, future Agency activities related to the safety and security of artificial intelligence, and the Agency’s contributions to Department-wide initiatives related to the safety and security of artificial intelligence. Such Task Force shall— (1) ensure coordination, cohesion, and alignment of Agency efforts to improve the safe and secure design, development, adoption, and deployment of artificial intelligence; (2) ensure coordination, cohesion, and alignment of Agency input into Department-led, interagency, and nongovernment working groups or collaborations related to artificial intelligence; (3) assess and evaluate relevant Agency safety and security initiatives, guidance, and programs to ensure the unique safety and security challenges related to artificial intelligence are contemplated and addressed and recommend updates to such initiatives, guidance, and programs, as appropriate; (4) ensure the full expertise from across the Agency is lever",https://www.congress.gov/bill/118th-congress/house-bill/8348/all-actions?overview=closed#tabs,en,"Strategies: New institution, Strategies: Evaluation, Strategies: Performance requirements, Strategies: Government study or report, Strategies: Governance development, Strategies: Disclosure, Strategies: Government support: AI workforce-related, Risk factors: Privacy, Risk factors: Security, Risk factors: Security: Cybersecurity, Applications: Government: military and public safety"
851,"S.4306, Five AIs Act 2024",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9889,low,0.0,220,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Five AIs Act 2024”.SEC. 2. ESTABLISHMENT OF WORKING GROUP FOR ARTIFICIAL INTELLIGENCE INITIATIVE AMONG FIVE EYES COUNTRIES. (a) Establishment.—Not later than 90 days after the date of the enactment of this Act, the Secretary of Defense, in coordination with the Director of National Intelligence, shall establish a working group to be known as the “Five AIs Strategic Artificial Intelligence Working Group” (in this section referred to as the “Working Group”). (b) Purpose.—The purpose of the Working Group shall be to develop and coordinate an artificial intelligence initiative among the Five Eyes countries.(c) Organization.— (1) DESIGNATION OF HEAD.—The Secretary of Defense, in coordination with the Director of National Intelligence, shall designate a senior civilian officer of the Department of Defense or senior military officer with experience leading relevant efforts, as determined by the Secretary, to serve as the head of the Working Group. (2) PARTICIPATION BY OTHER MEMBER COUNTRIES.—The Secretary of Defense, in coordination with the Director of National Intelligence, shall encourage participation in the Working Group by the members of the Five Eyes Intelligence Oversight and Review Council. (d) Responsibilities.—The responsibilities of the Working Group shall be to develop and coordinate efforts to implement an artificial intelligence initiative between the Department of Defense, the Office of the Intelligence Community",https://www.congress.gov/bill/118th-congress/senate-bill/4306/text,en,
852,ENFORCE Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.5267,low,0.1667,231,0.7,Defunct,"H. R. 8315 To amend the Export Control Reform Act of 2018 to prevent foreign adversaries from exploiting United States artificial intelligence and other enabling technologies, and for other purposes. IN THE HOUSE OF REPRESENTATIVES May 8, 2024 Mr. McCaul (for himself, Mr. Moolenaar, Mr. Krishnamoorthi, and Ms. Wild) introduced the following bill; which was referred to the Committee on Foreign Affairs A BILL To amend the Export Control Reform Act of 2018 to prevent foreign adversaries from exploiting United States artificial intelligence and other enabling technologies, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE AND TABLE OF CONTENTS. (a) Short Title.—This Act may be cited as the “Enhancing National Frameworks for Overseas Restriction of Critical Exports Act” or “ENFORCE Act”. (b) Table Of Contents.—The table of contents for this Act is as follows: Sec. 1. Short title and table of contents. Sec. 2. Definitions. Sec. 3. Authority of the President. Sec. 4. Additional authorities. Sec. 5. Amendment to International Emergency Economic Powers Act. SEC. 2. DEFINITIONS. Section 1742 of the Export Control Reform Act of 2018 (50 U.S.C. 4801) is amended by adding at the end the following: “(15) ADDITIONAL DEFINITIONS.— “(A) ARTIFICIAL INTELLIGENCE.—The term ‘artificial intelligence’ has the meaning given that term in section 5002(3) of the National Artificial Intelligence",https://www.congress.gov/bill/118th-congress/house-bill/8315/text,en,"Harms: Harm to health/safety, Risk factors: Security, Risk factors: Security: Cybersecurity, Strategies: Input controls, Strategies: Licensing, registration, and certification"
854,AI Grand Challenges Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9878,medium,0.3889,209,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “AI Grand Challenges Act of 2024”.SEC. 2. PRIZE COMPETITIONS FOR ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT. (a) Definition.—Except as otherwise expressly provided, in this section the term “Director” means the Director of the National Science Foundation. (b) Establishment Of Program.— (1) IN GENERAL.—Not later than 12 months after the date of enactment of this Act, the Director, in coordination with the Interagency Committee established under section 5103 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9413), shall establish a program to award prizes, utilizing the authorities and processes established under section 24 of the Stevenson-Wydler Technology Innovation Act of 1980 (15 U.S.C. 3719), to eligible participants as determined by the Director pursuant to subsection (e) to stimulate artificial intelligence research, development, and commercialization that solves or advances specific, well-defined, and measurable grand challenges in 1 or more of the following categories: (A) National security. (B) Cybersecurity. (C) Health. (D) Energy. (E) Environment. (F) Transportation. (G) Agriculture and rural development. (H) Education and workforce training. (I) Manufacturing. (J) Space and aerospace. (K) Quantum computing, including molecular modeling and simulation. (L) Materials science. (M) Supply chain resilience. (N) Disaster preparedness. (O) Natural resources management. (P) Cross cutting ch",https://www.congress.gov/bill/118th-congress/senate-bill/4236/text,en,"Risk factors: Reliability, Risk factors: Reliability: Robustness, Risk factors: Interpretability and explainability, Risk factors: Safety, Risk factors: Privacy, Risk factors: Bias, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Convening, Incentives: Subsidies, Strategies: Government study or report, Risk factors: Transparency"
855,Secure Artificial Intelligence Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9956,medium,0.5,233,0.7,Defunct,"S. 4230 To improve the tracking and processing of security and safety incidents and risks associated with artificial intelligence, and for other purposes. IN THE SENATE OF THE UNITED STATES May 1, 2024 Mr. Warner (for himself and Mr. Tillis) introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To improve the tracking and processing of security and safety incidents and risks associated with artificial intelligence, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Secure Artificial Intelligence Act of 2024” or the “Secure A.I. Act of 2024”. SEC. 2. DEFINITIONS. In this Act: (1) ARTIFICIAL INTELLIGENCE SAFETY INCIDENT.—The term “artificial intelligence safety incident” means an event that increases the risk that operation of an artificial intelligence system will— (A) result in physical or psychological harm; or (B) lead to a state in which human life, health, property, or the environment is endangered. (2) ARTIFICIAL INTELLIGENCE SECURITY INCIDENT.—The term “artificial intelligence security incident” means an event that increases— (A) the risk that operation of an artificial intelligence system occurs in a way that enables the extraction of information about the behavior or characteristics of an artificial intelligence system by a third party; or (B) the ability o",https://www.congress.gov/bill/118th-congress/senate-bill/4230/text,en,"Risk factors: Safety, Harms: Harm to health/safety, Risk factors: Security, Risk factors: Security: Cybersecurity, Risk factors: Security: Dissemination, Harms: Financial loss, Harms: Harm to property, Harms: Harm to infrastructure, Harms: Ecological harm, Strategies: Evaluation, Strategies: Disclosure: About incidents, Strategies: Disclosure: About evaluation, Strategies: Government study or report, Strategies: Tiering, Strategies: Tiering: Tiering based on impact"
856,Free Credit Scores for Consumers Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9904,low,0.0,230,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Free Credit Scores for Consumers Act of 2024”.SEC. 2. FINDINGS. Congress finds the following: (1) While nationwide consumer reporting agencies (“CRAs”) are required by law to supply consumers with a free copy of their credit report annually, they can charge consumers to obtain a credit score disclosure. (2) A July 2011 report by the Consumer Financial Protection Bureau (“Consumer Bureau”) titled “The Impact of Differences between Consumer- and Creditor-Purchased Credit Scores” found that the credit scores made available to and purchased by consumers from CRAs are unlikely to be the same credit scores used by creditors and lenders to evaluate consumers’ creditworthiness. (3) That report found that the scarcity of public educational tools to inform consumers of the differences among credit scores, the large combined market share and brand recognition of FICO credit scores, and the marketing practices of some credit score sellers may perpetuate consumers’ confusion about credit scores. As a result, some consumers may be purchasing an educational credit score or subscribing to a credit monitoring service sold by a CRA, without realizing the limitations and usefulness of these products and services. (4) Similarly, a September 2012 Consumer Bureau report titled “Analysis of Differences between Consumer- and Creditor-Purchased Credit Scores” found that consumers do not know before they purchase a credit score from a CRA whether t",https://www.congress.gov/bill/118th-congress/house-bill/8143/text,en,
857,Examining Educational Redlining in Lending Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9364,low,0.0,229,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Examining Educational Redlining in Lending Act”.SEC. 2. ASSESSMENT OF CERTAIN EDUCATIONAL DATA. (a) Assessment.—Not later than 180 days after the date of the enactment of this Act and annually thereafter, the Bureau of Consumer Financial Protection (referred to in this section as the “Bureau”) shall, in coordination with relevant executive agencies and national civil rights stakeholders, assess— (1) the use of certain educational data by covered persons in determining the creditworthiness of an applicant; (2) the use of an underwriting process that involves gathering data points and creating applicant profiles, including automated or algorithmic processes, and the risks of such use, by covered persons to determine the creditworthiness of an applicant; and (3) what policies and guidelines are in place to ensure decisions do not result in a disparate impact on a protected class.(b) Report To Congress.—Not later than 60 days after the completion of each assessment required under subsection (a) and annually thereafter, the Bureau shall submit to the Committee on Financial Services of the House of Representatives and the Committee on Banking, Housing, and Urban Affairs of the Senate the findings of such assessment and any recommendations based on such findings.(c) Publication.—Not later than 30 days after the completion of the assessment required under subsection (a), the Bureau shall make available on a publicly accessible web",https://www.congress.gov/bill/118th-congress/house-bill/8142/text,en,
860,Future of Artificial Intelligence Innovation Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9953,low,0.0,196,0.5,Defunct,"SECTION 1. SHORT TITLE; TABLE OF CONTENTS. (a) Short Title.—This Act may be cited as the “Future of Artificial Intelligence Innovation Act of 2024”. (b) Table Of Contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. Sec. 2. Sense of Congress. Sec. 3. Definitions. TITLE I—VOLUNTARY ARTIFICIAL INTELLIGENCE STANDARDS, METRICS, EVALUATION TOOLS, TESTBEDS, AND INTERNATIONAL COOPERATION Subtitle A—Artificial Intelligence Safety Institute And Testbeds Sec. 101. Artificial Intelligence Safety Institute. Sec. 102. Program on artificial intelligence testbeds. Sec. 103. National Institute of Standards and Technology and Department of Energy testbed to identify, test, and synthesize new materials. Sec. 104. National Science Foundation and Department of Energy collaboration to make scientific discoveries through the use of artificial intelligence. Sec. 105. Progress report. Subtitle B—International Cooperation Sec. 111. International coalition on innovation, development, and harmonization of standards with respect to artificial intelligence. Sec. 112. Requirement to support bilateral and multilateral artificial intelligence research collaborations. Subtitle C—Identifying Regulatory Barriers To Innovation Sec. 121. Comptroller General of the United States identification of risks and obstacles relating to artificial intelligence and Federal agencies. TITLE II—ARTIFICIAL INTELLIGENCE RESEARCH, DEVELOPMENT, CAPACITY BUILDING ACTIVITIES Sec. 201. P",https://www.congress.gov/bill/118th-congress/senate-bill/4178/text,en,
864,GRIData Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9592,low,0.0,237,0.5,Defunct,"S. 4140 To require the Secretary of Energy to identify, analyze, and share available data for the purpose of improving the reliability and resilience of the electric grid, and for other purposes. IN THE SENATE OF THE UNITED STATES April 17, 2024 Mr. Heinrich (for himself, Mr. Wyden, and Mr. Padilla) introduced the following bill; which was read twice and referred to the Committee on Energy and Natural Resources A BILL To require the Secretary of Energy to identify, analyze, and share available data for the purpose of improving the reliability and resilience of the electric grid, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Grid Reliability and Integrated Data Act of 2024” or the “GRIData Act of 2024”. SEC. 2. DEFINITIONS. (a) In General.—In this Act: (1) CUSTOMER AVERAGE INTERRUPTION DURATION INDEX; CAIDI.—In accordance with IEEE 1366, the term “Customer Average Interruption Duration Index” or “CAIDI” means the average number of minutes per sustained interruption experienced by customers per year. (2) DEPARTMENT.—The term “Department” means the Department of Energy. (3) ENERGY COMMUNITY.—The term “energy community” has the meaning given the term in section 45(b)(11)(B) of the Internal Revenue Code of 1986. (4) IEEE 1366.—The term “IEEE 1366” means the standard published by the Institute of Electrical and Electronics Engineers Standar",https://www.congress.gov/bill/118th-congress/senate-bill/4140/text,en,
865,Child Exploitation and Artificial Intelligence Expert Commission Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9762,low,0.1667,228,0.7,Defunct,"H. R. 8005 To establish the Commission of Experts on Child Exploitation and Artificial Intelligence. IN THE HOUSE OF REPRESENTATIVES April 15, 2024 Mr. Langworthy (for himself, Mr. Fry, Mr. Lawler, Mr. Davis of North Carolina, Mrs. Miller of Illinois, Mr. Nunn of Iowa, Mr. Carson, Mrs. Hinson, Mr. Bacon, Ms. Adams, Ms. Tenney, and Mr. D'Esposito) introduced the following bill; which was referred to the Committee on the Judiciary A BILL To establish the Commission of Experts on Child Exploitation and Artificial Intelligence. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Child Exploitation and Artificial Intelligence Expert Commission Act of 2024”. SEC. 2. COMMISSION OF EXPERTS ON CHILD EXPLOITATION AND ARTIFICIAL INTELLIGENCE. (a) Establishment.—There is established a commission, to be known as the “Commission of Experts on Child Exploitation and Artificial Intelligence” (in this section referred to as the “Commission”), which shall investigate and make recommendations on solutions to improve the ability of a law enforcement agency to prevent, detect, and prosecute child exploitation crimes committed using artificial intelligence. (b) Duties Of Commission.—The Commission shall— (1) investigate and assess how artificial intelligence may be used in the commission of a child exploitation crime; (2) evaluate the ability of a law enforcement agency to prevent, det",https://www.congress.gov/bill/118th-congress/house-bill/8005/text,en,"Risk factors: Safety, Harms: Violation of civil or human rights, including privacy, Strategies: New institution, Applications: Government: judicial and law enforcement, Strategies: Evaluation, Strategies: Evaluation: Post-market monitoring, Strategies: Governance development, Strategies: Evaluation: Impact assessment, Strategies: Government study or report, Strategies: Convening, Strategies: Government support, Risk factors: Transparency"
867,Open Translation Center Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9544,low,0.0,224,0.5,Defunct,"A BILL To establish the Open Translation Center, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Open Translation Center Act of 2024”. SEC. 2. Findings. Congress finds the following: (1) The success of United States foreign policy depends on the ability to accurately perceive and understand other countries’ foreign and domestic policies. (2) Open source materials published by the People’s Republic of China and other nations offer a uniquely valuable window into the politics, policy, ideology, intentions, and activities of those countries. (3) A lack of foreign language speakers greatly hinders United States policymakers, journalists, academics, students, and others’ ability to understand the People’s Republic of China and other nations and governments. (4) During the Cold War, the Foreign Broadcast Information Service provided translations and open source analysis that nourished generations of diplomats, journalists, academics, students, and others. (5) Today, a public translation and analysis organization is needed to support the development of United States foreign policy and to enrich public understanding. SEC. 3. Establishment. There is established a federally funded research and development center to be known as the “Open Translation Center” (referred to in this section as “OTC”). SEC. 4. Incorporation. (a) In general.—OTC shall be",https://www.congress.gov/bill/118th-congress/house-bill/7942/text,en,
872,Veterans Appeals Efficiency Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9792,low,0.0,240,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Veterans Appeals Efficiency Act of 2024”.SEC. 2. IMPROVEMENTS TO EFFICIENCY OF ADJUDICATIONS AND APPEALS OF CLAIMS FOR BENEFITS UNDER LAWS ADMINISTERED BY SECRETARY OF VETERANS AFFAIRS. (a) Annual Report On Length Of Adjudications.— (1) IN GENERAL.—Section 5109B of title 38, United States Code, is amended— (A) by striking “The Secretary” and inserting “(a) In General.—The Secretary”; and (B) by adding at the end the following new subsection:“(b) Annual Report.—The Secretary shall submit to the Committees on Veterans’ Affairs of the House of Representatives and the Senate an annual report that includes, with respect to the period covered by the report, a statement of the average length of time a claim (or issue within a claim) that is remanded by the Board of Veterans' Appeals is pending before the Secretary after such return or remand.”. (2) DEADLINE.—The Secretary of Veterans Affairs shall submit the first report required by subsection (b) of section 5109B of such title (as added by paragraph (1)) by not later than one year after the date of the enactment of this Act.(b) Requirement To Track Certain Claims For Benefits.— (1) IN GENERAL.—Chapter 51 of title 38, United States Code, is amended by inserting after section 5109B the following new section: “§ 5109C. Requirement to track and maintain information on certain claims for benefits; notice of certain assignments “(a) In General.—The Secretary shall use technology to tr",https://www.congress.gov/bill/118th-congress/house-bill/7917/text,en,
874,Generative AI Copyright Disclosure Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9561,low,0.1111,253,1.0,Defunct,"H. R. 7913 To require a notice be submitted to the Register of Copyrights with respect to copyrighted works used in building generative AI systems, and for other purposes. IN THE HOUSE OF REPRESENTATIVES April 9, 2024 Mr. Schiff introduced the following bill; which was referred to the Committee on the Judiciary A BILL To require a notice be submitted to the Register of Copyrights with respect to copyrighted works used in building generative AI systems, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Generative AI Copyright Disclosure Act of 2024”. SEC. 2. NOTICE TO BE SUBMITTED TO THE REGISTER OF COPYRIGHTS WITH RESPECT TO COPYRIGHTED WORKS USED IN BUILDING GENERATIVE AI SYSTEMS. (a) Notice.— (1) REQUIREMENT.—A person who creates a training dataset, or alters a training dataset (including by making an update to, refining, or retraining the dataset) in a significant manner, that is used in building a generative AI system shall submit to the Register a notice that contains— (A) a sufficiently detailed summary of any copyrighted works used— (i) in the training dataset (in the case that the person creates the dataset); or (ii) to alter the training dataset (in the case that the person alters the training data in a significant manner); and (B) the URL for such dataset (in the case of a training dataset that is publicly available on the inter",https://www.congress.gov/bill/118th-congress/house-bill/7913/text,en,"Risk factors: Transparency, Harms: Harm to property, Strategies: Disclosure, Strategies: Disclosure: About inputs, Incentives: Civil liability, Incentives: Fines, Strategies: Disclosure: In standard form"
878,Export Controls Enforcement Improvement Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9823,low,0.0,229,0.5,Defunct,"S. 4085 To establish the Export Enforcement Coordination Center in the Department of Homeland Security, and for other purposes. IN THE SENATE OF THE UNITED STATES April 9, 2024 Mr. Romney (for himself and Ms. Hassan) introduced the following bill; which was read twice and referred to the Committee on Banking, Housing, and Urban Affairs A BILL To establish the Export Enforcement Coordination Center in the Department of Homeland Security, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Export Controls Enforcement Improvement Act of 2024”. SEC. 2. ESTABLISHMENT OF EXPORT ENFORCEMENT COORDINATION CENTER. (a) Establishment.—The Secretary of Homeland Security shall establish, within the Department of Homeland Security for administrative purposes, an interagency Federal Export Enforcement Coordination Center (in this Act referred to as the “Center”). (b) Purposes.—The Center shall coordinate on matters relating to export enforcement among the following: (1) The Department of State. (2) The Department of the Treasury. (3) The Department of Defense. (4) The Department of Justice. (5) The Department of Commerce. (6) The Department of Energy. (7) The Department of Homeland Security. (8) The Office of the Director of National Intelligence. (9) Such other executive branch departments, agencies, or offices as the President, from time to time, may des",https://www.congress.gov/bill/118th-congress/senate-bill/4085/text,en,
879,Emerging Innovative Border Technologies Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.985,low,0.0556,234,0.7,Defunct,"H. R. 7832 To require the Secretary of Homeland Security to develop a plan to identify, integrate, and deploy new, innovative, disruptive, or other emerging or advanced technologies to enhance, or address capability gaps in, border security operations, and for other purposes. IN THE HOUSE OF REPRESENTATIVES March 29, 2024 Mr. Correa (for himself and Mr. Luttrell) introduced the following bill; which was referred to the Committee on Homeland Security A BILL To require the Secretary of Homeland Security to develop a plan to identify, integrate, and deploy new, innovative, disruptive, or other emerging or advanced technologies to enhance, or address capability gaps in, border security operations, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Emerging Innovative Border Technologies Act”. SEC. 2. INNOVATIVE AND EMERGING BORDER TECHNOLOGY PLAN. (a) In General.—Not later than 180 days after the date of the enactment of this Act, the Secretary of Homeland Security, acting through the Commissioner of U.S. Customs and Border Protection (CBP) and the Under Secretary for Science and Technology of the Department of Homeland Security, shall submit to the Committee on Homeland Security of the House of Representatives and the Committee on Homeland Security and Governmental Affairs of the Senate a plan to identify, integrate, and deploy new, innovativ",https://www.congress.gov/bill/118th-congress/house-bill/7832/text,en,"Strategies: Government support, Strategies: Government support: For R&D, Risk factors: Security, Strategies: Government study or report, Strategies: Governance development, Applications: Government: military and public safety"
880,Federal Improvement in Technology Procurement Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9413,low,0.0,212,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Federal Improvement in Technology Procurement Act” or the “FIT Procurement Act”.SEC. 2. FINDINGS. Congress makes the following findings: (1) The Government Accountability Office (GAO) has conducted a trend analysis of Government-wide contracting for each of the last several fiscal years. These analyses show that the Federal dollars obligated through contracts has been steadily increasing. (2) Contract spending accounts for more than 80 percent of the Federal information technology budget. (3) Spending on information security, software, cloud computing, data center solutions and services, software as a service, and artificial intelligence technologies is projected to grow significantly. (4) Rapid technological developments and increased Government demand create a need for a Federal acquisition workforce with an understanding of technology and related procurement considerations. (5) Federal agencies are challenged to shorten the procurement cycle to meet agency technology requirements. Technology acquired through procurements that take years from requirements development to implementation may be obsolete by the time it is fielded. (6) While Federal contracting dollars are increasing year over year, and the number of new business applications filed is at an all-time high, the number of Federal contractors receiving contract awards is shrinking. This trend could impair the Federal Government’s access to innovative commercial t",https://www.congress.gov/bill/118th-congress/senate-bill/4066/text,en,"Strategies: Government support, Strategies: Government support: AI workforce-related, Strategies: Government study or report, Strategies: New institution"
881,Contraband Awareness Technology Catches Harmful Fentanyl Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.966,low,0.0,214,0.5,Defunct,"SECTION 1. SHORT TITLES. This Act may be cited as the “Contraband Awareness Technology Catches Harmful Fentanyl Act” or the “CATCH Fentanyl Act”.SEC. 2. DEFINITIONS. In this Act: (1) APPROPRIATE CONGRESSIONAL COMMITTEES.—The term “appropriate congressional committees” means— (A) the Committee on Homeland Security and Governmental Affairs of the Senate; and (B) the Committee on Homeland Security of the House of Representatives. (2) ARTIFICIAL INTELLIGENCE; AI.—The terms “artificial intelligence” and “AI” have the meaning given the term “artificial intelligence” in section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Public Law 115–232; 10 U.S.C. 4061 note). (3) CBP INNOVATION TEAM.—The term “CBP Innovation Team” means the U.S. Customs and Border Protection Innovation Team within the Office of the Commissioner. (4) NONINTRUSIVE INSPECTION TECHNOLOGY; NII TECHNOLOGY.—The terms “nonintrusive inspection technology” and “NII technology” means technical equipment and machines, such as X-ray or gamma-ray imaging equipment, that allow cargo inspections without the need to open the means of transport and unload the cargo. (5) PILOT PROJECTS.—The term “pilot projects” means the projects required under section 3(a) for testing and assessing the use of technologies to improve the inspection process at land ports of entry.SEC. 3. PILOT PROJECTS ALLOWING ADDITIONAL TECHNOLOGY PROVIDERS TO PARTICIPATE IN INSPECTING CARS, TRUCKS, AND CARGO CONTAINERS A",https://www.congress.gov/bill/118th-congress/senate-bill/4062/text,en,
882,AI PLAN Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.4404,low,0.1667,240,0.7,Defunct,"H. R. 7781 To require a report on the economic and national security risks posed by the use of artificial intelligence in the commission of financial crimes, including fraud and the dissemination of misinformation, and for other purposes. IN THE HOUSE OF REPRESENTATIVES March 21, 2024 Mr. Nunn of Iowa (for himself and Ms. Spanberger) introduced the following bill; which was referred to the Committee on Financial Services A BILL To require a report on the economic and national security risks posed by the use of artificial intelligence in the commission of financial crimes, including fraud and the dissemination of misinformation, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Artificial Intelligence Practices, Logistics, Actions, and Necessities Act” or the “AI PLAN Act”. SEC. 2. REPORT ON RISKS POSED BY THE USE OF ARTIFICIAL INTELLIGENCE. (a) Sense Of Congress.—It is the sense of Congress that the development and use of artificial intelligence in the commission of financial crimes by adversarial actors poses a significant risk to the national and economic security of the United States. (b) Report On Risks Posed By Misinformation, Fraud, And Financial Crime Conducted With Artificial Intelligence.— (1) IN GENERAL.—Not later than 180 days after the date of the enactment of this Act and annually thereafter, the Secretary of the Treasury, th",https://www.congress.gov/bill/118th-congress/house-bill/7781/text,en,"Harms: Detrimental content, Harms: Financial loss, Strategies: Government study or report, Applications: Finance and investment, Harms: Violation of civil or human rights, including privacy, Strategies: Governance development"
883,Protecting Consumers from Deceptive AI Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8625,low,0.2778,238,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Protecting Consumers from Deceptive AI Act”.SEC. 2. FINDINGS. This Congress finds the following: (1) The majority of Americans consume most of their information online from social media platforms. A 2023 Pew Research survey found that a large majority of U.S. adults (86 percent) say they often or sometimes get news from a smartphone, computer or tablet, including 56 percent who say they do so often. (2) The increasing capabilities of generative artificial intelligence models has led to a marked increase in the creation of convincing “deepfakes” and greater difficulty for everyday Americans in telling real and deepfake images, audio, and videos apart. A December 2022 study found participants were only 62 percent accurate when asked to determine whether images were deepfake or real, and even worse, that their self-reported confidence in their answers was high, and unrelated to accuracy. (3) Deepfakes create consumer deception issues, where persons can create “deepfake” images and videos to fool consumers about information related to products they may wish to purchase. Fake celebrity endorsements of various products and scams have proliferated in the past year, including an ad in which a deepfake of famous actor Tom Hanks endorsed a dental insurance plan. (4) The proliferation of deepfakes can also create national security issues, such as a deepfake image of an explosion at the Pentagon that was shared widely last year and ca",https://www.congress.gov/bill/118th-congress/house-bill/7766/text,en,"Risk factors: Transparency, Risk factors: Safety, Harms: Financial loss, Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content, Applications: Consumer goods, Applications: Broadcasting and media production, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Government study or report, Strategies: Governance development, Strategies: New institution, Incentives: Access to business opportunities"
885,American Economic Independence Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9805,low,0.0,258,0.5,Defunct,"S. 4026 To require a report on the state of economic integration between the United States and the People's Republic of China and the risks of that integration to the national security of the United States. IN THE SENATE OF THE UNITED STATES March 21, 2024 Mr. Romney (for himself, Ms. Cortez Masto, Mr. Lankford, Mr. Brown, Mr. Cornyn, and Mr. Young) introduced the following bill; which was read twice and referred to the Committee on Finance A BILL To require a report on the state of economic integration between the United States and the People's Republic of China and the risks of that integration to the national security of the United States. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “American Economic Independence Act of 2024”. SEC. 2. REPORT ON ECONOMIC INTEGRATION BETWEEN THE UNITED STATES AND THE PEOPLE'S REPUBLIC OF CHINA AND RISKS TO THE NATIONAL SECURITY OF THE UNITED STATES. (a) In General.—Not later than one year after the date of the enactment of this Act, and every 3 years thereafter for 15 years, the President, acting through the Director of the Office of Management and Budget (in this section referred to as the “Director” ), and in consultation with the officials specified in subsection (c), shall submit to Congress a report on— (1) the state of economic integration between the United States and the People's Republic of China; and (2) the ris",https://www.congress.gov/bill/118th-congress/senate-bill/4026/text,en,
886,Living Wage for Musicians Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.4767,low,0.0556,233,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Living Wage for Musicians Act of 2024”.SEC. 2. ARTIST COMPENSATION ROYALTY FUND. (a) Establishment.— (1) IN GENERAL.—The Register, with the approval of the Librarian of Congress, shall designate an eligible entity to establish and administer a fund to be known as the Artist Compensation Royalty Fund. (2) NOTICE OF DESIGNATION IN FEDERAL REGISTER.—Not later than 30 days after the eligible entity is designated under paragraph (1), the Register shall publish a notice in the Federal Register that— (A) includes the contact information for the eligible entity; and (B) the reason for why the Register designated the eligible entity under such paragraph.(b) Deposit Of Amounts Into Fund.— (1) DEPOSIT.—The Fund Administrator shall deposit into the Fund any amounts received by the Fund Administrator under paragraph (2) or (3). (2) AMOUNTS FROM SERVICE PROVIDERS.—Not later than the last day of the first calendar quarter after the calendar quarter in which the Fund administrator is designated, and each calendar quarter thereafter, a service provider shall provide to the Fund Administrator, for deposit into the Fund— (A) the amounts collected by the service provider in the prior calendar quarter from the living wage royalty fee; and (B) 10 percent of any non-subscription revenue received by the service provider in the prior calendar quarter. (3) AMOUNTS FROM SOURCES OTHER THAN SERVICE PROVIDERS.—The Fund Administrator may receive amounts",https://www.congress.gov/bill/118th-congress/house-bill/7763/text,en,"Harms: Financial loss, Strategies: Government support, Applications: Broadcasting and media production, Strategies: Disclosure, Strategies: Government study or report, Incentives: Fines, Incentives: Civil liability"
887,CONSENT Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.6166,low,0.0,233,0.5,Defunct,"S. 3986 To establish a private right of action against a person who sends unsolicited visual depictions of sexually explicit conduct. IN THE SENATE OF THE UNITED STATES March 20, 2024 Mr. Schatz (for himself and Mr. Daines) introduced the following bill; which was read twice and referred to the Committee on the Judiciary A BILL To establish a private right of action against a person who sends unsolicited visual depictions of sexually explicit conduct. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Curbing Online Non-consensual Sexually Explicit Nudity Transfers Act” or the “CONSENT Act”. SEC. 2. TRANSMISSION OF UNSOLICITED VISUAL DEPICTIONS OF SEXUALLY EXPLICIT CONDUCT. (a) Definitions.— (1) IN GENERAL.—In this section: (A) CONSENT.—The term “consent” has the meaning given the term in section 1309 of the Violence Against Women Act Reauthorization Act of 2022 (15 U.S.C. 6851). (B) MACHINE-MANIPULATED MEDIA.—The term “machine-manipulated media” means a video, image, or audio recording generated or substantially modified using machine-learning techniques in order to— (i) falsely depict— (I) an event; or (II) the speech or conduct of an individual; or (ii) depict an individual who does not exist. (C) SEXUALLY EXPLICIT CONDUCT.—The term “sexually explicit conduct” has the meaning given the term in section 2256(2)(B) of title 18, United States Code. (D) THIRD-PARTY",https://www.congress.gov/bill/118th-congress/senate-bill/3986/text,en,
888,Targeting Online Sales of Fentanyl Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.5423,low,0.0,214,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Targeting Online Sales of Fentanyl Act”. SEC. 2. GAO STUDY ON THE SALE OF ILLICIT DRUGS ONLINE. (a) Study.—The Comptroller General of the United States shall conduct a study on the online sale of fentanyl and methamphetamine, including— (1) business models employed by online sellers of fentanyl and methamphetamine, including an examination of supply chains, logistics, and strategies utilized for customer acquisition, retention, and communication within illicit online marketplaces; (2) utilization of online illicit drug markets and providers (as defined in section 2258E of title 18, United States Code) for facilitating financial transactions in the online sale of fentanyl and methamphetamine, with a particular focus on their impact on individuals who are 18 years of age and younger; (3) efforts of the Federal Government to combat the online sale of fentanyl and methamphetamine, including— (A) interagency collaboration, including personnel detailed to other agencies to support efforts to combat the online trafficking of fentanyl and methamphetamine, and related illicit finance; (B) intergovernmental collaboration between the Federal Government and State, Tribal, local, and foreign governments; (C) intersectoral collaboration with the private sector, including businesses and non-governmental organizations; (D) examination of existing procedures followed by Federal law enforcement agencies in handling cases related to online s",https://www.congress.gov/bill/118th-congress/house-bill/7730/text,en,
889,AI CONSENT Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.986,low,0.1667,228,0.7,Defunct,"S. 3975 To require companies to receive consent from consumers to having their data used to train an artificial intelligence system. IN THE SENATE OF THE UNITED STATES March 19, 2024 Mr. Welch (for himself and Mr. Luján) introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To require companies to receive consent from consumers to having their data used to train an artificial intelligence system. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Artificial Intelligence Consumer Opt-in, Notification, Standards, and Ethical Norms for Training Act” or the “AI CONSENT Act”. SEC. 2. DEFINITIONS. In this Act: (1) ARTIFICIAL INTELLIGENCE SYSTEM.—The term “artificial intelligence system” means a machine-based system that— (A) is capable of influencing the environment by producing an output, including predictions, recommendations or decisions, for a given set of objectives; and (B) uses machine or human-based data and inputs to— (i) perceive real or virtual environments; (ii) abstract these perceptions into models through analysis in an automated manner (such as by using machine learning) or manually; and (iii) use model inference to formulate options for outcomes. (2) COMMISSION.—The term “Commission” means the Federal Trade Commission. (3) COVERED DATA.—The term “covered data” means information",https://www.congress.gov/bill/118th-congress/senate-bill/3975/text,en,"Risk factors: Transparency, Strategies: Disclosure, Strategies: Disclosure: In deployment, Risk factors: Security, Risk factors: Privacy, Strategies: Disclosure: About inputs, Strategies: Governance development, Strategies: Government study or report, Strategies: Evaluation, Incentives: Fines, Incentives: Civil liability"
891,No AI Audits Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9847,low,0.1111,221,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “No AI Audits Act”.SEC. 2. LIMITS ON THE USE OF ARTIFICIAL INTELLIGENCE BY INTERNAL REVENUE SERVICE. (a) Limitations On The Use Of Artificial Intelligence For Audit Or Investigation.—Section 7803(a) of the Internal Revenue Code of 1986 is amended by adding at the end the following new paragraph: “(5) LIMITATIONS ON THE USE OF ARTIFICIAL INTELLIGENCE FOR AUDIT OR INVESTIGATION.— “(A) GUIDANCE.—Notwithstanding subsection (b) of section 553 of title 5, United States Code, any guidance issued by the Commissioner relating to the use of artificial intelligence for selection for or initiation of an audit or investigation by the Internal Revenue Service shall be subject to the requirements of such section as if such guidance were a rule making. “(B) EXPLAINABILITY REQUIREMENT.—The Commissioner may not conduct an audit or investigation initiated as result of analysis or selection by artificial intelligence unless the Commissioner determines that such artificial intelligence meets the explainability principles for artificial intelligence established by the Director of the National Institute of Standards and Technology. “(C) ARTIFICIAL INTELLIGENCE.—For purposes of this paragraph, the term ‘artificial intelligence’ has the meaning given such term in section 5002 of the National Artificial Intelligence Initiative Act of 2020.”.(b) Comptroller General Report.—The Comptroller General of the United States shall conduct an audit of, and is",https://www.congress.gov/bill/118th-congress/house-bill/7694/text,en,"Risk factors: Interpretability and explainability, Applications: Government: other applications/unspecified, Strategies: Performance requirements, Strategies: Government study or report, Strategies: Evaluation, Strategies: Disclosure, Risk factors: Transparency"
894,Methane Emissions Mitigation Research and Development Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8647,low,0.0,213,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Methane Emissions Mitigation Research and Development Act”.SEC. 2. METHANE EMISSION DETECTION AND MITIGATION. (a) In General.—Subtitle F of title IX of the Energy Policy Act of 2005 (42 U.S.C. 16291 et seq.) is amended by adding at the end the following new section: “SEC. 969E. METHANE LEAK DETECTION AND MITIGATION. “(a) Technical Assistance.— “(1) IN GENERAL.—The Secretary, in consultation with the Administrator of the Environmental Protection Agency, the Secretary of Commerce, and the heads of other appropriate Federal agencies, shall carry out a program of methane emissions detection and mitigation research, development, and demonstration for technologies and methods that significantly detect, quantify, and mitigate methane emissions. In carrying out the program, the Secretary shall— “(A) enter into cooperative agreements with State or local governments, institutions of higher education, or for-profit entities to provide technical assistance to— “(i) prevent or respond to methane releases, including prediction, detection, mitigation, quantification, and identification of leaks, vents, and other outflows throughout the natural gas infrastructure (including natural gas storage, pipelines, and natural gas production sites); and “(ii) protect public health in the event of a major methane release; “(B) in coordination with representatives from private sector entities, State and local governments, and institutions of higher e",https://www.congress.gov/bill/118th-congress/house-bill/7651/text,en,
896,Preparing Election Administrators for AI Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.87,low,0.1111,232,0.7,Defunct,"S. 3897 To require the Election Assistance Commission to develop voluntary guidelines for the administration of elections that address the use and risks of artificial intelligence technologies, and for other purposes. IN THE SENATE OF THE UNITED STATES March 11, 2024 Ms. Klobuchar (for herself and Ms. Collins) introduced the following bill; which was read twice and referred to the Committee on Rules and Administration May 15, 2024 Reported by Ms. Klobuchar, with an amendment [Strike out all after the enacting clause and insert the part printed in italic] A BILL To require the Election Assistance Commission to develop voluntary guidelines for the administration of elections that address the use and risks of artificial intelligence technologies, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Preparing Election Administrators for AI Act”. SEC. 2. VOLUNTARY GUIDELINES FOR ADMINISTRATION OF ELECTIONS THAT ADDRESS THE USE AND RISKS OF ARTIFICIAL INTELLIGENCE TECHNOLOGIES. (a) Report And Voluntary Guidelines.—Not later than 60 days after the date of the enactment of this Act, the Election Assistance Commission shall, in consultation with the National Institute of Standards and Technology, submit to Congress, issue to State and local election offices, and make available to the public a report with voluntary guidelines for election offices that",https://www.congress.gov/bill/118th-congress/senate-bill/3897/text,en,"Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content, Strategies: Government study or report, Strategies: Governance development, Applications: Government: other applications/unspecified, Strategies: Disclosure, Strategies: Disclosure: About incidents"
897,Department of Defense Financial Audits Using Artificial Intelligence Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9847,low,0.0,236,0.5,Defunct,"H. R. 7603 To direct the Secretary of Defense to ensure that the audit of the financial statements of the Department of Defense for fiscal year 2024 is conducted using technology that uses artificial intelligence, and for other purposes. IN THE HOUSE OF REPRESENTATIVES March 8, 2024 Mr. Schweikert introduced the following bill; which was referred to the Committee on Armed Services, and in addition to the Committee on Appropriations, for a period to be subsequently determined by the Speaker, in each case for consideration of such provisions as fall within the jurisdiction of the committee concerned A BILL To direct the Secretary of Defense to ensure that the audit of the financial statements of the Department of Defense for fiscal year 2024 is conducted using technology that uses artificial intelligence, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. USE OF TECHNOLOGY USING ARTIFICIAL INTELLIGENCE TO FACILITATE AUDIT OF THE FINANCIAL STATEMENTS OF THE DEPARTMENT OF DEFENSE FOR FISCAL YEAR 2024. (a) Development Of AI Technology For Audits.—The Under Secretary of Defense (Comptroller) and the Inspector General of the Department of Defense shall jointly develop technology that uses artificial intelligence for the purpose of facilitating audits of the financial statements of the Department. (b) Use Of Technology.—The Secretary of Defense shall ensure that— (1) the audit of the finan",https://www.congress.gov/bill/118th-congress/house-bill/7603/text,en,
898,National Patient Safety Board Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9879,low,0.0,230,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “National Patient Safety Board Act of 2024”.SEC. 2. NATIONAL PATIENT SAFETY BOARD. (a) Establishment.—For the purpose of preventing and reducing patient safety events, there is hereby established, within the Office of the Secretary of Health and Human Services, an independent board, to be known as the National Patient Safety Board (in this section referred to as the “Board”).(b) Duties.— (1) IN GENERAL.—For the purpose stated in subsection (a), the Board shall— (A) support Federal departments and agencies in monitoring and anticipating patient safety events; (B) provide expertise to study the context and causes of patient safety events and prevented patient safety events; and (C) formulate recommendations and solutions to prevent patient safety events from occurring. (2) AUTHORITY.—The Board shall have the sole authority to— (A) request changes to, or approve, the patient safety measures and solutions recommended by the Patient Safety Research and Development Division under subsection (g); (B) review each report transmitted to the Board under subsection (g)(7) and based on such review require the Director of such Division— (i) to conduct further studies; or (ii) to make revisions to the report; and (C) make any such report publicly available. (3) TIMELINE FOR PUBLIC AVAILABILITY.—The Board shall ensure that each report transmitted to the Board under subsection (g)(7) is made publicly available not later than one year after",https://www.congress.gov/bill/118th-congress/house-bill/7591/text,en,
901,Protect Victims of Digital Exploitation and Manipulation Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.7367,low,0.1111,225,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Protect Victims of Digital Exploitation and Manipulation Act of 2024”.SEC. 2. DIGITAL FORGERIES OF INTIMATE VISUAL DEPICTIONS. (a) In General.—Chapter 88 of title 18, United States Code, is amended by adding at the end the following: “§ 1802. Prohibition of production or distribution of digital forgeries of intimate visual depictions of identifiable individuals“(a) Offense.—Except as provided in subsection (b), whoever knowingly or recklessly produces or distributes, or causes to be produced or distributed, in or affecting interstate or foreign commerce or using any means, channel, facility, or instrumentality of interstate or foreign commerce, a digital forgery of an identifiable individual, without the consent of the identifiable individual shall be fined under this title, imprisoned not more than 5 years, or both.“(b) Exceptions.— “(1) IN GENERAL.—This section shall not apply with respect to a distribution made in good faith— “(A) to a law enforcement officer or agency; “(B) as part of a legal proceeding; “(C) as part of medical education, diagnosis, or treatment; or “(D) in the reporting or investigation of— “(i) unlawful content; or “(ii) unsolicited or unwelcome conduct. “(2) SERVICE PROVIDERS.—This section shall not apply to any provider of a communications service with regard to content provided by another information content provider unless the provider of the communications service knowingly or recklessly distrib",https://www.congress.gov/bill/118th-congress/house-bill/7567/text,en,"Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content, Incentives: Criminal liability, Incentives: Fines, Incentives: Imprisonment"
902,TAME Extreme Weather Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9454,low,0.0,205,0.5,Defunct,"SECTION 1. SHORT TITLE; TABLE OF CONTENTS. (a) Short Title.—This Act may be cited as the “Transformational Artificial intelligence to Modernize the Economy against Extreme Weather Act” or the “TAME Extreme Weather Act”. (b) Table Of Contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. Sec. 2. Definitions. Sec. 3. Purpose. TITLE I—MATTERS RELATING TO THE NATIONAL OCEANIC AND ATMOSPHERIC ADMINISTRATION Sec. 101. Definitions. Sec. 102. Earth system reanalysis. Sec. 103. Advanced artificial intelligence applications for weather. Sec. 104. Technical assistance on use of artificial intelligence weather models. Sec. 105. Fire combustion modeling program. Sec. 106. Emissions monitoring and analysis program. Sec. 107. Partnerships for transformational innovation. Sec. 108. Retention of Federal Government expertise. Sec. 109. National security. TITLE II—MATTERS RELATING TO THE DEPARTMENT OF AGRICULTURE Sec. 201. Deforestation and illegal wood products. TITLE III—MATTERS RELATING TO THE DEPARTMENT OF ENERGY Sec. 301. Secretary defined. Sec. 302. Grid and transmission optimization. Sec. 303. Preparation of environmental review documents. TITLE IV—AUTHORIZATION OF APPROPRIATIONS Sec. 401. Authorization of appropriations.SEC. 2. DEFINITIONS. In this Act: (1) ARTIFICIAL INTELLIGENCE.— (A) IN GENERAL.—The term “artificial intelligence” means a machine-based system that can, for a given set of human-defined objectives, make predictions, recommend",https://www.congress.gov/bill/118th-congress/senate-bill/3888/text,en,
904,AI Transparency in Elections Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7603,low,0.0556,216,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “AI Transparency in Elections Act of 2024”.SEC. 2. REQUIRING DISCLAIMERS ON ADVERTISEMENTS CONTAINING CONTENT SUBSTANTIALLY GENERATED BY ARTIFICIAL INTELLIGENCE. (a) Requirement.—Section 318 of the Federal Election Campaign Act of 1971 (52 U.S.C. 30120) is amended by adding at the end the following new subsection: “(e) Special Disclaimer For Covered Communications Containing Content Substantially Generated By Artificial Intelligence.—“(1) DEFINITIONS.—For purposes of this subsection: “(A) COVERED COMMUNICATION.— “(i) IN GENERAL.—The term ‘covered communication’ means a communication through any broadcasting station, newspaper, magazine, outdoor advertising facility, mailing, telephone bank, internet or other digital medium, or any other type of general public political advertising that— “(I) expressly advocates for or against the nomination or election of a candidate; “(II) refers to a candidate at any time during the period beginning 120 days before the date of a primary election or nominating caucus or convention and ending on the date on which a general election occurs; or “(III) solicits a contribution for a candidate or political committee or any other person who makes disbursements for communications described in subclause (I) or (II). “(ii) VOICE AND LIKENESS.—A communication that invokes the likeness or voice of a candidate shall be treated as a communication that refers to such candidate. “(B) GENERATIVE ARTIFICIAL",https://www.congress.gov/bill/118th-congress/senate-bill/3875/text,en,"Strategies: Disclosure, Strategies: Disclosure: In deployment, Applications: Government: other applications/unspecified, Harms: Violation of civil or human rights, including privacy, Applications: Broadcasting and media production, Strategies: Disclosure: In standard form, Incentives: Civil liability, Incentives: Fines, Strategies: Governance development, Strategies: Government study or report"
905,Modernizing Retrospective Regulatory Review,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9317,low,0.0,228,0.7,Defunct,"H. R. 7533 To improve retrospective reviews of Federal regulations, and for other purposes. IN THE HOUSE OF REPRESENTATIVES March 5, 2024 Mr. Biggs introduced the following bill; which was referred to the Committee on Oversight and Accountability A BILL To improve retrospective reviews of Federal regulations, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Modernizing Retrospective Regulatory Review”. SEC. 2. IMPROVING RETROSPECTIVE REVIEWS OF FEDERAL REGULATIONS. (a) Report On Availability Of Existing Regulations In Machine-Readable Format.— (1) IN GENERAL.—Not later than 180 days after the date of the enactment of this Act, the Director of the Office of Management and Budget, acting through the Administrator and in consultation with the Director of GPO, the Archivist, and the Director of the Federal Register, shall submit to the appropriate congressional committees, a report on the progress of the Federal Government in making regulations of agencies available in machine-readable format. (2) CONTENTS OF REPORT.—The report required by paragraph (1) shall include— (A) an assessment of whether agency regulations have been made available in a machine-readable format to the public; and (B) information regarding the recognition by the Administrative Committee of the Federal Register of the eCFR maintained by the Director of the Federal Regis",https://www.congress.gov/bill/118th-congress/house-bill/7533/text,en,"Strategies: Government study or report, Strategies: Governance development"
906,Federal AI Governance and Transparency Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9874,high,0.7222,227,0.7,Defunct,"H. R. 7532 To amend chapter 35 of title 44, United States Code, to establish Federal AI system governance requirements, and for other purposes. IN THE HOUSE OF REPRESENTATIVES March 5, 2024 Mr. Comer (for himself, Mr. Raskin, Ms. Mace, Ms. Ocasio-Cortez, Mr. Higgins of Louisiana, Mr. Connolly, Mr. Langworthy, and Mr. Khanna) introduced the following bill; which was referred to the Committee on Oversight and Accountability A BILL To amend chapter 35 of title 44, United States Code, to establish Federal AI system governance requirements, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Federal AI Governance and Transparency Act”. SEC. 2. ESTABLISHMENT OF FEDERAL AGENCY ARTIFICIAL INTELLIGENCE SYSTEM GOVERNANCE REQUIREMENTS. (a) Federal AI System Governance.— (1) AMENDMENT.—Chapter 35 of title 44, United States Code, is amended by adding at the end the following: “SUBCHAPTER IV—ARTIFICIAL INTELLIGENCE SYSTEM GOVERNANCE “§ 3591. Purposes “The purposes of this subchapter, with respect to the design, development, acquisition, use, management, and oversight of artificial intelligence in the Federal Government, are to ensure the following: “(1) Actions that are consistent with the Constitution and any other applicable law and policy, including those addressing freedom of speech, privacy, civil rights, civil liberties, and an open and transparent",https://www.congress.gov/bill/118th-congress/house-bill/7532/text,en,"Risk factors: Transparency, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Risk factors: Reliability, Risk factors: Safety, Risk factors: Security, Risk factors: Reliability: Robustness, Risk factors: Interpretability and explainability, Risk factors: Bias, Applications: Government: other applications/unspecified, Strategies: Governance development, Risk factors: Privacy, Strategies: Government support, Risk factors: Security: Cybersecurity, Harms: Financial loss"
907,Comment Integrity and Management Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9849,low,0.0,239,0.5,Defunct,"H. R. 7528 IN THE SENATE OF THE UNITED STATES May 7, 2024 Received; read twice and referred to the Committee on Homeland Security and Governmental Affairs AN ACT To amend section 206 of the E-Government Act of 2002 to improve the integrity and management of mass comments and computer-generated comments in the regulatory review process, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Comment Integrity and Management Act of 2024”. SEC. 2. PURPOSE. The purpose of this Act is to help Federal agencies manage mass and computer-generated comments in the Federal regulatory process. This should in no way be understood to discourage mass comments, which are a vital part of the regulatory process. SEC. 3. IMPROVING INTEGRITY AND MANAGEMENT OF MASS COMMENTS AND COMPUTER-GENERATED COMMENTS IN THE REGULATORY REVIEW PROCESS. (a) In General.— Section 206 of the E–Government Act of 2002 (Public Law 107–347; 44 U.S.C. 3501 note) is amended by— (1) redesignating subsection (e) as subsection (f); and (2) inserting after subsection (d) the following: “(e) Information Integrity.— “(1) VERIFICATION OF ELECTRONIC SUBMISSIONS.—With respect to each comment accepted by electronic means under subsection (c), in accordance with the guidance established by Director in paragraph (3), the head of an agency shall verify, to the greatest extent possible, at the time the",https://www.congress.gov/bill/118th-congress/house-bill/7528/text,en,
911,Promoting United States Leadership in Standards Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9901,low,0.0,222,0.5,Defunct,"S. 3849 To promote United States leadership in technical standards by directing the National Institute of Standards and Technology and the Department of State to take certain actions to encourage and enable United States participation in developing standards and specifications for artificial intelligence and other critical and emerging technologies, and for other purposes. IN THE SENATE OF THE UNITED STATES February 29, 2024 Mr. Warner (for himself and Mrs. Blackburn) introduced the following bill; which was read twice and referred to the Committee on Commerce, Science, and Transportation A BILL To promote United States leadership in technical standards by directing the National Institute of Standards and Technology and the Department of State to take certain actions to encourage and enable United States participation in developing standards and specifications for artificial intelligence and other critical and emerging technologies, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. SHORT TITLE. This Act may be cited as the “Promoting United States Leadership in Standards Act of 2024”. SEC. 2. DEFINITIONS. In this Act: (1) ARTIFICIAL INTELLIGENCE AND OTHER CRITICAL AND EMERGING TECHNOLOGIES.—The term “artificial intelligence and other critical and emerging technologies” means a subset of artificial intelligence and other critical and emerging technologies included in the list of su",https://www.congress.gov/bill/118th-congress/senate-bill/3849/text,en,
914,Eliminating Abusive and Rampant Neglect of Interactive Technologies Act of 2023 (National Commission on Online Child Sexual Exploitation Prevention),United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.2263,low,0.0556,227,0.7,Defunct,"SEC. 3. NATIONAL COMMISSION ON ONLINE CHILD SEXUAL EXPLOITATION PREVENTION. (a) Establishment.—There is established a National Commission on Online Child Sexual Exploitation Prevention. (b) Purpose.—The purpose of the Commission is to develop recommended best practices that providers of interactive computer services may choose to implement to prevent, reduce, and respond to the online sexual exploitation of children, including the enticement, sex trafficking, and sexual abuse of children and the proliferation of online child sexual abuse material.(c) Membership.— (1) COMPOSITION.— (A) IN GENERAL.—The Commission shall be composed of 19 members. (B) AGENCY HEADS.—The following Federal officials shall serve as members of the Commission: (i) The Attorney General or his or her representative. (ii) The Secretary of Homeland Security or his or her representative. (iii) The Chairman of the Federal Trade Commission or his or her representative. (C) OTHER MEMBERS.—Of the remaining 16 members of the Commission— (i) 4 shall be appointed by the majority leader of the Senate, of whom— (I) 1 shall have the qualifications required under clause (i) or (ii) of paragraph (2)(A); (II) 1 shall have the qualifications required under paragraph (2)(B); (III) 1 shall have the qualifications required under clause (i) or (ii) of paragraph (2)(C); and (IV) 1 shall have the qualifications required under clause (i) or (ii) of paragraph (2)(D); (ii) 4 shall be appointed by the minority leader of the Senate",https://www.congress.gov/bill/118th-congress/senate-bill/1207/text,en,"Strategies: New institution, Risk factors: Safety, Strategies: Government support, Strategies: Convening"
915,"Preserving Telehealth, Hospital, and Ambulance Access Act, Sec. 105 (Report on Wearable Medical Devices)",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9246,low,0.0,104,0.5,Defunct,"SEC. 105. REPORT ON WEARABLE MEDICAL DEVICES. Not later than 18 months after the date of the enactment of this Act, the Comptroller General of the United States shall conduct a technology assessment of, and submit to Congress a report on, the capabilities and limitations of wearable medical devices used to support clinical decision-making. Such report shall include a description of— (1) the potential for such devices to accurately prescribe treatments; (2) an examination of the benefits and challenges of artificial intelligence to augment such capabilities; and (3) policy options to enhance the benefits and mitigate potential challenges of developing or using such devices.",https://www.congress.gov/bill/118th-congress/house-bill/8261/text,en,
917,"Countering Antisemitism Act, Sec. 8 (Online Antisemitism, Holocaust Denial, and Distortion)",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7184,low,0.0,184,0.5,Defunct,"SEC. 8. ONLINE ANTISEMITISM, HOLOCAUST DENIAL, AND DISTORTION. a) Study.—In order to assess steps to counter the spread of antisemitism online, not later than 180 days after the date of enactment of this Act, and every year thereafter for a period of 10 years, the National Coordinator to Counter Antisemitism, in conjunction with the Interagency Task Force to Counter Antisemitism, shall conduct a study and prepare a report that shall include each of the following: (1) An analysis of the prevalence of online antisemitic content, including Holocaust denial and Holocaust distortion content. (2) Recommendations to Congress to counter the spread of antisemitism online, including options for greater transparency requirements relating to algorithmic systems, content moderation, enforcement of community standards, accountability for individuals, and accountability for online platforms. (b) Report.—The National Coordinator to Counter Antisemitism shall make the report available to the Committee on Commerce, Science, and Transportation of the Senate, the Committee on Homeland Security and Governmental Affairs of the Senate, the Committee on Energy and Commerce of the House of Representatives, and the Committee on Oversight and Accountability of the House of Representatives.",https://www.congress.gov/bill/118th-congress/senate-bill/4091/text,en,
982,"Richard L. Trumka Protecting the Right to Organize Act of 2023, Sec. 309 (GAO Report)",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9779,low,0.0,218,0.5,Defunct,"SEC. 309. GAO REPORT. (a) In General.—The Comptroller General, through the Government Accountability Office, shall one year after the date of enactment of this Act commence a study on the impact of Section 101(a) and Section 101(b) of this Act regarding— (1) the effect on coverage of employees under of the National Labor Relations Act, and the impact from such change in coverage, on their capacity in various sectors to form unions and collectively bargain as a means to improve wages, benefits, workplace safety, and other working conditions; and (2) the effect on employers and other enterprises regarding the right of employees to organize and collectively bargain over wages, benefits, workplace safety, and other working conditions in such sectors.(b) Factors.—Such study shall identify, compare, and analyze impacts from changes implicated by Section 101(a) and Section 101(b) on— (1) flexibility for employees with respect to hours, shifts, assignments and working arrangements; (2) rates of compensation, health care, and employee benefits; (3) resolution of grievances and disputes, including employers’ ability to terminate and employees’ right to due process; (4) use of technology or algorithms, including the adoption of new technology and algorithms; and (5) workplace safety and health.(c) Stakeholder Input.—In preparing the report, the Government Accountability Office shall gather information from impacted stakeholders, including various business enterprises and labor organizat",https://www.congress.gov/bill/118th-congress/house-bill/20,en,
984,"Americas Act, Title I (""Administration""), Sec. 103 (""Additional Duties of Institute"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8934,low,0.0,198,0.5,Defunct,"SEC. 103. ADDITIONAL DUTIES OF INSTITUTE. (a) International Cooperation.—The Institute shall seek to promote collaboration between Americas partner countries on the development, standardization, and deployment of e-governance systems, including such systems developed outside the e-governance framework developed under section 102 and systems developed before the implementation of this Act. (b) Development Process.—The Institute shall be responsible for assisting Americas partner countries in the development and deployment of e-governance systems in compliance with the e-governance framework developed under section 102. Such assistance may include the following: (1) The development or adoption, in collaboration with appropriate national and international standards organizations, of technical standards necessary to promote the efficient development of systems under the framework. (2) The development of reference implementations for e-government services, as the Institute considers appropriate. (3) The development and maintenance of infrastructure that may be shared by multiple services, including across multiple Americas partner countries, as the Institute and such countries consider appropriate. (4) Providing technical assistance to Americas partner countries in the development of services, which may include entering into contracts for developing and hosting services on behalf of such countries. Such contracts may include terms for an Americas partner country to provide the Ins",https://www.congress.gov/bill/118th-congress/house-bill/7571/text#toc-HBF92C91AD22842D5B31D68515B8B014D,en,
985,"Americas Act, Title II (""Trade and Investment for the Americas""), Sec. 202 (""Americas Partnership Business Advisory Board"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.6249,low,0.0,201,0.5,Defunct,"SEC. 202. AMERICAS PARTNERSHIP BUSINESS ADVISORY BOARD. (a) Establishment.—The Americas Partnership Secretariat established under section 204 shall establish a business advisory board, which will meet periodically, on an ad hoc basis, at the Secretariat to inform discussions on the business environments of Americas partner countries. (b) Composition.—The business advisory board established under subsection (a) shall be composed of representatives of private sector entities, civil society organizations, and labor organizations from Americas partner countries. (c) Advisory Topics.—The business advisory board established under subsection (a) may provide advice to Americas partner countries through the Secretariat on the following topics relating to the business environment in Americas partner countries: (1) Regulatory hurdles. (2) Labor issues. (3) Dispute resolution challenges. (4) Legal hurdles to investment. (5) Alignment on regulation related to key emerging technologies such as artificial intelligence. (6) Harmonization of reference price systems. (7) Other issues affecting the business community in Americas partner countries. (d) Coordination.—The business advisory board established under subsection (a) shall coordinate with the central regulatory coordinating bodies referred to in Article 28.3 of the USMCA. (e) Annual Report.—Not less frequently than annually, the business advisory board established under subsection (a) shall submit to the Secretariat a report on the busi",https://www.congress.gov/bill/118th-congress/house-bill/7571/text#toc-H47D46EDC2C234F78AB2CD677CE44B834,en,
986,"Americas Act, Title II (""Trade and Investment for the Americas""), Sec. 255 (""Transformational Energy Development"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9798,low,0.0,201,0.5,Defunct,"SEC. 255. TRANSFORMATIONAL ENERGY DEVELOPMENT. (a) Chief Energy Officer.—The BUILD Act of 2018 (22 U.S.C. 9601 et seq.) is amended— (1) in section 1402— (A) by redesignating paragraphs (3) and (4) as paragraphs (5) and (6), respectively; (B) by redesignating paragraph (2) as paragraph (3); (C) by inserting after paragraph (1) the following: “(2) EARLY-STAGE PROJECT TECHNICAL ASSISTANCE.—The term ‘early-stage project technical assistance’ includes— “(A) feasibility studies; “(B) resource evaluations; “(C) project appraisal and costing; “(D) pilot projects; “(E) commercial support, such as trade missions, reverse trade missions, technical workshops, international buyer projects, and international partner searchers to link supplies to projects; “(F) technical assistance and other guidance to improve the local regulatory environment and market frameworks to encourage transparent competition and enhance energy security; and “(G) long-term energy sector planning.”; (D) by inserting after paragraph (3) (as so redesignated) the following: “(4) MULTILATERAL DEVELOPMENT BANKS.—The term ‘multilateral development banks’ has the meaning given that term in section 1701(c) of the International Financial Institutions Act (22 U.S.C. 262r(c)).”; and (E) by adding at the end the following: “(7) TRANSFORMATIONAL ENERGY TECHNOLOGY.—The term ‘transformational energy technology’ means— “(A) renewable energy systems; “(B) hydrogen fuel cell technology for residential, energy, industrial, or transpor",https://www.congress.gov/bill/118th-congress/house-bill/7571/text#toc-H86333C558C404A829B868F8921AF66DC,en,
987,Google DeepMind Frontier Safety Framework Version 1.0,Private-sector companies,,,Corporate policies and commitments,Other,2025-02-04,2025,2,positive,0.7964,medium,0.5,233,0.7,Defunct,"Frontier Safety Framework Version 1.0 The Frontier Safety Framework is our first version of a set of protocols that aims to address severe risks that may arise from poweful capabilities of future foundation models. In focusing on these risks at the model level, it is intended to complement Google’s existing suite of AI responsibility and safety practices, and enable AI innovation and deployment consistent with our AI Principles. In the Framework, we specify protocols for the detection of capability levels at which models may pose severe risks (which we call “Critical Capability Levels (CCLs)”), and aticulate a spectrum of mitigation options to address such risks. We are stating with an initial set of CCLs in the domains of Autonomy, Biosecurity, Cybersecurity, and Machine Learning R&D. Risk assessment in these domains will necessarily involve evaluating cross-cutting capabilities such as agency, tool use, and scientific understanding. We will be expanding our set of CCLs over time as we gain experience and insights on the projected capabilities of future frontier models. We aim to have this initial framework implemented by early 2025, which we anticipate should be well before these risks materialize. The Framework is exploratory and based on preliminary research, which we hope will contribute to and benefit from the broader scientific conversation. It will be reviewed periodically and we expect it to evolve substantially as our understanding of the risks and benefits of front",https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/,en,"Harms: Harm to health/safety, Risk factors: Safety, Strategies: Tiering, Risk factors: Security: Cybersecurity, Risk factors: Security: Dissemination, Strategies: Tiering: Tiering based on impact, Strategies: Tiering: Tiering based on generality, Strategies: Tiering: Tiering based on inputs, Strategies: Tiering: Tiering based on planning ability, Strategies: Governance development, Strategies: Convening, Strategies: Evaluation, Strategies: Disclosure: About evaluation, Strategies: Disclosure: About incidents, Strategies: Disclosure: In deployment"
988,"Countering Communist China Act, Title I (""Matters Related to Trade, Investment, and Economic Relations""), Sec. 101 (""Preventing Adversaries from Developing Critical Capabilities"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.9438,low,0.0,220,0.7,Defunct,"SEC. 101. PREVENTING ADVERSARIES FROM DEVELOPING CRITICAL CAPABILITIES. (a) Short Title.—This section may be cited as the “Preventing Adversaries from Developing Critical Capabilities Act”. (b) Exercise Of Authorities Under The International Emergency Economic Powers Act.— (1) IN GENERAL.—The President may exercise all authorities provided under the International Emergency Economic Powers Act (50 U.S.C. 1701 et seq.) necessary to carry out the provisions of this section, including authorities to impose penalties under section 206 of such Act. (2) DELEGATION.—The President may delegate the authorities described in paragraph (1) to the head of any Federal agency the President determines appropriate in order to carry out the provisions of this section. (c) Prohibition On Covered Activities In Covered Sectors That Pose Particularly Acute Threats To United States National Security.— (1) IDENTIFICATION OF CATEGORIES OF TECHNOLOGIES AND PRODUCTS.— (A) IN GENERAL.—Not later than one year after the date of the enactment of this Act, and annually thereafter as described in subparagraph (B), the President— (i) shall identify categories of technologies and products in covered sectors that may pose a particularly acute threat to the national security of the United States if developed or acquired by a country of concern; and (ii) publish a list of the categories of technologies and products identified under subparagraph (A) in the Federal Register. (B) UPDATES.—The President shall annually",https://www.congress.gov/bill/118th-congress/house-bill/7476/text#toc-H9ECD3593EFEC4D0C91FB287E828C57E0,en,"Strategies: Input controls: Compute circulation, Strategies: Input controls, Strategies: Disclosure, Strategies: Disclosure: About inputs, Strategies: Government support, Strategies: Government study or report, Incentives: Civil liability, Strategies: Input controls: Data use"
990,"Countering Communist China Act, Title I (""Matters Related to Trade, Investment, and Economic Relations""), Sec. 102 (""Sanctions with Respect to Communist Chinese Military and Surveillance Companies"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9858,low,0.0,229,0.7,Defunct,"SEC. 102. SANCTIONS WITH RESPECT TO COMMUNIST CHINESE MILITARY AND SURVEILLANCE COMPANIES. (a) In General.—Not later than 180 days after the date of the enactment of this Act, the President shall impose the sanctions described in subsection (e) with respect to any foreign person determined by the Secretary of the Treasury, in consultation with the Secretary of State and, as the Secretary of the Treasury determines appropriate, the Secretary of Defense, to knowingly engage in significant operations in the defense and related materiel sector or the surveillance technology sector of the economy of the People’s Republic of China. (b) Annual Determination And Report.—Not less frequently than annually, the Secretary of the Treasury shall— (1) undertake the determination described under subsection (a) with respect to foreign persons listed in the Annex to Executive Order 14032 (as amended by any revision to such Annex); and (2) submit a report explaining the results of the determination to the appropriate congressional committees. (c) Assessment.—For the purpose of making the determination described under subsection (a), the Secretary of the Treasury, in consultation with the Secretary of State, the Secretary of Commerce, and the Secretary of Defense, shall— (1) assess whether, under existing authorities, sanctions should be imposed with respect to the activities of— (A) foreign persons listed on the Military End User List (Supplement No. 7 to part 744 of the Export Administration R",https://www.congress.gov/bill/118th-congress/house-bill/7476/text#toc-H9ECD3593EFEC4D0C91FB287E828C57E0,en,"Strategies: Input controls, Incentives: Criminal liability, Incentives: Civil liability"
993,"Countering Communist China Act, Title VII (""Matters Related to Defense""), Sec. 701 (""Modifications to Use of Emergency Sanctions Authorities Regarding Communist Chinese Military Companies"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9439,low,0.0,218,0.7,Defunct,"SEC. 701. MODIFICATION TO USE OF EMERGENCY SANCTIONS AUTHORITIES REGARDING COMMUNIST CHINESE MILITARY COMPANIES. (a) In General.—Section 1237(a)(1) of the Strom Thurmond National Defense Authorization Act for Fiscal Year 1999 (50 U.S.C. 1701 note) is amended— (1) by striking “may exercise” and inserting “shall exercise”; (2) by striking clause (ii); (3) in the matter preceding clause (i), by striking “that—” and inserting “that is engaged in providing commercial services, manufacturing, producing, or exporting and—”; (4) in clause (i), by striking “; and” and inserting “; or”; and (5) by adding at the end the following new clause: “(ii) (I) is owned or controlled by, or affiliated with, the Chinese Communist Party or any person who has ever been a delegate of a National People’s Congress of the Chinese Communist Party; and “(II) is engaged in significant investment in the sectors of fifth-generation wireless communications, artificial intelligence, advanced computing, ‘big data’ analytics, autonomy, robotics, directed energy, hypersonics, or biotechnology.”. (b) Extension Of List Requirement.—Notwithstanding section 1061(i)(6) of the National Defense Authorization Act for Fiscal Year 2017 (10 U.S.C. 111 note), the submission required by subsection (b) of section 1237 of the Strom Thurmond National Defense Authorization Act for Fiscal Year 1999— (1) shall not terminate on December 31, 2021; and (2) shall continue in effect until December 31, 2026.",https://www.congress.gov/bill/118th-congress/house-bill/7476/text#toc-H9ECD3593EFEC4D0C91FB287E828C57E0,en,Strategies: Input controls
994,"Countering Communist China Act, Title VI (""Matters Related to Democracy, Human Rights, and Taiwan""), Sec. 615 (""Deterring America's Technological Adversaries Act"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9689,low,0.0,254,0.7,Defunct,"SEC. 615. DETERRING AMERICA’S TECHNOLOGICAL ADVERSARIES. (a) Short Title.—This section may be cited as the “Deterring America’s Technological Adversaries Act” or the “DATA Act”. (b) Findings.—Congress finds the following: (1) On December 2, 2022, the Director of the Federal Bureau of Investigation, Christopher Wray, stated, “We … do have national security concerns about the app TikTok. Its parent company is controlled by the Chinese government. And it gives them the potential to leverage the app in ways that I think should concern us … One, it gives them the ability to control the recommendation algorithm which allows them to manipulate content and if they want to, to use it for influence operations which are a lot more worrisome in the hands of the Chinese Communist Party than whether or not you’re steering somebody as an influencer to one product or another. They also have the ability to collect data through it on users which can be used for traditional espionage operations, for example. They also have the ability on it to get access, they have essentially access to the software to devices. So you’re talking about millions of devices and that gives them the ability to engage in different kinds of malicious cyber activity through that. And so all of these things are in the hands of a government that doesn’t share our values and that has a mission that’s very much at odds with what’s in the best interest of the United States that that should concern us.”. (2) On December 3, 2",https://www.congress.gov/bill/118th-congress/house-bill/7476/text#toc-H9ECD3593EFEC4D0C91FB287E828C57E0,en,
995,Blueprint for an AI Bill of Rights,Executive Office of the President,United States,Federal government,Editors' Picks,Law/Act,2022-10-01,2022,10,positive,0.9576,high,0.7222,214,1.0,Enacted,"[Introductory material omitted.] BLUEPRINT FOR AN AI BILL OF RIGHTS SAFE AND EFFECTIVE SYSTEMS You should be protected from unsafe or ineffective systems. Automated systems should be developed with consultation from diverse communities, stakeholders, and domain experts to identify concerns, risks, and potential impacts of the system. Systems should undergo pre-deployment testing, risk identification and mitigation, and ongoing monitoring that demonstrate they are safe and effective based on their intended use, mitigation of unsafe outcomes including those beyond the intended use, and adherence to domain-specific standards. Outcomes of these protective measures should include the possibility of not deploying the system or removing a system from use. Automated systems should not be designed with an intent or reasonably foreseeable possibility of endangering your safety or the safety of your community. They should be designed to proactively protect you from harms stemming from unintended, yet foreseeable, uses or impacts of automated systems. You should be protected from inappropriate or irrelevant data use in the design, development, and deployment of automated systems, and from the compounded harm of its reuse. Independent evaluation and reporting that confirms that the system is safe and effective, including reporting of steps taken to mitigate potential harms, should be performed and the results made public whenever possible. ALGORITHMIC DISCRIMINATION PROTECTIONS You should",https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf,en,"Strategies: Convening, Risk factors: Safety, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Evaluation: External auditing, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Risk factors: Reliability, Strategies: Evaluation: Post-market monitoring, Strategies: Performance requirements, Strategies: Disclosure: In standard form, Strategies: Disclosure: About incidents, Strategies: Disclosure: About inputs, Strategies: Disclosure: In deployment"
996,"Farm, Food, and National Security Act of 2024, Title VI (""Rural Development""), Sec. 6303 (""Promoting Precision Agriculture"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.984,low,0.0,209,0.5,Defunct,"SEC. 6303. PROMOTING PRECISION AGRICULTURE. (a) Definitions.—In this section: (1) ADVANCED WIRELESS COMMUNICATIONS TECHNOLOGY.—The term “advanced wireless communications technology” means advanced technology that contributes to mobile (5G or beyond) networks, next-generation Wi-Fi networks, or other future networks using other technologies, regardless of whether the network is operating on an exclusive licensed, shared licensed, or unlicensed frequency band. (2) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence” has the meaning given the term in section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Public Law 115–232; 10 U.S.C. note prec. 4061). (3) FOREIGN ADVERSARY.—The term “foreign adversary” means any foreign government or foreign nongovernment person engaged in a long-term pattern or serious instances of conduct significantly adverse to the national security of the United States, or security and safety of United States persons. (4) PRECISION AGRICULTURE; PRECISION AGRICULTURE TECHNOLOGY.—The terms “precision agriculture” and “precision agriculture technology” have the meanings given the terms in section 1201 of the Food Security Act of 1985. (5) TRUSTED.—The term “trusted” means, with respect to a provider of advanced communications service or a supplier of communications equipment or service, that the Secretary has determined that the provider or supplier is not owned by, controlled by, or subject to the influence of, a",https://www.congress.gov/bill/118th-congress/house-bill/8467/text#toc-HAAB57E5A81BB49B19FECB442CAF53B63,en,
997,"Farm, Food, and National Security Act of 2024, Title VII (""Research, Extension, and Related Matters""), Sec. 7208 (""Centers of Excellence"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9329,low,0.0,224,0.5,Defunct,"SEC. 7208. CENTERS OF EXCELLENCE. Section 1673 of the Food, Agriculture, Conservation, and Trade Act of 1990 (7 U.S.C. 5926) is amended— (1) by striking subsections (a), (b), and (c) and inserting the following: “(a) Centers Of Excellence.— “(1) IN GENERAL.—The Secretary of Agriculture shall establish at least one center of excellence for the purpose of carrying out research, extension, and education activities for each of the areas of focus described in paragraph (3). “(2) HOST INSTITUTIONS.— “(A) IN GENERAL.—Institutions eligible to host or co-host a center of excellence established under this subsection include— “(i) 1862 Institutions, as defined in section 2 of the Agricultural Research, Extension, and Education Reform Act of 1998 (7 U.S.C. 7601); “(ii) 1890 Institutions, as defined in section 2 of the Agricultural Research, Extension, and Education Reform Act of 1998 (7 U.S.C. 7601); “(iii) 1994 Institutions, as defined in section 532 of the Equity in Educational Land-Grant Status Act of 1994 (7 U.S.C. 301 note); “(iv) non-land-grant colleges of agriculture, as defined in section 1404 of the National Agricultural Research, Extension, and Teaching Policy Act of 1977 (7 U.S.C. 3103); “(v) Hispanic-serving agricultural colleges or universities, as defined in section 1404 of the National Agricultural Research, Extension, and Teaching Policy Act of 1977 (7 U.S.C. 3103); and “(vi) accredited schools of veterinary medicine. “(B) DISTRIBUTION.—To the maximum extent practicable,",https://www.congress.gov/bill/118th-congress/house-bill/8467/text#toc-H689458463A6A4EE49D1D5A139B452829,en,
998,"Farm, Food, and National Security Act of 2024, Title VIII (""Forestry""), Sec. 8414 (""Public-Private Wildfire Technology Deployment and Testbed Partnership"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.802,low,0.0,213,0.5,Defunct,"SEC. 8414. PUBLIC-PRIVATE WILDFIRE TECHNOLOGY DEPLOYMENT AND TESTBED PARTNERSHIP. (a) Definitions.—In this section: (1) APPROPRIATE COMMITTEES.—The term “appropriate committees” means— (A) the Committees on Agriculture, Natural Resources, and Science, Space, and Technology of the House of Representatives; and (B) the Committees on Agriculture, Nutrition, and Forestry, Energy and Natural Resources, and Commerce, Science, and Transportation of the Senate. (2) COVERED AGENCY.—The term “covered agency” means— (A) the National Park Service; (B) the United States Fish and Wildlife Service; (C) the Bureau of Land Management; (D) the Bureau of Reclamation; (E) the Forest Service; (F) the Department of Defense; (G) the National Oceanic and Atmospheric Administration; (H) the United States Fire Administration; (I) the Federal Emergency Management Agency; (J) the National Aeronautics and Space Administration; (K) the Bureau of Indian Affairs; and (L) any other Federal agency involved in wildfire response. (3) COVERED ENTITY.—The term “covered entity” means— (A) a private entity; (B) a nonprofit organization; or (C) an institution of higher education (as defined in section 101 of the Higher Education Act of 1965 (20 U.S.C. 1001)). (4) SECRETARIES.—The term “Secretaries” means the Secretary of Agriculture and the Secretary of the Interior, acting jointly. (5) PILOT PROGRAM.—The term “Pilot Program” means the deployment and testbed pilot program developed under subsection (b). (b) Deployme",https://www.congress.gov/bill/118th-congress/house-bill/8467/text#toc-H6F7E0F21D75A4FB79740AFCB59E68694,en,
999,"Coast Guard Authorization Act of 2024, Title II (""Coast Guard""), Sec. 207 (""Report on establishment of unmanned systems capabilities office"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9442,low,0.0,214,0.5,Defunct,"SEC. 207. REPORT ON ESTABLISHMENT OF UNMANNED SYSTEMS CAPABILITIES OFFICE. (a) In General.—Not later than 1 year after the date of enactment of this Act, the Commandant shall submit to the Committee on Transportation and Infrastructure of the House of Representatives and the Committee on Commerce, Science, and Transportation of the Senate a report that outlines a plan for establishing an unmanned systems capabilities office within the Coast Guard responsible for the acquisition and development of unmanned system and counter-unmanned system technologies and to expand the capabilities of the Coast Guard with respect to such technologies. (b) Contents.—The report required under subsection (a) shall include the following: (1) A management strategy for the acquisition, development, and deployment of unmanned system and counter-unmanned system technologies. (2) A service-wide coordination strategy to synchronize and integrate efforts across the Coast Guard in order to— (A) support the primary duties of the Coast Guard pursuant to section 102 of title 14, United States Code; and (B) pursue expanded research, development, testing, and evaluation opportunities and funding to expand and accelerate identification and transition of unmanned system and counter-unmanned system technologies. (3) The identification of contracting and acquisition authorities needed to expedite the development and deployment of unmanned system and counter-unmanned system technologies. (4) A detailed list of co",https://www.congress.gov/bill/118th-congress/house-bill/7659/text#toc-H11DDFAF9604B405E895D357CA6F1E15A,en,
1000,"Coast Guard Authorization Act of 2024, Title III (""Shipping and Navigation""), Sec. 342 (""Establishment of National Advisory Committee on Autonomous Maritime Systems"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9136,low,0.0,213,0.5,Defunct,"SEC. 342. ESTABLISHMENT OF NATIONAL ADVISORY COMMITTEE ON AUTONOMOUS MARITIME SYSTEMS. (a) In General.—Chapter 151 of title 46, United States Code, is amended by adding at the end the following: “§ 15110. Establishment of National Advisory Committee on Autonomous Maritime Systems “(a) Establishment.—There is established a National Advisory Committee on Autonomous Maritime Systems (in this section referred to as the ‘Committee’). “(b) Function.—The Committee shall advise the Secretary on matters relating to the regulation and use of Autonomous Systems within the territorial waters of the United States. “(c) Membership.— “(1) IN GENERAL.—The Committee shall consist of 9 members appointed by the Secretary in accordance with this section and section 15109. “(2) EXPERTISE.—Each member of the Committee shall have particular expertise, knowledge, and experience in matters relating to the function of the Committee. “(3) REPRESENTATION.—Each of the following groups shall be represented by at least 1 member on the Committee: “(A) Marine safety or security entities. “(B) Vessel design and construction entities. “(C) Entities engaged in the production or research of unmanned vehicles, including drones, autonomous or semi-autonomous vehicles, or any other product or service integral to the provision, maintenance, or management of such products or services. “(D) Port districts, authorities, or terminal operators. “(E) Vessel operators. “(F) National labor unions representing merchant marin",https://www.congress.gov/bill/118th-congress/house-bill/7659/text#toc-HA556F28A06544055981909E9182CFF21,en,
1001,"21st Century Peace through Strength Act, Division D (""Protecting Americans from Foreign Adversary Controlled Applications Act"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.3397,low,0.0,218,0.5,Defunct,"DIVISION D—PROTECTING AMERICANS FROM FOREIGN ADVERSARY CONTROLLED APPLICATIONS ACT SEC. 1. SHORT TITLE. This division may be cited as the “Protecting Americans from Foreign Adversary Controlled Applications Act”. SEC. 2. PROHIBITION OF FOREIGN ADVERSARY CONTROLLED APPLICATIONS. (a) In General.— (1) PROHIBITION OF FOREIGN ADVERSARY CONTROLLED APPLICATIONS.—It shall be unlawful for an entity to distribute, maintain, or update (or enable the distribution, maintenance, or updating of) a foreign adversary controlled application by carrying out, within the land or maritime borders of the United States, any of the following: (A) Providing services to distribute, maintain, or update such foreign adversary controlled application (including any source code of such application) by means of a marketplace (including an online mobile application store) through which users within the land or maritime borders of the United States may access, maintain, or update such application. (B) Providing internet hosting services to enable the distribution, maintenance, or updating of such foreign adversary controlled application for users within the land or maritime borders of the United States. (2) APPLICABILITY.—Subject to paragraph (3), this subsection shall apply— (A) in the case of an application that satisfies the definition of a foreign adversary controlled application pursuant to subsection (g)(3)(A), beginning on the date that is 270 days after the date of the enactment of this Act; and (B) in",https://www.congress.gov/bill/118th-congress/house-bill/8038/text#toc-H808ECDA050C44AE19AA10EFA0F5FA10B,en,
1002,"Department of Peacebuilding Act of 2023, Sec. 107 (""Office of Technology for Peace"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9907,low,0.0,177,0.5,Defunct,"SEC. 107. OFFICE OF TECHNOLOGY FOR PEACE. (a) In General.—There shall be in the Department an Office of Technology for Peace, the head of which shall be the Assistant Secretary for Technology for Peace. The Assistant Secretary for Technology for Peace shall carry out those functions in the Department affecting the awareness, study, ethical implications and impact of evolving existing technologies and developing new technologies, including artificial intelligence, mobile technologies, social media, drones, and data science and information, on the creation and maintenance of domestic and international peace, and disseminate applicable policies and research in consultation with appropriate entities of the Department of State. (b) Grants.—The Assistant Secretary for Technology for Peace shall make grants for the research and development of technologies in transportation, communications, agriculture, medicine, and energy that— (1) are nonviolent in application; (2) encourage the conservation and sustainability of natural resources, including air, water, land, in order to prevent future conflicts regarding scarce resources due to overuse or natural or human-caused disasters, including climate change and pandemics; and (3) promote a green, peaceful economy.",https://www.congress.gov/bill/118th-congress/house-bill/1111/text#toc-HAAEF828A12FE46748B0D634D216088D7,en,
1003,"Department of State, Foreign Operations, and Related Programs Appropriations Act 2024, Title VII (""General Provisions""), Sec. 7032 (""Democracy Programs"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9584,low,0.0,211,0.5,Defunct,"Democracy programs Sec. 7032. (a) Funding.— (1) IN GENERAL.—Of the funds appropriated by this Act under the headings “Development Assistance”, “Economic Support Fund”, “Democracy Fund”, “Assistance for Europe, Eurasia and Central Asia”, and “International Narcotics Control and Law Enforcement”, $2,900,000,000 should be made available for democracy programs. (2) PROGRAMS.—Of the funds made available for democracy programs under the headings “Economic Support Fund” and “Assistance for Europe, Eurasia and Central Asia” pursuant to paragraph (1), not less than $159,240,000 shall be made available to the Bureau of Democracy, Human Rights, and Labor, Department of State. (b) Authorities.— (1) AVAILABILITY.—Funds made available by this Act for democracy programs pursuant to subsection (a) and under the heading “National Endowment for Democracy” may be made available notwithstanding any other provision of law, and with regard to the National Endowment for Democracy (NED), any regulation. (2) BENEFICIARIES.—Funds made available by this Act for the NED are made available pursuant to the authority of the National Endowment for Democracy Act (title V of Public Law 98–164), including all decisions regarding the selection of beneficiaries. (c) Definition Of Democracy Programs.—For purposes of funds appropriated by this Act, the term “democracy programs” means programs that support good governance, credible and competitive elections, freedom of expression, association, assembly, and religio",https://www.congress.gov/bill/118th-congress/senate-bill/2438/text,en,
1007,"National Wildland Fire Risk Reduction Program Act, Sec. 7 (Responsibilities of Program Agencies)",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.6875,low,0.0,210,0.5,Defunct,"SEC. 7. RESPONSIBILITIES OF PROGRAM AGENCIES. (a) National Institute Of Standards And Technology.—The responsibilities of the Director of the National Institute of Standards and Technology with respect to the Program are as follows: (1) RESEARCH AND DEVELOPMENT ACTIVITIES.—The Director of the National Institute of Standards and Technology shall— (A) carry out research on the impact of wildland fires on communities, buildings, and other infrastructure, including structure-to-structure transmission of fire and spread within communities; (B) carry out research on the generation of firebrands from wildland fires and on methods and materials to prevent or reduce firebrand ignition of communities, buildings, and other infrastructure; (C) carry out research on novel materials, systems, structures, and construction designs to harden structures, parcels, and communities to the impact of wildland fires; (D) carry out research on the impact of environmental factors on wildland fire behavior, including wind, terrain, and moisture; and (E) support the development of performance-based tools to mitigate the impact of wildland fires, and work with appropriate groups to promote and assist in the use of such tools, including through model building codes and fire codes, standard test methods, voluntary consensus standards, and construction and retrofit best practices. (2) WILDLAND-URBAN INTERFACE FIRE POST-INVESTIGATIONS.—The Director of the National Institute of Standards and Technology shall—",https://www.congress.gov/bill/118th-congress/house-bill/4584/text,en,
1009,"Kids Online Safety Act, Title II (Filter Bubble Transparency)",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.6652,low,0.0556,204,0.7,Defunct,"TITLE II—FILTER BUBBLE TRANSPARENCYSEC. 201. DEFINITIONS. In this title: (1) ALGORITHMIC RANKING SYSTEM.—The term “algorithmic ranking system” means a computational process, including one derived from algorithmic decision-making, machine learning, statistical analysis, or other data processing or artificial intelligence techniques, used to determine the selection, order, relative prioritization, or relative prominence of content from a set of information that is provided to a user on an online platform, including the ranking of search results, the provision of content recommendations, the display of social media posts, or any other method of automated content selection. (2) APPROXIMATE GEOLOCATION INFORMATION.—The term “approximate geolocation information” means information that identifies the location of an individual, but with a precision of less than 5 miles. (3) COMMISSION.—The term “Commission” means the Federal Trade Commission. (4) CONNECTED DEVICE.—The term “connected device” means an electronic device that— (A) is capable of connecting to the internet, either directly or indirectly through a network, to communicate information at the direction of an individual; (B) has computer processing capabilities for collecting, sending, receiving, or analyzing data; and (C) is primarily designed for or marketed to consumers. (5) INPUT-TRANSPARENT ALGORITHM.— (A) IN GENERAL.—The term “input-transparent algorithm” means an algorithmic ranking system that does not use the user-spe",https://www.congress.gov/bill/118th-congress/house-bill/7891/text,en,"Risk factors: Interpretability and explainability, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About inputs"
1010,"A Stronger Workforce for America Act, Chapter 3 (Performance Accountability)",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.6597,low,0.0,224,0.7,Defunct,"Chapter 3-performance Accountability SEC. 119. PERFORMANCE ACCOUNTABILITY SYSTEM. (a) State Performance Accountability Measures.— (1) PRIMARY INDICATORS OF PERFORMANCE.—Section 116(b)(2)(A) of the Workforce Innovation and Opportunity Act (29 U.S.C. 3141(b)(2)(A)) is amended— (A) in clause (i)— (i) in subclause (II)— (I) by striking “fourth” and inserting “second”; and (II) by inserting “and remain in unsubsidized employment during the fourth quarter after exit from the program” after “the program”; (ii) in subclause (V)— (I) by striking “, during a program year,”; (II) by striking “are in” and inserting “enter into”; and (III) by inserting before the semicolon at the end the following: “within 6 months after the quarter in which the participant enters into the education and training program”; and (iii) by amending subclause (VI) to read as follows: “(VI) of the program participants who received training services and who exited the program during a program year, the percentage of such program participants who completed, prior to such exit, on-the-job training, employer-directed skills development, incumbent worker training, or an apprenticeship.”; (B) in clause (ii)— (i) in subclause (II)— (I) by striking “fourth” and inserting “second”; (II) by inserting “, and who remain in such activities or unsubsidized employment during the fourth quarter after exit from the program” after “the program”; and (III) by striking “and” at the end; (ii) in subclause (III)— (I) by striking “(VI",https://www.congress.gov/bill/118th-congress/house-bill/6655/text,en,"Applications: Government: other applications/unspecified, Strategies: Government support"
1011,"Community and Hydropower Improvement Act, Sec. 4 (Approach to Environmental Review)",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9488,low,0.0,223,0.5,Defunct,"SEC. 4. APPROACH TO ENVIRONMENTAL REVIEW. (a) In General.—Section 2403 of the Energy Policy Act of 1992 (16 U.S.C. 797d) is amended— (1) in the section heading, by striking “THIRD PARTY CONTRACTING BY FERC” and inserting “APPROACH TO ENVIRONMENTAL REVIEW”; (2) in subsection (a)— (A) in the subsection heading, by striking “Environmental Impact Statements” and inserting “Third-Party Contracting By The Federal Energy Regulatory Commission”; and (B) in the first sentence, by striking “Where the Federal” and inserting the following: “(1) ENVIRONMENTAL IMPACT STATEMENTS.—If the Federal”; (3) in subsection (c), by striking “This section” and inserting “This subsection”; (4) by redesignating subsections (b) and (c) as paragraphs (2) and (3), respectively, and indenting appropriately; and (5) by adding at the end the following:“(b) Cooperation With Other Agencies.— “(1) IN GENERAL.—The Federal Energy Regulatory Commission shall request that any Federal, State, or local agency or Indian Tribe with a responsibility under the National Environmental Policy Act of 1969 (42 U.S.C. 4321 et seq.) or comparable State or Tribal law requirements with respect to the licensing of a project cooperate in the preparation of the environmental assessment or environmental impact statement that will be a record basis for the decisions of the applicable agency or Indian Tribe with respect to the applicable application. “(2) EFFECT.—Cooperation under paragraph (1) shall not impair the right of a cooperatin",https://www.congress.gov/bill/118th-congress/senate-bill/1521/text,en,
1014,"Government Surveillance Reform Act of 2023, Title VII (Protection of Car Data from Warrantless Searches)",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9287,low,0.0,230,0.7,Defunct,"TITLE VII—PROTECTION OF CAR DATA FROM WARRANTLESS SEARCHES SEC. 701. PROTECTION OF CAR DATA FROM WARRANTLESS SEARCHES. (a) In General.—Part I of title 18, United States Code, is amended by adding at the end the following: “CHAPTER 124—ACCESSING VEHICLE DATA. “Sec. “2730. Definitions. “2731. Prohibition on access to vehicle data. “2732. Prohibition on use of acquired information as evidence.“§ 2730. Definitions “In this chapter: “(1) ACCESS.—The term ‘access’— “(A) means any retrieval of covered vehicle data, regardless of— “(i) whether the data is obtained as the information is being produced or from digital storage; and “(ii) where the vehicle data is stored or transmitted, including by wire or radio; and “(B) does not include data covered by chapter 119 of this title or section 104 of the Foreign Intelligence Surveillance Act of 1978 (50 U.S.C. 1804). “(2) CONSENT.—The term ‘consent’— “(A) means an affirmative, express, and voluntary agreement that— “(i) states that the person providing the consent is providing consent to a government official to access the digital contents, access credential, or online account information, or other information being sought; “(ii) specifies the type of content, access credential, or online account information the person is providing access to; “(iii) specifies the time period of the covered vehicle data to be accessed; “(iv) informs the person providing consent that consent is optional and that the government official attempting to obtain c",https://www.congress.gov/bill/118th-congress/senate-bill/3234/text,en,
1016,"Border Act of 2024, General Provisions Title",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.6369,low,0.0,207,0.5,Defunct,"GENERAL PROVISIONS—THIS TITLE Sec. 201. (a) The Secretary shall, by March 1, 2025, and quarterly thereafter, provide to the Committees on Appropriations of the House of Representatives and the Senate a report describing changes in performance metrics and operational capabilities relating to border security, immigration enforcement, and immigration services, and the relationship of those changes to actual and projected encounters on the southwest border.(b) The report required by subsection (a) shall also include an analytic assessment of how policy changes and resources provided in this title of this Act impact efficiencies and resource needs for— (1) other programs within the Department; and (2) other Federal Departments and agencies.Sec. 202. (a) Amounts made available in this Act under the heading “U.S. Customs and Border Protection—Procurement, Construction, and Improvements” for acquisition and deployment of border security technology shall be available only as follows: (1) $170,000,000 for the procurement and deployment of autonomous surveillance towers systems in locations that are not currently covered by such systems or technology, as defined in subsection (d); (2) $47,500,000 for the procurement and deployment of mobile surveillance capabilities, including mobile video surveillance systems and for obsolete mobile surveillance equipment replacement, counter-UAS, and small unmanned aerial systems; (3) $25,000,000 for subterranean detection capabilities; (4) $7,500,000",https://www.congress.gov/bill/118th-congress/senate-bill/4361/text,en,
1018,Federal Register Doc. No. 2024-01580. Taking Additional Steps To Address the National Emergency With Respect to Significant Malicious Cyber-Enabled Activities,Department of Commerce,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Law/Act,2024-04-29,2024,4,positive,0.9337,low,0.0,216,0.5,Proposed,"Subpart D—Infrastructure as a Service Providers' Responsibility To Verify the Identity of Their Customers, Special Measures, and the Use of Their Products for Large AI Model Training 7.300 Purpose and scope. 7.301 Definitions and application. 7.302 Customer Identification Program. 7.303 Foreign reseller requirements. 7.304 Customer Identification Program reporting requirements. 7.305 Compliance assessments. 7.306 Customer Identification Program exemptions. 7.307 Special measures for certain foreign jurisdictions or foreign persons. 7.308 Reporting of large AI model training. 7.309 Enforcement. 7.310 Reporting violations. § 7.300 Purpose and scope. Foreign actors may use United States Infrastructure as a Service (IaaS) products for a variety of malicious cyber-enabled activities. In light of these threats, it is the purpose of this subpart to: (a) Require U.S. IaaS providers of U.S. IaaS products to implement programs to maintain certain records related to IaaS Accounts in which foreign persons have an interest and verify the identity of such persons, and to require their foreign resellers to do the same, in order to facilitate law enforcement requests for such records and otherwise implement the provisions of Executive Order 13984 and Executive Order 14110; (b) Prevent foreign persons from using U.S. IaaS products to conduct malicious cyber-enabled activities; and (c) Safeguard the national security of the United States. § 7.301 Definitions and application. For the purposes o",https://www.federalregister.gov/documents/2024/01/29/2024-01580/taking-additional-steps-to-address-the-national-emergency-with-respect-to-significant-malicious,en,
1021,NSTC/OSTP Framework for Nucleic Acid Synthesis Screening,Office of Science and Technology Policy,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2024-04-29,2024,4,positive,0.9761,low,0.0,209,0.5,Enacted,"I. INTRODUCTION In October 2023, President Biden issued a landmark Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence (“Executive Order”). In section 4.4(b), the Executive Order directs the federal government to reduce the risks of misuse of synthetic nucleic acids and improve associated biosecurity measures. The Executive Order requires that OSTP develop a framework to encourage providers of synthetic nucleic acid sequences to implement comprehensive, scalable, and verifiable synthetic nucleic acid procurement screening mechanisms. As the building blocks for life, nucleic acids underpin much of research and development in the life sciences, thereby serving as a critical control point allowing industry to ensure beneficial usage and minimize the risk of misuse. This framework outlines a unified process for screening purchases of synthetic nucleic acids and benchtop nucleic acid synthesis equipment. While the framework will be incorporated into requirements for recipients of federal research funding, including through domestic and international funding documents, broader use of the framework is encouraged. This approach guides providers of synthetic nucleic acids (“Providers”) and manufacturers of benchtop nucleic acid synthesis equipment (“Manufacturers”) to screen purchase orders to identify sequences of concern (SOCs) and assess customer legitimacy. In support of this framework, as directed by section 4.4.(b)(ii) of the Execu",https://www.whitehouse.gov/wp-content/uploads/2024/04/Nucleic-Acid_Synthesis_Screening_Framework.pdf,en,
1025,Inventorship Guidance for AI-Assisted Inventions,Department of Commerce,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2024-02-13,2024,2,positive,0.9637,low,0.0,239,0.5,Enacted,"A. Impact on Examination Procedure and Prior Examination Guidance While this guidance is focused on AI-assisted inventions, portions of the guidance can apply to other types of inventions. To the extent that earlier guidance from the USPTO, including certain sections of the Manual of Patent Examining Procedure (9th Edition, rev. 07.2022, February 2023) (MPEP), is inconsistent with the guidance set forth in this notice, USPTO personnel are to follow these guidelines. The MPEP will be updated in due course. Disclaimer: This guidance does not constitute substantive rulemaking and does not have the force and effect of law. The guidance sets out agency policy with respect to the USPTO's interpretation of the inventorship requirements of the Patent Act in view of decisions by the Supreme Court of the United States (Supreme Court) and the United States Court of Appeals for the Federal Circuit (Federal Circuit). The guidance does not create any right or benefit, substantive or procedural, enforceable by any party against the USPTO. Rejections will continue to be based on the substantive law, and it is those rejections that are appealable to the PTAB and the courts.II. Inventors and Joint Inventors Named on U.S. Patents and Patent Applications Must Be Natural Persons On April 22, 2020, the USPTO issued a pair of decisions denying petitions to name the Device for the Autonomous Bootstrapping of Unified Sentience (DABUS), an AI system, as an inventor on two patent applications. The USPT",https://www.federalregister.gov/documents/2024/02/13/2024-02623/inventorship-guidance-for-ai-assisted-inventions,en,
1026,"USDA Framework for State, Local, Tribal, and Territorial Use of Artificial Intelligence for Public Benefit Administration",Department of Agriculture,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2024-04-29,2024,4,positive,0.9911,low,0.0,216,0.5,Enacted,"1. OVERVIEW Artificial intelligence (AI) is a powerful technology that presents both opportunities and risks for the delivery of public benefits. This framework outlines USDA’s principles and approach to support states, localities, tribes, and territories in responsibly using AI in the implementation and administration of USDA’s nutrition benefits and services. This framework is in response to Section 7.2(b)(ii) of Executive Order 14110 on Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence: 1 (ii) The Secretary of Agriculture shall, within 180 days of the date of this order and as informed by the guidance issued pursuant to section 10.1(b) of this order, issue guidance to state, local, tribal, and territorial public-benefits administrators on the use of automated or algorithmic systems in implementing benefits or in providing customer support for benefit programs administered by the Secretary, to ensure that programs using those systems: (A) maximize program access for eligible recipients; (B) employ automated or algorithmic systems in a manner consistent with any requirements for using merit systems personnel in public-benefits programs; (C) identify instances in which reliance on automated or algorithmic systems would require notification by the state, local, tribal, or territorial government to the Secretary; (D) identify instances when applicants and participants can appeal benefit determinations to a human reviewer for reconsideration and can re",https://www.fns.usda.gov/framework-artificial-intelligence-public-benefit,en,
1027,HHS Public Benefits and AI,Department of Health and Human Services,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2024-04-29,2024,4,positive,0.9953,low,0.0,214,0.5,Enacted,"United States Department of Health & Human Services Plan for Promoting Responsible Use of Artificial Intelligence in Automated and Algorithmic Systems by State, Local, Tribal, and Territorial Governments in Public Benefit Administration Introduction The United States Department of Health and Human Services (HHS) funds billions of dollars in public benefits1 across numerous programs annually. Many of these federally funded programs are administered by state, Tribal, local, and/or territorial government entities (STLTs), serving millions of Americans. Recent advances in the availability of powerful artificial intelligence (AI)2 in automated or algorithmic systems (referred to as “automated systems”3) open up significant opportunities to enhance public benefits program administration to better meet the needs of recipients and to improve the efficiency and effectiveness of those programs. These capabilities do not come without risk, however, and it is incumbent on government agencies to ensure that these technologies are deployed responsibly to get the best of what they offer without imposing significant risks on those administering or being served by these programs. To promote the equitable administration of public benefits, Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence (EO 14110) Section 7.2(b) requires the Secretary of Health and Human Services, in consultation with other agencies, to publish a plan addressing the use of au",https://www.hhs.gov/sites/default/files/public-benefits-and-ai.pdf,en,
1029,"Guidance on Application of the Fair Housing Act to the Advertising of Housing, Credit, and Other Real Estate-Related Transactions through Digital Platforms",Department of Housing and Urban Development,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Law/Act,2024-04-29,2024,4,positive,0.9073,low,0.0,227,0.5,Enacted,"I. Introduction This guidance from HUD’s Office of Fair Housing and Equal Opportunity explains how the Fair Housing Act (“Act”) applies to the advertising of housing, credit, and other real estate-related transactions through digital platforms.In particular, it addresses the increasingly common use of automated systems, such as algorithmic processes and Artificial Intelligence (AI),to facilitate advertisement targeting and delivery. New technologies can be used to target advertising toward some consumers and away from others.This can be done deliberately—for example, when advertisers choose to have their ads directed in a particular way—but it can also can occur through the operation of complex automated systems designed to make ad delivery more efficient in accomplishing an advertiser or ad platform’s purposes. These systems may conclude, for example, that women are more likely than men to click on advertising for certain products, and so direct such ads only to women (or, more precisely, to people they have estimated to be women). Or they may conclude that Black people respond more frequently to certain ad variants than others, and so direct only those ads to Black people.4 Importantly, this can happen without the advertiser’s direction or knowledge, and can even frustrate an advertiser’s intention that an ad be distributed more broadly. Such targeting and delivery, which may be permissible in other contexts, risks violating the Act when used for housing-related ads. As des",https://www.hud.gov/sites/dfiles/FHEO/documents/FHEO_Guidance_on_Advertising_through_Digital_Platforms.pdf,en,
1032,"Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence",Office of Management and Budget,United States,Federal government,Editors' Picks,Regulation,2025-04-03,2025,4,positive,0.992,medium,0.4444,224,0.7,Defunct,"MEMORANDUM FOR THE HEADS OF EXECUTIVE DEPARTMENTS AND AGENCIES FROM: Shalanda D. Young SUBJECT: Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence Artificial intelligence (AI) is one of the most powerful technologies of our time, and the President has been clear that we must seize the opportunities AI presents while managing its risks. Consistent with the AI in Government Act of 2020,1 the Advancing American AI Act,2 and Executive Order 14110 on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence, this memorandum directs agencies to advance AI governance and innovation while managing risks from the use of AI in the Federal Government, particularly those affecting the rights and safety of the public.3 1. OVERVIEW While AI is improving operations and service delivery across the Federal Government, agencies must effectively manage its use. As such, this memorandum establishes new agency requirements and guidance for AI governance, innovation, and risk management, including through specific minimum risk management practices for uses of AI that impact the rights and safety of the public. Strengthening AI Governance. Managing AI risk and promoting AI innovation requires effective AI governance. As required by Executive Order 14110, each agency must designate a Chief AI Officer (CAIO) within 60 days of the date of the issuance of this memorandum. This memorandum describes the roles, responsibilities, seniority",https://www.whitehouse.gov/wp-content/uploads/2024/03/M-24-10-Advancing-Governance-Innovation-and-Risk-Management-for-Agency-Use-of-Artificial-Intelligence.pdf,en,"Applications: Government: military and public safety, Strategies: Convening, Strategies: New institution, Risk factors: Bias, Risk factors: Safety, Risk factors: Security, Strategies: Government support: AI workforce-related, Strategies: Disclosure, Strategies: Evaluation: Impact assessment, Strategies: Government study or report, Strategies: Government support: For R&D, Risk factors: Reliability, Risk factors: Transparency, Strategies: Pilots and testbeds, Strategies: Disclosure: About evaluation"
1033,Increasing AI Capacity Across the Federal Government: AI Talent Surge Progress and Recommendations,Executive Office of the President,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2024-04-26,2024,4,positive,0.9932,low,0.0,238,0.5,Enacted,"I. Executive Summary Artificial intelligence (AI) is one of the most consequential technologies of our time. President Biden and Vice President Harris have been clear that the Federal Government must mitigate the risks of AI so that the nation can harness its benefits. In October 2023, President Biden signed Executive Order 14110, which directed Federal agencies to take broad and cohesive action to promote the safe, secure, and trustworthy development and use of AI. EO 14110 directs actions to strengthen AI safety and security, protect Americans’ privacy, advance equity and civil rights, stand up for consumers and workers, promote innovation and competition, and advance American leadership in AI around the world. Building upon the Executive Order, in March 2024, Vice President Harris announced that the Federal Government will lead by example in its own development and use of AI with the release of policy to promote AI innovation at agencies while protecting the public’s rights and safety. To execute on these priorities, EO 14110 launched a National AI Talent Surge to recruit and retain AI professionals into the Federal Government. The National AI Talent Surge is building a strong and diverse Federal AI workforce to execute on the following priorities: 1. Leveraging AI in Government. The U.S. Government is already using AI to benefit the public across its vast mission areas to include tackling global challenges such as climate change and cancer, and improving the quality and e",https://ai.gov/wp-content/uploads/2024/04/AI-Talent-Surge-Progress-Report.pdf,en,
1034,Government-wide Hiring Authorities for Advancing Federal Government Use of Artificial Intelligence (AI),Office of Personnel Management,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2023-12-29,2023,12,positive,0.9744,low,0.0,225,0.5,Enacted,"Memorandum for Heads of Departments and Agencies From: Kiran A. Ahuja Director Subject: Government-wide Hiring Authorities for Advancing Federal Government Use of Artificial Intelligence (AI) On October 30, 2023, the President signed Executive Order (EO) 14110 titled, “Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence.” Section 1 of the EO establishes the President’s commitment to harvesting the potential of AI through a coordinated plan of implementation across the Federal government: My Administration places the highest urgency on governing the development and use of AI safely and responsibly, and is therefore advancing a coordinated, Federal Government-wide approach to doing so. The rapid speed at which AI capabilities are advancing compels the United States to lead in this moment for the sake of our security, economy, and society. To address this critical hiring need, the EO calls for the advancement of AI across the Federal government. Section 10, subsection 10.2 “Increasing AI talent in Government” requires the U.S. Office of Personnel Management (OPM) to: (d)(i) within 60 days of the date of this order, conduct an evidence-based review on the need for hiring and workplace flexibility, including Federal Government- wide direct-hire authority for AI and related data-science and technical roles, and, where the Director of OPM finds such authority is appropriate, grant it; this review shall include the following job series at all General Schedule",https://chcoc.gov/content/government-wide-hiring-authorities-advancing-federal-government-use-artificial-intelligence,en,
1036,"Pay Flexibility, Incentive Pay, and Leave and Workforce Flexibility Programs for Artificial Intelligence (AI), AI-enabling, and Other Key Technical Employees (OPM)",Office of Personnel Management,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2024-02-27,2024,2,positive,0.981,low,0.0,226,0.5,Enacted,"Agencies have considerable discretionary authority to use a variety of pay flexibility, incentive pay, and leave and workforce flexibility programs to support their recruitment, relocation, and retention efforts for AI, AI-enabling, and other key technical employees. A summary of available flexibilities and programs is provided below with information on where to find additional resources. Most of these flexibilities and authorities can be used without approval from the Office of Personnel Management (OPM). Tips: • Many of the flexibilities below can be used simultaneously and with other human resources tools to enhance an agency’s AI and AI-enabling employee recruitment and retention efforts. For example, an agency may use an OPM-approved direct hire authority to hire a new AI employee, pay the new employee a recruitment incentive, set the new employee’s pay above step 1 of their grade using the superior qualifications and special needs pay setting authority, provide service credit towards a higher annual leave accrual rate based non-Federal AI work experience, and provide alternative work schedule and telework options. • These flexibilities may also be used by agencies to recruit and retain talent more broadly, and may therefore be used for other positions of need within agencies.Pay Flexibilities and Incentive Pay Programs • Recruitment Incentives – Agencies may offer newly appointed employees in difficult-to-fill positions up to 25 percent of basic pay multiplied by the nu",https://chcoc.gov/sites/default/files/Memo%20on%20Pay%20Leave%20Workforce%20Flexibilities%20for%20AI%20AI%20Enabling%20and%20Other%20Technical%20Talent.pdf,en,
1044,"Safe and Responsible AI in Australia Consultation, Interim Response",Government of Australia,Other countries,Other countries,Miscellaneous documents,Other,2024-01-17,2024,1,negative,-0.4772,low,0.0,228,0.5,Enacted,"The Australian Government’s interim response The government recognises that many applications of AI do not present risks that require a regulatory response. For example, AI can help monitor and measure biodiversity or help automate internal business processes. However, we have heard from consultations that the current regulatory framework likely does not sufficiently address known risks presented by AI systems, which enable actions and decisions to be taken at a speed and scale that hasn’t previously been possible. In particular, existing laws likely do not adequately prevent AI-facilitated harms before they occur, and more work is needed to ensure there is an adequate response to harms after they occur. The government is already undertaking work to strengthen existing laws in areas that will help to address known harms with AI. This includes the implementation of privacy law reforms, a review of the Online Safety Act 2021, and introduction of new laws relating to misinformation and disinformation. The government will continue to work with states and territories to consider opportunities to further strengthen regulatory frameworks. However, the submissions identified gaps where it was assessed laws do not sufficiently prevent harms from the deployment of AI systems in legitimate but high-risk contexts. When AI is used in high-risk contexts, harms can be difficult or impossible to reverse such that specific guardrails for AI design, development, deployment and use may be neede",https://storage.googleapis.com/converlens-au-industry/industry/p/prj2452c8e24d7a400c72429/public_assets/safe-and-responsible-ai-in-australia-governments-interim-response.pdf,en,
1045,Australia’s AI Ethics Principles,Government of Australia,Other countries,Other countries,Miscellaneous documents,Other,2019-11-07,2019,11,positive,0.9833,low,0.0,218,0.5,Enacted,"Principles at a glance Human, societal and environmental wellbeing: AI systems should benefit individuals, society and the environment. Human-centred values: AI systems should respect human rights, diversity, and the autonomy of individuals. Fairness: AI systems should be inclusive and accessible, and should not involve or result in unfair discrimination against individuals, communities or groups. Privacy protection and security: AI systems should respect and uphold privacy rights and data protection, and ensure the security of data. Reliability and safety: AI systems should reliably operate in accordance with their intended purpose. Transparency and explainability: There should be transparency and responsible disclosure so people can understand when they are being significantly impacted by AI, and can find out when an AI system is engaging with them. Contestability: When an AI system significantly impacts a person, community, group or environment, there should be a timely process to allow people to challenge the use or outcomes of the AI system. Accountability: People responsible for the different phases of the AI system lifecycle should be identifiable and accountable for the outcomes of the AI systems, and human oversight of AI systems should be enabled.Principles in detail Human, social and environmental wellbeing Throughout their lifecycle, AI systems should benefit individuals, society and the environment. This principle aims to clearly indicate from the outset that AI",https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-framework/australias-ai-ethics-principles,en,
1046,The Bletchley Declaration by Countries Attending the AI Safety Summit,Other multinational,Multinational,Multinational,Multinational,Other,2023-11-01,2023,11,positive,0.9971,low,0.0,232,0.5,Enacted,"Artificial Intelligence (AI) presents enormous global opportunities: it has the potential to transform and enhance human wellbeing, peace and prosperity. To realise this, we affirm that, for the good of all, AI should be designed, developed, deployed, and used, in a manner that is safe, in such a way as to be human-centric, trustworthy and responsible. We welcome the international community’s efforts so far to cooperate on AI to promote inclusive economic growth, sustainable development and innovation, to protect human rights and fundamental freedoms, and to foster public trust and confidence in AI systems to fully realise their potential. AI systems are already deployed across many domains of daily life including housing, employment, transport, education, health, accessibility, and justice, and their use is likely to increase. We recognise that this is therefore a unique moment to act and affirm the need for the safe development of AI and for the transformative opportunities of AI to be used for good and for all, in an inclusive manner in our countries and globally. This includes for public services such as health and education, food security, in science, clean energy, biodiversity, and climate, to realise the enjoyment of human rights, and to strengthen efforts towards the achievement of the United Nations Sustainable Development Goals. Alongside these opportunities, AI also poses significant risks, including in those domains of daily life. To that end, we welcome relevant",https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023,en,
1052,Canada Artificial Intelligence and Data Act (Companion document),Government of Canada,Other countries,Other countries,Miscellaneous documents,Law/Act,2022-06-16,2022,6,positive,0.9936,low,0.0,230,0.5,Proposed,"Introduction Artificial intelligence (AI) systems are poised to have a significant impact on the lives of Canadians and the operations of Canadian businesses. In June 2022, the Government of Canada tabled the Artificial Intelligence and Data Act (AIDA) as part of Bill C-27, the Digital Charter Implementation Act, 2022. The AIDA represents an important milestone in implementing the Digital Charter and ensuring that Canadians can trust the digital technologies that they use every day. The design, development, and use of AI systems must be safe, and must respect the values of Canadians. The framework proposed in the AIDA is the first step towards a new regulatory system designed to guide AI innovation in a positive direction, and to encourage the responsible adoption of AI technologies by Canadians and Canadian businesses. The Government intends to build on this framework through an open and transparent regulatory development process. Consultations would be organized to gather input from a variety of stakeholders across Canada to ensure that the regulations achieve outcomes aligned with Canadian values. The global interconnectedness of the digital economy requires that the regulation of AI systems in the marketplace be coordinated internationally. Canada has drawn from and will work together with international partners – such as the European Union (EU), the United Kingdom, and the United States (US) – to align approaches, in order to ensure that Canadians are protected globally",https://ised-isde.canada.ca/site/innovation-better-canada/en/artificial-intelligence-and-data-act-aida-companion-document,en,
1053,Canadian Guardrails for Generative AI – Code of Practice,Government of Canada,Other countries,Other countries,Miscellaneous documents,Law/Act,2023-08-16,2023,8,positive,0.9878,medium,0.5,229,0.7,Enacted,"Introduction In recent months, generative AI systems—such as ChatGPT, Dall-E 2, and Midjourney—have captured the world's attention. These AI systems are trained on vast datasets of text, images, or other data. Their distinguishing feature is their ability to generate novel content in a wide variety of different forms and contexts. As a result, a single system may be used to perform many different kinds of tasks. For example, a language-based system can perform tasks such as translating, summarizing text, suggesting edits or revisions to text, answering questions, or generating code. While they have many benefits, generative AI systems are powerful tools that can also be used for malicious or inappropriate purposes. Their generative abilities, combined with the broad scale of deployment, contribute to a distinct and potentially wide risk profile. These features have led to an urgent call to action on generative AI, including amongst leading AI industry experts. In recent months, the international community has taken steps toward helping make these systems safer and more trustworthy. For example, the G7 recently launched the Hiroshima AI Process to coordinate discussions on generative AI risks, and in July 2023, U.S. President Joe Biden announced eight voluntary commitments from large AI companies in support of safety, security, and trust. Canada has already taken significant steps toward ensuring that this technology evolves in a safe manner. Canada is well positioned to addre",https://ised-isde.canada.ca/site/ised/en/consultation-development-canadian-code-practice-generative-artificial-intelligence-systems/canadian-guardrails-generative-ai-code-practice,en,"Risk factors: Safety, Harms: Detrimental content, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Disclosure, Strategies: Disclosure: About incidents, Risk factors: Bias, Harms: Violation of civil or human rights, including privacy, Risk factors: Transparency, Strategies: Disclosure: In deployment, Risk factors: Reliability, Risk factors: Reliability: Robustness, Strategies: Evaluation: Adversarial testing, Risk factors: Security: Cybersecurity, Risk factors: Security"
1054,Directive on Automated Decision-Making (Canada),Government of Canada,Other countries,Other countries,Miscellaneous documents,Other,2023-04-25,2023,4,positive,0.8588,medium,0.3889,236,0.7,Enacted,"Directive on Automated Decision-Making 1. Effective date 1.1 This directive takes effect on April 1, 2019, with compliance required by no later than April 1, 2020. 1.2 This directive applies to all automated decision systems developed or procured after April 1, 2020. However, 1.2.1 existing systems developed or procured prior to April 25, 2023 will have until April 25, 2024 to fully transition to the requirements in subsections 6.2.3, 6.3.1, 6.3.4, 6.3.5 and 6.3.6 in this directive; 1.2.2 new systems developed or procured after April 25, 2023 will have until October 25, 2023 to meet the requirements in this directive. 1.3 This directive will be reviewed every two years, and as determined by the Chief Information Officer of Canada. 1. Authorities 2.1 This directive is issued pursuant to the same authority indicated in section 2 of the Policy on Service and Digital. 1. Definitions 3.1 Definitions to be used in the interpretation of this directive are listed in Appendix A. 1. Objectives and expected results 4.1 The objective of this directive is to ensure that automated decision systems are deployed in a manner that reduces risks to clients, federal institutions and Canadian society, and leads to more efficient, accurate, consistent and interpretable decisions made pursuant to Canadian law. 4.2 The expected results of this directive are as follows: 4.2.1 Decisions made by federal institutions are data-driven, responsible and comply with procedural fairness and due process requir",https://www.tbs-sct.canada.ca/pol/doc-eng.aspx?id=32592,en,"Applications: Government: other applications/unspecified, Risk factors: Reliability, Risk factors: Interpretability and explainability, Risk factors: Transparency, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Disclosure: In standard form, Strategies: Disclosure: In deployment, Risk factors: Security, Risk factors: Security: Dissemination, Strategies: Evaluation: External auditing, Strategies: Evaluation: Conformity assessment, Risk factors: Bias"
1064,Regulations of Shenzhen Special Economic Zone on Promoting the Artificial Intelligence Industry,Chinese provincial and local governments,China,China,Chinese law and policy,Regulation,2022-11-01,2022,11,positive,0.9814,low,0.0,210,0.5,Enacted,"Regulations of Shenzhen Special Economic Zone on Promoting the Artificial Intelligence Industry (Adopted at the 11th Session of the Standing Committee of the 7th People’s Congress of Shenzhen Municipality on August 30, 2022) Chapter I General Provisions Article 1 To promote the high-quality development of the artificial intelligence (AI) industry in Shenzhen Special Economic Zone, advance the in-depth integration and application of AI in economic and social fields, and regulate the orderly development of the AI industry, these Regulations are formulated in accordance with the basic principles of relevant laws and administrative regulations and in light of the actual needs of Shenzhen Special Economic Zone. Article 2 Artificial intelligence (AI) as mentioned in these Regulations refers to the simulation, extension or expansion of human intelligence by perceiving the environment, acquiring knowledge or deducing with computers or devices controlled by computers. Article 3 The artificial intelligence (AI) industry as mentioned in these Regulations refers to core industries such as the research, development, production, systematic applications and integrated services of AI-related hardware and software, as well as related industries driven by the integrated application of AI in services for people’s well-being, social governance and economic development. Article 4 The development of the AI industry in Shenzhen Municipality follows the technology-leading, application-driven, people","https://sf.sz.gov.cn/fggzywyb/content/post_11216296.html#:~:text=Article%2037%20Shenzhen%20Municipal%20People's,products%20and%20new%20AI%20models.",en,
1065,New Generation Artificial Intelligence Development Plan,Chinese central government,China,China,Chinese law and policy,Other,2017-07-20,2017,7,positive,0.9871,low,0.0,206,0.5,Enacted,"A New Generation Artificial Intelligence Development Plan The rapid development of artificial intelligence (AI) will profoundly change human society and life and change the world. To seize the major strategic opportunity for the development of AI, to build China’s first-mover advantage in the development of AI, to accelerate the construction of an innovative nation and global power in science and technology, in accordance with the requirements of the CCP Central Committee and the State Council, this plan has been formulated.I. The Strategic Situation The development of AI has entered a new stage. After sixty years of evolution, especially in mobile Internet, big data, supercomputing, sensor networks, brain science, and other new theories and new technologies, under the joint impetus of powerful demands of economic and social development, AI’s development has accelerated, displaying deep learning, cross-domain integration, man-machine collaboration, the opening of swarm intelligence, autonomous control, and other new characteristics. Big data-driven cognitive learning, cross-media collaborative processing, and man-machine collaboration–strengthened intelligence, swarm integrated intelligence, and autonomous intelligent systems have become the focus of the development of AI. The results of brain science research inspired human-like intelligence that awaits action; the trends involving the chips, hardware, and platform have become apparent; the development of AI has entered into",https://digichina.stanford.edu/work/full-translation-chinas-new-generation-artificial-intelligence-development-plan-2017/,en,
1072,AI Liability Directive,European Union,Multinational,Multinational,Multinational,Other,2022-03-03,2022,3,negative,-0.9316,low,0.0,243,0.5,Proposed,"Article 1 Subject matter and scope 1. This Directive lays down common rules on: (a) the disclosure of evidence on high-risk artificial intelligence (AI) systems to enable a claimant to substantiate a non-contractual fault-based civil law claim for damages; (b) the burden of proof in the case of non-contractual fault-based civil law claims brought before national courts for damages caused by an AI system. 1. This Directive applies to non-contractual fault-based civil law claims for damages, in cases where the damage caused by an AI system occurs after [the end of the transposition period]. This Directive does not apply to criminal liability. 1. This Directive shall not affect: (a) rules of Union law regulating conditions of liability in the field of transport; (b) any rights which an injured person may have under national rules implementing Directive 85/374/EEC; (c) the exemptions from liability and the due diligence obligations as laid down in [the Digital Services Act] and (d) national rules determining which party has the burden of proof, which degree of certainty is required as regards the standard of proof, or how fault is defined, other than in respect of what is provided for in Articles 3 and 4. 1. Member States may adopt or maintain national rules that are more favourable for claimants to substantiate a non-contractual civil law claim for damages caused by an AI system, provided such rules are compatible with Union law.Article 2 Definitions For the purposes of this Dir",https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52022PC0496,en,
1074,Commission Decision Establishing the European AI Office,European Union,Multinational,Multinational,Multinational,Other,2024-02-21,2024,2,positive,0.9818,low,0.0,228,0.5,Enacted,"COMMISSION DECISION of 24.1.2024 establishing the European Artificial Intelligence Office THE EUROPEAN COMMISSION, Having regard to the Treaty on the Functioning of the European Union, Whereas: (1) Artificial intelligence (AI) is a fast evolving family of technologies that can contribute to a wide array of economic and societal benefits across the entire spectrum of industries and social activities. At the same time, depending on the circumstances regarding its specific application and use, AI can generate risks and cause harm to public interests and fundamental rights that are protected by Union law. (2) The Commission has proposed a Regulation laying down harmonised rules on artificial intelligence (Artificial Intelligence Act) and amending certain Union legislative acts1, aiming to foster the development, use and uptake of artificial intelligence in the internal market that, at the same time, meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. The proposed Regulation is one of several measures of the Commission aimed to deliver on the twin objective of promoting the uptake of AI and of addressing the risks associated with certain uses of such technology. Further measures include the ‘Coordinated Plan on Artificial Intelligence’ in its review of 20212, initiatives of sectoral policies fostering the uptake of AI or Union funding programmes, such as those establishe",https://digital-strategy.ec.europa.eu/en/library/commission-decision-establishing-european-ai-office,en,
1076,Israel's Policy on Artificial Intelligence: Regulations and Ethics,Government of Israel,Other countries,Other countries,Miscellaneous documents,Regulation,2023-12-18,2023,12,positive,0.9881,low,0.0,211,0.5,Enacted,"Responsible Innovation: Israel's Policy on Artificial Intelligence Regulation and Ethics Introduction Artificial intelligence systems are being increasingly used across the world, in both the private and public sectors. AI systems already have a wide range of applications such as autonomous vehicles, medical imaging analysis, credit scoring, securities trading, personalized learning and employment – and the list of applications is constantly expanding. In the coming years, AI systems are expected to have profound economic and societal impact in diverse fields of activity such as health, education, labor, transportation, finance, agriculture, energy systems, construction, and industrial manufacturing. Along with its many advantages and great economic and societal benefit potential, the use of artificial intelligence presents major challenges for regulators in Israel and across the globe. Those challenges include the risk of bias and discrimination, lack of transparency and human oversight, potential harms to privacy, the vulnerability of AI systems, safety concerns, concerns about accountability and IP related considerations. To help address these challenges, Israel's Ministry of Innovation, Science and Technology published, on December 2023, its first-ever policy on AI regulation and ethics, which recommends concrete steps to foster responsible AI innovation in the private sector (the ""AI Policy""). The AI Policy is the fruit of comprehensive work led by the Ministry, and cond",https://www.gov.il/BlobFolder/news/most-news20231218/en/Israels%20AI%20Policy%202023.pdf,en,
1087,Artificial Intelligence and the Information Privacy Principles,Government of New Zealand,Other countries,Other countries,Miscellaneous documents,Other,2023-09-21,2023,9,positive,0.9758,low,0.3333,233,0.7,Proposed,"Artificial intelligence and the Information Privacy Principles 1. Introduction: Privacy is a starting point for responsible use of AI tools Thinking about privacy is vital if you’re going to use AI tools well. The uptake of these tools has been fast and focused on benefits, like having new ways to crunch data, do creative work, and make processes more efficient. However, there is also deep concern about the potential risks of making processes less transparent, reinforcing biases in data, and disconnecting people from important decisions. This guidance is for all New Zealanders If you’re using, or considering using, AI tools in New Zealand then this guidance is for you. The Privacy Act 2020 applies whenever you collect, use, or share personal information.1 As a rough guide, if you can say who information is about, it is personal information. That includes information like a name, address, contact details, or photographs of a person. It can also include technical metadata like map coordinates, Internet protocol addresses, or device identifiers related to a person. Finally, personal information includes information about a person that is inaccurate or made up, including fake social profiles and deepfake images. When working with personal information (including as part of using digital tools), you need to comply with the information privacy principles (IPPs). The Privacy Act applies to business, government, and community organisations of all sizes, as well as to individuals.2 Pri",https://privacy.org.nz/assets/New-order/Resources-/Publications/Guidance-resources/AI-Guidance-Resources-/AI-and-the-Information-Privacy-Principles.pdf,en,"Risk factors: Privacy, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Risk factors: Transparency, Strategies: Governance development, Risk factors: Bias, Strategies: Convening, Strategies: Disclosure, Strategies: Disclosure: In deployment, Risk factors: Security, Strategies: Disclosure: About inputs, Risk factors: Security: Cybersecurity, Strategies: Disclosure: About incidents, Risk factors: Reliability, Strategies: Evaluation: Conformity assessment"
1088,Initial advice on Generative Artificial Intelligence in the public service (New Zealand),Government of New Zealand,Other countries,Other countries,Miscellaneous documents,Other,2023-07-01,2023,7,positive,0.9826,low,0.0,234,0.5,Enacted,"This advice provides interim guidance on using GenAI in the New Zealand Public Service This guidance provides initial advice from the data, digital, privacy, procurement and security System Leaders about Public Service use of GenAI tools. This document and its attached A3 are intended to support agencies to make more informed decisions about using GenAI, balancing benefits and risks. Whilst we recognise that this guidance could have broader application and usefulness beyond the Public Service, it is intended for Public Service AI practitioners and decision-makers. This advice is the first collective effort of System Leaders to help agencies start to trial and use this new class of technology safely, ethically and in privacy-protecting ways. This guide provides ‘guardrails’ supporting safe learning of GenAI tools and may be updated as the technology evolves and as the risks and their impacts are better understood. It is also an interim measure while longer-term plans for broader GenAI/AI and other emerging technologies issues are developed and progressed by System Leads. Work on economy wide opportunities and impacts, and NZ wide regulatory settings, may also be needed. Who is this advice for? This advice is intended for public service procurement, data, digital, privacy and security leaders. It is intended to help you to better understand the key risks of using GenAI within the New Zealand Public Service, and mitigations, to support you to develop your policy, standards and p",https://www.digital.govt.nz/assets/Standards-guidance/Technology-and-architecture/Generative-AI/Joint-System-Leads-tactical-guidance-on-public-service-use-of-GenAI-September-2023.pdf,en,
1097,Proposed Model AI Governance Framework for Generative AI,Government of Singapore,Other countries,Other countries,Miscellaneous documents,Other,2024-01-16,2024,1,positive,0.9578,low,0.0,225,0.5,Proposed,"EXECUTIVE SUMMARY Generative AI has captured the world’s imagination. While it holds significant transformative potential, it also comes with risks. Building a trusted ecosystem is therefore critical – it helps people embrace AI with confidence, gives maximal space for innovation, and serves as a core foundation to harnessing AI for the Public Good. AI, as a whole, is a technology that has been developing over the years. Prior development and deployment is sometimes termed traditional AI. To lay the groundwork to promote the responsible use of traditional AI, Singapore released the first version of the Model AI Governance Framework in 2019, and updated it subsequently in 2020. The recent advent of generative AI has reinforced some of the same AI risks (e.g. bias, misuse, lack of explainability), and introduced new ones (e.g. hallucination, copyright infringement, value alignment). These concerns were highlighted in our earlier Discussion Paper on Generative AI: Implications for Trust and Governance, issued in June 2023. The discussions and feedback have been instructive. Existing governance frameworks need to be reviewed to foster a broader trusted ecosystem. A careful balance needs to be struck between protecting users and driving innovation. There have also been various international discussions pulling in the related and pertinent topics of accountability, copyright, misinformation, among others. These issues are interconnected and need to be viewed in a practical and holi",https://aiverifyfoundation.sg/downloads/Proposed_MGF_Gen_AI_2024.pdf,en,
1099,Singapore National AI Strategy 2.0,Government of Singapore,Other countries,Other countries,Editors' Picks,Other,2023-12-04,2023,12,positive,0.9887,medium,0.5,230,1.0,Proposed,"[Introductory sections omitted. Footnotes, figures and anecdotal/case study insets omitted throughout; refer to official version.] NATIONAL AI STRATEGY 2.0 Our Vision and Goals Developed through extensive engagements, NAIS 2.0 starts with the conviction that we must do our utmost to harness AI for the Public Good, for Singapore and the World. Singapore will be a place where AI can: - Address the needs and challenges of our time. For example, in areas of global importance such as population health and climate change. - Be the great equaliser. We shall uplift and empower our people and businesses, equipping them with the capabilities and resources to thrive in an AI-enabled future. NAIS 2.0 seeks to attain the twin goals of: Excellence. We will selectively develop peaks of excellence in AI, to advance the field and maximise value creation. Empowerment. We will raise up individuals, businesses, and communities to use AI with confidence, discernment, and trust. Our Plans To achieve our vision and goals, we will direct efforts under NAIS 2.0 toward three Systems, working through 10 Enablers. - System 1: Activity Drivers (Enablers: Industry, Government, Research). Industry, Government, and public research performers have deep technical capabilities that can be applied to deliver value. We need to orchestrate them around meaningful use cases and problem statements to transform our economy and society. - System 2: People & Communities (Enablers: Talent, Capabilities, Placemaking). We",https://file.go.gov.sg/nais2023.pdf,en,"Strategies: Convening, Strategies: Government support, Strategies: Government support: AI workforce-related, Strategies: Government support: For R&D, Applications: Manufacturing and process automation, Applications: Transportation, Applications: Finance and investment, Applications: Medicine, life sciences and public health, Applications: Education, Risk factors: Safety, Applications: Sales, retail, and customer relations, Applications: Business services and analytics, Applications: Government: other applications/unspecified, Strategies: Evaluation, Strategies: Governance development"
1109,Artificial Intelligence (Regulation) Act 2024,Government of the United Kingdom,Other countries,Other countries,Miscellaneous documents,Law/Act,2024-05-10,2024,5,positive,0.9882,medium,0.4444,232,0.7,Proposed,"A BILL TO Make provision for the regulation of artificial intelligence; and for connected purposes. BE IT ENACTED by the King’s most Excellent Majesty, by and with the advice and consent of the Lords Spiritual and Temporal, and Commons, in this present Parliament assembled, and by the authority of the same, as follows:— 1. The AI Authority (1) The Secretary of State must by regulations make provision to create a body called the AI Authority. (2) The functions of the AI Authority are to— (a) ensure that relevant regulators take account of AI; (b) ensure alignment of approach across relevant regulators in respect of AI; (c) undertake a gap analysis of regulatory responsibilities in respect of AI; (d) coordinate a review of relevant legislation, including product safety, privacy and consumer protection, to assess its suitability to address the challenges and opportunities presented by AI; (e) monitor and evaluate the overall regulatory framework’s effectiveness and the implementation of the principles in section 2, including the extent to which they support innovation; (f) assess and monitor risks across the economy arising from AI; (g) conduct horizon-scanning, including by consulting the AI industry, to inform a coherent response to emerging AI technology trends; (h) support testbeds and sandbox initiatives (see section 3) to help AI innovators get new technologies to market; (i) accredit independent AI auditors (see section 5(1)(a)(iv)); (j) provide education and awareness to",https://bills.parliament.uk/publications/53068/documents/4030,en,"Strategies: New institution, Strategies: Evaluation: Impact assessment, Strategies: Evaluation, Strategies: Government support, Strategies: Pilots and testbeds, Strategies: Convening, Risk factors: Safety, Risk factors: Security, Risk factors: Reliability: Robustness, Risk factors: Reliability, Risk factors: Transparency, Risk factors: Privacy, Harms: Discrimination, Strategies: Government support: For R&D, Risk factors: Bias"
1111,Maintaining American Leadership in Artificial Intelligence (EO 13859),Executive Office of the President,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2019-02-11,2019,2,positive,0.9944,medium,0.5556,217,0.7,Enacted,"Section 1 . Policy and Principles. Artificial Intelligence (AI) promises to drive growth of the United States economy, enhance our economic and national security, and improve our quality of life. The United States is the world leader in AI research and development (R&D) and deployment. Continued American leadership in AI is of paramount importance to maintaining the economic and national security of the United States and to shaping the global evolution of AI in a manner consistent with our Nation's values, policies, and priorities. The Federal Government plays an important role in facilitating AI R&D, promoting the trust of the American people in the development and deployment of AI-related technologies, training a workforce capable of using AI in their occupations, and protecting the American AI technology base from attempted acquisition by strategic competitors and adversarial nations. Maintaining American leadership in AI requires a concerted effort to promote advancements in technology and innovation, while protecting American technology, economic and national security, civil liberties, privacy, and American values and enhancing international and industry collaboration with foreign partners and allies. It is the policy of the United States Government to sustain and enhance the scientific, technological, and economic leadership position of the United States in AI R&D and deployment through a coordinated Federal Government strategy, the American AI Initiative (Initiative),",https://www.federalregister.gov/documents/2019/02/14/2019-02544/maintaining-american-leadership-in-artificial-intelligence,en,"Strategies: Governance development, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Harms: Violation of civil or human rights, including privacy, Harms: Financial loss, Risk factors: Safety, Risk factors: Security, Risk factors: Privacy, Applications: Government: other applications/unspecified, Risk factors: Security: Cybersecurity, Strategies: Convening, Strategies: Government study or report, Risk factors: Transparency, Risk factors: Interpretability and explainability"
1112,National Artificial Intelligence Research and Development Strategic Plan 2023 Update,Executive Office of the President,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2023-05-04,2023,5,positive,0.9885,low,0.0,233,0.5,Enacted,"Executive Summary Artificial intelligence (AI)1 is one of the most powerful technologies of our time. In order to seize the opportunities that AI presents, the Nation must first work to manage its risks. The federal government plays a critical role in this effort, including through smart investments in research and development (R&D) that promote responsible innovation and advance solutions to the challenges that other sectors will not address on their own. This includes R&D to leverage AI to tackle large societal challenges and develop new approaches to mitigate AI risks. The federal government must place people and communities at the center by investing in responsible R&D that serves the public good, protects people’s rights and safety, and advances democratic values. This update to the National AI R&D Strategic Plan is a roadmap for driving progress toward that goal. This plan defines the major research challenges in AI to coordinate and focus federal R&D investments. It will ensure continued U.S. leadership in the development and use of trustworthy AI systems, prepare the current and future U.S. workforce for the integration of AI systems across all sectors, and coordinate ongoing AI activities across all federal agencies.2 This plan, which follows national AI R&D strategic plans issued in 2016 and 2019, reaffirms eight strategies and adds a ninth to underscore a principled and coordinated approach to international collaboration in AI research: Strategy 1: Make long-term i",https://www.whitehouse.gov/wp-content/uploads/2023/05/National-Artificial-Intelligence-Research-and-Development-Strategic-Plan-2023-Update.pdf,en,
1115,TTC Joint Roadmap on Evaluation and Measurement Tools for Trustworthy AI and Risk Management,Other multinational,Multinational,Multinational,Multinational,Other,2022-12-01,2022,12,positive,0.9958,low,0.0,225,0.5,Enacted,"1. Background Tangible global leadership by the United States and the European Union can provide scalable, science-based methods to advance trustworthy approaches to AI that serve all people in responsible, equitable, and beneficial ways. Effective risk management and assessment can help earn and increase trust in the development, deployment, and use of AI systems. Recognizing the power of AI to address the world’s challenges, we also acknowledge AI systems entail risk. By minimizing the negative impacts of AI systems on individuals, culture, the economy, societies, and the planet, we can maximize the positive impacts and benefits of AI systems that support the shared values underpinning like-minded democracies. Towards that goal, the U.S.-EU Joint Statement of the Trade and Technology Council (May 2022) expressed an intention to develop a joint roadmap (“Joint Roadmap”) on evaluation and measurement tools for trustworthy AI and risk management. This Joint Roadmap aims to guide the development of tools, methodologies, and approaches to AI risk management and trustworthy AI by the EU and the United States and to advance our shared interest in supporting international standardization efforts and promoting trustworthy AI on the basis of a shared dedication to democratic values and human rights. The roadmap takes practical steps to advance trustworthy AI and uphold our shared commitment to the Organisation for Economic Co-operation and Development (OECD) Recommendation on AI. 2.",https://www.nist.gov/system/files/documents/2022/12/04/Joint_TTC_Roadmap_Dec2022_Final.pdf,en,
1116,Bipartisan Framework for U.S. AI Act,Other authorities,,,Miscellaneous documents,Law/Act,2023-09-07,2023,9,negative,-0.5859,low,0.0,208,0.5,Proposed,"Establish a Licensing Regime Administered by an Independent Oversight Body: Companies developing sophisticated general-purpose A.I. models (e.g., GPT-4) or models used in high-risk situations (e.g., facial recognition) should be required to register with an independent oversight body. Licensing requirements should include the registration of information about AI models and be conditioned on developers maintaining risk management, pre-deployment testing, data governance, and adverse incident reporting programs. The oversight body should have the authority to conduct audits of companies seeking licenses and cooperate with other enforcers, including considering vesting concurrent enforcement authority in state Attorneys General. The entity should also monitor and report on technological developments and economic impacts of A.I., such as effects on employment. Personnel must be subject to strong conflict of interest rules to mitigate capture and revolving door concerns.Ensure Legal Accountability for Harms: Congress should ensure that A.I. companies can be held liable through oversight body enforcement and private rights of action when their models and systems breach privacy, violate civil rights, or otherwise cause cognizable harms. Where existing laws are insufficient to address new harms created by A.I., Congress should ensure that enforcers and victims can take companies and perpetrators to court, including clarifying that Section 230 does not apply to A.I. In particular, Con",https://www.blumenthal.senate.gov/imo/media/doc/09072023bipartisanaiframework.pdf,en,
1117,The position paper submitted by the Chinese delegation to CCW 5th Review Conference,Chinese central government,China,China,Chinese law and policy,Other,2016-12-12,2016,12,negative,-0.7251,low,0.0,239,0.5,Enacted,"The poistion paper submitted by the Chinese delegation to CCW 5th Review Conference Over recent years, as a result of the continued advance in AI technology, the autonomous warfare platform has been developing rapidly in terms of its R&D and application, and the weaponization of relevant technologies has caused humanitarian concerns. LAWS, a complex product of S&T development and new military revolution, involves a wide array of areas. LAWS is closely related to existing weapons and to new types of weapons systems still under development. There is currently still a lack of a clear and agreed definition of LAWS. Most states deny the existence of such systems. Given the trends in S&T developments, the international community should monitor and accord due importance to such weapons. The position and views of China are essentially as follows: I. The definition and scope of LAWS are the precondition and basis for discussion on its other aspects. It is necessary to focus extensive and in-depth discussion on the definition and scope now with a view to achieving consensus. Discussions about definitions should focus on a number of core issues: 1. Levels of autonomy and criteria for their determination; 2. Relations and distinctions between automation, autonomy and remote control; 3. The mode of human involvement and the human role which requires a strict definition and cannot be replaced by such vague concepts as ‘human judgement’ or ‘meaningful human control’. As to the scope, distin",https://web.archive.org/web/20190527074927/https://www.unog.ch/80256EDD006B8954/(httpAssets)/DD1551E60648CEBBC125808A005954FA/$file/China%27s+Position+Paper.pdf,en,
1123,National New Generation AI Standards System Construction Guide,Chinese central government,China,China,Chinese law and policy,Other,2020-08-05,2020,8,positive,0.9848,low,0.0,210,0.5,Proposed,"Guidelines for the Construction of a National New Generation Artificial Intelligence Standards System The Guidelines for the Construction of a National New Generation Artificial Intelligence Standards System have been formulated in order to implement the decision and deployment of the Party Central Committee and the State Council on the development of artificial intelligence (AI), to promote the continuous self-optimization of AI technology in the open-source and open industrial ecosystem, to give full play to the leading role of basic general purpose standards, ethical standards, security standards, and privacy standards, to guide the formulation, revision, and coordination of AI national standards, industry standards, and group standards, and to form a new pattern in which standards lead the comprehensive and standardized development of the AI industry.1. General Requirements (1) Guiding ideology: Fully implement the spirit of the 19th Party Congress and the Second, Third, and Fourth Plenums of the 19th Central Committee, implement the decisions and deployments of the Party Central Committee and the State Council on the development of new generation AI, combine market-driven and government guidance, and follow the principles of “overall planning, categorized policies, market-driven, urgent use first, cross-industry integration, coordinated advancement, independent innovation (自主创新), and open collaboration.” Take domestic demand as the foundation while also considering the i",https://cset.georgetown.edu/wp-content/uploads/t0401_AI_standards_guidelines_EN.pdf,en,
1125,Ethical Norms for the New Generation Artificial Intelligence,Chinese central government,China,China,Chinese law and policy,Other,2021-09-25,2021,9,positive,0.989,medium,0.5556,215,0.7,Proposed,"Ethical Norms for the New Generation Artificial Intelligence This set of norms is formulated in order to deeply implement the “New Generation Artificial Intelligence Development Plan”, to refine and implement the ” Governance Principles for the New Generation Artificial Intelligence”, to enhance the ethical awareness on Artificial Intelligence (AI) and the behavioral awareness of the entire society, to actively guide the responsible AI research, development, and application activities, and to promote healthy development of AI. Chapter 1. General Principles 1. This set of norms aims to integrate ethics into the entire life cycle of AI, to promote fairness, justice, harmony, safety and security, and to avoid issues such as prejudice, discrimination, privacy and information leakage. 2. This set of norms applies to natural persons, legal persons, and other related organizations engaged in related activities such as management, research and development, supply, and use of AI. (1) The management activities mainly refer to strategic planning, formulation and implementation of policies, laws, regulations, and technical standards, resource allocation, supervision and inspection, etc. (2) The research and development activities mainly refer to scientific research, technology development, product development, etc. related to AI. (3) The supply activities mainly refer to the production, operation, and sales of AI products and services. (4) The use activities mainly refer to the procureme",https://ai-ethics-and-governance.institute/2021/09/27/the-ethical-norms-for-the-new-generation-artificial-intelligence-china/,en,"Risk factors: Bias, Risk factors: Safety, Risk factors: Privacy, Risk factors: Security, Harms: Harm to health/safety, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Strategies: Governance development, Strategies: Performance requirements, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Convening, Risk factors: Interpretability and explainability, Strategies: Input controls, Strategies: Input controls: Data use"
1126,Position Paper of the People’s Republic of China on Regulating Military Applications of Artificial Intelligence,Chinese central government,China,China,Chinese law and policy,Other,2021-12-13,2021,12,positive,0.9884,low,0.0,212,0.5,Enacted,"[introductory comments omitted] As world peace and development are confronted with multifaceted challenges, countries should embrace a vision of common, comprehensive, cooperative and sustainable global security, seek consensus on regulating military applications of AI through dialogue and cooperation and establish an effective governance regime, in order to prevent serious harms or even disasters caused by military applications of AI to mankind. We need to enhance the efforts to regulate military applications of AI with a view to forestalling and managing potential risks. Such efforts will help promote mutual trust among countries, safeguard global strategic stability, prevent arms race and alleviate humanitarian concerns. It will also contribute to building an inclusive and constructive security partnership and striving for the vision of building a community with a shared future for mankind in the AI field. China welcomes governments, international organizations, technology enterprises, research institutes, social organizations, individuals and other actors to uphold the principle of extensive consultation, joint contribution and shared benefits, and work together to promote security governance in the AI field. In this vein, China calls for the following: In terms of strategic security, countries, especially major countries, need to develop and apply AI technology in the military field in a prudent and responsible manner, refrain from seeking absolute military advantage, an",http://geneva.china-mission.gov.cn/eng/dbdt/202112/t20211213_10467517.htm,en,
1127,Opinion on Strengthening Science and Technology Ethics Governance,Chinese central government,China,China,Chinese law and policy,Other,2022-03-20,2022,3,positive,0.9888,low,0.0,214,0.5,Enacted,"[introductory comments omitted] I. GENERAL REQUIREMENTS 1. Guiding Ideas. Under the Guidance of the Xi Jinping thought on socialism with Chinese characteristics for a new era, and deeply implement the spirits of the CPC’s 19th National Congress and the plenary sessions, adhere to and strengthen the Party’s central leadership to the work related to Science and technology, speed up the construction of the systems on the ethics in Science and technology with Chinese characteristics, improve the systems on the ethics and governance of science and technology with multi-stakeholder participation and cooperative governance, adhere to the unification of promoting innovation and avoiding risks, strengthen the bottom-line thinking and risk awareness, construct and improve the system of ethics in Science and technology in line with the country’s national circumstances and the international community, shape the culture and the safeguard mechanisms for Science and technology for good, achieving the high-quality development of scientific and technological innovation and high-level, safe, and good interactions, promote the healthy development of Science and technology, provide strong scientific and technological support for the promotion of human well-being and the construction of a human community of shared future. 2. Governance Requirements – Ethics first. Strengthening governance at the source, paying attention to preventions, embedding the requirements on the ethics in Science and techn",https://ai-ethics-and-governance.institute/2022/03/22/china-released-opinion-on-strengthening-the-ethics-and-governance-in-science-and-technology/,en,
1128,Regulations for the Promotion of the Development of the Artificial Intelligence Industry in Shanghai Municipality,Chinese provincial and local governments,China,China,Chinese law and policy,Regulation,2022-10-01,2022,10,positive,0.9866,low,0.0,209,0.5,Enacted,"Chapter I General Provisions Article 1 This Regulation was formulated in accordance with relevant laws and administrative regulations and based on the actual situation of the municipality in order to promote the high-quality development of the artificial intelligence (AI) industry and strengthen the functions of new generation AI science and technology (S&T) innovation sources, promote the deep integration of AI with the economy, everyday life, urban governance, and other fields, and create a world-class AI industrial cluster. Article 2 As used in this Regulation, artificial intelligence refers to the system of theories, methods, technologies, and applications that uses computers and computer-controlled machines to simulate, extend, and expand human intelligence, perceive the environment, acquire knowledge, and use knowledge to achieve optimal results. The AI industry refers to industries that perform software and hardware product development and production, system applications, and service integration involved in the research, development, and application of AI technology, such as the key basic components industry, intelligent software industry, and smart terminal industry, as well as related industries driven by the integration and application of AI technology in fields such as the economy, everyday life, and urban governance. Article 3 This Regulation applies to activities such as AI S&T innovation, industrial development, application empowerment, and industrial governance",https://cset.georgetown.edu/publication/regulations-for-the-promotion-of-the-development-of-the-artificial-intelligence-industry-in-shanghai-municipality/,en,
1129,Position Paper of the People's Republic of China on Strengthening Ethical Governance of Artificial Intelligence (AI),Chinese central government,China,China,Chinese law and policy,Other,2022-11-17,2022,11,positive,0.9945,low,0.0,220,0.5,Enacted,"[introductory comments omitted] China is committed to building a community with a shared future for mankind in the domain of AI, advocating a people-centered approach and the principle of AI for good. China finds it important to enhance the understanding of all countries on AI ethics, and ensure that AI is safe, reliable, controllable, and capable of better empowering global sustainable development and enhancing the common well-being of all mankind. To this end, China calls on all parties to uphold the principles of extensive consultation, joint contribution and shared benefits, and advance international AI ethical governance. II. In December 2021, China released the Position Paper of the Peoples' Republic of China on Regulating Military Applications of Artificial Intelligence (AI), calling on parties to observe national or regional ethical norms for AI. In this connection, China, based on its own policies and practices and with reference to useful international experience, makes the following points in the aspects of regulation, research and development, utilization and international cooperation. (1) Regulation Governments should give priority to ethics, establish and improve rules, norms and accountability mechanisms for AI ethics, clarify responsibilities and power boundaries of AI-related entities, fully respect and protect the legitimate rights and interests of all groups, and respond to relevant ethical concerns at home and abroad in a timely manner. Governments should",https://www.mfa.gov.cn/eng/zy/wjzc/202405/t20240531_11367525.html,en,
1135,Measures of Beijing Municipality on Promoting the Innovative Development of Artificial General Intelligence,Chinese provincial and local governments,China,China,Chinese law and policy,Other,2023-05-30,2023,5,positive,0.9919,low,0.0,204,0.5,Proposed,"Measures have been formulated to fully implement the Implementation Plan for Accelerating the Development of a Globally Influential Artificial Intelligence Innovation Hub (2023-2025) in Beijing Municipality (hereinafter referred to as the Implementation Plan). These measures leverage government guidance and the dynamic force of innovation platforms. The primary objective is to promote innovation-based, rational, and sustainable growth of the Artificial General Intelligence (AGI) sector in Beijing. This will be achieved by integrating innovation resources, allocating developmental factors, creating a suitable environment for innovation, and emphasizing risk prevention. I. Boost Computing Power Resource Supply 1. Beijing shall take proactive measures to mobilize commercial computing resources, meeting the pressing requirements of the AGI sector. The Implementation Plan aims to foster closer cooperation with cloud service providers through the computing power partnership program, in order to provide the public with diverse computing power that is both high-quality and accessible. 2. Beijing shall efficiently promote the construction of new computing power facilities. The Implementation Plan is set to efficiently promote the construction of relevant projects with the aim to help the city offer large-scale and advanced computing power. These projects include the Beijing AI Public Computing Power Center and Beijing Digital Economy Computing Power Center. 3. Beijing shall establish",https://english.beijing.gov.cn/investinginbeijing/WhyBeijing/lawpolicy/policies/202307/t20230724_3205629.html,en,
1137,Interim Measures for the Management of Generative Artificial Intelligence Services,Chinese central government,China,China,Chinese law and policy,Other,2023-07-10,2023,7,positive,0.9703,low,0.0,226,0.5,Enacted,"Chapter I： General Provisions Article 1: These Provisions are drafted on the basis of the Cybersecurity Law of the PRC, the PRC Data Security Law, the Personal Information Protection Law of the PRC, the PRC Law on the Scientific and Technological Progress, and other relevant laws and administrative regulations, so as promote the healthy development and regulated use of generative AI, preserve national security and the societal public interest, and protect the lawful rights and interests of citizens, legal persons, and other organizations. Article 2: These measures apply to the use of generative AI technologies to provide services to the public in the [mainland] PRC for the generation of text, images, audio, video, or other content (hereinafter generative AI services). Where the state has other provisions on the use of generative AI services to engage in activities such as news and publication, film and television production, and artistic creation, those provisions are to be followed. These Measures do not apply where industry associations, enterprises, education and research institutions, public cultural bodies, and related professional bodies, etc., research, develop, and use generative AI technology, but have not provided generative AI services to the (mainland) public. Article 3: The state is to adhere to the principle of placing equal emphasis on development and security, merging the promotion of innovation with governance in accordance with law; employing effective measu",https://www.chinalawtranslate.com/en/generative-ai-interim/,en,
1138,Remarks by Ambassador Zhang Jun at the UN Security Council Briefing on Artificial Intelligence: Opportunities and Risks for International Peace and Security,Chinese central government,China,China,Chinese law and policy,Other,2023-07-18,2023,7,positive,0.9799,low,0.0,226,0.5,Proposed,"Mr. President, China welcomes you presiding over today's Security Council meeting and thanks Secretary-General Guterres for his briefing. Many of his proposals deserve our study. I would also like to thank Professor Zeng Yi and Professor Jack Clark for their briefings. Their insights can help us better understand and handle issues related to AI. In recent years, the world has witnessed a rapid development and wide application of AI with complex effects constantly emerging. On the one hand, the empowering role of AI in areas such as scientific research, healthcare, autonomous driving, and smart decision-making, is becoming increasingly prominent, generating huge technological dividends. On the other hand, the scope of AI application has been constantly expanding, causing increasing concerns in areas such as data privacy, spreading false information, exacerbating social inequality, and disrupting employment structures. In particular, the misuse of AI or abuse by terrorist or extremist forces will pose a significant threat to international peace and security. At present, as a cutting edge technology, AI is still in its early stage of development. As a double edged sword, whether it is good or evil, depends on how mankind utilized it, regulate it, and how we balance development and security. The international community should uphold the spirit of true multilateralism, engage in extensive dialogue, constantly seek consensus, and explore the development of guiding principles for AI",http://un.china-mission.gov.cn/eng/hyyfy/202307/t20230719_11114947.htm,en,
1144,Global AI Governance Initiative,Chinese central government,China,China,Chinese law and policy,Other,2023-10-18,2023,10,positive,0.9944,low,0.0,219,0.5,Enacted,"Global AI Governance Initiative [introductory comments omitted] As global peace and development faces various challenges, all countries should commit to a vision of common, comprehensive, cooperative, and sustainable security, and put equal emphasis on development and security. Countries should build consensus through dialogue and cooperation, and develop open, fair, and efficient governing mechanisms, in a bid to promote AI technologies to benefit humanity and contribute to building a community with a shared future for mankind. We call on all countries to enhance information exchange and technological cooperation on the governance of AI. We should work together to prevent risks, and develop AI governance frameworks, norms and standards based on broad consensus, so as to make AI technologies more secure, reliable, controllable, and equitable. We welcome governments, international organizations, companies, research institutes, civil organizations, and individuals to jointly promote the governance of AI under the principles of extensive consultation, joint contribution, and shared benefits. To make this happen, we would like to suggest the following: We should uphold a people-centered approach in developing AI, with the goal of increasing the wellbeing of humanity and on the premise of ensuring social security and respecting the rights and interests of humanity, so that AI always develops in a way that is beneficial to human civilization. We should actively support the role of",https://www.cac.gov.cn/2023-10/18/c_1699291032884978.htm,en,
1151,Technical Documentation of National Technical Committee 260 on Cybersecurity of Standardization Administration of China: Basic Safety Requirements for Generative Artificial Intelligence Services,Chinese central government,China,China,Chinese law and policy,Other,2024-02-29,2024,2,positive,0.9846,low,0.0,210,0.5,Enacted,"1 Scope This document specifies the basic requirements for the safety aspects of generative artificial intelligence (AI) services, including corpus safety (预料安全), model safety, and safety measures, and provides safety assessment requirements. This document applies to service providers carrying out safety assessments and improving their safety levels, and also provides the relevant main oversight department (主管部门) a reference for judging the safety levels of generative AI services. 2 Normative Reference Documents The contents of the following documents, through normative references in this text, constitute indispensable provisions of this document. Among them, for dated references, only the edition corresponding to that date applies to this document. For undated references, the latest edition (including all amendments) applies to this document. Information security technology terminology GB/T 25069-2022 3 Terminology and Definitions The terms and definitions defined in GB/T 25069-2022 and listed below apply to this document. 3.1 Generative Artificial Intelligence Services The use of generative AI technology to provide text, graphics, audio, video, and other content generation services to the public within the People’s Republic of China 3.2 Service Provider An organization or individual that provides generative AI services in the form of interactive interfaces, programmable interfaces, etc. 3.3 Training Data (训练语料) All data that serve directly as input for model training, inclu",https://cset.georgetown.edu/publication/china-safety-requirements-for-generative-ai-final/,en,
1152,"UN General Assembly Resolution A/78/L.49 (""Seizing the opportunities of safe, secure and trustworthy artificial intelligence systems for sustainable development""",United Nations,Multinational,Multinational,Multinational,Resolution,2024-03-11,2024,3,positive,0.8442,low,0.0,229,0.5,Enacted,"The General Assembly, Reaffirming international law, in particular the Charter of the United Nations, and recalling the Universal Declaration of Human Rights, Reaffirming also its resolution 70/1 of 25 September 2015, entitled “Transforming our world: the 2030 Agenda for Sustainable Development”, its resolution 69/313 of 27 July 2015 on the Addis Ababa Action Agenda of the Third International Conference on Financing for Development, and the political declaration adopted at the high-level political forum on sustainable development convened under the auspices of the General Assembly contained in the annex to its resolution 78/1 of 29 September 2023, Recalling its resolutions 77/320 of 25 July 2023 on the impact of rapid technological change on the achievement of the Sustainable Development Goals and targets, 78/132 of 19 December 2023 on information and communications technologies for sustainable development, 78/160 of 19 December 2023 on science, technology and innovation for sustainable development, 78/213 of 19 December 2023 on the promotion and protection of human rights in the context of digital technologies, 77/211 of 15 December 2022 on the right to privacy in the digital age, 70/125 of 16 December 2015 on the overall review of the implementation of the outcomes of the World Summit on the Information Society, all the outcomes of the World Summit on the Information Society, including the Geneva Declaration of Principles, the Geneva Plan of Action, the Tunis Commitment and",https://documents.un.org/doc/undoc/ltd/n24/065/92/pdf/n2406592.pdf,en,
1158,New Mexico SM 63,New Mexico,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-06-16,2024,6,negative,-0.9805,low,0.0,220,0.5,Defunct,"SENATE MEMORIAL 63 56TH LEGISLATURE - STATE OF NEW MEXICO - FIRST SESSION, 2023 INTRODUCED BY David M. Gallegos A MEMORIAL REQUESTING THE ATTORNEY GENERAL TO CONVENE A TASK FORCE TO STUDY THE INTRODUCTION AND USE BY THE CHILDREN, YOUTH AND FAMILIES DEPARTMENT OF A STRUCTURED DECISION-MAKING PHILOSOPHY AND STRUCTURED DECISION-MAKING TOOLS. WHEREAS, New Mexico's rate of repeat child abuse is among the worst in the country; and WHEREAS, more than forty percent of children in New Mexico who suffered a substantiated serious injury from physical abuse or neglect in 2022 belonged to families that had involvement with the children, youth and families department within the preceding year; and WHEREAS, in 2019, the children, youth and families department adopted a new structured decision-making philosophy and launched structured decision-making tools intended to more robustly assess strengths and risk factors and to support the department in better evaluating risk and targeting appropriate support and services; and WHEREAS, structured decision making is an approach to child protective services that uses clearly defined and consistently applied decision-making criteria to screen families for investigation, determine response priority, identify immediate threatened harm and estimate the risk of future abuse and neglect; and WHEREAS, as part of the introduction of the newly structured decision-making philosophy, the children, youth and families department adopted a policy position to redu",https://www.nmlegis.gov/Sessions/23%20Regular/memorials/senate/SM063.pdf,en,
1161,"James M. Inhofe National Defense Authorization Act for Fiscal Year 2023, Section 6718 (""Certification relating to information technology and software systems"")",United States Congress,United States,Federal government,NDAA provisions,Law/Act,2022-12-23,2022,12,positive,0.9684,low,0.0,222,1.0,Enacted,"SEC. 6718. CERTIFICATION RELATING TO INFORMATION TECHNOLOGY AND SOFTWARE SYSTEMS. (a) Certifications Required.--Prior to the date on which the head of an element of the intelligence community enters into, renews, or extends a contract for the acquisition of an information technology or software system, the head shall certify to the Director of National Intelligence the following: (1) That the information technology or software system is the most up-to-date version of the system available or, if it is not, why a more out of date version was chosen. (2) That the information technology or software system is compatible with integrating new and emerging technologies, such as artificial intelligence. (3) That the information technology or software system was thoroughly reviewed and alternative products are not superior to meet the requirements of the element. (b) Exemption.--The Director of National Intelligence may exempt elements of the intelligence community, as appropriate, from the requirements under (a) if meeting such requirements may pose security or operational risks. (c) Guidance.--The Director shall issue to the heads of the elements of the intelligence community, and submit to the congressional intelligence committees, the Subcommittee on Defense of the Committee on Appropriations of the Senate, and the Subcommittee on Defense of the Committee on Appropriations of the House of Representatives, guidance to-- (1) establish guidelines that the heads of the relevant element",https://www.congress.gov/bill/117th-congress/house-bill/7776/text,en,"Applications: Government: military and public safety, Strategies: Government support, Strategies: Government support: AI workforce-related, Strategies: Governance development"
1163,Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB 1047),California,United States,State governments,Editors' Picks,Law/Act,2024-09-30,2024,9,positive,0.9912,high,0.7222,224,0.7,Defunct,"SECTION 1. This act shall be known, and may be cited, as the Safe and Secure Innovation for Frontier Artificial Intelligence Models Act. SEC. 2. The Legislature finds and declares all of the following: (a) California is leading the world in artificial intelligence innovation and research, through companies large and small, as well as through our remarkable public and private universities. (b) Artificial intelligence, including new advances in generative artificial intelligence, has the potential to catalyze innovation and the rapid development of a wide range of benefits for Californians and the California economy, including advances in medicine, wildfire forecasting and prevention, and climate science, and to push the bounds of human creativity and capacity.(c) If not properly subject to human controls, future development in artificial intelligence may also have the potential to be used to create novel threats to public safety and security, including by enabling the creation and the proliferation of weapons of mass destruction, such as biological, chemical, and nuclear weapons, as well as weapons with cyber-offensive capabilities. (d) The state government has an essential role to play in ensuring that California recognizes the benefits of this technology while avoiding the most severe risks, as well as to ensure that artificial intelligence innovation and access to compute is accessible to academic researchers and startups, in addition to large companies.SEC. 3. Chapter 22.6",https://leginfo.legislature.ca.gov/faces/billCompareClient.xhtml?bill_id=202320240SB1047&showamends=false,en,"Strategies: Evaluation: External auditing, Strategies: Evaluation, Strategies: Disclosure: In standard form, Risk factors: Safety, Risk factors: Security, Strategies: Governance development, Strategies: Evaluation: Impact assessment, Strategies: Disclosure, Risk factors: Interpretability and explainability, Harms: Harm to health/safety, Strategies: Convening, Strategies: Tiering, Strategies: Tiering: Tiering based on domain of application, Strategies: New institution, Strategies: Performance requirements"
1187,"Part 170: Health Data, Technology, and Interoperability: Certification Program Updates, Algorithm Transparency, and Information Sharing",Department of Health and Human Services,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2024-02-08,2024,2,positive,0.7184,low,0.0,214,0.5,Enacted,"PART 170—HEALTH INFORMATION TECHNOLOGY STANDARDS, IMPLEMENTATION SPECIFICATIONS, AND CERTIFICATION CRITERIA AND CERTIFICATION PROGRAMS FOR HEALTH INFORMATION TECHNOLOGY 1. The authority citation for part 170 continues to read as follows: Authority: 42 U.S.C. 300jj-11; 42 U.S.C 300jj-14; 5 U.S.C. 553. 2. Amend § 170.102 by: a. Removing definitions for “2015 Edition Base EHR” and “2015 Edition health IT certification criteria”; and b. Adding definitions for “Base EHR”, “ONC certification criteria for health IT”, “Predictive Decision Support Intervention”, “Provide”, and “Revised certification criterion (or criteria)” in alphabetical order. The additions read as follows: § 170.102 Definitions. Base EHR means an electronic record of health-related information on an individual that: (1) Includes patient demographic and clinical health information, such as medical history and problem lists; (2) Has the capacity: (i) To provide clinical decision support; (ii) To support physician order entry; (iii) To capture and query information relevant to healthcare quality; (iv) To exchange electronic health information with, and integrate such information from other sources; and (3) Has been certified to the certification criteria adopted by the Secretary in— (i) Section 170.315(a)(1), (2), or (3); (a)(5) and (14), (b)(1), (c)(1), and (g)(7), (9), (10); and (h)(1) or (2); (ii) Section 170.315(a)(9) or (b)(11) for the period up to and including December 31, 2024; and (iii) Section 170.315(b)(11",https://www.federalregister.gov/documents/2024/01/09/2023-28857/health-data-technology-and-interoperability-certification-program-updates-algorithm-transparency-and,en,
1188,Section 106.11 Application: Nondiscrimination on the Basis of Sex in Education Programs or Activities Receiving Federal Financial Assistance,Department of Education,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Law/Act,2024-08-01,2024,8,positive,0.6908,low,0.0,210,0.5,Enacted,"E. Application 1. Section 106.11 Application Obligation To Address Conduct Occurring Under a Recipient's Education Program or Activity Comments: Many commenters expressed overall support for proposed § 106.11, including because it would remove many geographical limitations on a recipient's responsibilities under Title IX and require a recipient to address sex-based harassment in its education program or activity broadly—on a recipient's grounds, during school activities off campus, and under a recipient's disciplinary authority; would be consistent with recent court decisions recognizing that a recipient must respond to sex-based harassment in off-campus settings; would better reflect where sex-based harassment occurs given that students live, learn, and participate in education programs off campus and in remote settings; and would promote uniformity and consistency of Federal laws because it would be more consistent with Title VII. Some commenters also highlighted student populations more likely to live off campus who would benefit from proposed § 106.11, including graduate, vocational, and community college students; low-income students, students of color, former foster youth, and LGBTQI+ students; student athletes; and students who attend training and workforce development programs. Other commenters supported proposed § 106.11 because it would close a gap in the 2020 amendments that the commenters asserted created the potential for students to engage in off-campus sex-base",https://www.federalregister.gov/documents/2024/04/29/2024-07915/nondiscrimination-on-the-basis-of-sex-in-education-programs-or-activities-receiving-federal,en,
1189,Train Crew Size Safety Requirements (New Technology and Automated Operations),Department of Transportation,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2024-06-10,2024,6,positive,0.975,low,0.0,230,0.5,Enacted,"c. New Technology and Automated Operations As noted in the NPRM, although current FRA regulations do not explicitly require the presence of a human operator, FRA's regulations were developed and drafted based on a general assumption that a train would be operated by a person, albeit with assistance from technology.[243] For that reason, the NPRM proposed a special approval petition process that would have required a risk assessment before initiating an operation, and the NPRM's background stated that FRA understands that the rail industry is anticipating future growth in automation and is concerned how a train crew staffing rule might impact the future of rail innovation and automation. Further the NPRM noted that a railroad, seeking to use rail automation technology that does not comply with FRA's existing rail safety regulations, may file a petition for rulemaking under FRA's regulations, or a petition for a waiver of FRA's safety rules.[244] In response to FRA's proposal, some rail industry commenters asserted that the NPRM is anti-technology, that DOT has promoted automated operations for motor vehicles, including trucks, over railroads, and that the NPRM blocks incentives to innovate. For instance, AAR commented that the NPRM would cause a modal shift from railroads to trucks, directly impacting the railroad industry's competitiveness [245] —a position shared by ASLRRA.[246] To support its position, AAR provided a research paper it had commissioned that concluded the NPR",https://www.federalregister.gov/documents/2024/04/09/2024-06625/train-crew-size-safety-requirements,en,
1194,Consensus Statement on AI Safety as a Global Public Good,Other multinational,Multinational,Multinational,Multinational,Other,2024-09-08,2024,9,positive,0.9838,low,0.2778,225,1.0,Enacted,"Consensus Statement on AI Safety as a Global Public Good Rapid advances in artificial intelligence (AI) systems’ capabilities are pushing humanity closer to a world where AI meets and surpasses human intelligence. Experts agree these AI systems are likely to be developed in the coming decades, with many of them believing they will arrive imminently. Loss of human control or malicious use of these AI systems could lead to catastrophic outcomes for all of humanity. Unfortunately, we have not yet developed the necessary science to control and safeguard the use of such advanced intelligence. The global nature of these risks from AI makes it necessary to recognize AI safety as a global public good, and work towards global governance of these risks. Collectively, we must prepare to avert the attendant catastrophic risks that could arrive at any time. Promising initial steps by the international community show cooperation on AI safety and governance is achievable despite geopolitical tensions. States and AI developers around the world committed to foundational principles to foster responsible development of AI and minimize risks at two intergovernmental summits. Thanks to these summits, states established AI Safety Institutes or similar institutions to advance testing, research and standards-setting. These efforts are laudable and must continue. States must sufficiently resource AI Safety Institutes, continue to convene summits and support other global governance efforts. However, s",https://idais.ai/dialogue/idais-venice/,en,"Risk factors: Safety, Harms: Harm to health/safety, Strategies: Evaluation, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Tiering, Strategies: Tiering: Tiering based on impact, Strategies: Convening, Strategies: Evaluation: External auditing, Strategies: Disclosure: About incidents, Strategies: Licensing, registration, and certification, Strategies: Governance development, Strategies: Government support, Strategies: Government support: For R&D"
1195,Consensus Statement on Red Lines in Artificial Intelligence,Other multinational,Multinational,Multinational,Multinational,Other,2024-03-11,2024,3,negative,-0.964,low,0.2778,218,1.0,Enacted,"Consensus Statement on Red Lines in Artificial Intelligence Unsafe development, deployment, or use of AI systems may pose catastrophic or even existential risks to humanity within our lifetimes. These risks from misuse and loss of control could increase greatly as digital intelligence approaches or even surpasses human intelligence. In the depths of the Cold War, international scientific and governmental coordination helped avert thermonuclear catastrophe. Humanity again needs to coordinate to avert a catastrophe that could arise from unprecedented technology. In this consensus statement, we propose red lines in AI development as an international coordination mechanism, including the following non-exhaustive list. At future International Dialogues we will build on this list in response to this rapidly developing technology. Autonomous Replication or Improvement No AI system should be able to copy or improve itself without explicit human approval and assistance. This includes both exact copies of itself as well as creating new AI systems of similar or greater abilities. Power Seeking No AI system should take actions to unduly increase its power and influence. Assisting Weapon Development No AI systems should substantially increase the ability of actors to design weapons of mass destruction, or violate the biological or chemical weapons convention. Cyberattacks No AI system should be able to autonomously execute cyberattacks resulting in serious financial losses or equivalent h",https://idais.ai/idais-beijing/,en,"Risk factors: Safety, Harms: Harm to health/safety, Strategies: Governance development, Strategies: Convening, Strategies: Government support, Strategies: Government support: For R&D, Risk factors: Security, Risk factors: Security: Cybersecurity, Risk factors: Interpretability and explainability, Strategies: Evaluation, Strategies: Evaluation: Adversarial testing, Strategies: Evaluation: Post-market monitoring, Strategies: Licensing, registration, and certification, Strategies: Evaluation: External auditing, Strategies: Tiering"
1196,IDAIS-Oxford Statement (2023),Other multinational,Multinational,Multinational,Multinational,Other,2023-10-31,2023,10,positive,0.7783,low,0.2222,221,1.0,Enacted,"Global action, cooperation, and capacity building are key to managing risk from AI and enabling humanity to share in its benefits. AI safety is a global public good that should be supported by public and private investment, with advances in safety shared widely. Governments around the world — especially of leading AI nations — have a responsibility to develop measures to prevent worst-case outcomes from malicious or careless actors and to rein in reckless competition. The international community should work to create an international coordination process for advanced AI in this vein. We face near-term risks from malicious actors misusing frontier AI systems, with current safety filters integrated by developers easily bypassed. Frontier AI systems produce compelling misinformation and may soon be capable enough to help terrorists develop weapons of mass destruction. Moreover, there is a serious risk that future AI systems may escape human control altogether. Even aligned AI systems could destabilize or disempower existing institutions. Taken together, we believe AI may pose an existential risk to humanity in the coming decades. In domestic regulation, we recommend mandatory registration for the creation, sale or use of models above a certain capability threshold, including open-source copies and derivatives, to enable governments to acquire critical and currently missing visibility into emerging risks. Governments should monitor large-scale data centers and track AI incidents,",https://idais.ai/idais-oxford/,en,"Risk factors: Safety, Harms: Harm to health/safety, Strategies: Governance development, Risk factors: Reliability, Risk factors: Reliability: Robustness, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Convening, Strategies: Evaluation, Strategies: Evaluation: External auditing, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Disclosure: In deployment, Strategies: Licensing, registration, and certification, Strategies: Tiering"
1197,Lummis-Gillibrand Payment Stablecoin Act (Sec. 1-3),United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9858,low,0.0,244,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Lummis-Gillibrand Payment Stablecoin Act”. SEC. 2. DEFINITIONS. In this Act: (1) ALGORITHMIC PAYMENT STABLECOIN.—The term “algorithmic payment stablecoin” means a crypto asset that— (A) is represented by the issuer, or is otherwise designed to create the reasonable expectation, that the crypto asset will maintain a stable value relative to the value of a fixed amount of United States dollars; and (B) relies on the use of an algorithm that adjusts the supply of the crypto asset in response to changes in market demand for the crypto asset to maintain the expectation that the crypto asset will maintain a stable value. (2) APPLICABLE PAYMENT STABLECOIN REGULATOR.—The term “applicable payment stablecoin regulator” means, with respect to a payment stablecoin issuer— (A) in the case of a depository institution that issues a payment stablecoin under section 7, consistent with section 11(s)— (i) the Comptroller or State bank supervisor, as applicable; or (ii) the Board; and (B) in the case of a State non-depository trust company that issues a payment stablecoin under section 6, the applicable State bank supervisor and the Board, acting jointly. (3) BANK SECRECY ACT.—The term “Bank Secrecy Act” means— (A) section 21 of the Federal Deposit Insurance Act (12 U.S.C. 1829b); (B) chapter 2 of title I of Public Law 91–508 (12 U.S.C. 1951 et seq.); and (C) subchapter II of chapter 53 of title 31, United States Code. (4) BOARD.—The term “Bo",https://www.congress.gov/bill/118th-congress/senate-bill/4155/text,en,
1198,Artificial Intelligence Weapon Accountability and Risk Evaluation Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.1943,medium,0.4444,237,0.7,Defunct,"SECTION 1. Short title. This Act may be cited as the “Artificial Intelligence Weapon Accountability and Risk Evaluation Act of 2024” or the “AWARE Act of 2024”. SEC. 2. Managing risks relating to military use of artificial intelligence. (a) Ledger of use and deployment.— (1) IN GENERAL.—Not later than one year after the date of the enactment of this Act the Secretary of Defense shall commence creating, and not later than three years after the date of the enactment of this Act the Secretary shall complete creating, a ledger of all uses by the Department of Defense of covered systems. (2) REQUIREMENTS.—The Secretary shall ensure that the ledger created pursuant to paragraph (1)— (A) is a structured, indexed database; and (B) maintained and updated on a regular basis to ensure that the ledger is accurate. (b) Risk assessment process.— (1) IN GENERAL.—Not later than three years after the date of the enactment of this Act, the Secretary shall establish a risk assessment process that holistically evaluates each unique implementation by the Department of a covered system included in the ledger required by subsection (a). (2) ELEMENTS.— (A) IN GENERAL.—The process required by paragraph (1) shall, at a minimum, cover matters relating to the following: (i) Dependability. (ii) Cybersecurity. (iii) Privacy. (iv) Bias. (v) Bias towards escalation. (vi) Deployment span. (vii) Risk of civilian harm. (B) BIAS TOWARDS ESCALATION.—For purposes of subparagraph (A)(v), the process shall cover th",https://www.congress.gov/bill/118th-congress/senate-bill/5239/text,en,"Strategies: Disclosure, Applications: Government: military and public safety, Strategies: Disclosure: In standard form, Risk factors: Transparency, Strategies: Evaluation, Strategies: Governance development, Strategies: Evaluation: Impact assessment, Risk factors: Security, Risk factors: Security: Cybersecurity, Risk factors: Reliability, Risk factors: Privacy, Risk factors: Bias, Harms: Harm to health/safety, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure: In deployment"
1199,MedShield Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9788,low,0.0,228,0.5,Defunct,"A BILL To require the Secretary of Health and Human Services to implement a pandemic preparedness and response program using artificial intelligence. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “MedShield Act of 2024”. SEC. 2. Findings; sense of Congress. (a) Findings.—Congress finds as follows: (1) The COVID–19 pandemic revealed the need to better organize pathogen defense of the people of the United States. (2) The National Security Commission on Artificial Intelligence concluded that COVID–19 scientific advancements, notably accelerated by the application of artificial intelligence, in addition to many other existing science and technology initiatives in the United States, should be used to build a comprehensive, operational, and integrated biodefense program that functions like a “shield” against manmade and non-manmade pathogens. (b) Sense of Congress.—It is the sense of Congress that— (1) an initiative such as Operation Warp Speed should not be required for the next pandemic; (2) there is a requirement for a pandemic preparedness and response program that would negate the need for a future Operation Warp Speed-like program or a declaration of a public health emergency under section 319 of the Public Health Service Act (42 U.S.C. 247d); and (3) the program established under section 3 would operationalize artificial intelligence and a system-of-systems",https://www.congress.gov/bill/118th-congress/senate-bill/5222/text,en,
1200,Providing Individuals Various Opportunities for Technical Training to Build a Skills-Based Cyber Workforce Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9022,low,0.0,221,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Providing Individuals Various Opportunities for Technical Training to Build a Skills-Based Cyber Workforce Act of 2024” or the “Cyber PIVOTT Act”. SEC. 2. CISA EDUCATION AND TRAINING PROGRAMS AND RESOURCES. (a) In General.—Subtitle D of title XIII of the Homeland Security Act of 2002 is amended by adding at the end the following new section: 1334. CISA EDUCATION AND TRAINING PROGRAMS AND RESOURCES. “(a) Expanding Education And Training Programs And Resources To Community Colleges And Technical Schools.— “(1) STUDENT QUALIFICATIONS.— “(A) IN GENERAL.—The Director of the Cybersecurity and Infrastructure Security Agency (CISA) of the Department shall seek to enter into partnerships or other arrangements with community colleges (as such term is defined in section 5002 of the William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021 (15 U.S.C. 9401) and technical schools (as such term is defined in section 411.167 of title 20, Code of Federal Regulations) (in this section referred to as ‘participating institutions’) to establish education and training programs and facilitate internship and post-graduation Federal job opportunities at participating institutions. Such programs shall be known as the ‘Providing Individuals Various Opportunities for Technical Training to Build a Skills-Based Cyber Workforce Program’ or the ‘PIVOTT Program’ (in this section referred to as the ‘Program’). “(B) ELIGIBILITY.—Th",https://www.congress.gov/bill/118th-congress/house-bill/9770,en,
1201,"A bill to establish protections for individual rights with respect to computational algorithms, and for other purposes.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8402,low,0.0,206,0.5,Defunct,"SECTION 1. Short title; table of contents. (a) Short title.—This Act may be cited as the “Artificial Intelligence Civil Rights Act of 2024”. (b) Table of contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. Sec. 2. Definitions. TITLE I—CIVIL RIGHTS Sec. 101. Discrimination. Sec. 102. Pre-deployment evaluations and post-deployment impact assessments. TITLE II—COVERED ALGORITHM AND CONTRACT STANDARDS Sec. 201. Covered algorithm standards. Sec. 202. Relationships between developers and deployers. Sec. 203. Human alternatives and other protections. TITLE III—TRANSPARENCY Sec. 301. Notice and disclosure. Sec. 302. Study on explanations regarding the use of covered algorithms. Sec. 303. Consumer awareness. TITLE IV—ENFORCEMENT Sec. 401. Enforcement by the Commission. Sec. 402. Enforcement by States. Sec. 403. Private right of action. Sec. 404. Severability. Sec. 405. Rules of construction. TITLE V—FEDERAL RESOURCES Sec. 501. Occupational series relating to algorithm auditing. Sec. 502. United States Digital Service algorithm auditors. Sec. 503. Additional Federal resources. SEC. 2. Definitions. In this Act: (1) COLLECT; COLLECTION.—The terms “collect” and “collection”, with respect to personal data, mean buying, renting, gathering, obtaining, receiving, accessing, or otherwise acquiring such data by any means. (2) COMMISSION.—The term “Commission” means the Federal Trade Commission. (3) CONSEQUENTIAL ACTION.—The term “consequential act",https://www.congress.gov/bill/118th-congress/senate-bill/5152/text,en,
1202,Secure Artificial Intelligence Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9966,low,0.2222,223,0.7,Defunct,"A BILL To improve the tracking and processing of security and safety incidents and risks associated with artificial intelligence, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Secure Artificial Intelligence Act of 2024” or the “Secure A.I. Act of 2024”. SEC. 2. Definitions. In this Act: (1) ARTIFICIAL INTELLIGENCE SAFETY INCIDENT.—The term “artificial intelligence safety incident” means an event that increases the risk that operation of an artificial intelligence system will— (A) result in physical or psychological harm; or (B) lead to a state in which human life, health, or property is endangered. (2) ARTIFICIAL INTELLIGENCE SECURITY INCIDENT.—The term “artificial intelligence security incident” means an event that increases— (A) the risk that operation of an artificial intelligence system occurs in a way that enables the extraction of information about the behavior or characteristics of an artificial intelligence system by a third party; or (B) the ability of a third party to manipulate an artificial intelligence system in order to subvert the confidentiality, integrity, or availability of an artificial intelligence system or adjacent system. (3) ARTIFICIAL INTELLIGENCE SECURITY VULNERABILITY.—The term “artificial intelligence security vulnerability” means a weakness in an artificial intelligence system that could be exploited by a",https://www.congress.gov/bill/118th-congress/house-bill/9737/all-actions,en,"Strategies: Evaluation, Strategies: Governance development, Applications: Government: military and public safety, Risk factors: Security, Strategies: Disclosure, Strategies: Disclosure: About incidents, Strategies: Disclosure: In standard form, Strategies: Disclosure: Accuracy thereof, Risk factors: Safety, Applications: Government: benefits and welfare, Incentives: Civil liability, Strategies: Government study or report, Strategies: Convening, Risk factors: Privacy, Risk factors: Interpretability and explainability"
1203,AI Incident Reporting and Security Enhancement Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9633,low,0.1111,202,0.7,Defunct,"A BILL To direct the Director of the National Institute of Standards and Technology to update the national vulnerability database to reflect vulnerabilities to artificial intelligence systems, study the need for voluntary reporting related to artificial intelligence security and safety incidents, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “AI Incident Reporting and Security Enhancement Act”. SEC. 2. Activities to support voluntary vulnerability and incident tracking associated with artificial intelligence. (a) Update to national vulnerability database.—Subject to the availability of appropriations, the Director of the National Institute of Standards and Technology, in coordination with industry stakeholders, standards development organizations, and appropriate Federal agencies, as appropriate, shall carry out the following: (1) Establish or identify common definitions and any characteristics of artificial intelligence security vulnerabilities that make utilization of the National Vulnerability Database inappropriate for the management of such vulnerabilities, and develop processes and procedures for vulnerability management of such vulnerabilities. (2) Support the development of standards and guidance for technical vulnerability management processes related to artificial intelligence. (3) Consistent with paragraphs (1) and (2), as a",https://www.congress.gov/bill/118th-congress/house-bill/9720/text,en,"Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Governance development, Risk factors: Security, Risk factors: Safety, Strategies: Convening, Strategies: Government study or report"
1205,Modernizing Data Practices to Improve Government Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9758,low,0.0,231,0.5,Defunct,"A BILL To amend section 3520A of title 44, United States Code, to extend the Chief Data Officer Council's sunset and add new authorities for improving Federal agency data governance, including to enable reliable and secure adoption of emerging technologies and artificial intelligence, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Modernizing Data Practices to Improve Government Act”. SEC. 2. Amendments. (a) In general.—Section 3520A of title 44, United States Code, is amended— (1) by striking subsections (d) and (e); (2) by redesignating subsections (a) through (c) as subsections (b) through (d), respectively; (3) by inserting before subsection (b), as so redesignated, the following: “(a) Definitions.—In this section: “(1) ARTIFICIAL INTELLIGENCE.—The term ‘artificial intelligence’— “(A) has the meaning given that term in section 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401); and “(B) includes the artificial systems and techniques described in paragraphs (1) through (5) of section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Public Law 115–232; 10 U.S.C. 4061 note prec.). “(2) DATA GOVERNANCE.—The term ‘data governance’— “(A) means the approach of an agency to managing data during the lifecycle of the data, from acquisition, to use, to disposal; and “(B) i",https://www.congress.gov/bill/118th-congress/senate-bill/5109/text,en,
1206,Department of Energy Artificial Intelligence Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9936,low,0.0,218,0.5,Defunct,"A BILL To provide guidance for and investment in the research and development activities of artificial intelligence at the Department of Energy, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Department of Energy Artificial Intelligence Act of 2024”. SEC. 2. Department of Energy artificial intelligence research program. (a) In general.—Title LV of the William M. (Mac) Thornberry National Defense Authorization Act of 2021 (Public Law 116–283) is amended to read as follows: “TITLE LV—Department of Energy artificial intelligence research program “Sec. 5501. Department of Energy artificial intelligence research program. “Sec. 5502. Ensuring energy security for data centers and computing resources. “SEC. 5501. Department of Energy artificial intelligence research program. “(a) In general.—The Secretary shall carry out a cross-cutting research and development program to advance artificial intelligence tools, systems, capabilities, and workforce needs and develop artificial intelligence capabilities for the purposes of advancing the missions of the Department (in this section referred to as the ‘program’). In carrying out such program, the Secretary shall coordinate across all relevant offices and programs of the Department, including the Office of Science, the Office of Energy Efficiency and Renewable Energy, the Office of Nuclear Energy, th",https://www.congress.gov/bill/118th-congress/house-bill/9671/text,en,
1208,AI Ads Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.9747,low,0.0,224,0.5,Defunct,"A BILL To amend the Federal Election Campaign Act of 1971 to clarify that the prohibition under such Act against the fraudulent misrepresentation of campaign authority and the fraudulent solicitation of funds includes misrepresentation through the use of content generated in whole or in part with the use of artificial intelligence (generative AI), and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “AI Ads Act”. SEC. 2. Use of content generated by artificial intelligence as fraudulent misrepresentation of campaign authority. (a) Fraudulent misrepresentation.—Section 322(a)(1) of the Federal Election Campaign Act of 1971 (52 U.S.C. 30124(a)(1)) is amended by striking the semicolon and inserting the following: “, including through the use of content generated in whole or in part with the use of artificial intelligence (generative AI);”. (b) Fraudulent solicitation of funds.—Section 322(b)(1) of the Federal Election Campaign Act of 1971 (52 U.S.C. 30124(b)(1)) is amended by striking the semicolon and inserting the following: “, including through the use of content generated in whole or in part with the use of artificial intelligence (generative AI);”. SEC. 3. Extending prohibition against fraudulent misrepresentation by candidates for purposes of damaging other candidates to fraudulent misrepresentation of candidates and committees by any perso",https://www.congress.gov/bill/118th-congress/house-bill/9639/text,en,
1209,"H.R. 9626, To direct the Department of Defense to develop a plan for the establishment of a secure computing and data storage environment for the testing of artificial intelligence trained on biological data, and for other purposes.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9792,low,0.0,220,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “AIxBio Defense Sandbox Act”. SEC. 2. PLAN FOR ESTABLISHMENT OF SECURE COMPUTING AND DATA STORAGE ENVIRONMENT FOR TESTING OF ARTIFICIAL INTELLIGENCE TRAINED ON BIOLOGICAL DATA. (a) Plan Required.—The Under Secretary of Defense for Research and Engineering, in coordination with the Chief Digital and Artificial Intelligence Officer, shall develop a plan for the establishment of a secure computing and data storage environment to facilitate— (1) the testing of artificial intelligence models trained on biological data; and (2) the development and testing of products generated by such models. (b) Elements.—The plan under subsection (a) shall provide as follows: (1) DESIGNATION.—The secure computing and data storage environment described in subsection (a) shall be known as the “AIxBio sandbox”. (2) COMPUTING AND DATA STORAGE INFRASTRUCTURE.—The AIxBio sandbox shall consist of a secure computing and data storage infrastructure to be used for the testing and development activities described in subsection (a). To the extent feasible, such infrastructure shall be assembled from the existing computing and data storage infrastructure organizations and elements of the Department of Defense with relevant capabilities, such as the Test Resource Management Center and the AI Accelerator of the Department of the Air Force. (3) RESPONSIBLE OFFICIAL.—The Under Secretary of Defense for Research and Engineering shall be responsible for— (A) manag",https://www.congress.gov/bill/118th-congress/house-bill/9626/all-actions,en,
1212,"Artificial Intelligence Allied Collaboration for Crucial Operations, Research, and Development Act of 2024",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.99,low,0.0,229,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Artificial Intelligence Allied Collaboration for Crucial Operations, Research, and Development Act of 2024” or the “AI ACCORD Act of 2024”. SEC. 2. JOINT PARTNER-SHARING NETWORK CAPABILITIES FOR MIDDLE EAST DEFENSE INTEGRATION. (a) Strategy.— (1) IN GENERAL.—Not later than 180 days after the date of the enactment of this Act, the Secretary of Defense shall submit to the congressional defense committees a strategy to improve cooperation between the Department of Defense and allies and partners of the United States located in the Middle East so as to improve use of partner-sharing network capabilities to facilitate joint defense efforts among the United States and such allies and partners to protect the people, infrastructure, and territory of the United States and such allies and partners from state and non-state actors determined by the Secretary to undermine the national security interests of the United States. (2) CONTENTS.—The strategy submitted pursuant to paragraph (1) shall include the following: (A) A summary of ongoing efforts by United States Central Command (CENTCOM), or in which United States Central Command is participating, to implement a joint partner-sharing network capability integrated with the assets of allies and partners of the United States who are located in the Middle East. (B) A summary of challenges to further facilitate the implementation of a joint partner-sharing network capability integrated wi",https://www.congress.gov/bill/118th-congress/senate-bill/5058/text,en,
1214,SAFE Bet Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8225,low,0.0,228,0.5,Defunct,"SECTION 1. Short title; table of contents. (a) Short title.—This Act may be cited as the “Supporting Affordability and Fairness with Every Bet Act of 2024” or the “SAFE Bet Act”. (b) Table of contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. Sec. 2. Definitions. TITLE I—MINIMUM FEDERAL STANDARDS FOR SPORTS BETTING Sec. 101. General prohibition on sports wagering. Sec. 102. State sports wagering program. Sec. 103. State sports wagering program standards. TITLE II—PUBLIC HEALTH IN SPORTS BETTING Sec. 201. Annual nationwide survey on sports betting. Sec. 202. National Self-Exclusion List. Sec. 203. Surgeon General’s Report on Public Health Challenges Associated with Sports Betting. Sec. 204. Surveillance of gambling addiction. TITLE III—GENERAL PROVISIONS Sec. 301. State and Tribal authority. Sec. 302. Severability. SEC. 2. Definitions. In this Act: (1) AMATEUR ATHLETIC COMPETITION.—The term “amateur athletic competition” has the meaning given the term in section 220501 of title 36, United States Code. (2) ANONYMIZED SPORTS WAGERING DATA.—With respect to a sports wager accepted by a sports wagering operator, the term “anonymized sports wagering data” means— (A) a unique identifier for the transaction and, if available, the individual who placed the sports wager, except that such identifier shall not include any personally identifiable information of such individual; (B) the amount and type of sports wager; (C) the date and time a",https://www.congress.gov/bill/118th-congress/house-bill/9590/text,en,
1216,Veterans Online Information and Cybersecurity Empowerment Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.9844,low,0.0,228,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Veterans Online Information and Cybersecurity Empowerment Act of 2024” or the “VOICE Act of 2024”. SEC. 2. FINDINGS. (a) Findings.—Congress finds the following: (1) Researchers have documented persistent, pervasive, and coordinated online targeting of members of the Armed Forces, veterans, and their families by foreign adversaries seeking to undermine United States democracy in part because of public trust placed in these communities. Government agencies and researchers have also documented the targeting of veterans by fraudsters, especially online scammers, seeking to steal their government benefits. (2) According to the Federal Trade Commission, fraud costs veterans, members of the Armed Forces, and their families $267,000,000 in 2021. This was a 162-percent increase from 2020 and the median loss for these scam victims was $600, 20 percent higher than for the median loss for the general public. According to a 2017 survey conducted by the American Association of Retired Persons (AARP) veterans are twice as likely to unknowingly participate in a scam compared to the general population and an estimated 16 percent of veterans report having losing some money to fraud, while 78 percent report encountering scams that have explicitly designed to exploit their military service. (3) At the same time, adversaries from Russia, China, and Iran are using information warfare to influence democracies across the world, and extremist orga",https://www.congress.gov/bill/118th-congress/house-bill/9583/all-actions,en,
1218,Protecting Patients from Deceptive Drug Ads Online Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.6289,low,0.0,237,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Protecting Patients from Deceptive Drug Ads Online Act”. SEC. 2. REGULATION OF CERTAIN COMMUNICATIONS REGARDING PRESCRIPTION DRUGS. (a) Regulation Of Communications.— (1) IN GENERAL.—Section 303 of the Federal Food, Drug, and Cosmetic Act (21 U.S.C. 333) is amended by adding at the end the following: “(h) (1) In the case of a social media influencer or health care provider who makes false or misleading communications regarding a drug approved under section 505 or licensed under section 351 of the Public Health Service Act, and subject to section 503(b), shall be liable to the United States for a civil penalty in an amount described in paragraph (g)(1), in accordance with a process similar to the process described in paragraph (g)(2). “(2) For purposes of this paragraph— “(A) the term ‘false or misleading communications’— “(i) means advertisements or promotional communications on a social media platform from which there is a financial benefit to the person engaging in such communications regarding such drug— “(I) (aa) that are made knowingly or recklessly; and “(bb) contain a false or inaccurate statement or material omission of fact regarding a drug described in subparagraph (1); or “(II) fail to include information in brief summary relating to side effects, contraindications, and effectiveness of the drug in the same manner and to the same extent as such information is required in prescription drug advertisements pursuant",https://www.congress.gov/bill/118th-congress/senate-bill/5040/all-actions,en,
1219,Workforce of the Future Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9856,low,0.0,236,0.5,Defunct,"A BILL To promote a 21st century artificial intelligence workforce and to authorize the Secretary of Education to carry out a program to increase access to prekindergarten through grade 12 emerging and advanced technology education and upskill workers in the technology of the future. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Workforce of the Future Act of 2024”. SEC. 2. Table of contents. The table of contents for this Act is as follows: Sec. 1. Short title. Sec. 2. Table of contents. TITLE I—IMPACT OF ARTIFICIAL INTELLIGENCE ON JOBS Sec. 101. Sense of Congress. Sec. 102. Definitions. Sec. 103. Report on artificial intelligence. TITLE II—EMERGING AND ADVANCED TECHNOLOGY EDUCATION AND WORKFORCE DEVELOPMENT Sec. 201. Findings. Sec. 202. Definitions. Sec. 203. Department of Education grants. Sec. 204. Department of Labor grants. Sec. 205. Reporting requirements. Sec. 206. Amendments to other laws. TITLE I—Impact of Artificial Intelligence on Jobs SEC. 101. Sense of Congress. It is the sense of Congress that— (1) while the field of artificial intelligence is evolving quickly and has potential to disrupt jobs, there are opportunities to prepare the American workforce to develop and work alongside this new technology and mitigate the potential negative consequences of job displacement; and (2) to ensure these opportunities, it is imperative to identify the fol",https://www.congress.gov/bill/118th-congress/senate-bill/5031/text,en,
1221,Transformational Artificial intelligence to Modernize the Economy against Extreme Weather Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8885,low,0.0,206,0.5,Defunct,"SECTION 1. SHORT TITLE; TABLE OF CONTENTS. (a) Short Title.—This Act may be cited as the “Transformational Artificial intelligence to Modernize the Economy against Extreme Weather Act” or the “TAME Extreme Weather Act”. (b) Table Of Contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. Sec. 2. Definitions. Sec. 3. Earth system forecasting and information delivery. Sec. 4. Advanced artificial intelligence applications for weather and information delivery. Sec. 5. Technical assistance on use of artificial intelligence weather models. Sec. 6. Fire environment modeling program. Sec. 7. Emissions monitoring and analysis program. Sec. 8. Partnerships for transformational innovation. Sec. 9. Federal Government workforce expertise. Sec. 10. Data access.SEC. 2. DEFINITIONS. In this Act: (1) ADMINISTRATOR.—The term “Administrator” means the Administrator of the National Oceanic and Atmospheric Administration. (2) ARTIFICIAL INTELLIGENCE.— (A) IN GENERAL.—The term “artificial intelligence” means a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments, including by using machine-based and human-based inputs— (i) to abstract such objectives into models through analysis in an automated manner; and (ii) to use model inferences to generate information or formulate options for action. (B) INCLUSIONS.—The term “artificial intelligence” inc",https://www.congress.gov/bill/118th-congress/house-bill/9498/all-actions,en,
1222,AI Advancement and Reliability Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9666,low,0.2778,222,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “AI Advancement and Reliability Act of 2024”. SEC. 2. ARTIFICIAL INTELLIGENCE ADVANCEMENT AND RELIABILITY. (a) In General.—Section 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401; as enacted as part of division E of the William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021; Public Law 116–283) is amended— (1) by redesignating paragraphs (4), (5), (6), (7), (8), (9), (10), and (11) as paragraphs (6), (8), (9), (10), (11), (12), (13), and (14), respectively; (2) by inserting after paragraph (3) the following new paragraphs: “(4) ARTIFICIAL INTELLIGENCE RED TEAMING.—The term ‘artificial intelligence red teaming’ means a structured testing in a controlled environment simulating real-world conditions, using adversarial methods to find flaws and vulnerabilities in an artificial intelligence system and identify risks, flaws, and vulnerabilities of artificial intelligence systems, such as harmful outputs from such system, unforeseen or undesirable system behaviors, limitations, and potential risks associated with the misuse of such system. “(5) ARTIFICIAL INTELLIGENCE SYSTEM.—The term ‘artificial intelligence system’ has the meaning given such term in section 7223 of the Advancing American AI Act (40 U.S.C. 11301 note; as enacted as part of title LXXII of division G of the James M. Inhofe National Defense Authorization Act for Fiscal Year 2023; Public Law 117–263).”;",https://www.congress.gov/bill/118th-congress/house-bill/9497/all-actions,en,"Strategies: New institution, Risk factors: Reliability, Risk factors: Reliability: Robustness, Risk factors: Safety, Risk factors: Security, Strategies: Government support, Strategies: Convening, Risk factors: Transparency, Strategies: Evaluation, Strategies: Governance development, Strategies: Government study or report"
1223,AI Grand Challenges Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9878,low,0.0,210,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “AI Grand Challenges Act of 2024”. SEC. 2. PRIZE COMPETITIONS FOR ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT. (a) Definition.—Except as otherwise expressly provided, in this section the term “Director” means the Director of the National Science Foundation. (b) Establishment Of Program.— (1) IN GENERAL.—Not later than 12 months after the date of enactment of this Act, the Director, in coordination with the Interagency Committee established under section 5103 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9413), shall establish a program to award prizes, utilizing the authorities and processes established under section 24 of the Stevenson-Wydler Technology Innovation Act of 1980 (15 U.S.C. 3719), to eligible participants as determined by the Director pursuant to subsection (e) to stimulate artificial intelligence research, development, and commercialization that solves or advances specific, well-defined, and measurable grand challenges in 1 or more of the following categories: (A) National security. (B) Cybersecurity. (C) Health. (D) Energy. (E) Environment. (F) Transportation. (G) Agriculture and rural development. (H) Education and workforce training. (I) Manufacturing. (J) Space and aerospace. (K) Quantum computing, including molecular modeling and simulation. (L) Materials science. (M) Supply chain resilience. (N) Disaster preparedness. (O) Natural resources management. (P) Cross cutting c",https://www.congress.gov/bill/118th-congress/house-bill/9475/text,en,"Strategies: Government support, Strategies: Government support: For R&D, Incentives: Subsidies, Strategies: Convening, Applications: Medicine, life sciences and public health, Strategies: Government study or report"
1225,AI Development Practices Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9724,low,0.0,212,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “AI Development Practices Act of 2024”. SEC. 2. NIST RESEARCH ON DEVELOPMENT BEST PRACTICES. Section 22A of the National Institute of Standards and Technology Act (15 U.S.C. 278h–1) is amended— (1) by redesignating subsection (h) as subsection (i); and (2) by inserting after subsection (g) the following new subsection: “(h) Assessment Of The Practices Of Artificial Intelligence Development.— “(1) IN GENERAL.—The Director of the National Institute of Standards and Technology (in this subsection referred to as the ‘Director’) shall, subject to the availability of appropriations, develop, and periodically update, in collaboration with other public and private sector organizations, voluntary guidance for practices and guidelines relating to the development, release, and assessment of artificial intelligence systems. Such guidelines shall satisfy the following: “(A) Define methods and guidelines for developing reasonable risk tolerances for various use cases of artificial intelligence systems based on the following: “(i) The risks associated with the intended and unintended applications, use cases, and outcomes of the artificial intelligence system at issue, based on the guidelines specified in the voluntary risk management framework for trustworthy artificial intelligence systems, or successor framework, authorized under subsection (c), which may include different categories of risk, such as the following: “(I) Security risks,",https://www.congress.gov/bill/118th-congress/house-bill/9466/all-actions,en,
1227,PATHS Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.977,low,0.0,229,0.5,Defunct,"AN ACT To amend the Homeland Security Act of 2002 to enable secure and trustworthy technology through other transaction contracting authority, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Producing Advanced Technologies for Homeland Security Act” or the “PATHS Act”. SEC. 2. Research and development acquisition pilot program extension. (a) In general.—Section 831 of the Homeland Security Act of 2002 (6 U.S.C. 391) is amended— (1) in subsection (a)— (A) in the matter preceding paragraph (1), by striking “Until September 30, 2024, and subject to subsection (d)” and inserting “Until September 30, 2027, and subject to subsection (c)”; and (B) by adding at the end the following new paragraph: “(3) OTHER TRANSACTION AUTHORITY INVOLVING ARTIFICIAL INTELLIGENCE.—Not later than 72 hours after the use or extension of the transaction authority authorized under paragraph (1) involving artificial intelligence technology, the Secretary shall notify the Committee on Appropriations and the Committee on Homeland Security and Governmental Affairs of the Senate and the Committee on Appropriations and the Committee on Homeland Security of the House of Representatives and offer a briefing explaining the reason for the use or extension.”; and (2) in subsection (c)(1), in the matter preceding subparagraph (A), by striking “September 30, 2024” and inserting",https://www.congress.gov/bill/118th-congress/house-bill/9459/text,en,
1228,Expanding AI Voices Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9667,low,0.0556,215,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Expanding AI Voices through Capacity Building Act” or the “Expanding AI Voices Act”. SEC. 2. EXPANDING CAPACITY IN ARTIFICIAL INTELLIGENCE SCIENCE. Section 5401 of the National AI Initiative Act (15 U.S.C. 9451; enacted as part of title LIV of division E of the William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021; Public Law 116–283) is amended by— (1) redesignating subsection (g) as subsection (h); and (2) inserting after subsection (f) the following new subsection: “(g) Expanding Capacity In Artificial Intelligence.— “(1) IN GENERAL.—The Director of the National Science Foundation, in consultation with the heads of Federal agencies the Director considers appropriate, shall make awards on a competitive, merit-reviewed basis to eligible institutions of higher education specified in paragraph (2) or eligible nonprofit organizations (or consortia thereof) to broaden participation in artificial intelligence research, education, and workforce development by increasing the ability of the United States to increase capacity and partnerships for artificial intelligence research and development. “(2) ELIGIBLE INSTITUTIONS OF HIGHER EDUCATION SPECIFIED.—Eligible institution of higher education specified in this paragraph the following: “(A) An institution of higher education, that, according to the data published by the National Center for Science and Engineering Statistics, is not, on average, among t",https://www.congress.gov/bill/118th-congress/house-bill/9403,en,"Strategies: Government support, Strategies: Government support: For R&D, Incentives: Subsidies, Harms: Violation of civil or human rights, including privacy"
1230,Unleashing AI Innovation in Financial Services Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9766,low,0.0,236,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Unleashing AI Innovation in Financial Services Act”. SEC. 2. USE OF ARTIFICIAL INTELLIGENCE BY REGULATED FINANCIAL ENTITIES. (a) Definitions.—In this section: (1) AI TEST PROJECT.—The term “AI test project” means a financial product or service that falls under the jurisdiction of a financial regulatory agency and— (A) substantially uses artificial intelligence; and (B) is or may be subject to a Federal regulation or Federal statute. (2) APPROPRIATE FINANCIAL REGULATORY AGENCY.—The term “appropriate financial regulatory agency” means— (A) the appropriate Federal banking agency, as defined in section 3 of the Federal Deposit Insurance Act (12 U.S.C. 1813); (B) the Securities and Exchange Commission, with respect to— (i) any broker or dealer that is registered with the Commission under the Securities Exchange Act of 1934 (15 U.S.C. 78a et seq.), with respect to the activities of the broker or dealer that require the broker or dealer to be registered under that Act; (ii) any investment company that is registered with the Commission under the Investment Company Act of 1940 (15 U.S.C. 80a–1 et seq.), with respect to the activities of the investment company that require the investment company to be registered under that Act; (iii) any investment adviser that is registered with the Commission under the Investment Advisers Act of 1940 (15 U.S.C. 80b–1 et seq.), with respect to the investment advisory activities of such company and",https://www.congress.gov/bill/118th-congress/house-bill/9309/text,en,
1231,Supporting Innovation in Agriculture Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9901,low,0.0,228,0.5,Defunct,"A BILL To amend the Internal Revenue Code of 1986 to establish a credit for investments in innovative agricultural technology. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Supporting Innovation in Agriculture Act of 2024”. SEC. 2. Credit for investment in innovative agricultural technology. (a) In general.—Subpart E of part IV of subchapter A of chapter 1 of the Internal Revenue Code of 1986 is amended by inserting after section 48E the following new section: “SEC. 48F. Innovative agricultural technology investment credit. “(a) In general.—For purposes of section 46, the innovative agricultural technology investment credit for any taxable year is an amount equal to 30 percent of the qualified investment for such taxable year with respect to any innovative agricultural technology project. “(b) Qualified investment.— “(1) IN GENERAL.—For purposes of subsection (a), the qualified investment with respect to any innovative agricultural technology project for any taxable year is the basis of any qualified property placed in service by the taxpayer during such taxable year which is part of an innovative agricultural technology project. “(2) QUALIFIED PROPERTY.—For purposes of this section, the term ‘qualified property’ means property— “(A) which is— “(i) tangible personal property, whether or not affixed to real property (including equipment, systems and their com",https://www.congress.gov/bill/118th-congress/house-bill/9263/text,en,
1232,National Windstorm Impact Reduction Program Reauthorization Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.6249,low,0.0,225,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “National Windstorm Impact Reduction Program Reauthorization Act of 2024”. SEC. 2. NATIONAL WINDSTORM IMPACT REDUCTION PROGRAM. The National Windstorm Impact Reduction Act of 2004 (Public Law 108–360) is amended— (1) in section 204 (42 U.S.C. 15703)— (A) in subsection (a), by striking “the purpose of which is to achieve” through “cost-effective mitigation measures to reduce those impacts.” and inserting the following: “the purpose of which is to— “(1) achieve major measurable reductions in the losses of life and property from windstorms through a coordinated Federal effort, in cooperation with other levels of government, academia, scientific organizations, and the private sector, aimed at improving the understanding of windstorms and their impacts, including wind-driven rain and storm surge impacts; “(2) understand climate variability and climate change impacts on windstorms and the changing nature of windstorm risks and to provide the scientific basis for model building codes to be informed by future projections of storm frequency, intensity, and other factors; and “(3) develop and encourage the implementation of cost-effective mitigation measures to reduce the impacts described in paragraphs (1) and (2), which can be applied to communities with different types of housing and infrastructure in urban and rural areas across the United States.”; (B) in subsection (b)— (i) in paragraph (1)— (I) in subparagraph (A), by insertin",https://www.congress.gov/bill/118th-congress/house-bill/9252,en,
1233,Bureau of Industry and Security Information Technology Modernization Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9838,low,0.0,220,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Bureau of Industry and Security Information Technology Modernization Act” or the “BIS IT Modernization Act”. SEC. 2. MODERNIZATION OF INFORMATION TECHNOLOGY SYSTEMS AND APPLICATIONS OF THE BUREAU OF INDUSTRY AND SECURITY. (a) Sense Of Congress.—It is the sense of Congress that the effective use of export controls requires that— (1) the Bureau of Industry and Security of the Department of Commerce adopt and deploy cutting-edge data fusion, analytics, and decision-making capabilities, as well as supply chain illumination tools, and additional commercial data sets to streamline and standardize the export license adjudication process, better assess global industrial relationships, and identify evasive trade patterns and shell companies being used by adversary militaries; (2) the Bureau expand and scale up the adoption and use of modern data sharing interfaces and capabilities to share data safely and efficiently with industry, Federal agencies, and international partners; (3) Bureau information technology systems should over time enable the incorporation of artificial intelligence, machine learning, and other advanced tools as technologies evolve; (4) the Bureau expedite Entity List deliberations tied to countries of concern and enforcement activities related to tracking military end users and end uses in countries of concern including the People’s Republic of China (PRC), Russia, and Iran; (5) the Bureau work with relevant ag",https://www.congress.gov/bill/118th-congress/house-bill/9247/all-actions,en,
1234,Artificial Intelligence Acquisitions Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9565,low,0.0556,237,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Artificial Intelligence Acquisitions Act of 2024”. SEC. 2. DEFINITIONS. In this Act: (1) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence” has the meaning given that term in section 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401). (2) CONTROL.—The term “control” has the meaning given that term in section 800.208 of title 31, Code of Federal Regulations (as in effect on the date of enactment of this Act). (3) COUNTRY OF CONCERN.—The term “country of concern”— (A) means a country the government of which is a foreign adversary, as defined in section 8(c) of the Secure and Trusted Communications Networks Act of 2019 (47 U.S.C. 1607(c)); and (B) includes— (i) the People’s Republic of China (including the Special Administrative Regions of the People’s Republic of China, Hong Kong and Macau); (ii) the Russian Federation; (iii) the Islamic Republic of Iran; (iv) the Democratic People’s Republic of Korea; (v) the Republic of Cuba; (vi) the Maduro Regime of Venezuela; and (vii) the Syrian Arab Republic. (4) FEDERAL AGENCY.—The term “Federal agency” has the meaning given the term in section 5122 of title 42, United States Code. (5) FIRMWARE.—The term “firmware” has the meaning given the term in section 120.40 of title 22, Code of Federal Regulations. (6) FOREIGN PERSON OF CONCERN.—The term “foreign person of concern” means— (A) any corporation, business association, partnership, trust, s",https://www.congress.gov/bill/118th-congress/senate-bill/4976/text,en,"Strategies: Government study or report, Strategies: Licensing, registration, and certification, Strategies: Disclosure, Risk factors: Security, Applications: Government: military and public safety"
1239,Forecasting Optimization for Robust Earth Climate Analysis and Subseasonal-to-Seasonal Tracking Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9772,low,0.0,200,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Forecasting Optimization for Robust Earth Climate Analysis and Subseasonal-to-Seasonal Tracking Act of 2024” or the “FORECASTS Tracking Act of 2024”. SEC. 2. IMPROVEMENTS TO WEATHER RESEARCH AND FORECASTING. (a) Improvements To Subseasonal-To-Seasonal Forecasting.—Section 1762 of the Food Security Act of 1985 (15 U.S.C. 8521) is amended— (1) by amending subsection (c) to read as follows: “(c) Functions.— “(1) IN GENERAL.—The Under Secretary and the heads of such other programs of the National Oceanic and Atmospheric Administration as the Under Secretary considers appropriate, shall— “(A) conduct and support fundamental research to improve understanding of the sources and limitations of season-to-season predictability for temperature, precipitation, and other Earth system variables and applications; “(B) collect and utilize observational data across the Earth system and other information in order to make usable, reliable, and timely foundational forecasts of subseasonal-to-seasonal temperature and precipitation; “(C) prioritize the advancement of multi-model ensemble forecast systems and forecast verification and evaluation capacity, including— “(i) the development of advanced coupled data assimilation methods using robust Earth system observational data; “(ii) the development of improved coupled subseasonal-to-seasonal ensemble prediction systems; “(iii) the improvement of exchanges and interactions between datasets across",https://www.congress.gov/bill/118th-congress/senate-bill/4907/all-actions,en,
1241,AI Innovation and Development for Efficiency Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9865,low,0.0,204,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “AI Innovation and Development for Efficiency Act of 2024” or the “AIDE Act of 2024”. SEC. 2. NATIONAL SCIENCE FOUNDATION SUPPORT OF RESEARCH ON IMPACTS OF ARTIFICIAL INTELLIGENCE ON EFFICIENT TECHNOLOGIES. (a) Definitions.—In this section: (1) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence” means a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations or decisions influencing real or virtual environments. Artificial intelligence systems use machine and human-based inputs to— (A) perceive real and virtual environments; (B) abstract such perceptions into models through analysis in an automated manner; and (C) use model inference to formulate options for information or action. (2) DIRECTOR.—The term “Director” means the Director of the National Science Foundation. (3) EFFICIENT TECHNOLOGY.—The term “efficient technology” means a technology that critically considers minimizing emissions, securing clean air and water, building climate and community resiliency, promoting healthy food, and other sustainability pillars. (4) EPSCOR INSTITUTION.—The term “EPSCoR institution” means an institution of higher education, nonprofit organization, or other institution located in a jurisdiction eligible to participate in the Established Program to Stimulate Competitive Research under section 113 of the National Science Foundation Authorization Act of 1988 (42 U.S.C. 1862g).(",https://www.congress.gov/bill/118th-congress/senate-bill/4896/all-actions,en,
1242,NO FAKES Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.6775,low,0.0,233,0.5,Defunct,"A BILL To protect intellectual property rights in the voice and visual likeness of individuals, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Nurture Originals, Foster Art, and Keep Entertainment Safe Act of 2024” or the “NO FAKES Act of 2024”. SEC. 2. Voice and visual likeness rights. (a) Definitions.—In this section: (1) DIGITAL REPLICA.—The term “digital replica” means a newly-created, computer-generated, highly realistic electronic representation that is readily identifiable as the voice or visual likeness of an individual that— (A) is embodied in a sound recording, image, audiovisual work, including an audiovisual work that does not have any accompanying sounds, or transmission— (i) in which the actual individual did not actually perform or appear; or (ii) that is a version of a sound recording, image, or audiovisual work in which the actual individual did perform or appear, in which the fundamental character of the performance or appearance has been materially altered; and (B) does not include the electronic reproduction, use of a sample of one sound recording or audiovisual work into another, remixing, mastering, or digital remastering of a sound recording or audiovisual work authorized by the copyright holder. (2) INDIVIDUAL.—The term “individual” means a human being, living or dead. (3) ONLINE SERVICE.—The term “online servic",https://www.congress.gov/bill/118th-congress/senate-bill/4875/text,en,
1243,Workforce for AI Trust Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9898,low,0.0,210,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Workforce for AI Trust Act”. SEC. 2. NSF ARTIFICIAL INTELLIGENCE RESEARCH AND EDUCATION; NIST ARTIFICIAL INTELLIGENCE GOVERNANCE WORKFORCE. (a) NSF Artificial Intelligence Research And Education.—— (1) FELLOWSHIPS.—Subsection (e) of section 5401 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9451; enacted as part of title LIV of division E of the William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021 (Public Law 116–283)) is amended— (A) in paragraph (2)— (i) in the heading, by striking “FACULTY”; and (ii) by adding at the end the following new subparagraph: “(D) INTERDISCIPLINARY ARTIFICIAL INTELLIGENCE FELLOWSHIPS.— “(i) IN GENERAL.—The Director of the National Science Foundation may support graduate and postdoctoral research fellowships for students and postdoctoral researchers from across disciplines, including social science disciplines and the humanities, by making awards through qualified institutions of higher education for research and related activities related to the integration of ethical and responsible practices and principles into the design, development, training, deployment, evaluation, and understanding of artificial intelligence systems. “(ii) USE OF AWARDS.—An institution of higher education shall use awards under clause (i) for the following purposes: “(I) For graduate fellowships, tuition, education-related fees, and stipends for up to three acad",https://www.congress.gov/bill/118th-congress/house-bill/9215/text,en,"Strategies: Government support, Strategies: Government support: For R&D, Incentives: Subsidies, Strategies: Disclosure, Strategies: Convening, Applications: Government: other applications/unspecified, Strategies: Evaluation, Strategies: Government support: AI workforce-related"
1244,Literacy in Future Technologies Artificial Intelligence Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.993,low,0.0,230,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Literacy in Future Technologies Artificial Intelligence Act” or the “LIFT AI Act”. SEC. 2. PREPARING K–12 EDUCATORS AND STUDENTS FOR AN AI LITERATE FUTURE. (a) Sense Of Congress.—It is the sense of Congress that— (1) AI literacy education is crucial not only for developing a skilled workforce and positioning the Nation as a leader in this critical field, but also for mitigating the ethical challenges associated with AI; (2) as strategic adversaries pursue AI technology for the purposes of surveillance, weaponization, and economic competition, maintaining United States leadership through an AI literate public is essential; (3) AI literacy education at the K–12 level forms the foundation for success in this competitive environment, and proficiency with these technologies is becoming necessary to be an engaged and informed citizen; (4) AI technology is rapidly evolving, and current best practices for learning and developing AI literacy today may not be applicable in the future; (5) awards made under this section should recognize the rapidly evolving nature of AI technology, and identify and focus on those skills that will remain relevant to AI literacy considering likely changes in AI capabilities; and (6) awards made under this section should recognize student progression to more advanced topics as they progress through K–12 education.(b) Awards.—The Director may make awards on a merit-reviewed, competitive basis to institut",https://www.congress.gov/bill/118th-congress/house-bill/9211/text,en,"Strategies: Government support, Incentives: Subsidies"
1245,Atomic Supply Chain Solutions Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9884,low,0.0,237,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Atomic Supply Chain Solutions Act”. SEC. 2. FINDINGS. Congress finds the following: (1) The United States remains an esteemed global leader in the area of nuclear safety. (2) The strength of the nuclear supply chain of the United States is directly tied to the growth of the nuclear energy sector.SEC. 3. NUCLEAR SUPPLY CHAIN EVALUATION. (a) In General.—Not later than 270 days after the date of enactment of this Act, the Secretary of Energy shall develop and submit to the appropriate congressional committees an evaluation of the nuclear supply chain of the United States. (b) Contents.— (1) BUILDING UP AT THE RIGHT TIME.—The evaluation developed and submitted under subsection (a) shall include a general description of— (A) past efforts within the nuclear supply chain of the United States to meet increased demand; (B) the importance of proactively bolstering the nuclear supply chain of the United States in order to meet future demand for nuclear energy; and (C) lessons learned from the construction of Vogtle 3 and 4 in Georgia, including an analysis of how the nuclear supply chain of the United States operated during such construction and any improvements that could be made to assist with future nuclear construction projects, including workforce and supply chain considerations. (2) COMPONENT REGULATORY CHALLENGES.—The evaluation developed and submitted under subsection (a) shall include— (A) an analysis of whether the requirem",https://www.congress.gov/bill/118th-congress/house-bill/9200/text,en,
1246,Small Business Artificial Intelligence Advancement Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9811,low,0.0,211,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Small Business Artificial Intelligence Advancement Act”. SEC. 2. RESOURCES FOR SMALL BUSINESSES TO UTILIZE ARTIFICIAL INTELLIGENCE. Section 22A of the National Institute of Standards and Technology Act (15 U.S.C. 278h–1) is amended— (1) by redesignating subsection (h) as subsection (i); and (2) by inserting after subsection (g) the following new subsection: “(h) Development Of Resources For Small Businesses In Utilizing Artificial Intelligence.— “(1) IN GENERAL.—Subject to the availability of appropriations, the Director shall, in carrying out subsection (a), develop or identify, and disseminate (in accordance with paragraph (4)), resources for small business concerns (as such term is defined in section 3 of the Small Business Act (15 U.S.C. 632)) relating to artificial intelligence. Such resources may include technical standards, best practices, benchmarks, methodologies, procedures, or processes for the understanding, adoption, or integration of artificial intelligence. “(2) REQUIREMENTS.—The Director shall ensure that the resources described in paragraph (1) satisfy the following: “(A) Are generally applicable and usable by a wide range of small business concerns. “(B) Include elements that promote basic understanding, identification, and adoption of proper use cases of artificial intelligence. “(C) Include case studies of practical application across a range of business sizes and types. “(D) Are technology-neutral and",https://www.congress.gov/bill/118th-congress/house-bill/9197/text,en,
1247,Nucleic Acid Standards for Biosecurity Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9867,low,0.0,213,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited “Nucleic Acid Standards for Biosecurity Act”. SEC. 2. SUPPORTING NUCLEIC ACID SCREENING. Section 10221 of the Research and Development, Competition, and Innovation Act (42 U.S.C. 18931; enacted as part of title II of division B of Public Law 117–167) is amended— (1) in subsection (a)(1)— (A) in subparagraph (C), by striking “and” after the semicolon; (B) by redesignating subparagraph (D) as subparagraph (E); and (C) by inserting after subparagraph (C) the following new subparagraph: “(D) best practices, guidelines, and technical standards for risk management associated with engineering biology and biomanufacturing, including risks associated with the use of artificial intelligence; and”; (2) by redesignating subsections (b) and (c) as subsections (c) and (d), respectively; and (3) by inserting after subsection (a) the following new subsection: “(b) Nucleic Acid Synthesis Screening Tools And Standards.— “(1) IN GENERAL.—The Director, in consultation with heads of Federal agencies the Director considers appropriate, shall carry out measurement research to support the development and improvement of best practices and technical standards for biosecurity measures related to nucleic acid synthesis, including the following: “(A) Testing to improve the accuracy, efficacy, and reliability of screening for nucleic acid synthesis. “(B) Best practices, including security and access controls, for operational security and managing sequence-of-c",https://www.congress.gov/bill/118th-congress/house-bill/9194/text,en,
1248,"S.4870, A bill to require reports on artificial intelligence regulation in the financial services industry.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9839,low,0.0,224,0.5,Defunct,"SECTION 1. REPORT ON ARTIFICIAL INTELLIGENCE REGULATION IN FINANCIAL SERVICES INDUSTRY. (a) In General.—Not later than 90 days after the date of enactment of this Act, each of the Board of Governors of the Federal Reserve System, the Federal Deposit Insurance Corporation, the Office of the Comptroller of the Currency, the National Credit Union Administration, and the Bureau of Consumer Financial Protection shall submit to the Committee on Banking, Housing, and Urban Affairs of the Senate and the Committee on Financial Services of the House of Representatives a report on the gap in knowledge of the agency relating to artificial intelligence, including an analysis on— (1) which tasks are most frequently being assisted or completed with artificial intelligence in the institutions the agency regulates; (2) current governance standards in place for artificial intelligence use at the agency and current standards in place for artificial intelligence oversight by the agency; (3) potentially additional regulatory authorities required by the agency to continue to successfully execute the mission of the agency; (4) where artificial intelligence may lead to overlapping regulatory issues between agencies that require clarification; (5) how the agency is currently using artificial intelligence, how the agency plans to use such artificial intelligence the next 3 years, and the expected impact, including fiscal and staffing, of those plans; and (6) what resources, monetary or other resources",https://www.congress.gov/bill/118th-congress/senate-bill/4870,en,
1249,"S.4862, A bill to ensure that new advances in artificial intelligence are ethically adopted to improve the health of all individuals, and for other purposes.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9924,low,0.0,222,0.5,Defunct,"SECTION 1. GOVERNING ETHICAL AI USE AND INNOVATION FOR HEALTH CARE DEVELOPMENT. (a) National Institutes Of Health.—Part A of title IV of the Public Health Service Act is amended by inserting after section 403D (42 U.S.C. 283a–3) the following: “SEC. 403E. ARTIFICIAL INTELLIGENCE. “(a) In General.—The Director of NIH shall— “(1) develop computational resources and datasets necessary to use artificial intelligence approaches for health and health care research; “(2) provide expertise in biomedical research and the use of artificial intelligence; “(3) develop and maintain federated resources that provide unified access to data from fundamental biomedical research and the clinical care environment; “(4) provide education and ongoing support to a nationwide user community to foster scientifically sound, ethical, and inclusive research using artificial intelligence that addresses the health needs of all individuals; and “(5) extend the clinical research capabilities of the National Institutes of Health to address significant gaps in evidence to guide clinical care and to serve the needs of every community. “(b) Authorization Of Appropriations.—There is authorized to be appropriated to the Director of NIH to carry out this section $400,000,000 for fiscal year 2025.”. (b) Office Of The National Coordinator For Health Information Technology.—Subtitle C of title XXX of the Public Health Service Act (42 U.S.C. 300jj–51 et seq.) is amended by adding at the end the following:“SEC. 3023. A",https://www.congress.gov/bill/118th-congress/senate-bill/4862/text,en,
1251,Consumer Literacy and Empowerment to Advance Responsible Navigation of Artificial Intelligence Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9954,low,0.1111,216,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Consumer Literacy and Empowerment to Advance Responsible Navigation of Artificial Intelligence Act” or the “Consumers LEARN AI Act”. SEC. 2. FINDINGS. Congress finds the following: (1) Artificial intelligence is being incorporated into progressively more products and services that affect the lives of individuals across the United States every day. (2) Artificial intelligence technology has the potential to benefit consumers— (A) in terms of increased efficiency; (B) in areas such as automation, personalized learning, entertainment, problem solving, and more; and (C) with respect to future advances yet to be invented. (3) Consumers require new skill sets and guidance on best practices to make effective use of artificial intelligence products and services. A lack of familiarity with new technology can create barriers to its adoption and trust. An understanding of the strengths and limitations of artificial intelligence technologies can enable consumers to make informed decisions about when and where to employ artificial intelligence products and services. (4) Consumer education can supplement, although not replace, the responsibility of developers and deployers of artificial intelligence products and services to ensure their safety and efficacy and to provide product-specific consumer guidance about recommended uses as well as inappropriate or unsafe uses.SEC. 3. DEFINITIONS. In this Act: (1) ARTIFICIAL INTELLIGENCE.—The ter",https://www.congress.gov/bill/118th-congress/senate-bill/4838/text,en,"Strategies: Governance development, Strategies: Convening, Risk factors: Transparency, Risk factors: Interpretability and explainability, Strategies: Government support, Strategies: Government support: AI workforce-related, Applications: Finance and investment, Applications: Medicine, life sciences and public health, Applications: Broadcasting and media production, Applications: Business services and analytics, Applications: Networking and telecommunications, Strategies: Government study or report"
1258,Digital Social Platform Transparency Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.4019,low,0.0,241,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Digital Social Platform Transparency Act”. SEC. 2. TERMS OF SERVICE REQUIREMENT. (a) Terms Of Service.—Not later than 180 days after the date of enactment of this Act, digital social companies shall post terms of service for each digital social platform owned or operated by the company in a manner reasonably designed to inform all users of the digital social platform of the existence and contents of the terms of service. The terms of service posted pursuant to this section shall include each of the following: (1) Contact information for the purpose of allowing users to ask the digital social company questions about the terms of service. (2) A description of the process that users must follow to flag content, groups, or other users that they believe violate the terms of service, and the digital social company’s commitments on response and resolution time. (3) A list of potential actions the digital social company may take against an item of content or a user, including demonetization, deprioritization, muting, or banning. (b) Translations.—The terms of service posted pursuant to this section shall be made available in all languages in which the digital social platform offers product features, including menus and prompts.SEC. 3. REPORTING REQUIREMENT. (a) Terms Of Service Report.—Not later than 360 days after the date of enactment of this Act, and on a semiannual basis thereafter, each digital social company shall electronic",https://www.congress.gov/bill/118th-congress/house-bill/9126/all-actions,en,
1259,Validation and Evaluation for Trustworthy (VET) Artificial Intelligence Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9945,low,0.0,204,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Validation and Evaluation for Trustworthy (VET) Artificial Intelligence Act” or the “VET Artificial Intelligence Act”. SEC. 2. PURPOSES. The purposes of this Act are— (1) to develop consensus-driven, evidence-based voluntary guidelines and specifications for internal and external assurances through the testing, evaluation, validation, and verification of artificial intelligence systems, as appropriate based on the intended application, use-case, and risk profile of the artificial intelligence system; (2) to use meaningful assurance to supplement methodologies used to build trust in artificial intelligence systems, increase adoption of artificial intelligence systems, and provide for accountability and governance of artificial intelligence systems; and (3) to further the goals of the Artificial Intelligence Risk Management Framework, including any successor framework, published by the National Institute of Standards and Technology and the Artificial Intelligence Safety Institute pursuant to section 22A(c) of the National Institute of Standards and Technology Act (15 U.S.C. 278h–1(c)).SEC. 3. DEFINITIONS. In this Act: (1) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence” has the meaning given the term in section 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401). (2) ARTIFICIAL INTELLIGENCE SYSTEM.—The term “artificial intelligence system” has the meaning given such term in section",https://www.congress.gov/bill/118th-congress/senate-bill/4769/all-actions,en,
1261,"A bill to require the Secretary of Defense to carry out a pilot program on using artificial intelligence-enabled software to optimize the workflow and operations of depots, shipyards, and other manufacturing facilities run by the Department of Defense, and for other purposes.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.986,low,0.0,223,0.5,Defunct,"A BILL To require the Secretary of Defense to carry out a pilot program on using artificial intelligence-enabled software to optimize the workflow and operations of depots, shipyards, and other manufacturing facilities run by the Department of Defense, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Department of Defense pilot program on use of artificial intelligence. (a) Pilot program required.—Not later than 60 days after the date of the enactment of this Act, the Secretary of Defense shall commence carrying out a pilot program to assess the feasibility and advisability of using artificial intelligence-enabled software to optimize the workflow and operations for— (1) depots, shipyards, or other manufacturing facilities run by the Department of Defense; and (2) contract administration for the Department, including the adjudication and review of contracts managed by the Defense Contract Management Agency. (b) Software.—In carrying out the pilot program required by subsection (a), the Secretary shall— (1) use best in breed software platforms; (2) consider industry best practices in the selection of software programs; (3) be implemented based on human centered design practices to best identify the business needs for improvement; and (4) demonstrate connection to enterprise platforms of record with relevant data sources. (c) Minimum expenditures.—In carrying out the pilot program",https://www.congress.gov/bill/118th-congress/senate-bill/4758/text,en,
1263,"To provide for citizen engagement on the development and adoption of Federal civilian agency use of artificial intelligence, and for other purposes.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.986,low,0.0,205,0.5,Defunct,"A BILL To provide for citizen engagement on the development and adoption of Federal civilian agency use of artificial intelligence, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Citizen engagement on development and adoption of Federal civilian agency use of artificial intelligence. (a) In general.—The Secretary of Homeland Security shall conduct virtual and in-person listening sessions in various locations in the United States to provide a forum for discussion and consultation with appropriate representatives of States, territories, Tribal authorities, civil rights organizations, human rights organizations, women’s rights organizations, immigrant communities, faith communities, environmental protection organizations, agricultural businesses (including family and specialty farming and ranching entities), labor organizations, and academia regarding the development and adoption of Federal civilian agency use of artificial intelligence. (b) Further engagement.—The Secretary of Homeland Security shall encourage entities described in subsection (a) to conduct listening sessions similar to those described in such subsection, and report back to the Secretary regarding development and adoption of Federal civilian agency use of artificial intelligence. (c) Report.—Not later than 240 days after the date of the enactment of this Act and annually thereafter, the Secretary of Homeland Secu",https://www.congress.gov/bill/118th-congress/house-bill/9044/text,en,
1264,"To provide for Federal civilian agency laboratory development for testing and certification of artificial intelligence for civilian agency use, and for other purposes.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9779,low,0.2222,209,0.7,Defunct,"A BILL To provide for Federal civilian agency laboratory development for testing and certification of artificial intelligence for civilian agency use, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Federal civilian agency laboratory development for testing and certification of artificial intelligence for civilian agency use. (a) In general.—The Secretary of Homeland Security, acting through the Administrator of the Federal Emergency Management Agency, shall assess the competency and capacity required across the Federal Government to make recommendations on the design and equipping of Federal civilian agency laboratories for the conduct of artificial intelligence training engine development and test beds for generative artificial intelligence relating to sustaining the following: (1) Democratic norms, values, and legal protections for institutions. (2) The independence of personnel, government networks, the courts, and elected and appointed persons at all levels to fulfill their oaths of office and official duties. (b) Development.—To carry out subsection (a), the Secretary of Homeland Security, acting through the Administrator of the Federal Emergency Management Agency, shall develop artificial intelligence training and testing centers to score artificial intelligence systems that may be acquired for Federal civilian agency use with the following objectives: (1) Preserving priv",https://www.congress.gov/bill/118th-congress/house-bill/9043/text,en,"Strategies: Evaluation, Strategies: Pilots and testbeds, Strategies: Government study or report, Strategies: Governance development, Strategies: Government support, Strategies: Government support: For R&D, Risk factors: Privacy, Risk factors: Transparency, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Applications: Government: other applications/unspecified, Strategies: New institution"
1265,Civilian Agency AI Watermark Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9609,low,0.0,122,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Civilian Agency AI Watermark Act”. SEC. 2. CIVILIAN AGENCY ARTIFICIAL INTELLIGENCE WATERMARK SYSTEM. (a) In General.—Not later than eight months after the date of the enactment of this Act, the Secretary of Homeland Security shall seek to consult with the Director of the National Institute of Standards and Technology and the Director of the United States Patent and Trademark Office regarding development of an artificial intelligence watermark and trademark system to identify Federal agency approved artificial intelligence applications for civilian agency use. (b) Authorization Of Appropriations.—There is authorized to be appropriated to the Secretary of Homeland Security each fiscal year to carry out this section such sums as may be necessary.",https://www.congress.gov/bill/118th-congress/house-bill/9042/all-actions,en,
1269,Fraudulent Artificial Intelligence Regulations (FAIR) Elections Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9463,low,0.0,210,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Fraudulent Artificial Intelligence Regulations (FAIR) Elections Act of 2024”. SEC. 2. PROHIBITION ON FALSE AI-GENERATED ELECTION MEDIA. (a) Definitions.—In this section: (1) APPLICABLE FEDERAL ELECTION.—The term “applicable Federal election” means any general, primary, runoff, or special election held solely or in part for the purpose of nominating or electing a candidate for the office of President, Vice President, Presidential elector, Member of the Senate, Member of the House of Representatives, or Delegate or Commissioner from a Territory or possession. (2) ELECTION OFFICIAL.—The term “election official” means any individual legally authorized to perform duties in connection with an applicable Federal election, including workers, volunteers, poll workers, and authorized poll observers. (3) FALSE AI-GENERATED ELECTION MEDIA.—The term “false AI-generated election media” means text. image, audio, or video that— (A) is the product of a computational process that uses machine learning, natural language processing, artificial intelligence techniques, or other computational processing techniques of similar or greater complexity; and (B) either— (i) contains materially false information relating to— (I) the time, place, or manner of holding any applicable Federal election; or (II) the qualifications for or restrictions on voter eligibility for any such election; or (ii) falsely depicts an election official. (b) Prohibition.—Ex",https://www.congress.gov/bill/118th-congress/senate-bill/4714,en,
1270,Content Origin Protection and Integrity from Edited and Deepfaked Media Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.936,low,0.0,224,0.5,Defunct,"A BILL To require transparency with respect to content and content provenance information, to protect artistic content, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title; table of contents. This Act may be cited as the “Content Origin Protection and Integrity from Edited and Deepfaked Media Act of 2024”. SEC. 2. Sense of Congress. It is the sense of Congress that— (1) there is a lack of— (A) visibility into how artificial intelligence systems work; (B) transparency regarding the information used to train such systems; and (C) consensus-based standards and practices to guide the development and deployment of such systems; (2) it is becoming increasingly difficult to assess the nature, origins, and authenticity of digital content that has been generated or modified algorithmically; (3) these deficiencies negatively impact the public and, particularly, the journalists, publishers, broadcasters, and artists whose content is used to train these systems and is manipulated to produce synthetic content and synthetically-modified content that competes unfairly in the digital marketplace with covered content; and (4) the development and adoption of consensus-based standards would mitigate these impacts, catalyze innovation in this nascent industry, and put the United States in a position to lead the development of artificial intelligence systems moving forward. SEC. 3. Definitio",https://www.congress.gov/bill/118th-congress/senate-bill/4674/text,en,
1274,Department of Energy AI Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9794,low,0.0,211,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Department of Energy AI Act”. SEC. 2. FINDINGS. Congress finds that— (1) the Department has a leading role to play in making the most of the potential of artificial intelligence to advance the missions of the Department relating to national security, science, and energy (including critical materials); (2) the 17 National Laboratories employ over 40,000 scientists, engineers, and researchers with decades of experience developing world-leading advanced computational algorithms, computer science research, experimentation, and applications in machine learning that underlie artificial intelligence; (3) the NNSA manages the Stockpile Stewardship Program established under section 4201 of the Atomic Energy Defense Act (50 U.S.C. 2521), which includes the Advanced Simulation and Computing program, that provides critical classified and unclassified computing capabilities to sustain the nuclear stockpile of the United States; (4) for decades, the Department has led the world in the design, construction, and operation of the preeminent high-performance computing systems of the United States, which benefit the scientific and economic competitiveness of the United States across many sectors, including energy, critical materials, biotechnology, and national security; (5) across the network of 34 user facilities of the Department, scientists generate tremendous volumes of high-quality open data across diverse research areas, while the NNS",https://www.congress.gov/bill/118th-congress/senate-bill/4664/all-actions,en,
1276,"To amend the Communications Act of 1934 to establish technical and procedural standards for artificial or prerecorded voice systems created through generative artificial intelligence, and for other purposes.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9442,low,0.0,107,0.5,Defunct,"A BILL To amend the Communications Act of 1934 to establish technical and procedural standards for artificial or prerecorded voice systems created through generative artificial intelligence, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Technical and procedural standards for artificial or prerecorded voice systems created through generative artificial intelligence. Section 227(d)(3) of the Communications Act of 1934 (47 U.S.C. 227(d)(3)) is amended by inserting “(including those created through generative artificial intelligence (genAI), for example voice cloning, and other subsequent technologies as may be deemed appropriate by the Commission)” after “telephone”.",https://www.congress.gov/bill/118th-congress/house-bill/8939/text,en,
1280,Securing Elections From AI Deception Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8934,low,0.2778,214,1.0,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Securing Elections From AI Deception Act”. SEC. 2. DEFINITIONS. In this Act, the following definitions apply: (1) COMMISSION.—The term “Commission” means the Federal Trade Commission. (2) COVERED ALGORITHM.— (A) IN GENERAL.—The term “covered algorithm” means a computational process described in subparagraph (B) that— (i) creates or facilitates the creation of a product or information; (ii) promotes, recommends, ranks, or otherwise affects the display or delivery of material information; (iii) makes a decision; or (iv) facilitates human decision making. (B) COMPUTATIONAL PROCESS DESCRIBED.—In subparagraph (A), a computational process described in this subparagraph is— (i) a computational process that uses machine learning, natural language processing, artificial intelligence techniques, or other computational processing techniques of similar or greater complexity; or (ii) a deterministic computational process derived from a process described in clause (i). (3) DEPLOYER.—The term “deployer” means any person, other than an individual acting in a non-commercial context, that uses a covered algorithm. Nothing in this paragraph may be construed to prohibit a person who is a deployer under this paragraph from treatment as a developer under this Act. (4) DEVELOPER.—The term “developer” means any person that designs, codes, customizes, or produces a covered algorithm, or substantially modifies a covered algorithm, whether for its o",https://www.congress.gov/bill/118th-congress/house-bill/8858/text,en,"Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content, Incentives: Fines, Incentives: Imprisonment, Risk factors: Transparency, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: In standard form, Strategies: Governance development, Incentives: Civil liability, Strategies: Government study or report, Risk factors: Safety, Risk factors: Reliability, Strategies: Evaluation, Strategies: Evaluation: Impact assessment"
1283,Maintaining Innovation and Safe Technologies Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9761,low,0.0,155,0.5,Defunct,"A BILL To direct the Secretary of Health and Human Services to issue guidance on payment under the Medicare program for certain items involving artificial intelligence. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Maintaining Innovation and Safe Technologies Act”. SEC. 2. Guidance on Medicare payment for certain items involving artificial intelligence. Not later than January 1, 2026, the Secretary of Health and Human Services shall use existing communications mechanisms to issue guidance on requirements for payment under part B of title XVIII of the Social Security Act (42 U.S.C. 1395j et seq.) for remote monitoring devices, such as continuous glucose monitors, that— (1) use an artificial intelligence component (such as a continuous adjustment component); and (2) transmit information to a health care provider for purposes of management and treatment of an individual.",https://www.congress.gov/bill/118th-congress/house-bill/8832/text,en,
1287,Social Media and AI Resiliency Toolkits in Schools Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9493,low,0.1667,212,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Social Media and AI Resiliency Toolkits in Schools Act” or the “SMART in Schools Act”. SEC. 2. DEFINITIONS. In this Act: (1) ESEA DEFINITIONS.—The terms “elementary school”, “evidence-based”, “local educational agency”, “paraprofessional”, “parent”, “secondary school”, “specialized instructional support personnel”, and “State educational agency” have the meanings given the terms in section 8101 of the Elementary and Secondary Education Act of 1965 (20 U.S.C. 7801). (2) BUREAU-FUNDED SCHOOL.—The term “Bureau-funded school” has the meaning given the term in section 1141 of the Education Amendments of 1978 (25 U.S.C. 2021). (3) DEPARTMENTS.—The term “Departments” means the Department of Education and the Department of Health and Human Services. (4) DIGITAL CITIZENSHIP.—The term “digital citizenship” means the ability to— (A) safely, responsibly, and ethically use communication technologies and digital information technology tools and platforms; (B) create and share media content using principles of social and civic responsibility and with awareness of the legal and ethical issues involved; and (C) participate in the political, economic, social, and cultural aspects of life related to technology, communications, and the digital world by consuming and creating digital content, including media. (5) DIGITAL RESILIENCE.—The term “digital resilience” means the ability to recognize, manage, and recover from online risks. (6) EDUCATO",https://www.congress.gov/bill/118th-congress/senate-bill/4614/all-actions,en,"Risk factors: Interpretability and explainability, Risk factors: Transparency, Harms: Detrimental content, Applications: Education, Strategies: Convening, Strategies: Government support, Strategies: Tiering"
1288,Artificial Intelligence Public Awareness and Education Campaign Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9406,low,0.0,212,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Artificial Intelligence Public Awareness and Education Campaign Act”. SEC. 2. ARTIFICIAL INTELLIGENCE PUBLIC AWARENESS AND EDUCATION CAMPAIGN. (a) Definitions.—In this section: (1) AI CAMPAIGN.—The term “AI Campaign” means the public awareness and education campaign conducted under this section. (2) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence” has the meaning given the term in section 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401). (3) FEDERAL AGENCY.—The term “Federal agency” has the meaning given the term “agency” in section 551 of title 5, United States Code. (4) KEY PERFORMANCE INDICATOR.—The term “key performance indicator” means a quantifiable metric that demonstrates how effectively an initiative is at achieving its objectives. (5) RELEVANT CONGRESSIONAL COMMITTEES.—The term “relevant congressional committees” means— (A) the Committee on Commerce, Science, and Transportation of the Senate; and (B) the Committee on Science, Space, and Technology of the House of Representatives. (6) SECRETARY.—The term “Secretary” means the Secretary of Commerce. (b) AI Campaign.—Not later than 180 days after the date of enactment of this Act, the Secretary, in coordination with the heads of relevant Federal agencies, including the Director of the National Institute of Standards and Technology and the Administrator of the National Telecommunications and Information Administration, s",https://www.congress.gov/bill/118th-congress/senate-bill/4596,en,
1290,Ending FCC Meddling in Our Elections Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.4215,low,0.0,124,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Ending FCC Meddling in Our Elections Act”. SEC. 2. PROHIBITION ON FEDERAL COMMUNICATIONS COMMISSION RULES REGARDING DISCLOSURE OF AI-GENERATED CONTENT IN POLITICAL ADVERTISEMENTS. (a) Definition.—In this section, the term “rule” has the meaning given the term in section 804 of title 5, United States Code. (b) Prohibition.—The Federal Communications Commission may not promulgate or enforce any rule— (1) relating to the draft notice of proposed rulemaking circulated by the Chairwoman of the Commission on May 22, 2024, regarding disclosure of the use of artificial intelligence-generated content in political advertisements on television, radio, or any other service covered by the proposal; or (2) that is substantially similar to a rule described in paragraph (1).",https://www.congress.gov/bill/118th-congress/senate-bill/4594/all-actions,en,
1293,Tools to Address Known Exploitation by Immobilizing Technological Deepfakes on Websites and Networks Act,United States Congress,United States,Federal government,Risk factors: Privacy,Law/Act,2025-01-03,2025,1,negative,-0.824,low,0.3333,208,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Tools to Address Known Exploitation by Immobilizing Technological Deepfakes on Websites and Networks Act” or the “TAKE IT DOWN Act”. SEC. 2. CRIMINAL PROHIBITION ON INTENTIONAL DISCLOSURE OF NONCONSENSUAL INTIMATE VISUAL DEPICTIONS. (a) In General.—Section 223 of the Communications Act of 1934 (47 U.S.C. 223) is amended— (1) by redesignating subsection (h) as subsection (i); and (2) by inserting after subsection (g) the following: “(h) Intentional Disclosure Of Nonconsensual Intimate Visual Depictions.— “(1) DEFINITIONS.—In this subsection: “(A) CONSENT.—The term ‘consent’ means an affirmative, conscious, and voluntary authorization made by an individual free from force, fraud, duress, misrepresentation, or coercion. “(B) DEEPFAKE.—The term ‘deepfake’ means a video or image that is generated or substantially modified using machine-learning techniques or any other computer-generated or machine-generated means to falsely depict an individual’s appearance or conduct within an intimate visual depiction. “(C) IDENTIFIABLE INDIVIDUAL.— “(i) IN GENERAL.—The term ‘identifiable individual’ means an individual— “(I) who appears in whole or in part in an intimate visual depiction; and “(II) whose face, likeness, or other distinguishing characteristic (including a unique birthmark or other recognizable feature) is displayed in connection with such intimate visual depiction. “(ii) APPEARS.—For purposes of clause (i), an individual appe",https://www.congress.gov/bill/118th-congress/senate-bill/4569/text,en,"Risk factors: Privacy, Risk factors: Safety, Harms: Harm to health/safety, Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content, Harms: Financial loss, Strategies: Governance development, Incentives: Criminal liability, Incentives: Imprisonment"
1296,State Industrial Competitiveness Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9857,low,0.0,216,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “State Industrial Competitiveness Act of 2024”. SEC. 2. STATE FLEX-TECH ENERGY PROGRAM. (a) In General.—Part D of title III of the Energy Policy and Conservation Act (42 U.S.C. 6321 et seq.) is amended by adding at the end the following:“SEC. 367. FLEX-TECH ENERGY PROGRAM TO ENHANCE MANUFACTURING COMPETITIVENESS. “(a) Financial Assistance.—Upon request from the State energy agency of a State that has in effect an approved State energy conservation plan under this part, or an Indian Tribe, the Secretary shall provide financial assistance to such State energy agency or Indian Tribe to be used for the development, implementation, improvement, or expansion of a flex-tech energy program described in subsection (b) to enhance manufacturing competitiveness. “(b) Flex-Tech Energy Program Elements.— “(1) IN GENERAL.—A flex-tech energy program may include— “(A) provision of technical and administrative assistance to manufacturers through qualified engineering firms, as determined by the State energy agency or Indian Tribe; “(B) provision of financial assistance to manufacturers— “(i) for energy studies of manufacturing facilities that are conducted by qualified engineering firms; and “(ii) to support the implementation of the measures and recommendations identified in energy studies conducted pursuant to clause (i), including the design, acquisition, installation, testing, operation, maintenance, and repair of energy- and water-using",https://www.congress.gov/bill/118th-congress/house-bill/8769/all-actions,en,
1297,AI Leadership To Enable Accountable Deployment Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9871,medium,0.5,211,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “AI Leadership To Enable Accountable Deployment Act” or the “AI LEAD Act”. SEC. 2. DEFINITIONS. In this Act: (1) AGENCY.—The term “agency” has the meaning given the term in section 3502 of title 44, United States Code. (2) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence” has the meaning given the term in section 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401). (3) CHIEF ARTIFICIAL INTELLIGENCE OFFICER.—The term “Chief Artificial Intelligence Officer” means an official designated by the head of an agency pursuant to section 4(b)(1). (4) COUNCIL.—The term “Council” means the Chief Artificial Intelligence Officers Council established under section 3(a). (5) DIRECTOR.—The term “Director” means the Director of the Office of Management and Budget. (6) RELEVANT CONGRESSIONAL COMMITTEES.—The term “relevant congressional committees” means the Committee on Homeland Security and Governmental Affairs of the Senate and the Committee on Oversight and Accountability of the House of Representatives.SEC. 3. CHIEF ARTIFICIAL INTELLIGENCE OFFICERS COUNCIL. (a) Establishment.—Not later than 90 days after the date of enactment of this Act, the Director shall establish a Chief Artificial Intelligence Officers Council. (b) Duties.—The Council shall— (1) promote artificial intelligence innovation and responsible design, development, and application; (2) oversee compliance with Governmentwide requirem",https://www.congress.gov/bill/118th-congress/house-bill/8756/text,en,"Applications: Government: benefits and welfare, Applications: Government: other applications/unspecified, Strategies: Convening, Strategies: Government support: For R&D, Risk factors: Privacy, Risk factors: Security, Risk factors: Reliability: Robustness, Risk factors: Reliability, Harms: Violation of civil or human rights, including privacy, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Post-market monitoring, Strategies: Government support, Strategies: Governance development, Strategies: New institution"
1298,Improving Seniors’ Timely Access to Care Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9697,low,0.0,232,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Improving Seniors’ Timely Access to Care Act of 2024”. SEC. 2. ESTABLISHING REQUIREMENTS WITH RESPECT TO THE USE OF PRIOR AUTHORIZATION UNDER MEDICARE ADVANTAGE PLANS. (a) In General.—Section 1852 of the Social Security Act (42 U.S.C. 1395w–22) is amended by adding at the end the following new subsection: “(o) Prior Authorization Requirements.— “(1) IN GENERAL.—In the case of a Medicare Advantage plan that imposes any prior authorization requirement with respect to any applicable item or service (as defined in paragraph (5)) during a plan year, such plan shall— “(A) beginning with plan years beginning on or after January 1, 2027— “(i) establish the electronic prior authorization program described in paragraph (2); and “(ii) meet the enrollee protection standards specified pursuant to paragraph (4); and “(B) beginning with plan years beginning on or after January 1, 2026, meet the transparency requirements specified in paragraph (3). “(2) ELECTRONIC PRIOR AUTHORIZATION PROGRAM.— “(A) IN GENERAL.—For purposes of paragraph (1)(A), the electronic prior authorization program described in this paragraph is a program that provides for the secure electronic transmission of— “(i) a prior authorization request from a provider of services or supplier to a Medicare Advantage plan with respect to an applicable item or service to be furnished to an individual and a response, in accordance with this paragraph, from such plan to such prov",https://www.congress.gov/bill/118th-congress/senate-bill/4532,en,
1301,International Artificial Intelligence Research Partnership Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9939,low,0.0,201,0.7,Defunct,"A BILL To establish international artificial intelligence research partnerships, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “International Artificial Intelligence Research Partnership Act of 2024”. SEC. 2. International artificial intelligence research partnership. (a) Findings.—Congress finds the following: (1) For over six decades, international city-to-city partnerships have played a crucial role in promoting United States priorities, fostering mutual understanding, and strengthening diplomatic ties between the United States and countries around the world. (2) These partnerships have received strong bipartisan support over the past 40 years, as demonstrated by the participation of every United States President since Dwight D. Eisenhower and the passage of numerous congressional resolutions recognizing the contributions of these partnerships to international cooperation. (3) Collaboration between United States cities and their international counterparts on artificial intelligence research can further strengthen these partnerships while promoting United States leadership in this critical field. (4) Coordination with the National Science Foundation and leveraging the National AI Research Resource can ensure that partnership activities align with United States research priorities and benefit from existing resources and expertise. (b)",https://www.congress.gov/bill/118th-congress/house-bill/8700/text,en,"Strategies: Government support, Strategies: Government support: For R&D, Strategies: Convening, Strategies: Government support: AI workforce-related, Strategies: Government study or report"
1303,Promoting Responsible Evaluation and Procurement to Advance Readiness for Enterprise-wide Deployment for Artificial Intelligence Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.1613,high,0.8333,228,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Promoting Responsible Evaluation and Procurement to Advance Readiness for Enterprise-wide Deployment for Artificial Intelligence Act” or the “PREPARED for AI Act”. SEC. 2. DEFINITIONS. In this Act: (1) ADVERSE INCIDENT.—The term “adverse incident” means any incident or malfunction of artificial intelligence that directly or indirectly leads to— (A) harm impacting rights or safety, as described in section 7(a)(2)(D); (B) the death of an individual or damage to the health of an individual; (C) material or irreversible disruption of the management and operation of critical infrastructure, as described in section 7(a)(2)(D)(i)(II)(cc); (D) material damage to property or the environment; (E) loss of a mission-critical system or equipment; (F) failure of the mission of an agency; (G) the denial of a benefit, payment, or other service to an individual or group of individuals who would have otherwise been eligible; (H) the denial of an employment, contract, grant, or similar opportunity that would have otherwise been offered; or (I) another consequence, as determined by the Director with public notice. (2) AGENCY.—The term “agency”— (A) has the meaning given that term in section 3502(1) of title 44, United States Code; and (B) includes each of the independent regulatory agencies described in section 3502(5) of title 44, United States Code. (3) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence”— (A) has the meaning given t",https://www.congress.gov/bill/118th-congress/senate-bill/4495/all-actions,en,"Harms: Harm to health/safety, Harms: Harm to infrastructure, Harms: Violation of civil or human rights, including privacy, Harms: Ecological harm, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Risk factors: Safety, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Convening, Risk factors: Privacy, Risk factors: Security, Strategies: Evaluation: Post-market monitoring, Strategies: Disclosure, Strategies: Disclosure: About incidents"
1304,Small Business Artificial Intelligence Training Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8143,low,0.0,216,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Small Business Artificial Intelligence Training Act of 2024”. SEC. 2. ARTIFICIAL INTELLIGENCE TRAINING RESOURCES FOR SMALL BUSINESS CONCERNS. (a) Definitions.—In this section: (1) APPROPRIATE COMMITTEES OF CONGRESS.—The term “appropriate committees of Congress” means— (A) the Committee on Commerce, Science, and Transportation and the Committee on Small Business and Entrepreneurship of the Senate; and (B) the Committee on Science, Space, and Technology and the Committee on Small Business of the House of Representatives. (2) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence” has the meaning given such term in section 5002 of the William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021 (15 U.S.C. 9401). (3) CENTER.—The term “Center” has the meaning given such term in section 25(a) of the National Institute of Standards and Technology Act (15 U.S.C. 278k(a)). (4) DIRECTOR.—The term “Director” means the Director of the National Institute of Standards and Technology. (5) HOLLINGS MANUFACTURING EXTENSION PARTNERSHIP.—The term “Hollings Manufacturing Extension Partnership” has the meaning given such term in section 25(a) of the National Institute of Standards and Technology Act (15 U.S.C. 278k(a)). (6) INDIAN TRIBE.—The term “Indian Tribe” has the meaning given the term in section 4 of the Indian Self-Determination and Education Assistance Act (25 U.S.C. 5304). (7) KEY EMERGING TECHNOLOGIES.—The",https://www.congress.gov/bill/118th-congress/senate-bill/4487/all-actions,en,
1305,AI Transparency in Elections Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7603,low,0.1667,218,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “AI Transparency in Elections Act of 2024”. SEC. 2. REQUIRING DISCLAIMERS ON ADVERTISEMENTS CONTAINING CONTENT SUBSTANTIALLY GENERATED BY ARTIFICIAL INTELLIGENCE. (a) Requirement.—Section 318 of the Federal Election Campaign Act of 1971 (52 U.S.C. 30120) is amended by adding at the end the following new subsection: “(e) Special Disclaimer For Covered Communications Containing Content Substantially Generated By Artificial Intelligence.— “(1) DEFINITIONS.—For purposes of this subsection: “(A) COVERED COMMUNICATION.— “(i) IN GENERAL.—The term ‘covered communication’ means a communication through any broadcasting station, newspaper, magazine, outdoor advertising facility, mailing, telephone bank, internet or other digital medium, or any other type of general public political advertising that— “(I) expressly advocates for or against the nomination or election of a candidate; “(II) refers to a candidate at any time during the period beginning 120 days before the date of a primary election or nominating caucus or convention and ending on the date on which a general election occurs; or “(III) solicits a contribution for a candidate or political committee or any other person who makes disbursements for communications described in subclause (I) or (II). “(ii) VOICE AND LIKENESS.—A communication that invokes the likeness or voice of a candidate shall be treated as a communication that refers to such candidate. “(B) GENERATIVE ARTIFICI",https://www.congress.gov/bill/118th-congress/house-bill/8668/text,en,"Applications: Broadcasting and media production, Risk factors: Transparency, Harms: Detrimental content, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: In standard form, Strategies: Disclosure: Accuracy thereof, Harms: Violation of civil or human rights, including privacy, Incentives: Civil liability, Strategies: Governance development, Strategies: Government study or report"
1306,Supercritical Geothermal Research and Development Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9206,low,0.0,218,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Supercritical Geothermal Research and Development Act”. SEC. 2. GEOTHERMAL ENERGY. (a) In General.—The Energy Independence and Security Act of 2007 is amended— (1) in section 612 (42 U.S.C. 17191; relating to definitions)— (A) by redesignating paragraph (8) as paragraph (9); and (B) by inserting after paragraph (7) the following new paragraph: “(8) SUPERCRITICAL GEOTHERMAL.—The term ‘supercritical geothermal’ means energy derived from a subsurface rock resource in-situ existing at or above the supercritical conditions of the primary fluid present.”; (2) in section 613 (42 U.S.C. 17192; relating to hydrothermal research and development), by striking “advanced geologic tools to assist” and inserting “advanced tools, including machine learning algorithms, to assist”; (3) in section 614 (42 U.S.C. 17193; relating to general geothermal systems research and development)— (A) in paragraph (1) of subsection (d), by striking “among the Office of Fossil Energy, the Office of Energy Efficiency and Renewable Energy,” and inserting “across the Department”; and (B) in subsection (h)— (i) in paragraph (1), by inserting “and publicly available subsurface data, including data reported as part of fossil fuel and mining operations,” after “geothermal drilling information”; and (ii) in paragraph (2), by adding at the end the following new subparagraphs: “(C) UPDATES.—The repository established under paragraph (1) shall be periodically updated",https://www.congress.gov/bill/118th-congress/house-bill/8665/all-actions,en,
1307,Detection Equipment and Technology Evaluation to Counter the Threat of Fentanyl and Xylazine Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7351,low,0.0,236,0.5,Defunct,"SECTION 1. SHORT TITLES. This Act may be cited as the “Detection Equipment and Technology Evaluation to Counter the Threat of Fentanyl and Xylazine Act of 2024” or the “DETECT Fentanyl and Xylazine Act of 2024”. SEC. 2. ENHANCING THE CAPACITY TO DETECT, IDENTIFY, AND DISRUPT DRUGS SUCH AS FENTANYL AND XYLAZINE. Section 302 of the Homeland Security Act of 2002 (6 U.S.C. 182) is amended— (1) in paragraph (13), by striking “and” at the end; (2) in paragraph (14), by striking the period at the end and inserting “; and”; and (3) by adding at the end the following: “(15) carrying out research, development, testing, evaluation, and cost-benefit analyses to improve the safety, effectiveness, and efficiency of equipment and reference libraries for use by Federal, State, local, Tribal, and territorial law enforcement agencies for the accurate detection of drugs or the disruption of drug trafficking for drugs such as fentanyl and xylazine, including, but not limited to— “(A) portable equipment that can detect and identify drugs with minimal or no handling of the sample; “(B) equipment that can separate complex mixtures containing low concentrations of drugs and high concentrations of cutting agents into their component parts to enable signature extraction for field identification and detection; and “(C) technologies that use machine learning or artificial intelligence (as defined in section 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401)) and other t",https://www.congress.gov/bill/118th-congress/house-bill/8663/all-actions,en,
1310,SPEED through Screening Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9521,low,0.0,214,0.5,Defunct,"A BILL To improve the passenger experience during aviation checkpoint security screening, without reducing security effectiveness, by encouraging the deployment of technological and other solutions, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Supporting Passengers with Efficient and Effective Detection through Screening Act” or the “SPEED through Screening Act”. SEC. 2. Strategies to reduce patdowns and the need to divest items during screening without reducing security effectiveness. (a) Strategy To reduce patdowns without reducing security effectiveness.— (1) IN GENERAL.—Not later than one year after the date of the enactment of this Act, the Administrator shall submit to the appropriate congressional committees a strategy for the following five years to reduce the rate at which Administration personnel are required to conduct patdowns during passenger screening carried out pursuant to section 44901 of title 49, United States Code, to the extent practicable, without reducing overall security effectiveness. (2) CONSIDERATIONS.—In producing the strategy required under paragraph (1), the Administrator shall consider the following: (A) The effects of improvements made to screening activities within the immediately preceding five years, including refinements to advanced imaging technology detection algorithms, and an estimation of the",https://www.congress.gov/bill/118th-congress/house-bill/8630/text,en,
1311,Preventing the Algorithmic Facilitation of Rental Housing Cartels Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8176,low,0.0,216,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Preventing the Algorithmic Facilitation of Rental Housing Cartels Act of 2024”. SEC. 2. DEFINITIONS. In this Act: (1) CHAIR.—The term “Chair” means the Chair of the Commission. (2) COMMISSION.—The term “Commission” means the Federal Trade Commission. (3) CONSCIOUSLY PARALLEL PRICING COORDINATION.—The term “consciously parallel pricing coordination” means a tacit agreement between 2 or more rental property owners to raise, lower, change, maintain, or manipulate pricing for the purchase or sale of reasonably interchangeable products or services. (4) COORDINATING FUNCTION.—The term “coordinating function” means— (A) collecting historical or contemporaneous prices, supply levels, or lease or rental contract termination and renewal dates of residential dwelling units from 2 or more rental property owners; (B) analyzing or processing of the information described in subparagraph (A) using a system, software, or process that uses computation, including by using that information to train an algorithm; and (C) recommending rental prices, lease renewal terms, or ideal occupancy levels to a rental property owner. (5) COORDINATOR.—The term “coordinator” means any person that operates a software or data analytics service that performs a coordinating function for any rental property owner, including a rental property owner performing a coordinating function for their own benefit. (6) PERSON.—The term “person” has the meaning given the te",https://www.congress.gov/bill/118th-congress/house-bill/8622/all-actions,en,
1312,NSF and USDA Interagency Research Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9382,low,0.0,208,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “NSF and USDA Interagency Research Act”. SEC. 2. DEPARTMENT OF AGRICULTURE AND NATIONAL SCIENCE FOUNDATION RESEARCH AND DEVELOPMENT COORDINATION. (a) In General.—The Secretary of Agriculture (in this section referred to as the “Secretary”) and the Director of the National Science Foundation (in this section referred to as the “Director”) shall carry out cross-cutting and collaborative research and development activities focused on the joint advancement of Department of Agriculture and National Science Foundation mission requirements and priorities. (b) Memoranda Of Understanding.—The Secretary and the Director shall coordinate the activities under subsection (a) through the establishment of memoranda of understanding or other appropriate interagency agreements. Such memoranda or agreements, as the case may be, shall require the use of a competitive, merit review process, as appropriate. Such activities may include components proposed by Federal agencies, institutions of higher education, non-profit institutions, and other appropriate entities, as determined appropriate under the memoranda or agreements. (c) Coordination.—In carrying out the activities under subsection (a), the Secretary and the Director may— (1) conduct collaborative research in a variety of focus areas, such as— (A) plant, animal, and microbial biology relevant to agricultural challenges; (B) food and nutrition security; (C) rural economic revitalization;",https://www.congress.gov/bill/118th-congress/house-bill/8613/text,en,
1315,Agriculture and National Security Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9707,low,0.0,223,0.5,Defunct,"A BILL To improve connections between the Department of Agriculture and national and homeland security agencies, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Agriculture and National Security Act of 2024”. SEC. 2. Sense of Congress relating to agriculture and national security. It is the sense of Congress that there are increasingly robust Federal activities to address homeland security vulnerabilities across the food and agriculture sector, including with regard to agriculture and food defense, critical infrastructure, emergency management, and catastrophic events, but additional efforts are needed to identify national security vulnerabilities related to food and agriculture, particularly with regard to emerging technologies. SEC. 3. National security. (a) In general.—In recognition that food and agriculture are critical to the national security of the United States, the Secretary of Agriculture (referred to in this Act as the “Secretary”) shall prioritize national security in addition to homeland security in the Department of Agriculture (referred to in this Act as the “Department”), including by increasing the number of staff at the Department with security clearances and access to classified systems and networks. (b) Senior Advisor for National Security.— (1) APPOINTMENT.—Not later than 180 days after the date of enactment of thi",https://www.congress.gov/bill/118th-congress/house-bill/8522/text,en,
1316,Modernizing Retrospective Regulatory Review Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9406,low,0.0,217,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Modernizing Retrospective Regulatory Review Act”. SEC. 2. IMPROVING RETROSPECTIVE REVIEWS OF FEDERAL REGULATIONS. (a) Definitions.—In this section: (1) ADMINISTRATIVE COMMITTEE OF THE FEDERAL REGISTER.—The term “Administrative Committee of the Federal Register” means the committee established under section 1506 of title 44, United States Code. (2) ADMINISTRATOR.—The term “Administrator” means the Administrator of the Office of Information and Regulatory Affairs. (3) AGENCY.—The term “agency” has the meaning given the term in section 3502 of title 44, United States Code. (4) APPROPRIATE CONGRESSIONAL COMMITTEES.—The term “appropriate congressional committees” means— (A) the Committee on Oversight and Accountability of the House of Representatives; and (B) the Committee on Homeland Security and Governmental Affairs of the Senate. (5) DIRECTOR OF GPO.—The term “Director of GPO” means the Director of the Government Publishing Office. (6) MACHINE-READABLE.—The term “machine-readable” has the meaning given the term in section 3502 of title 44, United States Code. (7) RETROSPECTIVE REVIEW OF A REGULATION OF THE AGENCY.—The term “retrospective review of a regulation of the agency” means a review of regulations of the agency conducted after the regulation has been issued that is required by law or determined appropriate by the head of the agency. (b) Report On Availability Of Existing Regulations In Machine-Readable Format.— (1) IN",https://www.congress.gov/bill/118th-congress/senate-bill/4434/all-actions,en,
1319,Synthetic Biology Advancement Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9808,low,0.0,226,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Synthetic Biology Advancement Act of 2024”. SEC. 2. FINDINGS. Congress finds that— (1) the application of synthetic biology to accelerate innovation in food and agriculture is critical to— (A) the national security and economic future of the United States; and (B) the ability of the United States to feed and fuel the global economy; (2) while agriculture has experienced significant advancements in productivity and sustainability, the future of the food system relies on disruptive technologies catalyzed by synthetic biology at the intersections of soil health, plant science, animal health, and, ultimately, human health; (3) synthetic biology is a key tool to defend against terrorism and high-consequence events; (4) investments into synthetic biology will catalyze the strengths of engineering, agriculture, and manufacturing to develop a resilient food and agriculture system; (5) resiliency is accomplished through advanced biotechnology and digital solutions to keep the United States at the forefront of feeding the United States and the world; (6) Congress has historically prioritized a safe and secure food supply in the United States, as evidenced by the enactment of the Securing Our Agriculture and Food Act (Public Law 115–43; 131 Stat. 884); and (7) innovation and research are necessary to push the boundaries of science to develop disruptive technologies that advance national security through food security.SEC. 3. NATIONAL",https://www.congress.gov/bill/118th-congress/senate-bill/4413,en,
1320,Technology in the Parks Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8788,low,0.0556,235,0.7,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Technology in the Parks Act of 2024”. SEC. 2. E-RATE SUPPORT FOR COVERED LOCAL PARKS. Section 254 of the Communications Act of 1934 (47 U.S.C. 254) is amended— (1) in subsection (b)(6)— (A) in the heading, by striking “AND LIBRARIES” and inserting “LIBRARIES, AND COVERED LOCAL PARKS”; and (B) by striking “and libraries” and inserting “libraries, and covered local parks”; (2) in subsection (c)(3), by striking “and health care providers” and inserting “health care providers, and covered local parks”; (3) in subsection (h)— (A) in paragraph (1)(B)— (i) in the heading, by striking “AND LIBRARIES” and inserting “, LIBRARIES, AND COVERED LOCAL PARKS”; and (ii) by striking “and libraries” and inserting “libraries, and covered local parks”; (B) in paragraph (3)— (i) by inserting “or a covered local park” after “telecommunications user”; (ii) by inserting “or park” after “such user”; and (iii) by adding at the end the following: “Notwithstanding the preceding sentence, a covered local park may transfer telecommunications services and network capacity to an entity with which such park has a contract as described in subsection (m) to enable such entity to conduct a qualified technology training program as described in such subsection.”; (C) in paragraph (4), by striking “paragraph (7)(A)” and inserting “paragraph (8)(A)”; (D) by redesignating paragraph (7) as paragraph (8); and (E) by inserting after paragraph (6) the following: “(7)",https://www.congress.gov/bill/118th-congress/house-bill/8494/text,en,"Risk factors: Security: Cybersecurity, Strategies: Governance development, Applications: Government: other applications/unspecified, Strategies: Government support, Strategies: Government support: AI workforce-related, Applications: Education, Applications: Government: benefits and welfare"
1322,Fraudulent Misrepresentation of Campaign Authority,Federal Election Commission,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2024-09-26,2024,9,negative,-0.6339,low,0.0,231,0.5,Enacted,"The Federal Election Campaign Act (“FECA” or “Act”) prohibits the fraudulent misrepresentation of campaign authority. It does so in two ways: (1) by barring Federal candidates or their agents from fraudulently misrepresenting themselves or organizations under their control as “speaking or writing or otherwise acting for or on behalf of any other candidate or political party or employee or agent thereof on a matter which is damaging to such other candidate or political party or employee or agent thereof” or “willfully and knowingly” participating in or conspiring to do so; and (2) by barring any person from “fraudulently misrepresent[ing]” themselves “as speaking, writing, or otherwise acting for or on behalf of any candidate or political party or employee or agent thereof for the purpose of soliciting contributions or donations” or “willfully and knowingly” participating in or conspiring to do so. 52 U.S.C. 30124; see also11 CFR 110.16. It has been suggested that this statute may have a specific application in light of new developments in technology, especially content generated with the assistance of artificial intelligence (“AI”). For this reason, the Commission is issuing this guidance to clarify that 52 U.S.C. 30124 and 11 CFR 110.16 apply irrespective of the technology used to conduct fraudulent misrepresentation. For purposes of 52 U.S.C. 30124, it does not matter whether a regulated person uses any particular form of technology, including AI, in order to “fraudulently",https://www.federalregister.gov/documents/2024/09/26/2024-21983/fraudulent-misrepresentation-of-campaign-authority,en,
1336,Public Act 103-0804,Illinois,United States,State governments,U.S. state and local documents,Law/Act,2024-08-09,2024,8,neutral,-0.0176,low,0.0,237,0.5,Enacted,"Public Act 103-0804 HB3773 Enrolled LRB103 27562 SPS 53938 b AN ACT concerning business. Be it enacted by the People of the State of Illinois, represented in the General Assembly: Section 5. The Illinois Human Rights Act is amended by changing Sections 2-101 and 2-102 as follows: (775 ILCS 5/2-101) Sec. 2-101. Definitions. The following definitions are applicable strictly in the context of this Article. (A) Employee. (1) ""Employee"" includes: (a) Any individual performing services for remuneration within this State for an employer; (b) An apprentice; (c) An applicant for any apprenticeship. For purposes of subsection (D) of Section 2-102 of this Act, ""employee"" also includes an unpaid intern. An unpaid intern is a person who performs work for an employer under the following circumstances: (i) the employer is not committed to hiring the person performing the work at the conclusion of the intern's tenure; (ii) the employer and the person performing the work agree that the person is not entitled to wages for the work performed; and (iii) the work performed: (I) supplements training given in an educational environment that may enhance the employability of the intern; (II) provides experience for the benefit of the person performing the work; (III) does not displace regular employees; (IV) is performed under the close supervision of existing staff; and (V) provides no immediate advantage to the employer providing the training and may occasionally impede the operations of the employ",https://www.ilga.gov/legislation/publicacts/fulltext.asp?Name=103-0804,en,
1337,"American Privacy Rights Act of 2024, Sec. 114-5",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9578,low,0.0,207,0.5,Defunct,"SEC. 114. PRIVACY-ENHANCING TECHNOLOGY PILOT PROGRAM. (a) Privacy-Enhancing Technology Defined.—In this section, the term “privacy-enhancing technology”— (1) means any software or hardware solution, cryptographic algorithm, or other technical process of extracting the value of information without substantially reducing the privacy and security of the information; and (2) includes technologies with functionality similar to homomorphic encryption, differential privacy, zero-knowledge proofs, synthetic data generation, federated learning, and secure multi-party computation. (b) Establishment.—Not later than 1 year after the date of the enactment of this Act, the Commission shall establish and carry out a pilot program to encourage private sector use of privacy-enhancing technologies for the purposes of protecting covered data to comply with section 109. (c) Purposes.—Under the pilot program established under subsection (b), the Commission shall— (1) develop and implement a petition process for covered entities to request to be a part of the pilot program; and (2) build an auditing system that leverages privacy-enhancing technologies to support the enforcement actions of the Commission. (d) Petition Process.—A covered entity wishing to be accepted into the pilot program established under subsection (b) shall demonstrate to the Commission that the privacy-enhancing technologies to be used under the pilot program by the covered entity will establish data security practices that mee",https://www.congress.gov/bill/118th-congress/house-bill/8818,en,
1338,"Intelligence Authorization Act for Fiscal Year 2025, Title V, Section 504 (""National security procedures to address certain risks and threats relating to artificial intelligence"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9898,low,0.0,200,0.5,Defunct,"SEC. 504. National security procedures to address certain risks and threats relating to artificial intelligence. (a) Findings.—Congress finds the following: (1) Artificial intelligence systems demonstrate increased capabilities in the generation of synthetic media and computer programming code, as well as areas such as object recognition, natural language processing, and workflow orchestration. (2) The growing capabilities of artificial intelligence systems in the areas described in paragraph (1), as well as the greater accessibility of large-scale artificial intelligence models and advanced computation capabilities to individuals, businesses, and governments, have dramatically increased the adoption of artificial intelligence products in the United States and globally. (3) The advanced capabilities of the systems described in paragraph (1), and their accessibility to a wide-range of users, have increased the likelihood and effect of misuse or malfunction of these systems, such as to generate synthetic media for disinformation campaigns, develop or refine malware for computer network exploitation activity, enhance surveillance capabilities in ways that undermine the privacy of citizens of the United States, and increase the risk of exploitation or malfunction of information technology systems incorporating artificial intelligence systems in mission-critical fields such as health care, critical infrastructure, and transportation. (b) Procedures required.—Not later than 180 day",https://www.congress.gov/bill/118th-congress/senate-bill/4443/text,en,
1341,"Intelligence Authorization Act for Fiscal Year 2025, Title V, Section 510 (""Management of artificial intelligence security risks"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9931,low,0.0,202,0.5,Defunct,"SEC. 510. Management of artificial intelligence security risks. (a) Definitions.—In this section: (1) ARTIFICIAL INTELLIGENCE SAFETY INCIDENT.—The term “artificial intelligence safety incident” means an event that increases the risk that operation of an artificial intelligence system will— (A) result in physical or psychological harm; or (B) lead to a state in which human life, health, property, or the environment is endangered. (2) ARTIFICIAL INTELLIGENCE SECURITY INCIDENT.—The term “artificial intelligence security incident” means an event that increases— (A) the risk that operation of an artificial intelligence system occurs in a way that enables the extraction of information about the behavior or characteristics of an artificial intelligence system by a third party; or (B) the ability of a third party to manipulate an artificial intelligence system to subvert the confidentiality, integrity, or availability of an artificial intelligence system or adjacent system. (3) ARTIFICIAL INTELLIGENCE SECURITY VULNERABILITY.—The term “artificial intelligence security vulnerability” means a weakness in an artificial intelligence system that could be exploited by a third party to, without authorization, subvert the confidentiality, integrity, or availability of an artificial intelligence system, including through techniques such as— (A) data poisoning; (B) evasion attacks; (C) privacy-based attacks; and (D) abuse attacks. (4) COUNTER-ARTIFICIAL INTELLIGENCE.—The term “counter-artificia",https://www.congress.gov/bill/118th-congress/senate-bill/4443/text,en,
1342,"Intelligence Authorization Act for Fiscal Year 2025, Title V, Section 505 (""Establishment of Artificial Intelligence Security Center"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9945,low,0.0,211,0.5,Defunct,"SEC. 505. Establishment of Artificial Intelligence Security Center. (a) Establishment.—Not later than 90 days after the date of the enactment of this Act, the Director of the National Security Agency shall establish an Artificial Intelligence Security Center within the Cybersecurity Collaboration Center of the National Security Agency. (b) Functions.—The functions of the Artificial Intelligence Security Center shall be as follows: (1) Making available a research test bed to private sector and academic researchers, on a subsidized basis, to engage in artificial intelligence security research, including through the secure provision of access in a secure environment to proprietary third-party models, with the consent of the vendors of the models. (2) Developing guidance to prevent or mitigate counter-artificial intelligence techniques. (3) Promoting secure artificial intelligence adoption practices for managers of national security systems (as defined in section 3552 of title 44, United States Code) and elements of the defense industrial base. (4) Coordinating with the Artificial Intelligence Safety Institute of the National Institute of Standards and Technology. (5) Such other functions as the Director considers appropriate. (c) Test bed requirements.— (1) ACCESS AND TERMS OF USAGE.— (A) RESEARCHER ACCESS.—The Director shall establish terms of usage governing researcher access to the test bed made available under subsection (b)(1), with limitations on researcher publication onl",https://www.congress.gov/bill/118th-congress/senate-bill/4443/text,en,
1343,"Sec. 103, Supporting Affordability and Fairness with Every Bet Act",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8271,low,0.0,221,0.5,Defunct,"SEC. 103. STATE SPORTS WAGERING PROGRAM STANDARDS. (a) In General.—The Attorney General shall approve an application under section 102 unless the Attorney General determines that the proposed State sports wagering program does not meet the standards set forth in subsection (b). (b) Standards For State Sports Wagering Programs.—A State sports wagering program shall meet each of the following standards: (1) STATE REGULATORY ENTITY.—Establish or designate a public entity in the applicable State as the State regulatory entity for the purposes of regulating sports wagering operators and enforcing sports wagering laws in the State. (2) PERMISSIBLE SPORTS WAGERING.— (A) IN-PERSON SPORTS WAGERING.—Provide that in-person sports wagering may be offered only by a sports wagering operator. (B) INTERNET SPORTS WAGERING.— (i) IN GENERAL.—With respect to any authorization of sports wagering on an interactive sports wagering platform, provide that such sports wagering, as available, is available only to— (I) individuals located in the State; or (II) in the case of an interstate sports wagering compact approved by the Attorney General, individuals located in States and on Indian lands of Indian Tribes that are party to the compact. (ii) LOCATION VERIFICATION.—Include location verification requirements reasonably designed to prevent an individual from placing a sports wager on an interactive sports wagering platform from a location other than a location described in clause (i). (C) SPORTS WAGE",https://www.congress.gov/bill/118th-congress/senate-bill/5057,en,
1344,"Modernizing Wildfire Safety and Prevention Act of 2024, Section 405 (""Joint Office of the Fire Environment Center (Report Recommendations 104, 105, 106)"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.743,low,0.0,214,0.5,Defunct,"SEC. 405. Joint Office of the Fire Environment Center (Report Recommendations 104, 105, 106). (a) Establishment.— (1) IN GENERAL.—Not later than a 1 year after the date of the enactment of this Act, the Administrator of the National Oceanic and Atmospheric Administration shall establish a joint office, which shall be known as the “Joint Office of the Fire Environment Center”. (2) STRUCTURE.—The Joint Office shall be comprised of the following branches: (A) TECHNOLOGY AND ENGINEERING.—Technology and Engineering, which shall— (i) focus on modeling and the building and testing of technology; and (ii) may enter into public-private partnerships. (B) DATA SERVICES.—Data Services, which shall— (i) be responsible for testing artificial intelligence and machine learning technologies to support managers, firefighters, and public health officials on the ground, including producing decision consequence data, modeling risk, and suggesting resources based on fire and smoke conditions at the time and place of ignition detection; and (ii) working with State, local, and Tribal entities on data sharing. (C) ANALYSIS AND PREDICTION.—Analysis and Prediction. (D) EDUCATION AND CONSULTATION.—Education and Consultation, which shall be responsible for incident management. (E) OTHER.—Any other branch determined necessary or appropriate by the Board. (b) Functions of Joint Office.— (1) IN GENERAL.— (A) AVAILABILITY OF PRODUCTS AND INFORMATION.—The Joint Office shall make available any products and inf",https://www.congress.gov/bill/118th-congress/house-bill/8656/text,en,
1346,"STAND with Taiwan Act of 2024, Section 11 (""Prohibition on investments by United States financial institutions that benefit the Government of the People's Republic of China or the Chinese Communist Party"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9806,low,0.0,212,0.5,Defunct,"SEC. 11. Prohibition on investments by United States financial institutions that benefit the Government of the People's Republic of China or the Chinese Communist Party. (a) In general.—Not later than 3 days after a covered determination is made, the Secretary of the Treasury shall prohibit any United States financial institution from making any investments described in subsection (b). (b) Investments described.—An investment described in this subsection is a monetary investment— (1) to— (A) an entity owned or controlled by the Government of the People's Republic of China or the Chinese Communist Party; or (B) the People’s Liberation Army; or (2) for the benefit of any priority industrial sector identified in the “Made in China 2025” plan or the “14th Five Year Smart Manufacturing Development Plan”, including— (A) agriculture machinery; (B) information technology; (C) artificial intelligence, machine learning, and robotics; (D) green energy and green vehicles; (E) aerospace equipment; (F) ocean engineering and high tech ships; (G) railway equipment; (H) power equipment; (I) new materials; (J) medicine and medical devices; (K) fifth generation and future generation telecommunications and other advanced wireless networking technologies; (L) semiconductor manufacturing; (M) biotechnology; (N) quantum computing; (O) surveillance technologies, including facial recognition technologies and censorship software; (P) fiber optic cables; and (Q) mining and resource development. (c) Uni",https://www.congress.gov/bill/118th-congress/senate-bill/4789,en,
1348,"Health Equity and Accountability Act of 2024, Sec 1013 (""Task Force on Preventing Bias in AI and Algorithms"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9471,low,0.0,236,0.5,Defunct,"SEC. 1013. TASK FORCE ON PREVENTING BIAS IN AI AND ALGORITHMS. (a) In General.--Not later than 30 days after the date of enactment of this Act, the Secretary of Health and Human Services (referred to in this section as the “Secretary”) shall establish a Task Force to be known as the “Task Force on Preventing AI and Algorithmic Bias in Health Care” (referred to in this section as the “Task Force”) to provide clear and robust guidance on how to ensure that the development and integration of artificial intelligence and algorithmic technologies within the health care service delivery process does not exacerbate health disparities and inequities, expands access to health care services, and improves health care delivery. (b) Membership and Chairperson.-- (1) Membership.--The Task Force shall be composed of– (A) the Chief Information Officer of the Department of Health and Human Services; (B) the Director of the Centers for Disease Control and Prevention; (C) the Director of the National Institutes of Health; (D) the Commissioner of Food and Drugs; (E) the Administrator of the Federal Emergency Management Agency; (F) the Director of the National Institute on Minority Health and Health Disparities; (G) the Director of the Indian Health Service; (H) the Administrator of the Centers for Medicare & Medicaid Services; (I) the Director of the Agency for Healthcare Research and Quality; (J) the Surgeon General; (K) the Administrator of the Health Resources and Services Administration; (L)",https://www.congress.gov/bill/118th-congress/house-bill/9161/text,en,
1352,"Fix Our Forests Act, Section 102 (""Fireshed Center"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.34,low,0.0,234,0.5,Defunct,"SEC. 102. Fireshed center. (a) Establishment.— (1) IN GENERAL.—The Secretary, acting through the Chief of the Forest Service, and the Secretary of the Interior, acting through the Director of the U.S. Geological Survey, shall jointly establish a Fireshed Center (hereinafter referred to as the “Center”) comprised of at least one career representative from each of the following: (A) The Forest Service. (B) The Bureau of Land Management. (C) The National Park Service. (D) The Bureau of Indian Affairs. (E) The U.S. Fish and Wildlife Service. (F) The U.S. Geological Survey. (G) The Department of Defense. (H) The Department of Homeland Security. (I) The Department of Energy. (J) The Federal Emergency Management Agency. (K) The National Science Foundation. (L) The National Oceanic and Atmospheric Administration. (M) The National Aeronautics and Space Administration. (N) The National Institute of Standards and Technology. (2) DIRECTOR.—The Secretary, acting through the Chief of the Forest Service, and the Secretary of the Interior, acting through the Director of the U.S. Geological Survey, shall jointly appoint a Director of the Center, who— (A) shall be an employee of the U.S. Geological Survey or the Forest Service; (B) shall serve an initial term of not more than 7 years; and (C) may serve one additional term of not more than 7 years after the initial term described in subparagraph (B). (3) ADDITIONAL REPRESENTATION.—The Secretary, acting through the Chief of the Forest Service an",https://www.congress.gov/bill/118th-congress/house-bill/8790/text,en,
1353,"Fix Our Forests Act, Section 303 (""Public-private wildfire technology deployment and demonstration partnership"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.6369,low,0.0,219,0.5,Defunct,"SEC. 303. Public-private wildfire technology deployment and demonstration partnership. (a) Definitions.—In this section: (1) COVERED AGENCY.—The term “covered agency” means— (A) each Federal land management agency (as such term is defined in the Federal Lands Recreation Enhancement Act (16 U.S.C. 6801)); (B) the National Oceanic and Atmospheric Administration; (C) the United States Fire Administration; (D) the Federal Emergency Management Agency; (E) the National Aeronautics and Space Administration; (F) the Bureau of Indian Affairs; (G) the Department of Defense; (H) a State, Tribal, county, or municipal fire department or district operating through the United States Fire Administration or pursuant to an agreement with a Federal agency; and (I) any other Federal agency involved in wildfire response. (2) COVERED ENTITY.—The term “covered entity” means— (A) a private entity; (B) a nonprofit organization; or (C) an institution of higher education (as defined in section 101 of the Higher Education Act of 1965 (20 U.S.C. 1001)). (b) In general.—Not later than 1 year after the date of enactment of this Act, the Secretaries, in coordination with the heads of the covered agencies, shall establish a deployment and demonstration pilot program (in this section referred to as “Pilot Program”) for new and innovative wildfire prevention, detection, communication, and mitigation technologies. (c) Functions.—In carrying out the Pilot Program, the Secretaries shall— (1) incorporate the Pilot",https://www.congress.gov/bill/118th-congress/house-bill/8790/text,en,
1356,Advancing the Responsible Acquisition of Artificial Intelligence in Government,Office of Management and Budget,United States,Federal government,Editors' Picks,Regulation,2025-04-03,2025,4,positive,0.981,high,0.7778,210,0.7,Defunct,"September 24, 2024 M-24-18 MEMORANDUM FOR THE HEADS OF EXECUTIVE DEPARTMENTS AND AGENCIES FROM: Shalanda D. Young SUBJECT: Advancing the Responsible Acquisition of Artificial Intelligence in Government [Footnotes omitted throughout.] 1. OVERVIEW The use of artificial intelligence (AI) in the Federal Government presents tremendous opportunity for modernizing agency operations and improving the delivery of government services to the public, provided that the risks presented by the use of AI technology are mitigated. Realizing this goal involves recognizing that AI poses novel types of risk, and proactively integrating considerations for AI risk management into agency acquisition planning. This memorandum builds on previous efforts to harness the power and utility of AI in service of agency missions while protecting the public from potential risks or harms. Consistent with the Advancing American AI Act (“the Act”), Executive Order 14110, Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence, and Office of Management and Budget (OMB) Memorandum M-24-10, Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence, this memorandum directs agencies to improve their capacity for the responsible acquisition of AI. It contains new requirements and guidance for agencies on establishing meaningful cross-functional and interagency collaboration to reflect new AI responsibilities, managing AI risk and performance, and promoting a c",https://www.whitehouse.gov/wp-content/uploads/2024/10/M-24-18-AI-Acquisition-Memorandum.pdf,en,"Strategies: Performance requirements, Strategies: Evaluation: External auditing, Risk factors: Privacy, Harms: Violation of civil or human rights, including privacy, Risk factors: Bias, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Governance development, Applications: Government: other applications/unspecified, Strategies: Tiering, Strategies: Tiering: Tiering based on inputs, Strategies: Pilots and testbeds, Strategies: Disclosure, Strategies: Disclosure: About inputs"
1357,American Medical Innovation and Investment Act of 2024 (Sec. 5),United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9368,low,0.0,93,0.5,Defunct,"SEC. 5. GUIDANCE ON MEDICARE PAYMENT FOR CERTAIN ITEMS INVOLVING ARTIFICIAL INTELLIGENCE. Not later than January 1, 2026, the Secretary of Health and Human Services shall use existing communications mechanisms to issue guidance on requirements for payment under part B of title XVIII of the Social Security Act (42 U.S.C. 1395j et seq.) for remote monitoring devices, such as continuous glucose monitors, that— (1) use an artificial intelligence component (such as a continuous adjustment component); and (2) transmit information to a health care provider for purposes of management and treatment of an individual.",https://www.congress.gov/bill/118th-congress/house-bill/8816,en,
1358,"Combat Chinese Economic Aggression Act of 2024, Section 4 (""Protection of covered sectors."")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9657,low,0.0,216,0.5,Defunct,"SEC. 4. Protection of covered sectors. The Defense Production Act of 1950 (50 U.S.C. 4501 et seq.) is amended by adding at the end the following: “TITLE VIII—Protection of covered sectors “SEC. 801. Definitions. “In this title: “(1) APPROPRIATE CONGRESSIONAL COMMITTEES.—The term ‘appropriate congressional committees’ means— “(A) the Committee on Foreign Affairs, the Committee on Financial Services, the Committee on Ways and Means, the Committee on Appropriations, and the Permanent Select Committee on Intelligence of the House of Representatives; and “(B) the Committee on Foreign Relations, the Committee on Banking, Housing, and Urban Affairs, the Committee on Finance, the Committee on Appropriations, and the Select Committee on Intelligence of the Senate. “(2) COUNTRY OF CONCERN.—The term ‘country of concern’ includes— “(A) the Democratic People's Republic of North Korea; “(B) the People's Republic of China, including the Hong Kong Special Administrative Region and the Macau Special Administrative Region; “(C) the Russian Federation; “(D) the Islamic Republic of Iran; and “(E) any other country that the President has identified as engaging in a comprehensive, long-term strategy that directs, facilitates, or otherwise supports advancements in sensitive technologies and products that are critical to the military, intelligence, surveillance, or cyber-enabled capabilities of the country to counter United States capabilities in a way that threatens the national security of the Uni",https://www.congress.gov/bill/118th-congress/senate-bill/5016/text,en,
1371,"Platform Accountability and Transparency Act, Section 9 (""Rulemaking authority"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7506,low,0.0556,210,0.7,Defunct,"SEC. 9. Rulemaking authority. (a) Additional reporting requirements.— (1) IN GENERAL.—In consultation with the NSF, the Commission may, in accordance with section 553 of title 5, United States Code, and subject to subsection (g), issue regulations that require platforms to make available to qualified researchers data, metrics, or other information that the Commission determines will facilitate independent research in the public interest into activity on platforms. (2) FACTORS.—In exercising its authority under this subsection, the Commission shall consider the extent to which disclosures under this subsection may facilitate collaboration amongst qualified researchers and alleviate burdens on platforms and qualified researchers as compared to qualified research projects conducted pursuant to section 3. (3) FORM AND FREQUENCY; RETENTION OF INFORMATION.—The Commission shall specify in the regulations the required form and frequency of reporting or disclosures, as well as how long data, metrics, or other information should be retained and made available. It may require the information be provided in a form that is accessible for analysis by qualified researchers, such as through an application programming interface. (4) CONSULTATION.—The Commission shall further consult with the National Institutes of Health and other relevant government agencies, as appropriate, in exercising its authority under this subsection. (5) APPLICABILITY OF PRIOR SECTIONS.—For data made available to qua",https://www.congress.gov/bill/118th-congress/senate-bill/1876,en,"Applications: Sales, retail, and customer relations, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: In standard form, Risk factors: Privacy, Strategies: Disclosure: About inputs"
1372,"WIOA Performance Accountability Improvement Act, Section 2, Subsection (c) (""Evaluation of State programs."")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.872,low,0.0,97,0.5,Defunct,"(c) Evaluation of State programs.—Section 116(e) of the Workforce Innovation and Opportunity Act (29 U.S.C. 3141(e)) is amended— (1) in paragraph (1)— (A) in the first sentence, by striking “shall conduct ongoing” and inserting “shall use data to conduct analyses and ongoing”; and (B) in the second sentence, by striking “conduct the” and inserting “conduct such analyses and”; and (2) in paragraph (2), by adding “A State may use other forms of analysis, such as machine learning or other advanced analytics, to improve program operations and outcomes and to identify areas for further evaluation.” at the end.",https://www.congress.gov/bill/118th-congress/senate-bill/4501/text,en,
1373,"Artificial Intelligence Security Standardization White Paper, Section 5 (""Recommendations for AI security standardization work"")",Other authorities,,,Chinese law and policy,Other,2024-11-01,2024,11,positive,0.9958,low,0.0,223,0.5,Proposed,"5 Recommendations for AI security standardization work (1) Attach importance to improving a system of AI security standards We recommend launching AI standardization work, coordinating the planning of a system of AI security standards, strengthening research into fundamental AI security standards, and deepening the work of AI application security standards. The first is the overall planning of a system of AI security standards. In order to ensure the orderly progress of the development of AI security standards, we recommend investigating and analyzing the need for AI security standardization in China and giving priority to research on a system of AI security standards. The system of standards should cover the security needs of multiple objects such as the foundation, platform, technology, products, and applications of AI and should be able to clearly define relationships with related standards such as big data security, personal information protection, cloud computing security, and IoT security. Second, pay close attention to research and to implement the AI ethical principles. Focus on the outstanding issues of AI algorithm discrimination and algorithmic bias. Analyze and review the ethical needs of AI in various scenarios, develop and refine AI ethical principles, and guide the implementation of principles and requirements related to AI standards. (2) Accelerate the development of standards in key areas AI has the characteristics of wide coverage, complex application scenar",https://cset.georgetown.edu/publication/artificial-intelligence-security-standardization-white-paper-2019-edition/,en,
1374,"Sustaining America’s Fisheries for the Future Act of 2024, Title IV, Section 401 (""Data modernization."")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.886,low,0.0,158,0.5,Defunct,"SEC. 401. DATA MODERNIZATION. (a) In General.—Not later than 180 days after the date of the enactment of this section, the Secretary, acting through the Assistant Administrator for Fisheries, shall provide to Congress a national strategic plan for fisheries data, including a description of— (1) activities for the goals and objectives of the plan; (2) a schedule for implementation; (3) an estimated budget; (4) a plan for stakeholder engagement for development of user-centric systems, processes, and policies; and (5) how the initiative will align with other National Oceanic and Atmospheric Administration data management efforts to provide for efficiency and interoperability, including the Data Strategy, Cloud Strategy, and Artificial Intelligence Strategy of the National Oceanic and Atmospheric Administration. (b) Information From Experts.—In carrying out this section, the Secretary shall solicit information, as needed, from data management and technology experts inside and outside the government. (c) Report.—The Secretary shall annually report to Congress regarding progress in carrying out this section.",https://www.congress.gov/bill/118th-congress/house-bill/8862/text,en,
1375,"Sustaining America’s Fisheries for the Future Act of 2024, Title IV, Section 402 (""Expanding and improving electronic technologies."")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.886,low,0.0,205,0.5,Defunct,"SEC. 402. Expanding and improving electronic technologies. (a) Sense of Congress.—It is the sense of Congress that— (1) the use of electronic technologies such as digital video cameras and monitors, digital recording systems, and other forms of electronic technology as a complement to, and in some cases a replacement for, observers may maintain, increase, or improve the amount and accuracy of observer and fishery dependent information collected from fisheries while reducing costs and logistical difficulties; (2) to achieve optimum yields on a continuing basis while conserving and maintaining fisheries and integrating healthy ecosystem considerations, managers require reliable, timely data across all regions and fishing sectors for conservation, management, and scientific purposes; (3) to achieve management goals, especially in the context of climate change, the National Oceanic and Atmospheric Administration should work to meet evolving management needs and, in collaboration with industry stakeholders, identify appropriate data collection technologies and strategies; and (4) the National Oceanic and Atmospheric Administration should also consider the use of innovative technology in fishery independent data collection including stock and habitat assessments and environmental conditions. (b) Regional Fishery Management Councils.—Section 303(b)(8) (16 U.S.C. 1853(b)(8)) is amended to read as follows: “(8) require the collection of data necessary for the conservation and manageme",https://www.congress.gov/bill/118th-congress/house-bill/8862/text,en,
1376,An Act concerning consumer protections in interactions with artificial intelligence systems.,Colorado,United States,State governments,Editors' Picks,Law/Act,2024-05-17,2024,5,positive,0.9673,medium,0.5556,223,0.7,Enacted,"SENATE BILL 24-205 BY SENATOR(S) Rodriguez, Cutter, Michaelson Jenet, Priola, Winter F., Fenberg; also REPRESENTATIVE(S) Titone and Rutinel, Duran. CONCERNING CONSUMER PROTECTIONS IN INTERACTIONS WITH ARTIFICIAL INTELLIGENCE SYSTEMS. Capital letters or bold & italic numbers indicate new material added to existing law; dashes through words or numbers indicate deletions from existing law and such material is not part of the act. Be it enacted by the General Assembly of the State of Colorado: SECTION 1. In Colorado Revised Statutes, add part 17 to article 1 of title 6 as follows: PART 17 ARTIFICIAL INTELLIGENCE 6-1-1701. Definitions. As USED IN THIS PART 17, UNLESS THE CONTEXT OTHERWISE REQUIRES: (1) (a) ""ALGORITHMIC DISCRIMINATION"" MEANS ANY CONDITION IN WHICH THE USE OF AN ARTIFICIAL INTELLIGENCE SYSTEM RESULTS IN AN UNLAWFUL DIFFERENTIAL TREATMENT OR IMPACT THAT DISFAVORS AN INDIVIDUAL OR GROUP OF INDIVIDUALS ON THE BASIS OF THEIR ACTUAL OR PERCEIVED AGE, COLOR, DISABILITY, ETHNICITY, GENETIC INFORMATION, LIMITED PROFICIENCY IN THE ENGLISH LANGUAGE, NATIONAL ORIGIN, RACE, RELIGION, REPRODUCTIVE HEALTH, SEX, VETERAN STATUS, OR OTHER CLASSIFICATION PROTECTED UNDER THE LAWS OF THIS STATE OR FEDERAL LAW. (b) ""ALGORITHMIC DISCRIMINATION"" DOES NOT INCLUDE: (I) THE OFFER, LICENSE, OR USE OF A HIGH-RISK ARTIFICIAL INTELLIGENCE SYSTEM BY A DEVELOPER OR DEPLOYER FOR THE SOLE PURPOSE OF: (A) THE DEVELOPER'S OR DEPLOYER'S SELF-TESTING TO IDENTIFY, MITIGATE, OR PREVENT DISCRIMINATION OR O",https://leg.colorado.gov/sites/default/files/2024a_205_signed.pdf,en,"Risk factors: Bias, Risk factors: Reliability, Risk factors: Transparency, Harms: Discrimination, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About evaluation, Strategies: Disclosure: About inputs, Strategies: Performance requirements, Harms: Harm to health/safety, Strategies: Disclosure: About incidents, Harms: Financial loss"
1377,Artificial Intelligence Law of the People’s Republic of China (Draft for Suggestions from Scholars),Other authorities,,,Chinese law and policy,Other,2024-03-16,2024,3,positive,0.9943,high,0.7778,225,0.7,Proposed,"Artificial Intelligence Law of the People’s Republic of China (Draft for Suggestions from Scholars) --- Chapter 1 General Provisions --- Article 1 Legislative Intent This Law is enacted in accordance with the Constitution in order to promote technological innovation in artificial intelligence (AI), facilitate the healthy development of the AI industry, regulate AI product and service development, provision, and use activities, as well as their supervision and management, safeguard national security and the public interest, and protect the legitimate rights and interests of individuals and organizations. --- Article 2 Scope of Application This Law applies to AI development, provision, and use activities within the People’s Republic of China (PRC), and to the supervision and management thereof. This Law applies to those AI development, provision, and use activities outside the PRC that may affect the national security or public interests of, or the legitimate rights and interests of individuals or organizations in, the PRC. --- Article 3 Principle of Scientific and Technological Ethics The development of AI shall (应当) adhere to a people-centered (以人为本) approach, respect personal freedom and dignity, promote the well-being of the people, and provide assurance for the public interest, so as to guide and regulate the healthy and orderly development of the AI industry. AI developers, providers, and users shall prevent and control the possible ethical risks of AI in accordance with",https://cset.georgetown.edu/publication/china-ai-law-draft/,en,"Strategies: Government support, Strategies: Governance development, Strategies: Convening, Strategies: Government support: For R&D, Incentives: Civil liability, Harms: Violation of civil or human rights, including privacy, Strategies: Tiering, Strategies: Tiering: Tiering based on generality, Risk factors: Safety, Risk factors: Security, Harms: Detrimental content, Strategies: Disclosure: About incidents, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Performance requirements"
1378,"An Act to amend Tennessee Code Annotated, Title 39, Chapter 14, Part 1 and Title 47, relative to the protection of personal rights.",Tennessee,United States,State governments,Editors' Picks,Law/Act,2024-03-21,2024,3,positive,0.6124,low,0.1667,235,1.0,Enacted,"AN ACT to amend Tennessee Code Annotated, Title 39, Chapter 14, Part 1 and Title 47, relative to the protection of personal rights. BE IT ENACTED BY THE GENERAL ASSEMBLY OF THE STATE OF TENNESSEE: SECTION 1. Tennessee Code Annotated, Section 47-25-1101, is amended by deleting ""Personal Rights Protection Act of 1984"" and substituting ""Ensuring Likeness, Voice, and Image Security Act of 2024"". SECTION 2. Tennessee Code Annotated, Section 47-25-1102(4), is amended by inserting ""individual,"" before ""firm,"". SECTION 3. Tennessee Code Annotated, Section 47-25-1102, is amended by adding the following as a new subdivision: ( ) ""Voice"" means a sound in a medium that is readily identifiable and attributable to a particular individual, regardless of whether the sound contains the actual voice or a simulation of the voice of the individual; SECTION 4. Tennessee Code Annotated, Section 47-25-1103, is amended by deleting subsection (a) and substituting: (a) Every individual has a property right in the use of that individual's name, photograph, voice, or likeness in any medium in any manner. SECTION 5. Tennessee Code Annotated, Section 47-25-1104, is amended by deleting subdivision (b)(2) and substituting: (2) (A) The exclusive right to commercial exploitation of the property rights is terminated by proof of the non-use of the name, photograph, voice, or likeness of an individual for commercial purposes by an executor, assignee, heir, or devisee to the use for a period of two (2) years subs",https://publications.tnsosfiles.com/acts/113/pub/pc0588.pdf,en,"Strategies: Tiering, Strategies: Tiering: Tiering based on domain of application, Strategies: Tiering: Tiering based on impact, Harms: Violation of civil or human rights, including privacy, Risk factors: Privacy, Strategies: Governance development, Incentives: Civil liability, Applications: Consumer goods, Applications: Broadcasting and media production, Applications: Sales, retail, and customer relations, Harms: Detrimental content, Applications: Arts, sports, leisure, travel, and lifestyle"
1379,"Council of Europe Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law",Other multinational,Multinational,Multinational,Multinational,Other,2024-05-17,2024,5,positive,0.9786,medium,0.5,220,0.7,Enacted,"Council of Europe Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law Vilnius, 5.IX.2024 Preamble [Omitted.] Chapter I – General provisions Article 1 – Object and purpose 1 The provisions of this Convention aim to ensure that activities within the lifecycle of artificial intelligence systems are fully consistent with human rights, democracy and the rule of law. 2 Each Party shall adopt or maintain appropriate legislative, administrative or other measures to give effect to the provisions set out in this Convention. These measures shall be graduated and differentiated as may be necessary in view of the severity and probability of the occurrence of adverse impacts on human rights, democracy and the rule of law throughout the lifecycle of artificial intelligence systems. This may include specific or horizontal measures that apply irrespective of the type of technology used. 3 In order to ensure effective implementation of its provisions by the Parties, this Convention establishes a follow-up mechanism and provides for international co-operation. Article 2 – Definition of artificial intelligence systems For the purposes of this Convention, “artificial intelligence system” means a machine-based system that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations or decisions that may influence physical or virtual environments. Different artificial intel",https://rm.coe.int/1680afae3c,en,"Risk factors: Transparency, Strategies: Disclosure, Strategies: Disclosure: In deployment, Harms: Violation of civil or human rights, including privacy, Strategies: Evaluation, Risk factors: Reliability, Strategies: Governance development, Strategies: Evaluation: Impact assessment, Strategies: Tiering, Strategies: Tiering: Tiering based on domain of application, Strategies: Tiering: Tiering based on impact, Strategies: Convening, Applications: Government: other applications/unspecified, Risk factors: Safety, Strategies: New institution"
1380,Political Declaration on Responsible Military Use of Artificial Intelligence and Autonomy,Other multinational,Multinational,Multinational,Multinational,Other,2023-11-09,2023,11,positive,0.9451,medium,0.3889,216,1.0,Enacted,"An increasing number of States are developing military AI capabilities, which may include using AI to enable autonomous functions and systems. Military use of AI can and should be ethical, responsible, and enhance international security. Military use of AI must be in compliance with applicable international law. In particular, use of AI in armed conflict must be in accord with States’ obligations under international humanitarian law, including its fundamental principles. Military use of AI capabilities needs to be accountable, including through such use during military operations within a responsible human chain of command and control. A principled approach to the military use of AI should include careful consideration of risks and benefits, and it should also minimize unintended bias and accidents. States should take appropriate measures to ensure the responsible development, deployment, and use of their military AI capabilities, including those enabling autonomous functions and systems. These measures should be implemented at relevant stages throughout the life cycle of military AI capabilities. The endorsing States believe that the following measures should be implemented in the development, deployment, or use of military AI capabilities, including those enabling autonomous functions and systems: - States should ensure their military organizations adopt and implement these principles for the responsible development, deployment, and use of AI capabilities. - States should t",https://www.state.gov/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy-2/,en,"Risk factors: Reliability, Risk factors: Safety, Applications: Government: military and public safety, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Evaluation: Post-market monitoring, Strategies: Governance development, Harms: Harm to health/safety, Strategies: Tiering, Strategies: Tiering: Tiering based on impact, Strategies: Tiering: Tiering based on domain of application, Risk factors: Bias, Harms: Violation of civil or human rights, including privacy, Risk factors: Transparency, Risk factors: Interpretability and explainability"
1381,"Seizing the opportunities of safe, secure and trustworthy artificial intelligence systems for sustainable development",United Nations,Multinational,Multinational,Editors' Picks,Other,2024-03-21,2024,3,positive,0.9961,low,0.0,201,0.5,Enacted,"The General Assembly, [Opening declarations omitted.] 1. Resolves to bridge the artificial intelligence and other digital divides between and within countries; 2. Resolves to promote safe, secure and trustworthy artificial intelligence systems to accelerate progress towards the full realization of the 2030 Agenda for Sustainable Development, 10 further bridging the artificial intelligence and other digital divides between and within countries; and stresses the need for the standard of safe, secure and trustworthy artificial intelligence systems to promote, not hinder, digital transformation and equitable access to their benefits in order to achieve all 17 Sustainable Development Goals and sustainable development in its three dimensions – economic, social and environmental – and address other shared global challenges, particularly for developing countries; 3. Encourages Member States and invites multi-stakeholders from all regions and countries, within their respective roles and responsibilities, including from the private sector, international and regional organizations, civil society, the me dia, academia and research institutions and technical communities and individuals, to develop and support regulatory and governance approaches and frameworks related to safe, secure and trustworthy artificial intelligence systems that create an enabling ecosystem at all levels, including for innovation, entrepreneurship and the dissemination of knowledge and technologies on mutually agre",https://documents.un.org/doc/undoc/ltd/n24/065/92/pdf/n2406592.pdf,en,
1382,Hiroshima Process International Guiding Principles for Advanced AI Systems,Other multinational,Multinational,Multinational,Multinational,Other,2023-10-30,2023,10,positive,0.9821,high,0.7778,219,0.7,Enacted,"The International Guiding Principles for Organizations Developing Advanced AI Systems aims to promote safe, secure, and trustworthy AI worldwide and will provide guidance for organizations developing and using the most advanced AI systems, including the most advanced foundation models and generative AI systems (henceforth ""advanced AI systems""). Organizations may include, among others, entities from academia, civil society, the private sector, and the public sector. This non-exhaustive list of guiding principles is discussed and elaborated as a living document to build on the existing OECD AI Principles in response to recent developments in advanced AI systems and are meant to help seize the benefits and address the risks and challenges brought by these technologies. These principles should apply to all AI actors, when and as applicable to cover the design, development, deployment and use of advanced AI systems. We look forward to developing these principles further as part of the comprehensive policy framework, with input from other nations and wider stakeholders in academia, business and civil society. We also reiterate our commitment to elaborate an international code of conduct for organizations developing advanced AI systems based on the guiding principles below. Different jurisdictions may take their own unique approaches to implementing these guiding principles in different ways. We call on organizations in consultation with other relevant stakeholders to follow these",https://digital-strategy.ec.europa.eu/en/library/hiroshima-process-international-guiding-principles-advanced-ai-system,en,"Risk factors: Transparency, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: In standard form, Strategies: Performance requirements, Strategies: Convening, Strategies: Governance development, Risk factors: Security, Risk factors: Bias, Harms: Discrimination, Risk factors: Privacy, Risk factors: Safety, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Evaluation: Post-market monitoring"
1383,Hiroshima Process International Code of Conduct for Organizations Developing Advanced AI Systems,Other multinational,Multinational,Multinational,Multinational,Other,2023-10-30,2023,10,positive,0.9877,high,0.8333,218,1.0,Enacted,"Hiroshima Process International Code of Conduct for Organizations Developing Advanced AI Systems On the basis of the International Guiding Principles for Organizations Developing Advanced AI systems, the International Code of Conduct for Organizations Developing Advanced AI Systems aims to promote safe, secure, and trustworthy AI worldwide and will provide voluntary guidance for actions by organizations developing the most advanced AI systems, including the most advanced foundation models and generative AI systems (henceforth ""advanced AI systems""). Organizations should follow these actions in line with a risk-based approach. Organizations that may endorse this Code of Conduct may include, among others, entities from academia, civil society, the private sector, and/or the public sector. This non-exhaustive list of actions is discussed and elaborated as a living document to build on the existing OECD AI Principles in response to the recent developments in advanced AI systems and is meant to help seize the benefits and address the risks and challenges brought by these technologies. Organizations should apply these actions to all stages of the lifecycle to cover, when and as applicable, the design, development, deployment and use of advanced AI systems. This document will be reviewed and updated as necessary, including through ongoing inclusive multistakeholder consultations, in order to ensure it remains fit for purpose and responsive to this rapidly evolving technology. Differ",https://digital-strategy.ec.europa.eu/en/library/hiroshima-process-international-code-conduct-advanced-ai-systems,en,"Risk factors: Privacy, Risk factors: Security, Strategies: Evaluation, Risk factors: Bias, Strategies: Performance requirements, Risk factors: Transparency, Strategies: Governance development, Strategies: Convening, Harms: Violation of civil or human rights, including privacy, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Disclosure: In standard form, Strategies: Disclosure: Accuracy thereof, Risk factors: Interpretability and explainability, Strategies: Evaluation: Post-market monitoring"
1385,"Memorandum on Advancing the United States’ Leadership in Artificial Intelligence; Harnessing Artificial Intelligence to Fulfill National Security Objectives; and Fostering the Safety, Security, and Trustworthiness of Artificial Intelligence",Executive Office of the President,United States,Federal government,Editors' Picks,Regulation,2024-10-24,2024,10,positive,0.9937,high,0.8333,205,0.7,Enacted,"[Introductory material omitted.] Section 1. Policy. (a) This memorandum fulfills the directive set forth in subsection 4.8 of Executive Order 14110 of October 30, 2023 (Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence). This memorandum provides further direction on appropriately harnessing artificial intelligence (AI) models and AI-enabled technologies in the United States Government, especially in the context of national security systems (NSS), while protecting human rights, civil rights, civil liberties, privacy, and safety in AI-enabled national security activities. A classified annex to this memorandum addresses additional sensitive national security issues, including countering adversary use of AI that poses risks to United States national security. (b) United States national security institutions have historically triumphed during eras of technological transition. To meet changing times, they developed new capabilities, from submarines and aircraft to space systems and cyber tools. To gain a decisive edge and protect national security, they pioneered technologies such as radar, the Global Positioning System, and nuclear propulsion, and unleashed these hard-won breakthroughs on the battlefield. With each paradigm shift, they also developed new systems for tracking and countering adversaries’ attempts to wield cutting-edge technology for their own advantage. (c) AI has emerged as an era-defining technology and has demonstrated significant and g",https://www.whitehouse.gov/briefing-room/presidential-actions/2024/10/24/memorandum-on-advancing-the-united-states-leadership-in-artificial-intelligence-harnessing-artificial-intelligence-to-fulfill-national-security-objectives-and-fostering-the-safety-security/,en,"Strategies: Evaluation, Strategies: Tiering: Tiering based on impact, Strategies: Evaluation: Impact assessment, Risk factors: Security: Cybersecurity, Risk factors: Security, Applications: Security, Applications: Government: military and public safety, Strategies: Tiering: Tiering based on domain of application, Strategies: Disclosure: About evaluation, Risk factors: Safety, Risk factors: Reliability, Strategies: Tiering, Strategies: Disclosure, Strategies: Government study or report, Strategies: Tiering: Tiering based on generality"
1387,Framework to Advance AI Governance and Risk Management in National Security,Executive Office of the President,United States,Federal government,Editors' Picks,Regulation,2024-10-24,2024,10,positive,0.9933,medium,0.5556,223,1.0,Enacted,"Framework to Advance AI Governance and Risk Management in National Security Scope The Framework to Advance AI Governance and Risk Management in National Security (“AI Framework”) builds on and fulfills the requirements found in Section 4.2 of the National Security Memorandum on Advancing the United States’ Leadership in AI, Harnessing AI to Fulfill National Security Objectives, and Fostering the Safety, Security, and Trustworthiness of AI (“AI NSM”), which directs designated Department Heads to issue guidance to their respective components/sub-agencies to advance governance and risk management practices regarding the use of AI as a component of a National Security System (NSS). This AI Framework is intended to support and enable the U.S. Government to continue taking active steps to uphold human rights, civil rights, civil liberties, privacy, and safety; ensure that AI is used in a manner consistent with the President’s authority as commander-in-chief to decide when to order military operations in the nation’s defense; and ensure that military use of AI capabilities is accountable, including through such use during military operations within a responsible human chain of command and control. AI use in military contexts shall adhere to the principles and measures articulated in the Political Declaration on Responsible Military Use of Artificial Intelligence and Autonomy, announced by the United States on November 9, 2023. This AI Framework includes four primary pillars relating",https://ai.gov/wp-content/uploads/2024/10/NSM-Framework-to-Advance-AI-Governance-and-Risk-Management-in-National-Security.pdf,en,"Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Disclosure, Strategies: Tiering: Tiering based on impact, Strategies: Government study or report, Harms: Harm to health/safety, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Applications: Government: military and public safety, Applications: Government: other applications/unspecified, Strategies: New institution, Strategies: Convening, Strategies: Governance development, Strategies: Tiering, Risk factors: Privacy"
1390,White Paper on Artificial Intelligence Standardization 2021,Other authorities,,,Chinese law and policy,Other,2021-07-21,2021,7,positive,0.9776,low,0.0,219,0.5,Proposed,"5. Key recommendations for AI standardization work Based on the current state of AI technology and industry development, together with the progress of standardization work and the establishment of the standards system, we propose key work recommendations for China’s AI standardization. (1) Improve the working mechanism and help industry to achieve healthy and sustainable development AI is deeply integrated into the real economy, and the standardization of AI is exhibiting a trend of collaborative participation in multiple fields. First, through the National Information Technology Standardization Technical Committee’s AI Technical Subcommittee (SAC/TC 28/SC 42), the standardization of new generation information technology fields such as AI, the Internet of Things (IoT), cloud computing, and big data should be coordinated and promoted to strengthen the application of AI in vertical fields. Second, the role of the national AI standardization working group platform should be given full play to coordinate the development of AI standards in the real economy and related fields, and to absorb the energy of government, industry, academia, research institutes, and users to jointly promote AI standardization. (2) Develop key standards and improve the AI standards system The development of key AI standards must be promoted based on the principles of “advantages first, maturity first, lead with basics, and be application-driven.” The first is to consolidate the industrial foundation with",https://cset.georgetown.edu/publication/artificial-intelligence-standardization-white-paper-2021-edition/,en,
1391,"Better Mental Health Care for Americans Act, Sec. 201",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9812,low,0.0,212,0.5,Defunct,"SEC. 201. PARITY IN MENTAL HEALTH AND SUBSTANCE USE DISORDER BENEFITS UNDER MEDICARE ADVANTAGE AND PRESCRIPTION DRUG PLANS. (a) Medicare Advantage Plans.— (1) IN GENERAL.—Section 1852 of the Social Security Act (42 U.S.C. 1395w–22) is amended by adding at the end the following new subsection: “(o) Parity In Mental Health And Substance Use Disorder Benefits.— “(1) IN GENERAL.—Each MA organization shall ensure that the benefit design of each MA plan offered by such organization meets the following requirements: “(A) FINANCIAL REQUIREMENTS.—The financial requirements applicable to mental health or substance use disorder benefits covered by the plan may not exceed the predominant financial requirements applied to substantially all medical benefits covered by the plan, including supplemental benefits, and there are no separate cost sharing requirements that are applicable only with respect to mental health and substance use disorder benefits. “(B) TREATMENT LIMITATIONS.—The treatment limitations applicable to mental health or substance use disorder benefits are no more restrictive than the predominant treatment limitations applied to substantially all medical benefits covered by the plan and there are no separate treatment limitations that are applicable only with respect to mental health or substance use disorder benefits, including supplemental benefits. “(2) DETERMINATIONS OF MEDICAL NECESSITY.— “(A) IN GENERAL.—Each MA organization shall ensure that any determination of medica",https://www.congress.gov/bill/118th-congress/senate-bill/923/text,en,
1392,"Better Mental Health Care for Americans Act, Sec. 203",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.5226,low,0.0,226,0.5,Defunct,"SEC. 203. PROVIDING INFORMATION ON BEHAVIORAL HEALTH COVERAGE TO PROMOTE INFORMED CHOICE. Section 1851(d)(4) of the Social Security Act (42 U.S.C. 1395w–21(d)(4)) is amended by adding at the end the following new subparagraph: “(F) BEHAVIORAL HEALTH INFORMATION.—For 2025 and subsequent plan years, to the extent available, the following information with respect to the preceding plan year: “(i) Information on access to in-network behavioral health providers, disaggregated by those who prescribe and those who offer mental health or substance use disorder services, including— “(I) the average wait time (as defined by the Secretary) for an appointment for a new patient with an in-network provider for mental health or substance disorder services; “(II) the total number and percentage of providers who have participation agreements with the organization who submitted at least one request for payment for a mental health or substance use disorder service during a 6 month period (or other period specified by the Secretary); and “(III) the percentage of requests for payment for mental health or substance use disorder services that were submitted by— “(aa) in-network providers; and “(bb) out-of-network providers. “(ii) Information on the number of denials of prior authorization requests or denials of payment for mental health or substance use disorder services compared to non-mental health and substance use disorder services overall, categorized by the type of denial and by the type of se",https://www.congress.gov/bill/118th-congress/senate-bill/923/text,en,
1394,"Digital Charter Implementation Act 2022, Part 3 (""Artificial Intelligence and Data Act"")",Government of Canada,Other countries,Other countries,Miscellaneous documents,Law/Act,2022-06-16,2022,6,positive,0.9814,low,0.0,225,0.5,Proposed,"Artificial Intelligence and Data Act Enactment of Act 39 The Artificial Intelligence and Data Act is enacted as follows: An Act respecting artificial intelligence systems and data used in artificial intelligence systems Short Title Short title 1 This Act may be cited as the Artificial Intelligence and Data Act. Definitions and Application Definitions 2 The following definitions apply in this Act. artificial intelligence system means a technological system that, autonomously or partly autonomously, processes data related to human activities through the use of a genetic algorithm, a neural network, machine learning or another technique in order to generate content or make decisions, recommendations or predictions. (système d’intelligence artificielle) person includes a trust, a joint venture, a partnership, an unincorporated association and any other legal entity. (personne) personal information has the meaning assigned by subsections 2(1) and (3) of the Consumer Privacy Protection Act. (renseignement personnel) Non-application 3 (1) This Act does not apply with respect to a government institution as defined in section 3 of the Privacy Act. Product, service or activity (2) This Act does not apply with respect to a product, service or activity that is under the direction or control of (a) the Minister of National Defence; (b) the Director of the Canadian Security Intelligence Service; (c) the Chief of the Communications Security Establishment; or (d) any other person who is resp",https://www.parl.ca/DocumentViewer/en/44-1/bill/C-27/first-reading,en,
1395,The Global Security Initiative Concept Paper,Chinese central government,China,China,Chinese law and policy,Other,2023-02-22,2023,2,positive,0.9971,low,0.0,227,0.5,Enacted,"III. Priorities of cooperation It is our common aspiration to achieve lasting world peace, so that all countries can enjoy a peaceful and stable external environment and their people can live a happy life with their rights fully guaranteed. Like passengers aboard the same ship, countries need to work in solidarity to foster a community of shared security for mankind and build a world that is free from fear and enjoys universal security. To realize these visions, China is ready to conduct bilateral and multilateral security cooperation with all countries and international and regional organizations under the framework of the Global Security Initiative, and actively promote coordination of security concepts and convergence of interests. China calls on all parties to carry out single or multiple cooperation in aspects including but not limited to the following ones, so as to pursue mutual learning and complementarity and to jointly promote world peace and tranquility: 1.Actively participate in formulating a New Agenda for Peace and other proposals put forth in Our Common Agenda by the UN Secretary-General. Support UN efforts to enhance conflict prevention and fully harness the peace-building architecture to assist post-conflict states in peace-building. Further leverage the Secretary-General’s Peace and Security Sub-Fund of the China-UN Peace and Development Trust Fund and support a bigger UN role in global security affairs. Support the UN in enhancing capacity for implementing",http://cr.china-embassy.gov.cn/esp/ndle/202302/t20230222_11029046.htm,en,
1396,Recommendation of the Council on Artificial Intelligence (5/2/2024),OECD,Multinational,Multinational,Editors' Picks,Other,2024-05-02,2024,5,positive,0.9236,medium,0.6111,222,1.0,Enacted,"THE COUNCIL, [Opening declarations omitted.] On the proposal of the Digital Policy Committee: I. AGREES that for the purpose of this Recommendation the following terms should be understood as follows: ‒AI system: An AI system is a machine-based system that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments. Different AI systems vary in their levels of autonomy and adaptiveness after deployment. ‒AI system lifecycle: An AI system lifecycle typically involves several phases that include to: plan and design; collect and process data; build model(s) and/or adapt existing model(s) to specific tasks; test, evaluate, verify and validate; make available for use/deploy; operate and monitor; and retire/decommission. These phases often take place in an iterative manner and are not necessarily sequential. The decision to retire an AI system from operation may occur at any point during the operation and monitoring phase. ‒AI actors: AI actors are those who play an active role in the AI system lifecycle, including organisations and individuals that deploy or operate AI. ‒AI knowledge: AI knowledge refers to the skills and resources, such as data, code, algorithms, models, research, know-how, training programmes, governance, processes, and best practices required to understand and participate in the AI system lifecycle, including mana",https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449,en,"Strategies: Government support, Strategies: Government support: For R&D, Strategies: Governance development, Strategies: Convening, Risk factors: Reliability, Harms: Detrimental content, Harms: Violation of civil or human rights, including privacy, Risk factors: Privacy, Harms: Discrimination, Strategies: Pilots and testbeds, Strategies: Government support: AI workforce-related, Risk factors: Transparency, Risk factors: Interpretability and explainability, Strategies: Evaluation, Strategies: Evaluation: Impact assessment"
1399,Alabama House Bill 172,Alabama,United States,State governments,U.S. state and local documents,Law/Act,2024-10-01,2024,10,positive,0.9734,low,0.0,212,0.5,Enacted,"An Act, Relating to elections; to provide that the distribution of materially deceptive media in an attempt to influence an upcoming election is a crime; to authorize certain parties to seek permanent injunctive relief against anyone who distributes materially deceptive media in an attempt to influence an upcoming election; to provide definitions; and to provide exceptions. BE IT ENACTED BY THE LEGISLATURE OF ALABAMA: Section 1. For the purposes of this bill, the following terms have the following meanings: (1) ARTIFICIAL INTELLIGENCE. Any artificial system or generative artificial intelligence system that performs tasks under varying and unpredictable circumstances without significant human oversight or that can learn from experience and improve performance when exposed to data sets. (2) CREATOR. Any candidate, candidate campaign committee, political party, political action committee, other political committee or entity, any employee, representative, or agent of the foregoing, or any other person who prepares, creates, or causes the preparation or creation and the dissemination of any political advertising, material, or media produced by generative artificial intelligence. The term does not include a broadcaster, cable provider, digital newspaper, online service, Internet service provider, streaming platform, provider, or developer of any technology in the generation of media by artificial intelligence, or any employee, representative, or agent thereof, solely for the distri",https://alison.legislature.state.al.us/files/pdf/SearchableInstruments/2024RS/HB172-enr.pdf,en,
1402,Colorado House Bill 1147,Colorado,United States,State governments,U.S. state and local documents,Law/Act,2024-05-24,2024,5,negative,-0.9577,low,0.0,234,0.5,Enacted,"Be it enacted by the General Assembly of the State of Colorado: SECTION 1. In Colorado Revised Statutes, 1-45-111.5, add (1.5)(c.5) as follows: 1-45-111.5. Duties of the secretary of state - enforcement - sanctions - definitions. (1.5) (c.5) IN ADDITION TO AND WITHOUT PREJUDICE TO ANY OTHER PENALTY AUTHORIZED UNDER THIS ARTICLE 45, A HEARING OFFICER SHALL IMPOSE A CIVIL PENALTY AS FOLLOWS: (I) AT LEAST ONE HUNDRED DOLLARS FOR EACH VIOLATION THAT IS A FAILURE TO INCLUDE A DISCLOSURE STATEMENT IN ACCORDANCE WITH SECTION 1-46-103 (2), IF THE VIOLATION DOES NOT INVOLVE ANY PAID ADVERTISING OR OTHER SPENDING TO PROMOTE OR ATTRACT ATTENTION TO A COMMUNICATION PROHIBITED BY SECTION 1-46-103 (1), OR SUCH OTHER HIGHER AMOUNT THAT, BASED ON THE DEGREE OF DISTRIBUTION AND PUBLIC EXPOSURE TO THE UNLAWFUL COMMUNICATION, THE HEARING OFFICER DEEMS APPROPRIATE TO DETER FUTURE VIOLATIONS OF SECTION 1-46-103; AND (II) AT LEAST TEN PERCENT OF THE AMOUNT PAID OR SPENT TO ADVERTISE, PROMOTE, OR ATTRACT ATTENTION TO A COMMUNICATION PROHIBITED BY SECTION 1-46-103 (1) THAT DOES NOT INCLUDE A DISCLOSURE STATEMENT IN ACCORDANCE WITH SECTION 1-46-103 (2), OR SUCH OTHER HIGHER AMOUNT THAT, BASED ON THE DEGREE OF DISTRIBUTION AND PUBLIC EXPOSURE TO THE UNLAWFUL COMMUNICATION, THE HEARING OFFICER DEEMS APPROPRIATE TO DETER FUTURE VIOLATIONS OF SECTION 1-46-103. SECTION 2. In Colorado Revised Statutes, 1-45-111.7, amend (2)(a) as follows: 1-45-111.7. Campaign finance complaints - initial review - curing vi",https://leg.colorado.gov/sites/default/files/2024a_1147_signed.pdf,en,
1403,Colorado House Bill 24-1468,Colorado,United States,State governments,U.S. state and local documents,Law/Act,2024-06-06,2024,6,positive,0.9822,low,0.0,214,0.5,Enacted,"Be it enacted by the General Assembly of the State of Colorado: SECTION 1. In Colorado Revised Statutes, 2-3-1701, amend (1) and (12) as follows: 2-3-1701. Definitions. As used in this part 17, unless the context otherwise requires: (1) ""Artificial intelligence"" OR ""ARTIFICIAL INTELLIGENCE SYSTEM"" means: (b) ANY MACHINE-BASED SYSTEM THAT, FOR ANY EXPLICIT OR IMPLICIT OBJECTIVE, INFERS, FROM THE INPUTS THE SYSTEM RECEIVES, HOW TO GENERATE OUTPUTS, INCLUDING CONTENT, DECISIONS, PREDICTIONS, OR RECOMMENDATIONS, THAT CAN INFLUENCE PHYSICAL OR VIRTUAL ENVIRONMENTS. (12) ""Task force"" means the ARTIFICIAL INTELLIGENCE IMPACT TASK FORCE created in section 2-3-1707. SECTION 2. In Colorado Revised Statutes, repeal and reenact, with amendments, 2-3-1707 as follows: 2-3-1707. Artificial intelligence impact task force - creation - membership - duties - compensation - staff support - report - definitions - repeal. (1) Definitions. AS USED IN THIS SECTION, UNLESS CONTEXT OTHERWISE REQUIRES: (a) ""ALGORITHMIC DISCRIMINATION"" MEANS ANY CONDITION IN WHICH THE USE OF AN AUTOMATED DECISION SYSTEM OR ARTIFICIAL INTELLIGENCE SYSTEM RESULTS IN AN UNLAWFUL DIFFERENTIAL TREATMENT OR IMPACT THAT DISFAVORS AN INDIVIDUAL ORA GROUP OF INDIVIDUALS ON THE BASIS OF THEIR ACTUAL OR PERCEIVED AGE, COLOR, DISABILITY, ETHNICITY, GENETIC INFORMATION, LIMITED PROFICIENCY IN THE ENGLISH LANGUAGE, NATIONAL ORIGIN, RACE, RELIGION, REPRODUCTIVE HEALTH, SEX, VETERAN STATUS, OR OTHER CLASSIFICATION PROTECTED UNDER THE L",https://leg.colorado.gov/sites/default/files/2024a_1468_signed.pdf,en,
1406,Delaware House Bill 333,Delaware,United States,State governments,U.S. state and local documents,Law/Act,2024-07-17,2024,7,positive,0.9629,low,0.0,225,0.5,Enacted,"BE IT ENACTED BY THE GENERAL ASSEMBLY OF THE STATE OF DELAWARE: Section 1. Amend Chapter 90C, Title 29 of the Delaware Code by making deletions as shown by strike through and insertions as shown by underline as follows: Subchapter IV: Delaware Artificial Intelligence (AI) Commission § 9041C. Purpose. The Delaware AI Commission is created to do all of the following: (a) Make recommendations to the General Assembly and to the Chief Information Officer of the Department on legislative and executive actions regarding AI in Delaware. (b) Develop and recommend statewide processes, principles, and guidelines for executive, legislative, and judicial agencies to follow regarding use of AI. (c) Encourage agencies to utilize AI to improve service delivery, where appropriate. (d) Examine, develop, and recommend legislative, executive, and judicial actions that ensure the use of AI in Delaware keeps citizens safe and does not violate any individual’s rights. (e) Conduct an inventory of all Generative AI usage in Delaware executive, legislative, and judicial agencies and identify high risk areas for the implementation of Generative AI. § 9042C. Definitions. As used in this subchapter: (a) “Appointed member” means an individual appointed under § 9043C of this subchapter. (b) “Artificial Intelligence” or “AI” means a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments. (c) “Commis",https://legis.delaware.gov/json/BillDetail/GenerateHtmlDocumentEngrossment?engrossmentId=36232&docTypeId=6,en,
1407,Florida House Bill 919,Florida,United States,State governments,U.S. state and local documents,Law/Act,2024-04-26,2024,4,positive,0.9186,low,0.1111,212,0.7,Enacted,"An act relating to artificial intelligence use in political advertising; creating s. 106.145, F.S.; providing a definition; requiring certain political advertisements, electioneering communications, or other miscellaneous advertisements to include a specified disclaimer; specifying requirements for the disclaimer; providing for criminal and civil penalties; authorizing any person to file certain complaints; providing for expedited hearings; providing an effective date. Be It Enacted by the Legislature of the State of Florida: Section 1. Section 106.145, Florida Statutes, is created to read: 106.145 Use of artificial intelligence.— (1) As used in this section, the term ""generative artificial intelligence"" means a machine-based system that can, for a given set of human-defined objectives, emulate the structure and characteristics of input data in order to generate derived synthetic content including images, videos, audio, text, and other digital content. (2) If a political advertisement, an electioneering communication, or other miscellaneous advertisement of a political nature contains images, video, audio, graphics, or other digital content created in whole or in part with the use of generative artificial intelligence, if the generated content appears to depict a real person performing an action that did not actually occur, and if the generated content was created with intent to injure a candidate or to deceive regarding a ballot issue, the political advertisement, electionee",https://www.flsenate.gov/Session/Bill/2024/919/BillText/er/PDF,en,"Harms: Detrimental content, Risk factors: Transparency, Strategies: Disclosure, Incentives: Criminal liability"
1411,Hawaii Senate Bill 2284 (Relating To A Wildfire Forecast System For Hawaii),Hawaii,United States,State governments,U.S. state and local documents,Law/Act,2024-08-07,2024,8,positive,0.6249,low,0.0,243,0.5,Enacted,"A BILL FOR AN ACT RELATING TO A WILDFIRE FORECAST SYSTEM FOR HAWAII. BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF HAWAII: SECTION 1. The legislature finds that requiring the university of Hawaii to establish a two-year program to develop a wildfire forecast system for the State using artificial intelligence is a matter of statewide concern pursuant to article X, section 6, of the Hawaii State Constitution. SECTION 2. (a) The university of Hawaii shall establish and implement a two-year program to develop a wildfire forecast system for the State using artificial intelligence. The university of Hawaii shall develop the system to forecast the risk of wildfire statewide and thus enhance public safety, preparedness, and risk mitigation, including improving the preparedness of firefighters and enabling residents to take fire mitigation measures for their homes and to plan for evacuations. (b) The university of Hawaii shall submit a report on the effectiveness of the program and any findings and recommendations, including any proposed legislation, to the legislature no later than twenty days prior to the convening of the regular session of 2026. SECTION 3. There is appropriated out of the general revenues of the State of Hawaii the sum of $1,000,000 or so much thereof as may be necessary for fiscal year 2024-2025 for the development of the wildfire forecast system pursuant to section 2 of this Act. The sum appropriated shall be expended by the university of Hawaii for the purpos",https://legiscan.com/HI/text/SB2284/id/3005346/Hawaii-2024-SB2284-Amended.html,en,
1416,Indiana House Bill 1047,Indiana,United States,State governments,U.S. state and local documents,Law/Act,2024-03-12,2024,3,negative,-0.9785,low,0.0,257,0.5,Enacted,"AN ACT to amend the Indiana Code concerning criminal law and procedure. Be it enacted by the General Assembly of the State of Indiana: SECTION 1. IC 34-11-2-4, AS AMENDED BY P.L.44-2013, SECTION 1,IS AMENDED TO READ AS FOLLOWS [EFFECTIVE UPON PASSAGE]: Sec. 4. (a) An action for: (1) injury to person or character; (2) injury to personal property; or (3) a forfeiture of penalty given by statute; must be commenced within two (2) years after the cause of action accrues. (b) Except as provided in subsections (c) and (d), an action for injury to a person that results from the sexual abuse of a child must be commenced within the later of: (1) seven (7) years after the cause of action accrues; or (2) four (4) years after the person ceases to be a dependent of the person alleged to have performed the sexual abuse. (c) An action for injury to a person that: (1) results from the sexual abuse of a child; (2) is barred due to the expiration of the statute of limitations period described in subsection (b); and (3) is brought against a congressionally chartered organization that was incorporated before June 16, 1916; may be commenced in accordance with subsection (d). (d) An action described in subsection (c) may be commenced before July 1, 2025, by a person who, before January 1, 2024, participated in a bankruptcy proceeding or bankruptcy settlement that: (1) was initiated on February 18, 2020; and (2) involved the organization described in subsection (c)(3). SECTION 2. IC 34-21.5-2-1, AS",https://iga.in.gov/pdf-documents/123/2024/house/bills/HB1047/HB1047.06.ENRS.pdf,en,
1417,Indiana Senate Bill 2024-150,Indiana,United States,State governments,U.S. state and local documents,Law/Act,2024-03-13,2024,3,positive,0.9454,low,0.1667,263,0.7,Enacted,"AN ACT to amend the Indiana Code concerning technology. Be it enacted by the General Assembly of the State of Indiana: SECTION 1. IC 2-5-53.7 IS ADDED TO THE INDIANA CODE AS A NEW CHAPTER TO READ AS FOLLOWS [EFFECTIVE JULY 1, 2024]: Chapter 53.7. Artificial Intelligence Task Force Sec. 1. As used in this chapter, ""artificial intelligence"" has the meaning set forth in IC 4-13.1-5-1. Sec. 2. As used in this chapter, ""college or university"" has the meaning set forth in IC 21-7-13-10. Sec. 3. As used in this chapter, ""task force"" refers to the artificial intelligence task force established by section 4 of this chapter. Sec. 4. The artificial intelligence task force is established as a temporary task force serving the general assembly. Sec. 5. (a) The task force consists of the following fifteen (15) members: (1) A member of the house of representatives who is appointed to the task force by the speaker of the house of representatives. (2) A member of the senate who is appointed to the task force by the president pro tempore of the senate. (3) A member of the house of representatives who is appointed to the taskforce by the minority leader of the house of representatives. (4) A member of the senate who is appointed to the task force by the minority leader of the senate. (5) The chief information officer appointed under IC 4-13.1-2-3, who serves as an ex officio member of the task force. (6) The chief data officer appointed under IC 4-3-26-9, who serves as an ex officio member of th",https://iga.in.gov/pdf-documents/123/2024/senate/bills/SB0150/SB0150.06.ENRH.pdf,en,"Strategies: Convening, Strategies: Government study or report, Harms: Financial loss, Harms: Violation of civil or human rights, including privacy, Strategies: Governance development, Applications: Government: other applications/unspecified, Risk factors: Security: Cybersecurity, Strategies: Disclosure: In deployment, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Disclosure: About inputs, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Disclosure: About incidents, Strategies: Disclosure: In standard form"
1420,Maryland House Bill 1128,Maryland,United States,State governments,U.S. state and local documents,Law/Act,2024-05-09,2024,5,positive,0.9926,low,0.0,221,0.5,Enacted,"AN ACT concerning Labor and Employment – Workforce Development – Talent Innovation Program and Fund FOR the purpose of establishing the Talent Innovation Program in the Maryland Department of Labor to increase access to high–quality job training; establishing the Talent Innovation Fund as a special, nonlapsing fund; requiring interest earnings of the Fund to be credited to the Fund; and generally relating to the Talent Innovation Program and Talent Innovation Fund. BY adding to Article – Labor and Employment Section 11–1601 through 11–1604 to be under the new subtitle “Subtitle 16. Talent Innovation Program and Fund” Annotated Code of Maryland (2016 Replacement Volume and 2023 Supplement) BY repealing and reenacting, without amendments, Article – State Finance and Procurement Section 6–226(a)(2)(i) Annotated Code of Maryland (2021 Replacement Volume and 2023 Supplement) BY repealing and reenacting, with amendments, Article – State Finance and Procurement Section 6–226(a)(2)(ii)189. and 190. Annotated Code of Maryland (2021 Replacement Volume and 2023 Supplement) BY adding to Article – State Finance and Procurement Section 6–226(a)(2)(ii)191. Annotated Code of Maryland (2021 Replacement Volume and 2023 Supplement) SECTION 1. BE IT ENACTED BY THE GENERAL ASSEMBLY OF MARYLAND, That the Laws of Maryland read as follows: Article – Labor and Employment SUBTITLE 16. TALENT INNOVATION PROGRAM AND FUND. 11–1601. (A) IN THIS SUBTITLE THE FOLLOWING WORDS HAVE THE MEANINGS INDICATED. (B)",https://legiscan.com/MD/text/HB1128/2024,en,
1426,Maryland Senate Bill 1068,Maryland,United States,State governments,U.S. state and local documents,Law/Act,2024-05-09,2024,5,positive,0.926,low,0.0,105,0.5,Enacted,"SECTION 1. BE IT ENACTED BY THE GENERAL ASSEMBLY OF MARYLAND, That it is the intent of the General Assembly that the Department of Information Technology: (1) evaluate the potential of artificial intelligence in creating a statewide virtual 3–1–1 portal as a source for Maryland residents to obtain nonemergency government information and services; and (2) if the Department determines that the use of artificial intelligence in creating a virtual 3–1–1 portal is feasible, prioritize the creation of a virtual 3–1–1 portal. SECTION 5. 2. AND BE IT FURTHER ENACTED, That this Act shall take effect July 1, 2024. Approved by the Governor, May 9, 2024.",https://mgaleg.maryland.gov/2024RS/Chapters_noln/CH_450_sb1068t.pdf,en,
1431,New Hampshire House Bill 1432,New Hampshire,United States,State governments,U.S. state and local documents,Law/Act,2024-07-19,2024,7,negative,-0.9633,low,0.0,246,0.5,Enacted,"AN ACT relative to prohibiting certain uses of deepfakes and creating a private claim of action. Be it Enacted by the Senate and House of Representatives in General Court convened: 243:1 New Section; Criminal Code; Fraud; Fraudulent Use of Deepfakes. Amend RSA 638 by inserting after section 26 the following new section: 638:26-a Fraudulent Use of Deepfakes. I. In this section: (a) ""Artificial intelligence"" or ""AI"" means the ability of a machine to display human-like capabilities for cognitive tasks such as reasoning, learning, planning, and creativity. AI systems may adapt their behavior to a certain degree by analyzing the effects of previous actions and operating under varying and unpredictable circumstances without significant human oversight. (b) ""Deepfake"" means a video, audio, or any other media of a person in which his or her face, body, or voice has been digitally altered so that he or she appears to be someone else, he or she appears to be saying something that he or she has never said, or he or she appears to be doing something that he or she has never done. II. A person is guilty of a class B felony if the person knowingly creates, distributes, or presents any likeness in video, audio, or any other media of an identifiable individual that constitutes a deepfake for the purpose of embarrassing, harassing, entrapping, defaming, extorting, or otherwise causing any financial or reputational harm to the identifiable person. III. If a person violates paragraph II, and th",https://www.gencourt.state.nh.us/bill_Status/pdf.aspx?id=32243&q=billVersion,en,
1432,New Hampshire House Bill 1688,New Hampshire,United States,State governments,U.S. state and local documents,Law/Act,2024-07-12,2024,7,positive,0.9555,low,0.0,240,0.5,Enacted,"AN ACT relative to the use of artificial intelligence by state agencies. Be it Enacted by the Senate and House of Representatives in General Court convened: 209:1 New Chapter; Use of Artificial Intelligence by State Agencies. Amend RSA by inserting after chapter 5-C the following new chapter: CHAPTER 5-D USE OF ARTIFICIAL INTELLIGENCE BY STATE AGENCIES 5-D:1 Definitions. In this chapter: I. ""Artificial intelligence"" or ""AI"" is the ability of a machine to display human-like capabilities for cognitive tasks such as reasoning, learning, planning, and creativity. AI systems may adapt their behavior to a certain degree by analyzing the effects of previous actions and operating under varying and unpredictable circumstances without significant human oversight. II. ""Generative AI"" is AI that can generate text, images, or other media in response to prompts. III. ""Deepfake"" means a video, audio, or any other media of a person in which his or her face, body, or voice has been digitally altered so that he or she appears to be someone else, he or she appears to be saying something that he or she has never said, or he or she appears to be doing something that he or she has never done. IV. ""State agency"" means any department, commission, board, institution, bureau, office, law enforcement, or other entity, by whatever name called, including the legislative and judicial branches of state government, established in the state constitution, statutes, session laws or executive orders. 5-D:2 Appl",https://www.gencourt.state.nh.us/bill_Status/pdf.aspx?id=32184&q=billVersion,en,
1434,New Jersey Senate Bill 3432,New Jersey,United States,State governments,U.S. state and local documents,Law/Act,2024-07-25,2024,7,positive,0.9201,low,0.0,235,0.5,Enacted,"An Act concerning the development of artificial intelligence innovations, ventures, and facilities, and amending and supplementing P.L.2020, c.156. Be It Enacted by the Senate and General Assembly of the State of New Jersey: C.34:1B-394 Short title. 1. P.L.2024, c.49 (C.34:1B-394 et al.) shall be known and may be cited as the �Next New Jersey Program Act.� C.34:1B-395 Definitions. 2. As used in P.L.2024, c.49 (C.34:1B-394 et al.): �Affiliate� means an entity that directly or indirectly controls, is under common control with, or is controlled by an eligible business. Control exists in all cases in which the entity is a member of a controlled group of corporations as defined pursuant to section 1563 of the federal Internal Revenue Code (26 U.S.C. s.1563) or the entity is an organization in a group of organizations under common control that is subject to the regulations applicable to organizations pursuant to subsection (b) or (c) of section 414 of the federal Internal Revenue Code (26 U.S.C. s.414). An eligible business may establish by clear and convincing evidence, as determined by the authority, that control exists in situations involving lesser percentages of ownership than required by the above referenced federal statutes if the eligible business shall have control, at a minimum, of all aspects of compliance with this program. An affiliate of an eligible business may contribute towards the capital investment requirement and may satisfy the requirement for site control duri",https://legiscan.com/NJ/text/S3432/2024,en,
1435,New Mexico House Bill 182 of 2024(Campaign Reporting Act),New Mexico,United States,State governments,U.S. state and local documents,Law/Act,2024-03-05,2024,3,positive,0.2063,low,0.0,220,0.5,Enacted,"AN ACT RELATING TO ELECTIONS; AMENDING AND ENACTING SECTIONS OF THE CAMPAIGN REPORTING ACT BY ADDING DISCLAIMER REQUIREMENTS FOR ADVERTISEMENTS CONTAINING MATERIALLY DECEPTIVE MEDIA; CREATING THE CRIME OF DISTRIBUTING OR ENTERING INTO AN AGREEMENT WITH ANOTHER PERSON TO DISTRIBUTE MATERIALLY DECEPTIVE MEDIA; ADDING DEFINITIONS; PROVIDING PENALTIES. BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF NEW MEXICO: SECTION 1. Section 1-19-26 NMSA 1978 (being Laws 1979, Chapter 360, Section 2, as amended) is amended to read: ""1-19-26. DEFINITIONS.--As used in the Campaign Reporting Act: A. ""advertisement"" means a communication referring to a candidate or ballot question that is published, disseminated, distributed or displayed to the public by print, broadcast, satellite, cable or electronic media, including recorded phone messages, or by printed materials, including mailers, handbills, signs and billboards, but ""advertisement"" does not include: (1) a communication by a membership organization or corporation to its current members, stockholders or executive or administrative personnel; (2) a communication appearing in a news story or editorial distributed through a print, broadcast,satellite, cable or electronic medium; (3) a candidate debate or forum or a communication announcing a candidate debate or forum paid for on behalf of the debate or forum sponsor; provided that two or more candidates for the same position have been invited to participate or, in the case of an uncontested e",https://www.nmlegis.gov/Sessions/24%20Regular/final/HB0182.pdf,en,
1437,North Carolina House Bill 591,North Carolina,United States,State governments,U.S. state and local documents,Law/Act,2024-12-01,2024,12,negative,-0.9146,low,0.0,230,0.5,Enacted,"AN ACT TO ESTABLISH SEXUAL EXTORTION OFFENSES, TO UPDATE OFFENSES RELATED TO SEXUAL EXPLOITATION OF A MINOR, TO UPDATE SEX OFFENDER AND PUBLIC PROTECTION REGISTRATION PROGRAMS, AND TO CLARIFY THE OFFENSE OF DISCLOSURE OF PRIVATE IMAGES. The General Assembly of North Carolina enacts: ESTABLISH SEXUAL EXTORTION OFFENSES SECTION 1. Article 26 of Chapter 14 of the General Statutes is amended by adding a new section to read: ""§ 14-202.7. Sexual extortion; aggravated sexual extortion. (a) Definitions. – The following definitions apply in this section: (1) Adult. – A person 18 years or older. (2) Disclose. – To transfer, publish, distribute, or reproduce. (3) Image. – A photograph, film, videotape, recording, live transmission, digital or computer-generated visual depiction, including a realistic visual depiction created, adapted, or modified by technological means, including algorithms or artificial intelligence, such that a reasonable person would believe the image depicts an identifiable individual, or any other reproduction that is created, adapted, or modified by electronic, mechanical, or other means. (4) Immediate family member. – As defined in G.S. 14-43.17. (5) Individual with a disability. – As defined in G.S. 14-32.1. (6) Minor. – A person who has not reached the age of 18 years. (7) Private image. – An image depicting sexual activity or sexually explicit nudity. (8) Sexual activity. – As defined in G.S. 14-190.13. (9) Sexually explicit nudity. – As defined in G.S. 14-190",https://www.ncleg.gov/Sessions/2023/Bills/House/PDF/H591v5.pdf,en,
1439,Oregon House Bill 4153,Oregon,United States,State governments,U.S. state and local documents,Law/Act,2024-03-27,2024,3,positive,0.9231,low,0.0,246,0.5,Enacted,"AN ACT Relating to artificial intelligence; and declaring an emergency. Be It Enacted by the People of the State of Oregon: SECTION 1. (1) The Task Force on Artificial Intelligence is established. (2) The task force consists of 14 members appointed as follows: (a) The President of the Senate shall appoint one member from among members of the Senate. (b) The Speaker of the House of Representatives shall appoint one member from among members of the House of Representatives. (c) The President of the Senate and the Speaker of the House of Representatives shall jointly appoint: (A) Three members who represent business leagues, including trade or professional associations. (B) Two members who represent public universities listed in ORS 352.002. (C) One member who represents local governments. (D) One member who represents consumer advocacy groups. (E) One member who has expertise in ethics and technology. (F) One member who is from the Legislative Fiscal Office. (d) The Chief Justice of the Supreme Court shall appoint one member who is from the Judicial Department. (e) One member shall be the Attorney General or a designee of the Attorney General. (f) One member shall be the State Chief Information Officer or a designee of the State Chief Information Officer. (3) The two members appointed from the Legislative Assembly may not be from the same political party. (4) All voting members of the task force must have expertise in two or more of the following areas: (a) Computer science. (b",https://olis.oregonlegislature.gov/liz/2024R1/Downloads/MeasureDocument/HB4153/Enrolled,en,
1444,South Dakota 2024 Senate Bill 79,South Dakota,United States,State governments,U.S. state and local documents,Law/Act,2024-02-06,2024,2,positive,0.347,low,0.0,221,0.5,Enacted,"An Act ENTITLED An Act to revise provisions related to the possession, distribution, and manufacture of child pornography. Be it enacted by the Legislature of the State of South Dakota: Section 1. That § 22-24A-2 be AMENDED: 22-24A-2. Terms used in §§ 22-19A-1, 22-24A-1 to 22-24A-20, inclusive, 22-24B-1, 23A-27-14.1, and 43-43B-1 to 43-43B-3, inclusive, mean: (1) ""Adult,"" any person eighteen years of age or older; (2) ""Child pornography,"" any image or visual depiction of a minor engaged in prohibited sexual acts; (3) ""Child"" or ""minor,"" any person under the age of eighteen years; (3A) ""Child-like sex doll,"" any obscene anatomical doll, obscene anatomical mannequin, or obscene anatomical robot that is intentionally designed to resemble a prepubescent child and either to entice sexual excitement or to engage in prohibited sexual acts; (4) ""Computer,"" any electronic, magnetic, optical, electrochemical, or other high-speed data processing device performing logical, arithmetic, or storage functions and includes any data storage facility or communications facility directly related to or operating in conjunction with such device, including wireless communication devices such as cellular phones. The term also includes any on-line service, internet service, or internet bulletin board; (5) ""Computer-generated child pornography,"" any visual depiction of: (a) An actual minor that has been created, adapted, or modified to depict that minor engaged in a prohibited sexual act; (b) An actual",https://sdlegislature.gov/Session/Bill/24991/264651,en,
1445,Tennessee House Bill 2325,Tennessee,United States,State governments,U.S. state and local documents,Law/Act,2024-05-29,2024,5,positive,0.9874,low,0.0,218,0.5,Enacted,"BE IT ENACTED BY THE GENERAL ASSEMBLY OF THE STATE OF TENNESSEE: SECTION 1. This act is known and may be cited as the ""Tennessee Artificial Intelligence Advisory Council Act."" SECTION 2. The purpose of the council is to recommend an action plan to guide awareness, education, and usage of artificial intelligence in state government that aligns with the state's policies and goals and that supports public employees in the efficient and effective delivery of customer service. The council shall include definitive actions, policies, and investments needed to leverage artificial intelligence as part of the plan. SECTION 3. As used in this act: (1) ""Advisory council"" means the Tennessee artificial intelligence advisory council; and (2) ""Artificial intelligence"" means models and systems capable of performing functions generally associated with human intelligence, including reasoning and learning. SECTION 4. (a) There is created the Tennessee artificial intelligence advisory council. (b) The advisory council must be composed of twenty-four (24) members, as follows: (1) The commissioner of finance and administration, or the commissioner's designee; (2) The commissioner of the department of human resources, or the commissioner's designee; (3) The commissioner of economic and community development, or the commissioner's designee; (4) The commissioner of labor and workforce development, or the commissioner's designee; (5) The commissioner of education, or the commissioner's designee; (6) T",https://legiscan.com/TN/text/HB2325/2023,en,
1446,Tennessee Senate Bill 1711,Tennessee,United States,State governments,U.S. state and local documents,Law/Act,2024-03-11,2024,3,positive,0.9509,low,0.0,233,0.5,Enacted,"AN ACT to amend Tennessee Code Annotated, Title 49, relative to artificial intelligence. BE IT ENACTED BY THE GENERAL ASSEMBLY OF THE STATE OF TENNESSEE: SECTION 1. Tennessee Code Annotated, Title 49, Chapter 7, Part 1, is amended by adding the following as a new section: (a) As used in this section, ""artificial intelligence"" means a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments and that is capable of using machine and human-based inputs to perceive real and virtual environments, abstract such perceptions into models through analysis in an automated manner, and use model inference to formulate options for information or action. (b) The board of trustees of the University of Tennessee, the board of regents, and each local governing board of trustees of a state university shall adopt a policy regarding the use of artificial intelligence technology by students, faculty, and staff for instructional and assignment purposes. The policy must be implemented no later than July 1, 2025. The Uniform Administrative Procedures Act, compiled in title 4, chapter 5, does not apply to a policy adopted pursuant to this subsection (b ). (c) Public institutions of higher education are encouraged to collaborate in the development and implementation of policies regarding the use of artificial intelligence technology pursuant to subsection (b ). (d) The board of trustees of the Uni",https://publications.tnsosfiles.com/acts/113/pub/pc0550.pdf,en,
1447,Utah House Bill 249 (Utah Legal Personhood Amendments),Utah,United States,State governments,U.S. state and local documents,Law/Act,2024-05-01,2024,5,positive,0.7617,low,0.0,238,0.5,Enacted,"Be it enacted by the Legislature of the state of Utah: Chapter 31. LEGAL PERSONHOOD Section 1, Section 63G-31-101 is enacted to read: 63G-31-101. Definitions. As used in this chapter: (1) ""Body of water"" means any natural or man-made accumulation of water, regardless of whether the accumulation of water is static or subject to a force that causes a hydrological current. (2) ""Governmental entity"" means: (a) a court; (b) the Legislature; (c) the legislative body of a political subdivision; or (d) another entity of the state or a political subdivision, if the entity has adjudicatory or rulemaking authority. (3) ""Human being"" means a member of the species classified as Homo sapiens; (4) ""Land"" means the solid terrestrial surface or subsurface of the earth. (5) ""Legal personhood"" means: (a) the legal rights and obligations of an individual under the laws of this state; or (b) the legal rights and obligations of a person other than an individual under the laws of this state. (6) ""Political subdivision"" means the same as that term is defined in Section 63G-7-102. (7) ""Real property"" means any building, fixture, improvement, appurtenance, structure, or other development that is affixed permanently to land. (8) ""State"" means the same as that term is defined in Section 63G-7-102. Section 2, Section 63G-31-102 is enacted to read: 63G-31-102. Legal personhood restricted. Notwithstanding any other provision of law, a governmental entity may not grant legal personhood to, nor recognize leg",https://le.utah.gov/~2024/bills/static/HB0249.html,en,
1454,Virginia Senate Bill 487,Virginia,United States,State governments,U.S. state and local documents,Law/Act,2024-04-08,2024,4,positive,0.9732,low,0.0,231,0.5,Enacted,"Be it enacted by the General Assembly of Virginia: 1. § 1. That the Joint Commission on Technology and Science (JCOTS) shall, in consultation with relevant stakeholders, conduct an analysis of the use of artificial intelligence by public bodies in the Commonwealth and the creation of a Commission on Artificial Intelligence. The analysis shall include an examination of proper policies and procedures regarding artificial intelligence systems to (i) govern the procurement, implementation, and ongoing assessment of any such system by a public body; (ii) ensure that no such system results in any unlawful discrimination or unlawful disparate impact against any individual or group of individuals; and (iii) require a public body to assess the likely impact of using any such system and perform ongoing assessments to ensure that the use of any such system does not result in any such unlawful discrimination or disparate impact. The analysis shall also include an assessment of creating a Commission on Artificial Intelligence to advise the General Assembly on issues related to artificial intelligence, the proper composition of such a commission, and the proper duties of the commission in accordance with the provisions of clauses (i), (ii), and (iii). JCOTS shall submit a report of its findings and recommendations to the Chairmen of the House Committees on Appropriations and Communications, Technology and Innovation and the Senate Committees on Finance and Appropriations and General Laws a",https://legacylis.virginia.gov/cgi-bin/legp604.exe?241+ful+CHAP0678+pdf,en,
1459,West Virginia HB 5690 (Artificial Intelligence Task Force),West Virginia,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-06-02,2024,6,positive,0.91,low,0.0,245,0.5,Enacted,"AN ACT to amend the Code of West Virginia, 1931, as amended, by adding thereto a new section, designated §5A-6-9, related to creating a ""West Virginia Task Force on Artificial Intelligence”; setting forth the membership of the same; providing for appointment of members; delineating responsibilities of the task force; providing it complete a report and specifying contents of same; and providing a date for termination of the task force. Be it enacted by the Legislature of West Virginia: ARTICLE 6. Office of Technology. §5A-6-9. West Virginia Task Force on Artificial Intelligence. (a) As used in this Section, ""Task Force"" means the West Virginia Task Force on Artificial Intelligence established by this section. (b) The West Virginia Task Force on Artificial Intelligence is created and shall be organized within the Office of the Governor. (c) The Task Force shall be composed of the following members: (1) One ex officio, non-voting member from the House of Delegates, appointed by the Speaker of the House of Delegates. (2) One ex officio, non-voting member from the State Senate, appointed by the President of the Senate. (3) The Chief Information Officer of the Office of Technology or his or her designee. (4) The State Superintendent of Schools or his or her designee. (5) The Chancellor of the West Virginia Higher Education Policy Commission or his or her designee. (6) The Attorney General or his or her designee. (7) The Secretary of the Department of Administration or his or her de",https://www.wvlegislature.gov/bill_status/bills_text.cfm?billdoc=hb5690%20enr.htm&yr=2024&sesstype=RS&i=5690,en,
1460,Wisconsin Act 2023-123 (Artificial Intelligence Content Disclosure),Wisconsin,United States,State governments,U.S. state and local documents,Law/Act,2024-03-21,2024,3,positive,0.9127,low,0.0,227,0.5,Enacted,"An Act to amend 11.1303 (title); and to create 11.1303 (2m) of the statutes; relating to: disclosures regarding content generated by artificial intelligence in political advertisements, granting rule-making authority, and providing a penalty. The people of the state of Wisconsin, represented in senate and assembly, do enact as follows: Section 1. 11.1303 (title) of the statutes is amended to read: 11.1303 (title) Attribution of political contributions, disbursements and communications; synthetic media. Section 2. 11.1303 (2m) of the statutes is created to read: 11.1303 (2m) (a) In this subsection: 1. “Issue advocacy” means a communication that provides information about political or social issues and is made to influence the outcome of an election. 2. “Synthetic media” means audio or video content that is substantially produced in whole or in part by means of generative artificial intelligence. (b) Every audio communication otherwise described in sub. (2) (a) or (b) but containing express advocacy or issue advocacy or supporting or opposing a referendum and that contains synthetic media shall include both at the beginning and at the end of the communication the words “Contains content generated by AI.” (c) Every video communication otherwise described in sub. (2) (a) or (b) but containing express advocacy or issue advocacy or supporting or opposing a referendum shall include throughout the duration of each portion of the communication containing synthetic media, in writing th",https://docs.legis.wisconsin.gov/2023/related/acts/123,en,
1464,Connecticut Substitute Senate Bill 1103,Connecticut,United States,State governments,U.S. state and local documents,Law/Act,2023-06-07,2023,6,positive,0.9679,low,0.0,224,0.5,Enacted,"Substitute Senate Bill No. 1103 Public Act No. 23-16 AN ACT CONCERNING ARTIFICIAL INTELLIGENCE, AUTOMATED DECISION-MAKING AND PERSONAL DATA PRIVACY. Be it enacted by the Senate and House of Representatives in General Assembly convened: Section 1. (NEW) (Effective July 1, 2023) (a) For the purposes of this section: (1) ""Artificial intelligence"" means (A) an artificial system that (i) performs tasks under varying and unpredictable circumstances without significant human oversight or can learn from experience and improve such performance when exposed to data sets, (ii) is developed in any context, including, but not limited to, software or physical hardware, and solves tasks requiring human-like perception, cognition, planning, learning, communication or physical action, or (iii) is designed to (I) think or act like a human, including, but not limited to, a cognitive architecture or neural network, or (II) act rationally, including, but not limited to, an intelligent software agent or embodied robot that achieves goals using perception, planning, reasoning, learning, communication, decision-making or action, or (B) a set of techniques, including, but not limited to, machine learning, that is designed to approximate a cognitive task; and (2) ""State agency"" has the same meaning as provided in section 4d-1 of the general statutes. (b) (1) Not later than December 31, 2023, and annually thereafter, the Department of Administrative Services shall conduct an inventory of all systems th",https://www.cga.ct.gov/2023/ACT/PA/PDF/2023PA-00016-R00SB-01103-PA.PDF,en,
1468,Maryland House Bill 622,Maryland,United States,State governments,U.S. state and local documents,Law/Act,2023-05-08,2023,5,positive,0.9863,low,0.0,217,0.5,Enacted,"(House Bill 622) AN ACT concerning Economic Development – Industry 4.0 Technology Grant Program FOR the purpose of establishing the Industry 4.0 Technology Grant Program in the Department of Commerce to provide grants to certain small and medium–sized manufacturing enterprises to assist those manufacturers with implementing new Industry 4.0 technology or related infrastructure for certain purposes; establishing the Industry 4.0 Technology Grant Fund as a special, nonlapsing fund; requiring the Governor to include in the annual budget bill a certain appropriation to the Fund in certain fiscal years; and generally relating to the Industry 4.0 Technology Grant Program for manufacturers. BY adding to Article – Economic Development Section 5–2301 through 5–2304 to be under the new subtitle “Subtitle 23. Industry 4.0 Technology Grant Program” Annotated Code of Maryland (2018 Replacement Volume and 2022 Supplement) SECTION 1. BE IT ENACTED BY THE GENERAL ASSEMBLY OF MARYLAND, That the Laws of Maryland read as follows: Article – Economic Development SUBTITLE 23. INDUSTRY 4.0 TECHNOLOGY GRANT PROGRAM. 5–2301. (A) IN THIS SUBTITLE THE FOLLOWING WORDS HAVE THE MEANINGS INDICATED. (B) “FUND” MEANS THE INDUSTRY 4.0 TECHNOLOGY GRANT FUND. (C) (1) “INDUSTRY 4.0 TECHNOLOGY” MEANS SMART HARDWARE AND SOFTWARE MANUFACTURING TECHNOLOGIES. (2) “INDUSTRY 4.0 TECHNOLOGY” INCLUDES: (I) ADVANCED SENSOR INTEGRATION; (II) EMBEDDED SOFTWARE SYSTEM APPLICATIONS; (III) ROBOTICS AND AUTONOMOUS EQUIPMENT TH",https://mgaleg.maryland.gov/2023RS/Chapters_noln/CH_498_hb0622t.pdf,en,
1470,Michigan HB 5143,Michigan,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2023-11-30,2023,11,positive,0.9022,low,0.0,223,0.5,Enacted,"AN ACT to amend 1976 PA 388, entitled “An act to regulate political activity; to regulate campaign financing; to restrict campaign contributions and expenditures; to require campaign statements and reports; to regulate anonymous contributions; to regulate campaign advertising and literature; to provide for segregated funds for political purposes; to provide for the use of public funds for political purposes; to create certain funds; to provide for reversion, retention, or refunding of unexpended balances in certain funds; to require other statements and reports; to regulate acceptance of certain gifts, payments, and reimbursements; to prescribe the powers and duties of certain state departments and state and local officials and employees; to provide appropriations; to prescribe penalties and provide remedies; and to repeal certain acts and parts of acts,” by amending section 2 (MCL 169.202), as amended by 2001 PA 250. The People of the State of Michigan enact: Sec. 2. (1) “Artificial intelligence” means a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments, and that uses machine and human-based inputs to do all of the following: (a) Perceive real and virtual environments. (b) Abstract such perceptions into models through analysis in an automated manner. (c) Use model inference to formulate options for information or action. (2) “Award” means a plaque, trophy, certi",https://legislature.mi.gov/documents/2023-2024/publicact/htm/2023-PA-0264.htm,en,
1481,West Virginia House Bill 3214,West Virginia,United States,State governments,U.S. state and local documents,Law/Act,2023-06-08,2023,6,positive,0.9537,low,0.0,234,0.5,Enacted,"A BILL to amend the Code of West Virginia, 1931, as amended, by adding thereto a new section, designated §17-2A-25, relating to creation of the ""Road Optimization and Assessment Data Road Pilot Program""; legislative findings and purpose; Commissioner of Highways to promulgate rules; and specifics to be contained in rules to determine how best to maintain roads and highways. Be it enacted by the Legislature of West Virginia: ARTICLE 2A. WEST VIRGINIA COMMISSIONER OF HIGHWAYS. §17-2A-25. Road optimization and assessment data road pilot program; legislative findings and purposes. (a) The Legislature hereby finds and declares that: (1) Properly maintained roads and highways are important to the economic and industrial growth and development and well-being of the state and to the health, education, welfare, and prosperity of its citizens; (2) Roads and highways of the state that are not well maintained because of potholes, patching, cracking, road shoulder issues, canopy brush, and drainage issues, do not contribute to the health, education, welfare, and prosperity of its citizens of this state; (3) Data has been collected from the West Virginia Division of Highways containing an overall assessment and evaluation of the issues stated in subdivision of this section; (4) The purpose of this section is to create a pilot program to study alternative methods of assessing the conditions of the roads and highways and methods of financing road and highway maintenance with respect to the i",https://www.wvlegislature.gov/Bill_Status/bills_text.cfm?billdoc=hb3214%20intr.htm&yr=2023&sesstype=RS&i=3214,en,
1484,Arizona 2024 House Bill 2394,Arizona,United States,State governments,U.S. state and local documents,Law/Act,2024-05-21,2024,5,positive,0.7755,low,0.0,248,0.5,Enacted,"AN ACT AMENDING TITLE 16, CHAPTER 7, ARTICLE 1, ARIZONA REVISED STATUTES, BY ADDING SECTION 16-1023; RELATING TO PROHIBITED ACTS. BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF ARIZONA: SECTION 1. TITLE 16, CHAPTER 7, ARTICLE 1, ARIZONA REVISED STATUTES, IS AMENDED BY ADDING SECTION 16-1023, TO READ: 16-1023. DIGITAL IMPERSONATION OF CANDIDATE OR OTHER PERSON; RELIEF; APPLICABILITY; DEFINITIONS A. A CANDIDATE FOR PUBLIC OFFICE OR POLITICAL PARTY OFFICE WHO WILL APPEAR ON THE BALLOT IN THIS STATE OR ANY CITIZEN OF THIS STATE MAY BRING AN ACTION FOR DIGITAL IMPERSONATION WITHIN TWO YEARS AFTER THE DATE THAT THE PERSON KNOWS, OR IN THE EXERCISE OF REASONABLE DILIGENCE SHOULD KNOW, THAT A DIGITAL IMPERSONATION OF THE PERSON WHO IS BRINGING THE ACTION WAS PUBLISHED. THE SOLE REMEDY ON THIS CAUSE OF ACTION IS PRELIMINARY AND PERMANENT DECLARATORY RELIEF EXCEPT AS OTHERWISE EXPRESSLY PROVIDED BY THIS SECTION. TO PREVAIL ON AN ACTION PRESCRIBED BY THIS SECTION, A PLAINTIFF MUST PROVE ALL OF THE FOLLOWING: 1. THAT A DIGITAL IMPERSONATION OF THE PERSON WAS PUBLISHED TO ONE OR MORE OTHER PERSONS WITHOUT THE PERSON'S CONSENT. 2. THAT AT THE TIME OF PUBLICATION EITHER OF THE FOLLOWING APPLIES: (a) THE PUBLISHER DID NOT REASONABLY CONVEY TO THE PERSONS TO WHOM THE PUBLICATION WAS MADE THAT THE RECORDING OR IMAGE WAS A DIGITAL IMPERSONATION OR THAT ITS AUTHENTICITY WAS DISPUTED. (b) IT WOULD NOT BE OBVIOUS TO A REASONABLE PERSON THAT THE RECORDING OR IMAGE WAS A DIGITAL IMPERSONATION. B.",https://www.azleg.gov/legtext/56leg/2R/laws/0193.htm,en,
1485,Arizona 2024 Senate Bill 1359,Arizona,United States,State governments,U.S. state and local documents,Law/Act,2024-05-29,2024,5,negative,-0.443,low,0.0,236,0.5,Enacted,"An Act AMENDING TITLE 16, CHAPTER 7, ARTICLE 1, ARIZONA REVISED STATUTES, BY ADDING SECTION 16-1023; RELATING TO ELECTION COMMUNICATIONS. Be it enacted by the Legislature of the State of Arizona: Section 1. Title 16, chapter 7, article 1, Arizona Revised Statutes, is amended by adding section 16-1023, to read: 16-1023. Deepfakes; candidates; political parties; exemptions; violation; classification; definitions A. Within ninety days before an election at which a candidate for elected office will appear on the ballot, a person who acts as a creator shall not create and distribute a synthetic media message that the person knows is a deceptive and fraudulent deepfake of that candidate that is on that ballot unless the synthetic media message includes a clear and conspicuous disclosure that conveys to a reasonable person that the media includes content generated by artificial intelligence. B. This section does not apply to: 1. Media that constitutes satire or parody. 2. An interactive computer service as defined in 47 United States Code section 230. C. A person who fails to make the disclosure required under this section is liable for the civil penalty prescribed by section 16-937, subsection B, for each day that they distribute the deceptive and fraudulent deepfake without such disclosure. D. For the purposes of this section: 1. ""Creator"": (a) means any person that uses artificial intelligence or other digital technology to generate synthetic media. (b) does not include the provi",https://www.azleg.gov/legtext/56leg/2R/laws/0199.htm,en,
1496,Florida Senate Bill 1680,Florida,United States,State governments,U.S. state and local documents,Law/Act,2024-04-26,2024,4,positive,0.7964,low,0.0,204,0.5,Enacted,"An act relating to advanced technology; creating s. 282.802, F.S.; creating the Government Technology Modernization Council within the Department of Management Services for a specified purpose; providing for council membership, meetings, and duties; requiring the council to submit specified recommendations to the Legislature and specified reports to the Governor and the Legislature by specified dates; creating s. 827.072, F.S.; defining terms; prohibiting a person from knowingly possessing or controlling or intentionally viewing photographs, motion pictures, representations, images, data files, computer depictions, or other presentations which the person knows to include generated child pornography; providing criminal penalties; prohibiting a person from intentionally creating generated child pornography; providing criminal penalties; providing applicability; amending s. 92.561, F.S.; prohibiting the reproduction of generated child pornography; providing an effective date. Be It Enacted by the Legislature of the State of Florida: Section 1. Section 282.802, Florida Statutes, is created to read: 282.802 Government Technology Modernization Council.— (1) The Government Technology Modernization Council, an advisory council as defined in s. 20.03(7), is created within the department. Except as otherwise provided in this section, the advisory council shall operate in a manner consistent with s. 20.052. (2) The purpose of the council is to study and monitor the development and deplo",https://flsenate.gov/Session/Bill/2024/1680/BillText/er/HTML,en,
1497,Hawaii Senate Bill 2687,Hawaii,United States,State governments,U.S. state and local documents,Law/Act,2024-07-03,2024,7,negative,-0.11,low,0.0,222,0.5,Enacted,"A BILL FOR AN ACT RELATING TO ELECTIONS. BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF HAWAII: SECTION 1. The legislature finds that although artificial intelligence (AI) technology can greatly benefit certain aspects of society, it can also have dangerous consequences if applied maliciously. For example, the use of deepfakes or generative AI in elections can be a powerful tool used to spread disinformation and misinformation, which can increase political tensions and result in electoral-related conflict and violence. Several states, including Michigan, Minnesota, and Washington, have enacted legislation governing the use of AI in elections. The legislature believes that regulating the use of deepfake and generative AI technologies to influence elections is necessary to protect the democratic process in the State. Accordingly, the purpose of this Act is to: (1) Prohibit a person from recklessly distributing, or entering into an agreement with another person to distribute, materially deceptive media with exceptions; (2) Establish criminal penalties for distributing materially deceptive media; and (3) Establish remedies for parties injured by the distribution of materially deceptive media. SECTION 2. Chapter 11, Hawaii Revised Statutes, is amended by adding two new sections to part XIII to be appropriately designated and to read as follows: ""§11-A Distribution of materially deceptive media; prohibited; penalties. (a) Except as provided in subsections (b) and (c), no person s",https://www.capitol.hawaii.gov/sessions/session2024/bills/SB2687_CD1_.HTM,en,
1499,Idaho House Bill 575,Idaho,United States,State governments,U.S. state and local documents,Law/Act,2024-07-01,2024,7,negative,-0.9819,low,0.1667,236,0.7,Enacted,"AN ACT RELATING TO DISCLOSING EXPLICIT SYNTHETIC MEDIA; AMENDING CHAPTER 66, TITLE 18, IDAHO CODE, BY THE ADDITION OF A NEW SECTION 18-6606, IDAHO CODE, TO PROVIDE FOR THE CRIME OF DISCLOSING EXPLICIT SYNTHETIC MEDIA, TO PROVIDE PENALTIES, TO DEFINE TERMS, TO PROVIDE EXEMPTIONS, AND TO PROVIDE SEVERABILITY; AND DECLARING AN EMERGENCY AND PROVIDING AN EFFECTIVE DATE. Be It Enacted by the Legislature of the State of Idaho: SECTION 1. That Chapter 66, Title 18, Idaho Code, be, and the same is hereby amended by the addition thereto of a NEW SECTION, to be known and designated as Section 18-6606, Idaho Code, and to read as follows: 18-6606. DISCLOSING EXPLICIT SYNTHETIC MEDIA. (1) A person is guilty of disclosing explicit synthetic media when the person knowingly: (a) Discloses explicit synthetic media and knows or reasonably should know that: (i) An identifiable person portrayed in whole or in part in the explicit synthetic media did not consent to such disclosure; and (ii) Disclosure of the explicit synthetic media would cause the identifiable person substantial emotional distress; (b) Discloses explicit synthetic media with the intent to annoy, terrify, threaten, intimidate, harass, offend, humiliate, or degrade an identifiable person portrayed in whole or in part in the explicit syn23 thetic media; or (c) Possesses and threatens to disclose explicit synthetic media with the intent to obtain money or other valuable consideration from an identifiable person portrayed in whole or",https://legislature.idaho.gov/wp-content/uploads/sessioninfo/2024/legislation/H0575.pdf,en,"Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content, Harms: Financial loss, Incentives: Criminal liability, Incentives: Imprisonment, Strategies: Disclosure"
1500,Idaho House Bill 664 (Freedom From AI-Rigged Elections Act),Idaho,United States,State governments,U.S. state and local documents,Law/Act,2024-03-25,2024,3,positive,0.9643,low,0.0,233,0.5,Enacted,"AN ACT RELATING TO THE FREEDOM FROM AI-RIGGED (FAIR) ELECTIONS ACT; AMENDING CHAP3 TER 66, TITLE 67, IDAHO CODE, BY THE ADDITION OF A NEW SECTION 67-6628A, IDAHO CODE, TO PROVIDE A SHORT TITLE, TO DEFINE TERMS, TO PROVIDE FOR RELIEF PROHIBITING THE PUBLICATION OF SYNTHETIC MEDIA IN ELECTIONEERING COMMUNICATIONS, TO ESTABLISH PROVISIONS REGARDING AN ACTION PROHIBITING THE PUBLICATION OF SYNTHETIC MEDIA IN ELECTIONEERING COMMUNICATIONS, AND TO PROVIDE EXCEPTIONS; PROVIDING SEVERABILITY; AND DECLARING AN EMERGENCY. Be It Enacted by the Legislature of the State of Idaho: SECTION 1. That Chapter 66, Title 67, Idaho Code, be, and the same is hereby amended by the addition thereto of a NEW SECTION, to be known and designated as Section 67-6628A, Idaho Code, and to read as follows: 67-6628A. ELECTIONEERING COMMUNICATIONS -- USE OF SYNTHETIC MEDIA. (1) This section shall be known and may be cited as the ""Freedom From AI-Rigged (FAIR) Elections Act."" (2) For purposes of this section: (a) ""Information content provider"" means any person or entity that is responsible, in whole or in part, for the creation or development of information provided through the internet or any other interactive computer service. (b) ""Interactive computer service"" means any information service, system, or access software provider that provides or enables computer access by multiple users to a computer server, including specifically a service or system that provides access to the internet and such systems operate",https://legislature.idaho.gov/wp-content/uploads/sessioninfo/2024/legislation/H0664.pdf,en,
1501,Illinois House Bill 2123,Illinois,United States,State governments,U.S. state and local documents,Law/Act,2023-07-28,2023,7,negative,-0.9246,low,0.0,234,0.5,Enacted,"AN ACT concerning civil law. Be it enacted by the People of the State of Illinois, represented in the General Assembly: Section 5. The Civil Remedies for Nonconsensual Dissemination of Private Sexual Images Act is amended by changing Sections 5, 10, 15, and 25 as follows: (740 ILCS 190/5) Sec. 5. Definitions. As used in this Act: (1) ""Child"" means an unemancipated individual who is less than 18 years of age. (2) ""Consent"" means affirmative, conscious, and voluntary authorization by an individual with legal capacity to give authorization. (3) ""Depicted individual"" means an individual whose body is shown, in whole or in part, in a private sexual image. (4) ""Dissemination"" or ""disseminate"" means publication or distribution to another person with intent to disclose. (5) ""Harm"" means physical harm, economic harm, or emotional distress whether or not accompanied by physical or economic harm. (6) ""Identifiable"" means recognizable by a person other than the depicted individual: (A) from a private sexual image itself; or (B) from a private sexual image and identifying characteristic displayed in connection with the image. (7) ""Identifying characteristic"" means information that may be used to identify a depicted individual. (8) ""Individual"" means a human being. (9) ""Parent"" means an individual recognized as a parent under laws of this State. (10) ""Private"" means: (A) created or obtained under circumstances in which a depicted individual had a reasonable expectation of privacy; or (B) m",https://www.ilga.gov/legislation/publicacts/fulltext.asp?Name=103-0294,en,
1504,Illinois House Bill 4875,Illinois,United States,State governments,U.S. state and local documents,Law/Act,2024-08-09,2024,8,positive,0.9509,low,0.0,226,0.5,Enacted,"AN ACT concerning civil law. Be it enacted by the People of the State of Illinois, represented in the General Assembly: Section 5. The Right of Publicity Act is amended by changing Sections 5, 20, 30, and 35 as follows: (765 ILCS 1075/5) Sec. 5. Definitions. As used in this Act: ""Artificial intelligence"" means a machine-based system that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments. ""Artificial intelligence"" includes generative artificial intelligence. ""Commercial purpose"" means the public use or holding out of an individual's identity (i) on or in connection with the offering for sale or sale of a product, merchandise, goods, or services; (ii) for purposes of advertising or promoting products, merchandise, goods, or services; or (iii) for the purpose of fundraising. ""Application software provider"" means a person providing a digital distribution service for other software applications and that allows users to search for and download such applications. ""Cloud service provider"" means a cloud service provider as defined by 6 U.S.C. 650. ""Digital replica"" means a newly created, electronic representation of the voice, image, or likeness of an actual individual created using a computer, algorithm, software, tool, artificial intelligence, or other technology that is fixed in a sound recording or audiovisual work in which",https://www.ilga.gov/legislation/publicacts/fulltext.asp?Name=103-0836,en,
1505,Illinois Senate Bill 382,Illinois,United States,State governments,U.S. state and local documents,Law/Act,2023-12-08,2023,12,negative,-0.9246,low,0.0,234,0.5,Enacted,"AN ACT concerning civil law. Be it enacted by the People of the State of Illinois, represented in the General Assembly: Section 5. The Civil Remedies for Nonconsensual Dissemination of Private Sexual Images Act is amended by changing Sections 5 and 15 as follows: (740 ILCS 190/5) (Text of Section before amendment by P.A. 103-294) Sec. 5. Definitions. As used in this Act: (1) ""Child"" means an unemancipated individual who is less than 18 years of age. (2) ""Consent"" means affirmative, conscious, and voluntary authorization by an individual with legal capacity to give authorization. (3) ""Depicted individual"" means an individual whose body is shown, in whole or in part, in a private sexual image. (4) ""Dissemination"" or ""disseminate"" means publication or distribution to another person with intent to disclose. (5) ""Harm"" means physical harm, economic harm, or emotional distress whether or not accompanied by physical or economic harm. (6) ""Identifiable"" means recognizable by a person other than the depicted individual: (A) from a private sexual image itself; or (B) from a private sexual image and identifying characteristic displayed in connection with the image. (7) ""Identifying characteristic"" means information that may be used to identify a depicted individual. (8) ""Individual"" means a human being. (9) ""Parent"" means an individual recognized as a parent under laws of this State. (10) ""Private"" means: (A) created or obtained under circumstances in which a depicted individual had a r",https://www.ilga.gov/legislation/publicacts/fulltext.asp?Name=103-0571,en,
1507,Indiana 2024 House Bill 1133,Indiana,United States,State governments,U.S. state and local documents,Law/Act,2024-03-12,2024,3,positive,0.7378,low,0.0,248,0.5,Enacted,"AN ACT to amend the Indiana Code concerning elections. Be it enacted by the General Assembly of the State of Indiana: SECTION 1. IC 3-9-8 IS ADDED TO THE INDIANA CODE AS A NEW CHAPTER TO READ AS FOLLOWS [EFFECTIVE UPON PASSAGE]: Chapter 8. Use of Digitally Altered Media in Elections Sec. 1. (a) As used in this chapter, ""campaign communication"" means a communication, regardless of the format of the communication or the medium through which the communication is disseminated: (1) that advocates for the election or defeat of a clearly identified candidate; (2) the purpose of which is to: (A) injure a candidate in an election; or (B) influence the outcome of an election; or (3) that solicits a contribution. (b) For purposes of subsection (a)(1), a candidate is clearly identified if any of the following apply: (1) The communication includes one (1) or more of the following: (A) The name of the candidate. (B) A video, photograph, or drawing of the candidate. (C) Fabricated media depicting the candidate. (2) The identity of the candidate is apparent by unambiguous reference. Sec. 2.(a)For purposes of this chapter,subject to subsection(b), ""candidate"" has the meaning set forth in IC 3-5-2-6. (b) For purposes of this chapter, ""candidate"" includes an individual who holds an elected office, including: (1) a federal or state office, including a federal or state legislative office; (2) a school board office; or (3) a local office. Sec. 3. As used in this chapter, ""fabricated media"" means a",https://iga.in.gov/pdf-documents/123/2024/house/bills/HB1133/HB1133.06.ENRS.pdf,en,
1508,"Iowa S 2243 (Sexual Exploitation of Minors, Use of Falsely Created Images)",Iowa,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-04-10,2024,4,negative,-0.9762,low,0.0,233,0.5,Enacted,"AN ACT RELATING TO SEXUAL EXPLOITATION OF A MINOR BY THE CREATION, ADAPTATION, OR MODIFICATION OF A VISUAL DEPICTION TO GIVE THE APPEARANCE THAT AN IDENTIFIABLE MINOR IS ENGAGED IN A PROHIBITED SEXUAL ACT OR THE SIMULATION OF A PROHIBITED SEXUAL ACT, AND MAKING PENALTIES APPLICABLE, BE IT ENACTED BY THE GENERAL ASSEMBLY OF THE STATE OF IOWA: Section 1. Section 728.12, subsection 3, Code 2024, is amended to read as follows: 3. a. It shall be unlawful to knowingly purchase or possess a visual depiction of a minor engaging in a prohibited sexual act or the simulation of a prohibited sexual act. b. A visual depiction containing pictorial representations of different minors shall be prosecuted and punished as separate offenses for each pictorial representation of a different minor in the visual depiction. However, violations of this subsection involving multiple visual depictions of the same minor shall be prosecuted and punished as one offense. c. A person who commits a violation of this subsection commits a class “D"" felony for a first offense and a class “C"" felony for a second or subsequent offense. d. For purposes of this subsection, an offense is considered a second or subsequent offense if, prior to the person's having been convicted under this subsection, the person has a prior conviction or deferred judgment under this subsection or has a prior conviction or deferred judgment in another jurisdiction",https://www.legis.iowa.gov/legislation/BillBook?ba=SF2243&ga=90,en,
1510,Louisiana Senate Bill 6,Louisiana,United States,State governments,U.S. state and local documents,Law/Act,2024-08-01,2024,8,positive,0.7216,low,0.0,246,0.5,Enacted,"AN ACT To enact R.S. 14:73.14, relative to computer related crime; to create the crime of unlawful dissemination or sale of images of another created by artificial intelligence; to provide definitions; to provide penalties; and to provide for related matters. Be it enacted by the Legislature of Louisiana: Section 1. R.S. 14:73.14 is hereby enacted to read as follows: §73.14. Unlawful dissemination or sale of images of another created by artificial intelligence A. It shall be unlawful for any person, with the intent to coerce, harass, intimidate, or maliciously disseminate or sell any video or still image created by artificial intelligence that depicts another person who is totally nude or in a state of undress so as to expose the genitals, pubic area, buttocks, or female breast, when the person disseminating the video or still image knows or has reason to know that he is not licensed or authorized to disseminate or sell such video or still image. B. The provisions of this Section shall not apply to an interactive computer service, electronic mail service provider, or a provider of a telecommunications service or any information service as defined in 47 U.S.C.153, system, or access software provider that provides or enables computer access by multiple users to a computer server that was used by a person to commit any act prohibited by Subsection A of this Section. C. For purposes of this Section: (1) ""Another person"" includes a person whose image was used in creating, adapting",https://legis.la.gov/legis/ViewDocument.aspx?d=1379408,en,
1513,Michigan House Bill 5141,Michigan,United States,State governments,U.S. state and local documents,Law/Act,2023-11-30,2023,11,positive,0.9081,low,0.0,233,0.5,Enacted,"AN ACT to amend 1976 PA 388, entitled “An act to regulate political activity; to regulate campaign financing; to restrict campaign contributions and expenditures; to require campaign statements and reports; to regulate anonymous contributions; to regulate campaign advertising and literature; to provide for segregated funds for political purposes; to provide for the use of public funds for political purposes; to create certain funds; to provide for reversion, retention, or refunding of unexpended balances in certain funds; to require other statements and reports; to regulate acceptance of certain gifts, payments, and reimbursements; to prescribe the powers and duties of certain state departments and state and local officials and employees; to provide appropriations; to prescribe penalties and provide remedies; and to repeal certain acts and parts of acts,” by amending section 47 (MCL 169.247), as amended by 2015 PA 269, and by adding section 59 The People of the State of Michigan enact: Sec. 47. (1) Except as otherwise provided in this subsection and subject to subsections (3) and (4), a billboard, placard, poster, pamphlet, or other printed matter having reference to an election, a candidate, or a ballot question, must display an identification that contains the name and address of the person paying for the matter. Except as otherwise provided in this subsection and subsection (5) and subject to subsections (3) and (4), if the printed matter relating to a candidate is an inde",https://www.legislature.mi.gov/documents/2023-2024/publicact/htm/2023-PA-0263.htm,en,
1515,Michigan House Bill 5144 of 2023 (Election Law),Michigan,United States,State governments,U.S. state and local documents,Law/Act,2023-12-01,2023,12,negative,-0.3612,low,0.0,241,0.5,Enacted,"AN ACT to amend 1954 PA 116, entitled “An act to reorganize, consolidate, and add to the election laws; to provide for election officials and prescribe their powers and duties; to prescribe the powers and duties of certain state departments, state agencies, and state and local officials and employees; to provide for the nomination and election of candidates for public office; to provide for the resignation, removal, and recall of certain public officers; to provide for the filling of vacancies in public office; to provide for and regulate primaries and elections; to provide for the purity of elections; to guard against the abuse of the elective franchise; to define violations of this act; to provide appropriations; to prescribe penalties and provide remedies; and to repeal certain acts and all other acts inconsistent with this act,” (MCL 168.1 to 168.992) by adding section 932f. The People of the State of Michigan enact: Sec. 932f. (1) Except as otherwise provided in subsection (2), a person shall not distribute, or enter into an agreement with another person to distribute, materially deceptive media if all of the following apply: (a) The person knows the media falsely represents a depicted individual. (b) The distribution occurs within 90 days before an election. (c) The person intends the distribution to harm the reputation or electoral prospects of a candidate in an election, and the distribution is reasonably likely to cause that result. (d) The person intends the distrib",https://www.legislature.mi.gov/documents/2023-2024/publicact/htm/2023-PA-0265.htm,en,
1517,Minnesota HF 1370 (Deepfake Accountability and Public Safety),Minnesota,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2023-05-26,2023,5,negative,-0.97,low,0.0,229,0.5,Enacted,"A bill for an act relating to public safety; establishing a cause of action for nonconsensual dissemination of deep fake sexual images; establishing the crime of using deep fake technology to influence an election; establishing a crime for nonconsensual dissemination of deep fake sexual images; proposing coding for new law in Minnesota Statutes, chapters 604; 609; 617. BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF MINNESOTA: Section 1. [604.32] CAUSE OF ACTION FOR NONCONSENSUAL DISSEMINATION OF A DEEP FAKE DEPICTING INTIMATE PARTS OR SEXUAL ACTS. Subdivision 1. Definitions. (a) As used in this section, the following terms have the meanings given. (b) ""Deep fake"" means any video recording, motion-picture film, sound recording, electronic image, or photograph, or any technological representation of speech or conduct substantially derivative thereof: (1) that is so realistic that a reasonable person would believe it depicts speech or conduct of an individual; and (2) the production of which was substantially dependent upon technical means, rather than the ability of another individual to physically or verbally impersonate such individual. (c) ""Depicted individual"" means an individual in a deep fake who appears to be engaging in speech or conduct in which the individual did not engage. (d) ""Intimate parts"" means the genitals, pubic area, partially or fully exposed nipple, or anus of an individual. (e) ""Personal information"" means any identifier that permits communication or in",https://www.revisor.mn.gov/bills/text.php?number=HF1370&type=bill&version=3&session=ls93&session_year=2023&session_number=0,en,
1519,Mississippi Senate Bill 2577,Mississippi,United States,State governments,U.S. state and local documents,Law/Act,2024-04-30,2024,4,positive,0.8125,low,0.0,227,0.5,Enacted,"AN ACT TO CREATE A NEW SECTION IN TITLE 97, CHAPTER 13, MISSISSIPPI CODE OF 1972, TO CREATE CRIMINAL PENALTIES FOR THE WRONGFUL DISSEMINATION OF DIGITIZATIONS; AND FOR RELATED PURPOSES. BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF MISSISSIPPI: SECTION 1. (1) For the purposes of this section: (a) ""Candidate"" means an individual who seeks a nomination or election to a federal, statewide, state district, legislative, judicial, county, county district or municipal office. (b) ""Digitization"" means to alter an image or audio in a realistic manner utilizing an image or audio of a person, other than the person depicted, computer-generated images or audio, commonly called deepfakes. ""Digitization"" also includes the creation of an image or audio through the use of software, machine learning artificial intelligence or any other computer-generated or technological means. This includes any digital representation of speech or conduct that: (i) A reasonable person would believe depicts the speech and/or conduct of an individual who did not engage in the speech and/or conduct as presented; and (ii) The production of which was substantially dependent on technical means, rather than the ability of another individual to physically or verbally impersonate an individual. (c) ""Depicted individual"" means an individual in a digitization who appears to be engaging in speech and/or conduct. (d) ""Disseminates"" means transmitting a digitization to another person through social media, electronic mail",https://billstatus.ls.state.ms.us/documents/2024/html/SB/2500-2599/SB2577SG.htm,en,
1521,New Hampshire House Bill 1596,New Hampshire,United States,State governments,U.S. state and local documents,Law/Act,2024-08-02,2024,8,positive,0.8277,low,0.0,241,0.5,Enacted,"AN ACT requiring a disclosure of deceptive artificial intelligence usage in political advertising. Be it Enacted by the Senate and House of Representatives in General Court convened: 345:1 New Section; Synthetic Media and Deceptive and Fraudulent Deep Fakes. Amend RSA 664 by inserting after section 14-b the following new section: 664:14-c Synthetic Media and Deceptive and Fraudulent Deepfakes. I. In this section: (a) ""Synthetic media"" means an image, an audio recording, or a video recording of an individual's appearance, speech, or conduct that has been created or intentionally manipulated with the use of generative adversarial network techniques or other digital technology in a manner to create a realistic but false image, audio, or video. (b) ""Artificial intelligence"" or ""AI"" is the ability of a machine to display human-like capabilities for cognitive tasks such as reasoning, learning, planning, and creativity. AI systems may adapt their behavior to a certain degree by analyzing the effects of previous actions and operating under varying and unpredictable circumstances without significant human oversight. (c) ""Generative AI"" is AI that can generate text, images, or other media in response to prompts. (d) ""Deepfake"" means a video, audio, or any other media of a person in which his or her face, body, or voice has been digitally altered so that he or she appears to be someone else, he or she appears to be saying something that he or she has never said, or he or she appears to",https://www.gencourt.state.nh.us/bill_status/billinfo.aspx?id=1392&inflect=2,en,
1525,New York Senate Bill 1042,New York,United States,State governments,U.S. state and local documents,Law/Act,2023-09-29,2023,9,positive,0.1205,low,0.0,249,0.5,Enacted,"AN ACT to amend the penal law, in relation to unlawful dissemination or publication of intimate images created by digitization and of sexually explicit depictions of an individual; and to repeal certain provisions of such law relating thereto THE PEOPLE OF THE STATE OF NEW YORK, REPRESENTED IN SENATE AND ASSEMBLY, DO ENACT AS FOLLOWS: Section 1. Subdivisions 1 and 2 of section 245.15 of the penal law, as added by chapter 109 of the laws of 2019, are amended to read as follows: 1. A person is guilty of unlawful dissemination or publication of an intimate image when: (a) with intent to cause harm to the emotional, financial or physical welfare of another person, they intentionally disseminate or publish a still or video image depicting such other person with one or more intimate parts exposed or engaging in sexual conduct with another person, including an image created or altered by digitization, where such person may reasonably be identified from the still or video image itself or from information displayed in connection with the still or video image; and (b) The actor knew or reasonably should have known that the person depicted did not consent to such dissemination or publication, including the dissemination or publication of an image taken with the consent of the person depicted when such person had a reasonable expectation that the image would remain private, regardless of whether the actor was present when such image was taken. 2. For purposes of this section the followin",https://www.nysenate.gov/legislation/bills/2023/S1042/amendment/A,en,
1526,New York Senate Bill 9678,New York,United States,State governments,U.S. state and local documents,Law/Act,2024-06-28,2024,6,positive,0.4749,low,0.0,260,0.5,Enacted,"AN ACT to amend the election law, in relation to materially deceptive media in political communications THE PEOPLE OF THE STATE OF NEW YORK, REPRESENTED IN SENATE AND ASSEMBLY, DO ENACT AS FOLLOWS: Section 1. Paragraph (b) of subdivision 5 of section 14-106 of the election law, as added by section 1 of subpart B of part MM of chapter 58 of the laws of 2024, is amended and a new subdivision 7 is added to read as follows: (b) (i) A person, firm, association, corporation, campaign, committee, or organization that distributes or publishes any political communication that was produced by or includes materially deceptive media and has actual knowledge that it is materially deceptive shall be required to disclose this use. (ii) (1) For visual media the disclosure shall be printed or typed in a legible font size easily readable by the average viewer that is no smaller than other text appearing in the visual media and in the same language used on the communication to read as follows: ""This (image, video, or audio) has been manipulated"". (2) For communication that is auditory, such as radio or automated telephone calls, clearly speaking the statement at the beginning of the audio, at the end of the audio, and, if the audio is greater than two minutes in length, interspersed within the audio at intervals of not greater than two minutes each and in the same language as the rest of the audio used in the communication, and in a pitch that can be easily heard by the average listener satisfi",https://www.nysenate.gov/legislation/bills/2023/S9678/amendment/B,en,
1527,Oklahoma H 3642,Oklahoma,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-11-01,2024,11,negative,-0.8824,low,0.0,240,0.5,Enacted,"BE IT ENACTED BY THE PEOPLE OF THE STATE OF OKLAHOMA: SECTION 1. AMENDATORY 21 O.S. 2021, Section 1021.2, is amended to read as follows: Section 1021.2 A. Any person who shall procure or cause the participation of any minor under the age of eighteen (18) years in any child pornography or obscene material or who knowingly possesses, views, accesses, shares, streams, downloads, procures, sells, distributes, or manufactures, or causes to be possessed, viewed, accessed, shared, streamed, downloaded, procured, sold or, distributed, or manufactured any child pornography shall be guilty, upon conviction, be guilty of a felony and shall be punished by imprisonment in the custody of the Department of Corrections for not more than twenty (20) years and by the imposition of a fine of not more than Twenty-five Thousand Dollars ($25,000.00). Persons convicted under this section shall not be eligible for a deferred sentence. Except for persons sentenced to life or life without parole, any person sentenced to imprisonment for two (2) years or more for a violation of this subsection shall be required to serve a term of post-imprisonment supervision pursuant to subparagraph f of paragraph 1 of subsection A of Section 991a of Title 22 of the Oklahoma Statutes under conditions determined by the Department of Corrections. The jury shall be advised that the mandatory post-imprisonment supervision shall be in addition to the actual imprisonment. B. The consent of the minor, or of the mother, fathe",http://webserver1.lsb.state.ok.us/cf_pdf/2023-24%20ENR/hB/HB3642%20ENR.PDF,en,
1528,Oregon Senate Bill 1571,Oregon,United States,State governments,U.S. state and local documents,Law/Act,2024-03-27,2024,3,positive,0.2382,low,0.0,230,0.5,Enacted,"AN ACT Relating to the use of artificial intelligence in campaign communications; creating new provisions; amending ORS 260.345; and declaring an emergency. Be It Enacted by the People of the State of Oregon: SECTION 1. (1) As used in this section: (a)(A) “Campaign communication” means a communication in support of or in opposition to a clearly identified candidate or measure, as defined in ORS 260.005 (10)(c). (B) Notwithstanding ORS 260.005 (10)(c)(B)(i), a campaign communication may involve aggregate expenditures of any amount. (b) “Synthetic media” means an image, audio recording or video recording of an individual’s appearance, speech or conduct that has been intentionally manipulated with the use of artificial intelligence techniques or similar digital technology in a manner to create a realistic but false image, audio recording or video recording that produces: (A) A depiction that a reasonable person would believe is of a real individual in appearance, speech or conduct but that did not actually occur in reality; and (B) A materially different understanding or impression than a reasonable person would have from the unaltered, original version of the image, audio recording or video recording. (2) A campaign communication that includes any form of synthetic media must include a disclosure stating that the image, audio recording or video recording has been manipulated. (3) The Secretary of State may institute proceedings to enjoin any violation of this section. The Attor",https://olis.oregonlegislature.gov/liz/2024r1/Downloads/MeasureDocument/SB1571/Enrolled,en,
1531,Tennessee House Bill 2163 (Sexual Exploitation of Children),Tennessee,United States,State governments,U.S. state and local documents,Law/Act,2024-05-13,2024,5,positive,0.9733,low,0.0,215,0.5,Enacted,"AN ACT to amend Tennessee Code Annotated, Title 39 and Title 40, relative to the sexual exploitation of children. BE IT ENACTED BY THE GENERAL ASSEMBLY OF THE STATE OF TENNESSEE: SECTION 1. Tennessee Code Annotated, Section 39-17-1002, is amended by deleting subdivision (2)(E) and substituting: (E) Any computer image, or computer-generated image, including an image created, adapted, or modified by artificial intelligence, whether made or produced by electronic, mechanical, or other means; SECTION 2. Tennessee Code Annotated, Section 39-17-1002, is amended by adding the following new subdivisions: ( ) ""Artificial intelligence"": (A) Means a machine-based system that: (i) Can, for a given set of human-defined objectives, make predictions, recommendations, or decisions; influence real and virtual environments without significant human oversight; or that can learn from experience in an automated manner and improve such performance when exposed to data sets; or (ii) Is developed in any context, including software or physical hardware, and solves tasks requiring human-like perception, cognition, planning, learning, communication, or physical action; and (B) Includes generative artificial intelligence; ( ) ""Generative artificial intelligence"" means an artificial intelligence system that is capable of creating new content or data, including text, images, audio, or video, when prompted by an individual; SECTION 3. This act takes effect July 1, 2024, the public welfare requiring it.",https://www.capitol.tn.gov/Bills/113/Bill/HB2163.pdf,en,
1532,Utah House Bill 148,Utah,United States,State governments,U.S. state and local documents,Law/Act,2024-03-13,2024,3,positive,0.2732,low,0.0,223,0.5,Enacted,"Be it enacted by the Legislature of the state of Utah: Section 1, Section 76-5b-103 is amended to read: 76-5b-103. Definitions. As used in this chapter: (1)""Child sexual abuse material"" means any visual depiction, including any live performance, photograph, film, video, picture, or computer or computer-generated image or , picture, or video, whether made or produced by electronic, mechanical, or other means, of sexually explicit conduct, where: (a)the production of the visual depiction involves the use of a minor engaging in sexually explicit conduct; (b)the visual depiction is of a minor engaging in sexually explicit conduct; or (c)the visual depiction has been created, adapted, or modified to appear that an identifiable minor is engaging in sexually explicit conduct. (2)""Distribute"" means the selling, exhibiting, displaying, wholesaling, retailing, providing, giving, granting admission to, or otherwise transferring or presenting child sexual abuse material or vulnerable adult sexual abuse material with or without consideration , with or without consideration, to sell, exhibit, display, provide, give, grant admission to, provide access to, or otherwise transfer . (3)""Identifiable minor"" means a person an individual: (a) (i)who was a minor at the time the visual depiction was created, adapted, or modified; or (ii)whose image as a minor was used in creating, adapting, or modifying the visual depiction; and (b)who is recognizable as an actual person individual by the person's i",https://le.utah.gov/~2024/bills/static/HB0148.html,en,
1535,Utah Senate Bill 131 Information Technology Act Amendments (2024),Utah,United States,State governments,U.S. state and local documents,Law/Act,2024-07-01,2024,7,positive,0.9829,low,0.0,217,0.5,Enacted,"Be it enacted by the Legislature of the state of Utah: Section 1, Section 20A-11-1104 is enacted to read: 20A-11-1104 (Effective 05/01/24). Disclosure of synthetic media. (1) As used in this section: (a) ""Artificial intelligence"" means a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments. (b) (i) ""Creator"" means a person that uses artificial intelligence to generate synthetic media. (ii) ""Creator"" does not include a person that solely provides the technology used in the creation of the synthetic media. (c) ""Digital content provenance"" means purely factual information that: (i) details a digital resource's creator, origin, context, history, and editing process; and (ii) conforms to an open industry technical standard. (d) ""Generative artificial intelligence"" means artificial intelligence technology that is capable of creating content such as text, audio, image, or video based on patterns learned from large volumes of data rather than being explicitly programmed with rules. (e) ""Sponsor"" means a person that pays for the content that uses artificial intelligence to generate synthetic media. (f) ""Synthetic audio media"" means audio content that was substantially produced by generative artificial intelligence. (g) ""Synthetic visual media"" means an image or video that was substantially produced by generative artificial intelligence. (2) This section applies to an audio o",https://le.utah.gov/~2024/bills/static/SB0131.html,en,
1536,Virginia 2024 SB 731,Virginia,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-03-28,2024,3,positive,0.2732,low,0.0,249,0.5,Enacted,"Be it enacted by the General Assembly of Virginia: 1. That § 18.2-374.1 of the Code of Virginia is amended and reenacted as follows: § 18.2-374.1. Production, publication, sale, financing, etc., of child pornography; presumption as to age. A. For purposes of this article and Article 4 (§ 18.2-362 et seq.) of this chapter, ""child pornography"" means sexually explicit visual material that (i) utilizes or has as a subject an identifiable minor or (ii) depicts a minor in a state of nudity or engaged in sexual conduct, as those terms are defined in § 18.2-390, where such depiction is obscene as defined in § 18.2-372. An identifiable minor is a person who was a minor at the time the visual depiction was created, adapted, or modified; or whose image as a minor was used in creating, adapting or modifying the visual depiction; and who is recognizable as an actual person by the person's face, likeness, or other distinguishing characteristic, such as a unique birthmark or other recognizable feature; and shall not be construed to require proof of the actual identity of the identifiable minor. For the purposes of clause (ii), the minor depicted does not have to actually exist. For the purposes of this article and Article 4 (§ 18.2-362 et seq.) of this chapter, the term ""sexually explicit visual material"" means a picture, photograph, drawing, sculpture, motion picture film, digital image, including such material stored in a computer's temporary Internet cache when three or more images or st",https://legacylis.virginia.gov/cgi-bin/legp604.exe?241+ful+CHAP0262,en,
1537,Washington House Bill 1999,Washington,United States,State governments,U.S. state and local documents,Law/Act,2024-03-14,2024,3,positive,0.1528,low,0.0,223,0.5,Enacted,"AN ACT Relating to fabricated intimate or sexually explicit images and depictions; amending RCW 9.68A.011, 9.68A.055, 9.68A.110, 9.68A.170, 9.68A.180, 9.68A.190, 9A.86.010, 9A.86.020, 7.110.010, 7.110.020, 7.110.030, 7.110.050, and 7.110.060; adding a new section to chapter 9A.86 RCW; adding a new section to chapter 7.110 RCW; and prescribing penalties. BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF WASHINGTON: Sec. 1. RCW 9.68A.011 and 2010 c 227 s 3 are each amended to read as follows: Unless the context clearly indicates otherwise, the definitions in this section apply throughout this chapter. (1) An ""internet session"" means a period of time during which an internet user, using a specific internet protocol address, visits or is logged into an internet site for an uninterrupted period of time. (2) To ""photograph"" means to make a print, negative, slide, digital image, motion picture, or videotape. A ""photograph"" means anything tangible or intangible produced by photographing. (3) ""Visual or printed matter"" means any photograph or other material that contains a reproduction of a photograph. ""Visual or printed matter"" includes, but is not limited to, any such photograph or other material that constitutes a fabricated depiction of an identifiable minor. (4) ""Sexually explicit conduct"" means actual or simulated: (a) Sexual intercourse, including genital-genital, oral-genital, anal-genital, or oral-anal, whether between persons of the same or opposite sex or between humans and",https://lawfilesext.leg.wa.gov/biennium/2023-24/Pdf/Bills/House%20Passed%20Legislature/1999-S.PL.pdf?q=20241212151122,en,
1538,Washington Senate Bill 5152,Washington,United States,State governments,U.S. state and local documents,Law/Act,2023-07-23,2023,7,positive,0.8847,low,0.0,236,0.5,Enacted,"AN ACT Relating to defining synthetic media in campaigns for elective office, and providing relief for candidates and campaigns; and adding a new chapter to Title 42 RCW.3 BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF WASHINGTON: NEW SECTION. Sec. 1. The definitions used in chapter 42.17A RCW apply throughout this chapter unless the context clearly requires otherwise. NEW SECTION. Sec. 2. (1) For purposes of this section ""synthetic media"" means an image, an audio recording, or a video recording of an individual's appearance, speech, or conduct that has been intentionally manipulated with the use of generative adversarial network techniques or other digital technology in a manner to create a realistic but false image, audio, or video that produces: (a) A depiction that to a reasonable individual is of a real individual in appearance, action, or speech that did not actually occur in reality; and (b) A fundamentally different understanding or impression of the appearance, action, or speech than a reasonable person would have from the unaltered, original version of the image, audio recording, or video recording. (2) A candidate whose appearance, action, or speech is altered through the use of a synthetic media in an electioneering communication may seek injunctive or other equitable relief prohibiting the publication of such synthetic media. (3) A candidate whose appearance, action, or speech is altered through the use of a synthetic media in an electioneering communication ma",https://lawfilesext.leg.wa.gov/biennium/2023-24/Pdf/Bills/Session%20Laws/Senate/5152-S.SL.pdf?q=20241202194404,en,
1539,Washington Senate Bill 5838 (2024),Washington,United States,State governments,U.S. state and local documents,Law/Act,2024-03-18,2024,3,positive,0.4404,low,0.0,223,0.5,Enacted,"BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF WASHINGTON: [introductory comments omitted] NEW SECTION. Sec. 2. (1) Subject to the availability of amounts appropriated for this specific purpose, a task force to assess current uses and trends and make recommendations to the legislature regarding guidelines and potential legislation for the use of artificial intelligence systems is established. (2) The task force is composed of an executive committee consisting of members as provided in this subsection. (a) The president of the senate shall appoint one member from each of the two largest caucuses of the senate. (b) The speaker of the house of representatives shall appoint one member from each of the two largest caucuses of the house of representatives. (c) The attorney general shall appoint the following members, selecting only individuals with experience in technology policy: (i) One member from the office of the governor; (ii) One member from the office of the attorney general; (iii) One member from Washington technology solutions; (iv) One member from the Washington state auditor; (v) One member representing universities or research institutions that are experts in the design and effect of an algorithmic system; (vi) One member representing private technology industry groups; (vii) One member representing business associations; (viii) Three members representing community advocate organizations that represent communities that are disproportionately vulnerable to being harme",https://lawfilesext.leg.wa.gov/biennium/2023-24/Pdf/Bills/Senate%20Passed%20Legislature/5838-S2.PL.pdf?q=20241117144809,en,
1543,California Assembly Bill 1831 (2024),California,United States,State governments,U.S. state and local documents,Law/Act,2024-09-29,2024,9,negative,-0.9806,low,0.1111,224,0.7,Enacted,"The people of the State of California do enact as follows: SECTION 1. The Legislature finds and declares all of the following: (a) The sexual abuse of children is a most serious crime and an act repugnant to the moral instincts of decent people. Therefore, the prevention of sexual exploitation and abuse of children constitutes a government objective of paramount importance. California has a compelling interest in protecting the physical and psychological well-being of children and in eliminating the market for images of child sexual exploitation. (b) Child sexual assault material (CSAM) is a visual depiction of the sexual abuse and exploitation of children. Its creation, distribution, and possession perpetuates the sexual exploitation of children and places children in danger of exploitation. Research has shown a correlation between the consumption of CSAM and an increased risk of individuals engaging in hands-on sexual offenses against minors. This is similar to research on the impact of legal pornography, which has concluded that pornography may increase sexually aggressive thoughts and behaviors. (c) The possession of CSAM normalizes and validates the sexual exploitation of children and contributes to new victimization. Some offenders use CSAM to groom children into believing that sex with adults is appropriate. Moreover, for some higher risk offenders, viewing CSAM leads to escalating behavior, including physical sexual assault of children. Moreover, exchange of CSAM over",https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240AB1831,en,"Harms: Detrimental content, Harms: Violation of civil or human rights, including privacy, Applications: Government: judicial and law enforcement, Incentives: Criminal liability, Incentives: Fines, Incentives: Imprisonment"
1544,California AB 1836,California,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-09-17,2024,9,negative,-0.8001,low,0.1111,248,0.7,Enacted,"The people of the State of California do enact as follows: SECTION 1. It is the intent of the Legislature to enact legislation to ensure that all intellectual property is sufficiently protected from exploitation. SEC. 2. Section 3344.1 of the Civil Code is amended to read: 3344.1. (a) (1) (A) Subject to subparagraph (B), a person who uses a deceased personality’s name, voice, signature, photograph, or likeness, in any manner, on or in products, merchandise, or goods, or for purposes of advertising or selling, or soliciting purchases of, products, merchandise, goods, or services, without prior consent from the person or persons specified in subdivision (c), shall be liable for any damages sustained by the person or persons injured as a result thereof. In addition, in any action brought under this section, the person who violated the section shall be liable to the injured party or parties in an amount equal to the greater of seven hundred fifty dollars ($750) or the actual damages suffered by the injured party or parties, as a result of the unauthorized use, and any profits from the unauthorized use that are attributable to the use and are not taken into account in computing the actual damages. In establishing these profits, the injured party or parties shall be required to present proof only of the gross revenue attributable to the use, and the person who violated the section shall prove the person’s deductible expenses. Punitive damages may also be awarded to the injured part",https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240AB1836,en,"Applications: Arts, sports, leisure, travel, and lifestyle, Incentives: Civil liability, Harms: Detrimental content, Harms: Violation of civil or human rights, including privacy"
1545,California Assembly Bill 2013 (2024),California,United States,State governments,U.S. state and local documents,Law/Act,2024-09-28,2024,9,positive,0.9081,low,0.2222,221,0.7,Enacted,"The people of the State of California do enact as follows: SECTION 1. Title 15.2 (commencing with Section 3110) is added to Part 4 of Division 3 of the Civil Code, to read: TITLE 15.2. Artificial Intelligence Training Data Transparency 3110. For purposes of this title, the following definitions shall apply: (a) “Artificial intelligence” means an engineered or machine-based system that varies in its level of autonomy and that can, for explicit or implicit objectives, infer from the input it receives how to generate outputs that can influence physical or virtual environments. (b) “Developer” means a person, partnership, state or local government agency, or corporation that designs, codes, produces, or substantially modifies an artificial intelligence system or service for use by members of the public. For purposes of this subdivision, “members of the public” does not include an affiliate as defined in subparagraph (A) of paragraph (1) of subdivision (c) of Section 1799.1a, or a hospital’s medical staff member. (c) “Generative artificial intelligence” means artificial intelligence that can generate derived synthetic content, such as text, images, video, and audio, that emulates the structure and characteristics of the artificial intelligence’s training data. (d) “Substantially modifies” or “substantial modification” means a new version, new release, or other update to a generative artificial intelligence system or service that materially changes its functionality or performance,",https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240AB2013,en,"Strategies: Evaluation, Risk factors: Privacy, Risk factors: Transparency, Risk factors: Security: Dissemination, Risk factors: Security, Strategies: Disclosure, Strategies: Disclosure: About inputs, Strategies: Disclosure: In standard form, Applications: Government: military and public safety, Applications: Transportation"
1549,California AB 2839 (2024),California,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-09-17,2024,9,positive,0.128,low,0.1667,250,0.7,Enacted,"The people of the State of California do enact as follows: SECTION 1. Section 35 of the Code of Civil Procedure, as amended by Section 1 of Chapter 343 of the Statutes of 2023, is amended to read: 35. (a) Proceedings in cases involving the registration or denial of registration of voters, the certification or denial of certification of candidates, the certification or denial of certification of ballot measures, election contests, actions under Section 20010 or 20012 of the Elections Code, and actions under Chapter 2 (commencing with Section 21100) of Division 21 of the Elections Code shall be placed on the calendar in the order of their date of filing and shall be given precedence. (b) This section shall remain in effect only until January 1, 2027, and as of that date is repealed, unless a later enacted statute, that is enacted before January 1, 2027, deletes or extends that date. SEC. 1.5. Section 35 of the Code of Civil Procedure, as amended by Section 1 of Chapter 343 of the Statutes of 2023, is amended to read: 35. (a) Proceedings in cases involving the registration or denial of registration of voters, the certification or denial of certification of candidates, the certification or denial of certification of ballot measures, election contests, actions under Section 20010 or 20012 of the Elections Code, actions under Chapter 7 (commencing with Section 20510) of Division 20 of the Elections Code, and actions under Chapter 2 (commencing with Section 21100) of Division 21 of",https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240AB2839,en,"Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content, Strategies: Disclosure: In deployment, Strategies: Disclosure, Applications: Government: judicial and law enforcement, Applications: Government: other applications/unspecified, Applications: Broadcasting and media production, Risk factors: Transparency, Incentives: Civil liability, Applications: Networking and telecommunications"
1550,California Assembly Bill 2876 (2024),California,United States,State governments,U.S. state and local documents,Law/Act,2024-09-30,2024,9,positive,0.9638,low,0.0,210,0.7,Enacted,"THE PEOPLE OF THE STATE OF CALIFORNIA DO ENACT AS FOLLOWS: SECTION 1. Section 33548 of the Education Code is amended to read: 33548. (a) For purposes of this section, the following definitions apply: (1) “Artificial Intelligence (AI) literacy” means the knowledge, skills, and attitudes associated with how artificial intelligence works, including its principles, concepts, and applications, as well as how to use artificial intelligence, including its limitations, implications, and ethical considerations. (2) “Digital citizenship” means a diverse set of skills related to current technology and social media, including the norms of appropriate, responsible, and healthy behavior. (3) “Media literacy” means the ability to access, evaluate, analyze, and use media and information and encompasses the foundational skills that lead to digital citizenship. (b) When the English language arts/English language development (ELA/ELD) curriculum framework is next revised after January 1, 2024, the commission shall consider incorporating the Model Library Standards developed pursuant to Section 18101. The commission shall also consider incorporating media literacy content at each grade level. (c) (1) The commission shall consider incorporating media literacy content into the mathematics, science, and history-social science curriculum frameworks when those frameworks are next revised after January 1, 2024. (2) When ELA/ELD instructional materials are next adopted by the state board after January",https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240AB2876,en,"Applications: Education, Strategies: Governance development"
1551,California AB 2885 (2024),California,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-09-28,2024,9,positive,0.1653,medium,0.3889,231,0.7,Enacted,"The people of the State of California do enact as follows: SECTION 1. Section 22675 of the Business and Professions Code is amended to read: 22675. For purposes of this chapter, the following definitions apply: (a) “Actioned” means a social media company, due to a suspected or confirmed violation of the terms of service, has taken some form of action, including, but not limited to, removal, demonetization, deprioritization, or banning, against the relevant user or relevant item of content. (b) “Artificial intelligence” has the same definition as in Section 11546.45.5 of the Government Code. (c) (1) “Content” means statements or comments made by users and media that are created, posted, shared, or otherwise interacted with by users on an internet-based service or application. (2) “Content” does not include media put on a service or application exclusively for the purpose of cloud storage, transmitting files, or file collaboration. (d) “Public or semipublic internet-based service or application” excludes a service or application used to facilitate communication within a business or enterprise among employees or affiliates of the business or enterprise, provided that access to the service or application is restricted to employees or affiliates of the business or enterprise using the service or application. (e) “Social media company” means a person or entity that owns or operates one or more social media platforms. (f) “Social media platform” means a public or semipublic internet",https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240AB2885,en,"Applications: Broadcasting and media production, Applications: Networking and telecommunications, Risk factors: Bias, Risk factors: Privacy, Risk factors: Security: Cybersecurity, Risk factors: Security, Risk factors: Reliability, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Post-market monitoring, Strategies: Government study or report, Applications: Government: other applications/unspecified, Strategies: Governance development, Harms: Detrimental content, Risk factors: Transparency"
1552,California Assembly Bill 3030 (2024),California,United States,State governments,U.S. state and local documents,Law/Act,2024-09-28,2024,9,positive,0.9709,low,0.0556,213,0.7,Enacted,"The people of the State of California do enact as follows: SECTION 1. Chapter 2.13 (commencing with Section 1339.75) is added to Division 2 of the Health and Safety Code, to read: CHAPTER 2.13. Artificial Intelligence in Health Care Services 1339.75. (a) A health facility, clinic, physician’s office, or office of a group practice that uses generative artificial intelligence to generate written or verbal patient communications pertaining to patient clinical information shall ensure that those communications include both of the following: (1) A disclaimer that indicates to the patient that the communication was generated by generative artificial intelligence. (A) For written communications involving physical and digital media, including letters, emails, and other occasional messages, the disclaimer shall appear prominently at the beginning of each communication. (B) For written communications involving continuous online interactions, including chat-based telehealth, the disclaimer shall be prominently displayed throughout the interaction. (C) For audio communications, the disclaimer shall be provided verbally at the start and the end of the interaction. (D) For video communications, the disclaimer shall be prominently displayed throughout the interaction. (2) Clear instructions describing how a patient may contact a human health care provider, employee of the health facility, clinic, physician’s office, or office of a group provider, or other appropriate person. (b) If a commun",https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240AB3030,en,"Risk factors: Transparency, Strategies: Disclosure, Strategies: Disclosure: In standard form, Applications: Medicine, life sciences and public health"
1553,California Senate Bill 1120 (2024),California,United States,State governments,U.S. state and local documents,Law/Act,2024-09-30,2024,9,positive,0.9756,medium,0.5,225,0.7,Enacted,"THE PEOPLE OF THE STATE OF CALIFORNIA DO ENACT AS FOLLOWS: SECTION 1. Section 1367.01 of the Health and Safety Code is amended to read: 1367.01. (a) A health care service plan and any entity with which it contracts for services that include utilization review or utilization management functions, that prospectively, retrospectively, or concurrently reviews and approves, modifies, delays, or denies, based in whole or in part on medical necessity, requests by providers prior to, retrospectively, or concurrent with the provision of health care services to enrollees, or that delegates these functions to medical groups or independent practice associations or to other contracting providers, shall comply with this section. (b) A health care service plan that is subject to this section shall have written policies and procedures establishing the process by which the plan prospectively, retrospectively, or concurrently reviews and approves, modifies, delays, or denies, based in whole or in part on medical necessity, requests by providers of health care services for plan enrollees. These policies and procedures shall ensure that decisions based on the medical necessity of proposed health care services are consistent with criteria or guidelines that are supported by clinical principles and processes. These criteria and guidelines shall be developed pursuant to Section 1363.5. These policies and procedures, and a description of the process by which the plan reviews and approves, modifies,",https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1120,en,"Strategies: Evaluation, Strategies: Evaluation: Post-market monitoring, Strategies: Evaluation: Impact assessment, Risk factors: Bias, Risk factors: Reliability, Risk factors: Interpretability and explainability, Risk factors: Privacy, Risk factors: Safety, Harms: Harm to health/safety, Harms: Violation of civil or human rights, including privacy, Applications: Medicine, life sciences and public health, Risk factors: Transparency, Strategies: Disclosure, Strategies: Disclosure: In deployment, Applications: Government: benefits and welfare"
1554,California Senate Bill 1288 (2024),California,United States,State governments,U.S. state and local documents,Law/Act,2024-09-30,2024,9,positive,0.9796,medium,0.5,228,0.7,Enacted,"An act to add and repeal Section 33328.5 of the Education Code, relating to public schools. [ Approved by Governor September 28, 2024. Filed with Secretary of State September 28, 2024. ] LEGISLATIVE COUNSEL'S DIGEST SB 1288, Becker. Public schools: artificial intelligence working group. Existing law requires the Superintendent of Public Instruction to establish procedures within the State Department of Education to, among other things, annually identify the critical needs for which effective educational programs and practices are to be identified, developed, and disseminated to public schools. This bill would require the Superintendent to convene a working group, composed as provided, for specific purposes related to artificial intelligence in public schools, as specified. The bill would require, among other things, the working group to develop, on or before January 1, 2026, guidance for school districts, county offices of education, and charter schools on the safe use of artificial intelligence in education, and to, on or before July 1, 2026, develop a model policy for those local educational agencies regarding the safe and effective use of artificial intelligence in ways that benefit, and do not negatively impact, pupils and educators, as provided. The bill would require the working group to, on or before January 1, 2027, report its findings and recommendations to the appropriate policy and fiscal committees of the Legislature, as provided. The bill would dissolve the worki",https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1288,en,"Applications: Education, Risk factors: Safety, Strategies: Convening, Strategies: Governance development, Strategies: New institution, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Harms: Financial loss, Strategies: Licensing, registration, and certification, Risk factors: Bias, Risk factors: Privacy, Risk factors: Security, Risk factors: Security: Dissemination, Risk factors: Transparency, Harms: Violation of civil or human rights, including privacy"
1555,California Senate Bill 1381 (2024),California,United States,State governments,U.S. state and local documents,Law/Act,2024-09-30,2024,9,positive,0.6369,low,0.1111,237,0.7,Enacted,"An act to amend Sections 311.1, 311.3, 311.4 and, 312.3 of the Penal Code, relating to crimes. [ Approved by Governor September 29, 2024. Filed with Secretary of State September 29, 2024. ] LEGISLATIVE COUNSEL'S DIGEST SB 1381, Wahab. Crimes: child pornography. Existing law prohibits the production, development, duplication, distribution, or possession, as specified, of matter, in specified formats, that depicts a person under 18 years of age engaging in or simulating sexual conduct, as defined. Existing law separately prohibits this conduct where it is done for consideration or where such matter is shared with a minor. Existing law also prohibits the employment or use of a minor, or the permitting by a parent or guardian of the employment or use of a minor for the production of such matter. Existing law authorizes the forfeiture and destruction of such matter regardless of whether a conviction is sought or obtained. This bill would expand the scope of certain of these provisions to include matter that is digitally altered or generated by the use of artificial intelligence, as such matter is defined. By expanding the scope of an existing crime, this bill would impose a state-mandated local program. The California Constitution requires the state to reimburse local agencies and school districts for certain costs mandated by the state. Statutory provisions establish procedures for making that reimbursement. This bill would provide that no reimbursement is required by this act fo",https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1381,en,"Risk factors: Safety, Harms: Detrimental content, Incentives: Fines, Incentives: Imprisonment, Incentives: Criminal liability, Strategies: Disclosure"
1558,California Senate Bill 942 (2024),California,United States,State governments,U.S. state and local documents,Law/Act,2024-09-20,2024,9,positive,0.9011,low,0.1111,226,0.7,Enacted,"The people of the State of California do enact as follows: SECTION 1. Chapter 25 (commencing with Section 22757) is added to Division 8 of the Business and Professions Code, to read: CHAPTER 25. AI Transparency Act 22757. This chapter shall be known as the California AI Transparency Act. 22757.1. As used in this chapter: (a) “Artificial intelligence” or “AI” means an engineered or machine-based system that varies in its level of autonomy and that can, for explicit or implicit objectives, infer from the input it receives how to generate outputs that can influence physical or virtual environments. (b) “Covered provider” means a person that creates, codes, or otherwise produces a generative artificial intelligence system that has over 1,000,000 monthly visitors or users and is publicly accessible within the geographic boundaries of the state. (c) “Generative artificial intelligence system” or “GenAI system” means an artificial intelligence that can generate derived synthetic content, including text, images, video, and audio, that emulates the structure and characteristics of the system’s training data. (d) “Latent” means present but not manifest. (e) “Manifest” means easily perceived, understood, or recognized by a natural person. (f) “Metadata” means structural or descriptive information about data. (g) “Personal information” has the same meaning as defined in Section 1798.140 of the Civil Code. (h) “Personal provenance data” means provenance data that contains either of the fo",https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB942,en,"Risk factors: Privacy, Strategies: Disclosure, Strategies: Input controls, Strategies: Input controls: Data use, Applications: Broadcasting and media production, Risk factors: Transparency, Strategies: Disclosure: In deployment, Strategies: Disclosure: Accuracy thereof, Strategies: Licensing, registration, and certification, Incentives: Fines, Incentives: Civil liability, Strategies: Tiering: Tiering based on domain of application, Strategies: Tiering"
1560,California Assembly Bill 2905 (2024),California,United States,State governments,U.S. state and local documents,Law/Act,2024-09-23,2024,9,positive,0.6908,low,0.0556,239,0.7,Enacted,"THE PEOPLE OF THE STATE OF CALIFORNIA DO ENACT AS FOLLOWS: SECTION 1. Section 2874 of the Public Utilities Code is amended to read: 2874. (a) Whenever telephone calls are placed through the use of an automatic dialing-announcing device, the device may be operated only after an unrecorded, natural voice announcement has been made to the person called by the person calling. The announcement shall do all of the following: (1) State the nature of the call and the name, address, and telephone number of the business or organization being represented, if any. (2) Inquire as to whether the person called consents to hear the prerecorded message of the person calling. (3) Inform the person called if the prerecorded message uses an artificial voice. (b) The person calling, as described in subdivision (a), shall disconnect the automatic dialing-announcing device from the telephone line upon the termination of the call by either the person calling or the person called. (c) For purposes of this section, both of the following definitions apply: (1) “Artificial intelligence” means an engineered or machine-based system that varies in its level of autonomy and that can, for explicit or implicit objectives, infer from the input it receives how to generate outputs that can influence physical or virtual environments. (2) “Artificial voice” means a voice that is generated or significantly altered using artificial intelligence. SEC. 2. No reimbursement is required by this act pursuant to Section 6",https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240AB2905,en,"Risk factors: Transparency, Strategies: Disclosure, Strategies: Disclosure: In deployment, Applications: Networking and telecommunications"
1562,California (2023-2024) AB 96,California,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2023-10-08,2023,10,positive,0.1635,low,0.0556,223,1.0,Enacted,"The people of the State of California do enact as follows: SECTION 1. Chapter 9.1 (commencing with Section 3125) is added to Division 4 of Title 1 of the Government Code, to read: CHAPTER 9.1. Public Transit Employer Obligations 3125. For the purposes of this chapter: (a) “Autonomous transit vehicle technology” means technology that has the capability to drive a vehicle without the active physical control by a human operator. (b) “Plan to acquire or deploy” includes any public notification that initiates acquisition or deployment of autonomous transit vehicle technology. (c) “Procurement process” means the issuance of a request for proposals, a solicitation of proposals, or a request for quotations. (d) “Public transit employer” means any local governmental agency, including any city, county, city and county, special district, transit district, or joint powers authority, that provides public transit services within the state. (e) “Public transit services” means the provision of passenger transportation services by the public transit employer to the general public, including paratransit service. 3126. (a) At least 10 months before beginning a procurement process to acquire or deploy any autonomous transit vehicle technology for public transit services that would eliminate job functions or jobs of the workforce, a public transit employer shall notify, in writing, the exclusive employee representative of the workforce affected by the autonomous transit vehicle technology of its",https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240AB96,en,"Applications: Transportation, Strategies: Disclosure: In deployment, Risk factors: Transparency, Strategies: Disclosure, Strategies: Government support: AI workforce-related, Strategies: Government support"
1579,California (2021-2022) SB 1398,California,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2022-09-13,2022,9,positive,0.1528,low,0.0,239,0.5,Enacted,"The people of the State of California do enact as follows: SECTION 1. Section 24011.5 is added to the Vehicle Code, to read: 24011.5. (a) A dealer or manufacturer shall not sell any new passenger vehicle that is equipped with any partial driving automation feature, or provide any software update or other vehicle upgrade that adds any partial driving automation feature, without, at the time of delivering or upgrading the vehicle, providing the buyer or owner with a distinct notice that provides the name of the feature and clearly describes the functions and limitations of the feature. (b) A manufacturer or dealer shall not name any partial driving automation feature, or describe any partial driving automation feature in marketing materials, using language that implies or would otherwise lead a reasonable person to believe, that the feature allows the vehicle to function as an autonomous vehicle, as defined in Section 38750, or otherwise has functionality not actually included in the feature. A violation of this subdivision shall be considered a misleading advertisement for the purposes of Section 11713. (c) As used in this section, “partial driving automation feature” has the same meaning as “Level 2 partial driving automation” in the Society of Automotive Engineers (SAE) Standard J3016 (April 2021). (d) Compliance with this section shall not alter any existing duty of care or limit the civil liability of a manufacturer or dealer, including, but not limited to, claims for negl",https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202120220SB1398,en,
1588,Washington (2022) SB 5460,Washington,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2021-07-25,2021,7,negative,-0.5859,low,0.0,236,0.7,Enacted,"AN ACT Relating to implementing recommendations of the autonomous vehicle work group; amending RCW 46.92.010 and 46.37.480; amending 2020 c 182 s 4 (uncodified); and providing an effective date. BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF WASHINGTON: Sec. 1. RCW 46.92.010 and 2020 c 182 s 2 are each amended to read as follows: (1) In order to test an autonomous motor vehicle on any public roadway under the department's autonomous vehicle self-certification testing pilot program, the following information must be provided by the self-certifying entity testing the autonomous motor vehicle: (a) Contact information specified by the department; (b) Local jurisdictions where testing is planned; (c) The vehicle identification numbers of the autonomous vehicles being tested, provided that one is required by state or federal law; and (d) Proof of an insurance policy that meets the requirements of RCW 46.30.050. (2) Any autonomous motor vehicle to which subsection (1) of this section is applicable and that does not have a vehicle identification number and is not otherwise required under state or federal law to have a vehicle identification number assigned to it must be assigned a unique identification number that is provided to the department and that is displayed in the vehicle in a manner similar to the display of vehicle identification numbers in motor vehicles. (3)(a) The self-certifying entity testing the autonomous motor vehicle on any public roadway must notify the departme",https://lawfilesext.leg.wa.gov/biennium/2021-22/Pdf/Bills/Senate%20Passed%20Legislature/5460-S.PL.pdf?q=20250127184204,en,"Strategies: Licensing, registration, and certification, Strategies: Disclosure, Strategies: Disclosure: About incidents, Strategies: Pilots and testbeds, Strategies: Government study or report"
1613,Alabama (2019) SB 47,Alabama,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2019-06-10,2019,6,negative,-0.1779,low,0.0,227,0.5,Enacted,"An Act, Relating to motor vehicles; to authorize autonomous commercial vehicles operated by an automated driving system and commercial motor vehicles with teleoperation systems. BE IT ENACTED BY THE LEGISLATURE OF ALABAMA: Section 1. For the purposes of this act, the following words shall have the following meanings: (1) AUTOMATED COMMERCIAL MOTOR VEHICLE. A commercial motor vehicle equipped with an automated driving system. (2) AUTOMATED DRIVING SYSTEM. The hardware and software that are collectively capable of performing the entire dynamic driving task on a sustained basis, regardless of whether it is limited to a specific operational design domain. (3) COMMERCIAL MOTOR VEHICLE. A commercial motor vehicle as defined in subdivision (2) of Section 32-9A-1, Code of Alabama 1975. (4) CONVENTIONAL DRIVER. A driver who manually exercises in-vehicle braking, accelerating, steering, and transmission gear selection input devices in order to operate a vehicle. (5) DYNAMIC DRIVING TASK. All of the real-time operational and tactical functions required to operate a vehicle in on-road traffic excluding strategic functions such as trip scheduling and selection of destinations and waypoints. (6) MINIMAL RISK CONDITION. A condition to which a user or an automated driving system may bring a vehicle in order to reduce the risk of a crash upon experiencing a failure of the vehicle's automated driving system that renders the vehicle unable to perform the entire dynamic driving task. (7) OPERATI",https://alison.legislature.state.al.us/files/pdf/SearchableInstruments/2019RS/PrintFiles/SB47-Enr.pdf,en,
1621,Iowa (2019) SB 302 (Automated Driving System Motor Vehicles),Iowa,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2019-05-03,2019,5,positive,0.6807,low,0.0,221,0.5,Enacted,"AN ACT RELATING TO MOTOR VEHICLES OPERATED BY AN AUTOMATED DRIVING SYSTEM, AND MAKING PENALTIES APPLICABLE. BE IT ENACTED BY THE GENERAL ASSEMBLY OF THE STATE OF IOWA: Section 1. NEW SECTION. 321.514 Definitions. As used in this section and sections 321.515 through 321.519, unless the context otherwise requires: 1. “Automated driving system” means the hardware and software collectively capable of performing the entire dynamic driving task on a sustained basis, regardless of whether the system is limited to a specific operational design domain, if any. 2. “Conventional human driver” means a natural person who manually controls the in-vehicle accelerating, braking, steering, and transmission gear selection input devices in order to operate a motor vehicle. 3. ''Driver less-capable vehicle"" means a system-equipped vehicle capable of performing the entire dynamic driving task within the automated driving system's operational design domain, if any, including but not limited to achievement of a minimal risk condition without intervention or supervision by a conventional human driver. 4. ''Dynamic driving task"" means all real-time operational and tactical functions required to operate a motor vehicle on a highway in traffic within an automated driving system's specific operational design domain, if any. “Dynamic driving task” does not include any strategic function such as trip scheduling or the selection of destinations and waypoints. 5. ''Minimal risk condition” means a reasonably",https://www.legis.iowa.gov/legislation/BillBook?ga=88&ba=SF302,en,
1625,New Jersey (2019) Assembly Joint Resolution 164,New Jersey,United States,State governments,U.S. state and local documents,Resolution,2019-03-18,2019,3,positive,0.9538,low,0.0,245,0.5,Enacted,"A Joint Resolution establishing the “New Jersey Advanced Autonomous Vehicle Task Force.” Be It Enacted by the Senate and General Assembly of the State of New Jersey: 1. a. There is established a task force to be known as the “New Jersey Advanced Autonomous Vehicle Task Force.” The purpose of the task force shall be to conduct a study of advanced autonomous vehicles and to make recommendations on laws, rules, and regulations that this State may enact or adopt to safely integrate advanced autonomous vehicles on the State’s highways, streets, and roads. b. The task force shall consist of 11 members as follows: (1) the Commissioner of Transportation, who shall serve ex officio, or the commissioner’s designee; (2) the Chief Administrator of the New Jersey Motor Vehicle Commission, who shall serve ex officio, or the chief administrator’s designee; (3) the Director of the Division of Highway Traffic Safety in the Department of Law and Public Safety, who shall serve ex officio, or the director’s designee; (4) a commissioner of the Board of Public Utilities, selected by the Governor, who shall serve ex officio, or that commissioner’s designee; (5) five public members, who shall be appointed by the Governor, one with an expertise in highway traffic safety, one with an expertise in autonomous vehicle technology , one with an expertise in automotive manufacturing, one who is licensed in this State as a professional engineer pursuant to P.L.1938, c.342 (C.45:8-27 et seq.) , and one, who s",https://www.njleg.state.nj.us/bill-search/2018/AJR164/bill-text?f=PL19&n=1002_,en,
1658,Washington (2018) HB 2970,Washington,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2018-03-22,2018,3,positive,0.9246,low,0.0,246,0.7,Enacted,"AN ACT Relating to the establishment of an autonomous vehicle work group; adding a new section to chapter 47.01 RCW; creating a new section; and providing an expiration date.3 BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF WASHINGTON: NEW SECTION. Sec. 1. A new section is added to chapter 47.01 RCW to read as follows: The commission must convene an executive and legislative work group to develop policy recommendations to address the operation of autonomous vehicles on public roadways in the state, subject to the availability of amounts appropriated for this specific purpose. (1)(a)(i) Executive branch membership of the work group must include, but is not limited to: The governor or his or her designee or designees, the insurance commissioner or his or her designee or designees, the director of the department of licensing or his or her designee or designees, the secretary or his or her designee or designees, the chief of the Washington state patrol or his or her designee or designees, and the director of the traffic safety commission or his or her designee or designees. (ii) Executive branch membership of the work group may also include: The assistant secretary of the department of social and health services aging and long-term support administration or his or her designee or designees and the deputy director of the department of enterprise services who oversees fleet operations or his or her designee or designees. (b) The president of the senate shall appoint two interested",https://lawfilesext.leg.wa.gov/biennium/2017-18/Pdf/Bills/House%20Passed%20Legislature/2970-S.PL.pdf?q=20250127103501,en,"Strategies: New institution, Strategies: Disclosure, Strategies: Governance development, Strategies: Convening, Strategies: Government study or report"
1663,California (2017) AB 1444,California,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2019-01-01,2019,1,positive,0.7783,low,0.0,249,0.5,Enacted,"The people of the State of California do enact as follows: SECTION 1. Section 38756 is added to the Vehicle Code, to read: 38756. (a) Notwithstanding Section 38750, the Livermore Amador Valley Transit Authority is authorized to conduct a shared autonomous vehicle (SAV) demonstration project for the testing of autonomous vehicles that do not have a driver seated in the driver’s seat and are not equipped with a steering wheel, a brake pedal, or an accelerator, provided the following requirements are met: (1) The testing shall be conducted only within the City of Dublin and the vehicles may traverse public roads within the area of the demonstration project. (2) The autonomous vehicle shall operate at speeds of less than 35 miles per hour. (b) Prior to the start of the testing of an autonomous vehicle that does not have a driver seated in the driver’s seat on or across a public road, the Livermore Amador Valley Transit Authority or a private entity, or a combination of the two, shall do both of the following: (1) Obtain an instrument of insurance, surety bond, or proof of self-insurance in an amount of five million dollars ($5,000,000), and shall provide evidence of the insurance, surety bond, or proof of self-insurance to the Department of Motor Vehicles in the form and manner required by the department. (2) Submit a detailed description of the testing program to the department. The detailed description shall include all of the following: (A) Certification that, prior to testing",https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180AB1444,en,
1664,Connecticut (2017) SB 260,Connecticut,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2017-06-27,2017,6,positive,0.7183,low,0.0,223,0.5,Enacted,"AN ACT CONCERNING AUTONOMOUS VEHICLES. Be it enacted by the Senate and House of Representatives in General Assembly convened: Section 1. (NEW) (Effective from passage) (a) For the purposes of this section: (1) ""Fully autonomous vehicle"" means a motor vehicle that is equipped with an automated driving system, designed to function without an operator and classified as level four or level five by SAE J3016; (2) ""Automated driving system"" means the hardware and software that are collectively capable of performing the entire dynamic driving task on a sustained basis, regardless of whether the automated driving system is limited to a specific operational design domain; (3) ""Dynamic driving task"" means the real-time operational and tactical functions required to operate a motor vehicle on highways, excluding the strategic functions such as trip scheduling and selection of destinations and waypoints; (4) ""Operational design domain"" means a description of the operating domains in which an automated driving system is designed to function, including, but not limited to, geographic, roadway, environmental and speed limitations; (5) ""SAE J3016"" means the ""Taxonomy and Definitions for Terms Related to Driving Automation Systems for On-Road Motor Vehicles"" published by SAE International in September 2016; (6) ""Operator"" means the person seated in the driver's seat of a fully autonomous vehicle; (7) ""Autonomous vehicle tester"" means an autonomous vehicle manufacturer, institution of higher e",https://www.cga.ct.gov/2017/ACT/pa/2017PA-00069-R00SB-00260-PA.htm,en,
1678,Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters,Department of Commerce,United States,Federal government,Editors' Picks,Regulation,2024-09-11,2024,9,positive,0.9413,low,0.2778,233,0.7,Proposed,"15 CFR part 702 is proposed to be amended as follows: PART 702—INDUSTRIAL BASE SURVEYS—DATA COLLECTIONS 1. The authority citation for 15 CFR part 702 is revised to read as follows: Authority: 50 U.S.C. 4501 et seq.; E.O. 13603, 77 FR 16651, 3 CFR, 2012 Comp., p. 225; E.O. 14110, 88 FR 75191, 3 CFR, 2023 Comp., p. 657. 2. Section 702.7 is added to read as follows: § 702.7 Special requirements for on-going reporting regarding the development of advanced artificial intelligence models and computing clusters. (a) Reporting requirements. (1) Covered U.S. persons are required to submit a notification to the Department by emailing ai_reporting@bis.doc.gov on a quarterly basis as defined in paragraph (a)(2) of this section if the covered U.S. person engages in, or plans, within six months, to engage in `applicable activities,' defined as follows: (i) Conducting any AI model training run using more than 10^26 computational operations (e.g., integer or floating-point operations); or (ii) Acquiring, developing, or coming into possession of a computing cluster that has a set of machines transitively connected by data center networking of greater than 300 Gbit/s and having a theoretical maximum greater than 10^20 computational operations (e.g., integer or floating-point operations) per second (OP/s) for AI training, without sparsity. Note 1 to paragraph (a)(1): Consistent with industry conventions, one multiply-accumulate computation, D = A × B + C, should be counted as two operations. (2",https://www.federalregister.gov/documents/2024/09/11/2024-20529/establishment-of-reporting-requirements-for-the-development-of-advanced-artificial-intelligence,en,"Strategies: Disclosure, Strategies: Tiering, Strategies: Tiering: Tiering based on inputs, Strategies: Disclosure: In deployment, Strategies: Evaluation, Strategies: Evaluation: Adversarial testing, Strategies: Disclosure: About evaluation, Risk factors: Security, Risk factors: Security: Cybersecurity, Risk factors: Safety, Risk factors: Reliability, Strategies: Tiering: Tiering based on domain of application, Harms: Harm to health/safety"
1679,Modernizing Data Practices to Improve Government Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.969,low,0.0,239,0.5,Defunct,"A BILL To amend title 44, United States Code, to modernize data practices to improve government, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Modernizing Data Practices to Improve Government Act”. SEC. 2. Modernizing data practices to improve government. (a) Definitions.—Section 3502 of title 44, United States Code, is amended— (1) in paragraph (22), by striking “; and” and inserting a semicolon; (2) in paragraph (23), by striking the period at the end and inserting a semicolon; and (3) by adding at the end the following: “(24) the term ‘artificial intelligence’— “(A) has the meaning given the term ‘artificial intelligence’ in section 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401); and “(B) includes the artificial systems and techniques described in paragraphs (1) through (5) of section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Public Law 115–232; 10 U.S.C. 4061 note prec.); and “(25) the term ‘data governance’ means the policies and procedures of an agency to manage data throughout the lifecycle of such data, including acquisition, collection, analysis, protection, use, dissemination, disposal, or archival, including— “(A) any data asset; and “(B) any action taken and any technology or process used by an agency to manage such data or data asset.”. (b)",https://www.congress.gov/bill/118th-congress/house-bill/10151/text,en,
1680,Improving Diagnosis in Medicine Act of 2024,United States Congress,United States,Federal government,U.S. state and local documents,Law/Act,2025-01-03,2025,1,positive,0.9902,low,0.0,220,0.5,Defunct,"A BILL To improve the quality, appropriateness, and effectiveness of diagnosis in health care, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Improving Diagnosis in Medicine Act of 2024”. SEC. 2. Research program to improve diagnostic safety and quality. Part B of title IX of the Public Health Service Act (42 U.S.C. 299b et seq.) is amended by adding at the end the following: “SEC. 918. Research program to improve diagnostic safety and quality. “(a) In general.—The Director shall establish a comprehensive program of research and quality improvement to— “(1) assess and understand diagnostic errors, including diagnostic delays, and how to eliminate common failures in the diagnostic process that lead to significant patient harm; and “(2) identify, develop, implement, and disseminate evidence-based strategies and best practices for improving diagnostic quality, safety, and health care value. “(b) Activities.—The program established under subsection (a) shall include the following: “(1) CONTINUUM OF RESEARCH.—A portfolio of conducted and supported activities that is consistent with the research, implementation, and dissemination activities of the Center for Quality Improvement and Patient Safety, as described in section 933, including— “(A) investigator-initiated research to assess diagnostic errors and identify improved methods to prevent",https://www.congress.gov/bill/118th-congress/house-bill/10135/text,en,
1681,AI Fraud Deterrence Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9022,low,0.0,235,0.7,Defunct,"A BILL To increase penalties for the commission of financial crimes using artificial intelligence. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “AI Fraud Deterrence Act”. SEC. 2. Financial crimes and artificial intelligence. (a) Mail fraud.—Section 1341 of title 18, United States Code, is amended— (1) by striking “$1,000,000” and inserting “$2,000,000”; and (2) by inserting after the period at the end the following: “If the violation is committed with the assistance of artificial intelligence, such person shall be fined not more than $1,000,000 or imprisoned not more than 20 years, or both.”. (b) Wire fraud.—Section 1343 of title 18, United States Code, is amended— (1) by striking “$1,000,000” and inserting “$2,000,000”; and (2) by inserting after the period at the end the following: “If the violation is committed with the assistance of artificial intelligence, such person shall be fined not more than $1,000,000 or imprisoned not more than 20 years, or both.”. (c) Bank fraud.—Section 1344 of title 18, United States Code, is amended— (1) by striking “Whoever knowingly” and inserting the following: “(a) In general.—Whoever knowingly”; and (2) by adding at the end the following: “(b) Artificial intelligence.—Whoever commits subsection (a) with the assistance of artificial intelligence shall be fined not more than $2,000,000 or imprisoned not more than 30 years,",https://www.congress.gov/bill/118th-congress/house-bill/10125/text,en,"Incentives: Criminal liability, Incentives: Civil liability, Applications: Government: judicial and law enforcement"
1684,Economic Security and Diplomacy Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9022,low,0.0,241,0.5,Defunct,"A BILL To amend the State Department Basic Authorities Act to establish a Deputy Secretary of State for Economic Security, redesignate and relocate other offices of the Department of State, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Economic Security and Diplomacy Act of 2024”. SEC. 2. Amendments to the state department basic authorities act. Section 1 of the State Department Basic Authorities Act of 1956 (22 U.S.C. 2651a) is amended— (1) in subsection (a)(2), by inserting “the Deputy Secretary of State for Economic Security,” after “the Deputy Secretary of State,”; (2) in subsection (b)(1), by striking “6” and inserting “5”; (3) in subsection (c)(1), by striking “24” and inserting “27”; and (4) in subsection (i)— (A) in paragraph (1), by striking the second sentence and inserting “Subject to the numerical limitation under subsection (c)(1), the head of the Bureau shall be an Assistant Secretary for Cyberspace and Digital Policy and shall report to the Deputy Secretary for Economic Security.”; (B) by striking paragraph (4); and (C) by redesignating paragraphs (5) through (7) as paragraphs (4) through (6), respectively. SEC. 3. Establishment of deputy secretary for economic security. The Secretary of State shall take such steps as may be necessary to ensure the following: (1) To transfer, pursuant to the amendment made by section 1(",https://www.congress.gov/bill/118th-congress/house-bill/10100/text,en,
1685,Eliminating Bias in Algorithmic Systems Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9432,low,0.0,242,0.5,Defunct,"A BILL To require agencies that use, fund, or oversee algorithms to have an office of civil rights focused on bias, discrimination, and other harms of algorithms, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Eliminating Bias in Algorithmic Systems Act of 2024”. SEC. 2. Definitions. In this Act: (1) AGENCY.—The term “agency” has the meaning given the term in section 3502 of title 44, United States Code. (2) COVERED AGENCY.—The term “covered agency” means an agency that— (A) uses, funds, or procures a covered algorithm, or funds or otherwise participates in the development of a covered algorithm; or (B) oversees, regulates, or advises on the development or use of a covered algorithm. (3) COVERED ALGORITHM.—The term “covered algorithm” means a process that— (A) is— (i) a computational process that uses machine learning, natural language processing, artificial intelligence techniques, or other computational processing techniques of similar or greater complexity; or (ii) a computational process derived from a process described in clause (i); and (B) has the potential to have a material effect on the impact of, access to, availability of, eligibility for, cost of, terms of, or conditions of— (i) a program operated or funded by an agency; (ii) an economic opportunity regulated by an agency; or (iii) rights protected by an agency. SEC. 3. Ci",https://www.congress.gov/bill/118th-congress/house-bill/10092/text,en,
1687,Next Generation Military Education Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9893,low,0.0,225,0.5,Defunct,"A BILL To provide personnel of the Department of Defense with increased access to training and education in artificial intelligence and machine learning, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Next Generation Military Education Act”. SEC. 2. Modification to artificial intelligence education strategy. Section 256 of the National Defense Authorization Act for Fiscal Year 2020 (Public Law 116–92; 133 Stat. 1290) is amended by adding at the end the following new subsection: “(d) Artificial intelligence and machine learning education platforms.— “(1) IN GENERAL.—Not later than 180 days after the date of the enactment of this subsection, the Chief Digital and Artificial Intelligence Officer of the Department of Defense, in coordination with the Under Secretary of Defense for Personnel and Readiness, shall— “(A) develop a set of distance education courses on— “(i) the foundational concepts of artificial intelligence and machine learning; and “(ii) the responsible and ethical use of artificial intelligence and machine learning applications; and “(B) make such courses available to members of the Armed Forces. “(2) ELEMENTS.—The courses developed under paragraph (1) shall address— “(A) basic artificial intelligence literacy to enable members of the Armed Forces to make informed decisions about the use of artificial intelligence products",https://www.congress.gov/bill/118th-congress/house-bill/9903/text,en,
1690,Data Protection Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.875,low,0.0,225,0.5,Defunct,"A BILL To establish the Data Protection Agency. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Data Protection Act of 2024”. SEC. 2. Definitions. In this Act: (1) AGENCY.—The term “Agency” means the Data Protection Agency established under section 3. (2) ANONYMIZED DATA.—The term “anonymized data” means information— (A) that does not identify an individual; and (B) with respect to which there is no reasonable basis to believe that the information can be used on its own or in combination with other reasonably available information to identify an individual. (3) AUTOMATED DECISION SYSTEM.—The term “automated decision system” means a computational process, including one derived from machine learning, statistics, or other data processing or artificial intelligence techniques, that automates, analyzes, aids, or augments decisions. (4) BIOMETRIC INFORMATION.—The term “biometric information”— (A) means information regarding the physiological or biological characteristics of an individual that may be used, singly or in combination with each other or with other identifying data, to establish the identity of an individual; (B) includes— (i) genetic data; (ii) imagery of the iris, retina, fingerprint, face, hand, palm, vein patterns, and voice recordings, from which an identifier template, such as a faceprint, a minutiae template, or a voiceprint, can be extracted; (iii",https://www.congress.gov/bill/118th-congress/senate-bill/5170/text,en,
1714,Iowa Senate Bill 2435,Iowa,United States,State governments,U.S. state and local documents,Law/Act,2024-05-09,2024,5,positive,0.7579,low,0.0,240,0.5,Enacted,"DIVISIONIII FY2024-2025APPROPRIATIONS——STATE BOARD OF REGENTS. Sec.6. GENERAL FUND APPROPRIATIONS. There is appropriated from the general fund of the state to the state board of regents for the fiscal year beginning July 1, 2024, and ending June 30, 2025, the following amounts, or so much thereof as is necessary, to be used for the purposes designated: 1. OFFICE OF STATE BOARD OF REGENTS a. For salaries, support, maintenance, and miscellaneous purposes, and for not more than the following full-time equivalent positions: Amount: $764,642 FTEs: 2.48 For the fiscal year beginning July 1, 2024, and ending June 30, 2025, the state board of regents shall submit a quarterly financial report to the general assembly in a format agreed upon by the state board of regents office and the legislative services agency. The report submitted for the quarter ending December 31, 2024, shall include the five-year graduation rates for the regents universities. b. For distribution to the Western Iowa Regents Resource Center: Amount: $268,297 c. For the fiscal year beginning July 1, 2024, and ending June 30, 2025, the state board of regents and the institutions of higher learning governed by the state board of regents shall not reduce moneys budgeted for the fiscal year for the institutions’ police departments. d. For allocation in equal parts by the state board of regents to the State University of Iowa, Iowa State University of Science and Technology, and the University of Northern Iowa to support",https://legiscan.com/IA/text/SF2435/id/2988266/Iowa-2023-SF2435-Enrolled.html,en,
1715,Mississippi Senate Bill 3000,Mississippi,United States,State governments,U.S. state and local documents,Law/Act,2023-04-19,2023,4,positive,0.8625,low,0.0,198,0.5,Enacted,"SECTION 42. The following sum, or so much thereof as may be necessary, is reappropriated out of any money in the Education Enhancement Fund not otherwise appropriated, to the Institutions of Higher Learning for the purpose of reauthorizing the expenditure of Education Enhancement Funds to defray the expenses of the Institutions of Higher Learning, as authorized in Senate Bill 3002, 2022 Regular Session, for the fiscal year beginning July 1, 2023, and ending June 30, 2024 $ 53,478,000.00. This appropriation is made for the purpose of reauthorizing the expenditure of funds as allocated herein: (a) Delta State University – Commercial Aviation Department to defray expenses related to the purchase of flight simulators, training equipment, and other capital improvements....................... .............................................. $ 2,478,000.00. (b) University of Mississippi to defray expenses related to the operations of the Haley Barbour Center for the Study of American Politics.............................................. $ 1,000,000.00. (c) University of Mississippi to defray expenses related to the Healthcare Innovation Tech Hub Infrastructure, Biomedical Innovation, Nano-Bio Immuno Engineering Consortium (NIEC), Data Science and Artificial Intelligence........................ $ 15,000,000.00. (d) University of Mississippi to defray expenses related to the UM Early Learning and Evaluation Center............ $ 10,000,000.00. (e) Mississippi State University to defray",https://billstatus.ls.state.ms.us/documents/2023/html/SB/3000-3099/SB3000PS.htm,en,
1716,"Nebraska L 1284 (Teacher Incentive Programs), Sec. 2.",Nebraska,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-04-25,2024,4,positive,0.9898,low,0.0,236,0.5,Enacted,"Sec. 2. (1) For purposes of this section: (a) Department means the State Department of Education; and (b) Eligible applicant means a privately owned business based in Nebraska that is in the process of researching artificial-intelligence-based writing assistance that can be used to assist individuals with dyslexia. (2) The Dyslexia Research Grant Program is created and shall be administered by the department. (3)(a) An eligible applicant may apply to the department for a grant under the Dyslexia Research Grant Program. The department shall prescribe the application form that is to be completed when applying for a grant under the Dyslexia Research Grant Program. The grant shall be conditioned on compliance with this section. (b) Except as provided in subdivision (c) of this subsection, the department may award a grant to any eligible applicant. (c) The total amount of all grants awarded under the Dyslexia Research Grant Program shall not be more than five hundred thousand dollars. It is the intent of the Legislature that grants awarded pursuant to this section shall be funded from the Education Future Fund. (4) All grant money received under the Dyslexia Research Grant Program shall be used only for the purpose of researching the use of artificial intelligence-based writing assistance by individuals with dyslexia. Such research shall be focused on using aggregate writing analytics to identify writing errors and patterns that can be used by teachers to develop a comprehensive l",https://nebraskalegislature.gov/FloorDocs/108/PDF/Slip/LB1284.pdf,en,
1719,Budget Act of 2024,California,United States,State governments,U.S. state and local documents,Law/Act,2024-06-26,2024,6,positive,0.9169,low,0.0,203,0.7,Enacted,"0511-001-0001—For support of Secretary of Government Operations ........................ 18,756,000 Schedule: (1) 0250-Office of the Secretary of Government Operations ........................ 7,161,000 (2) 0257-Cradle to Career ........................ 15,401,000 (3) Reimbursements to 0250-Office of the Secretary of Government Operations ........................ −3,806,000 Provisions: 1. The Government Operations Agency shall establish monthly Generative Artificial Intelligence meetings with designated legislative staff of the Assembly and Senate to discuss the agency’s ongoing efforts regarding the implementation of Executive Order N-12-23. The Speaker of the Assembly and President pro tempore of the Senate shall each designate staff persons to attend these monthly meetings. During the meetings, the agency shall provide updates on the completion of, and compliance with, each deliverable in the executive order. In addition, the agency shall report on the implementation and results of any proof of concepts implemented pursuant to the Executive Order. Proof of concept reporting shall also include the identification of the funding source for the proof of concepts. To the extent additional budgetary resources above the levels appropriated in this budget act are needed to implement or procure a generative artificial intelligence technology solution for a proof a concept, the agency shall support the impacted department’s efforts to submit a request for budgetary resources through",https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240AB107,en,"Strategies: Government study or report, Strategies: Governance development, Strategies: Government support, Strategies: Input controls, Strategies: Input controls: Data use"
1721,Idaho House Bill 2472,Idaho,United States,State governments,U.S. state and local documents,Law/Act,2024-07-19,2024,7,positive,0.6249,low,0.0,242,0.5,Enacted,"Section 30. The Managed Care Reform and Patient Rights Act is amended by changing Sections 10, 45, and 85 as follows: (215 ILCS 134/10) Sec. 10. Definitions. In this Act: For a health care plan under Section 45 or for a utilization review program under Section 85, ""adverse determination"" has the meaning given to that term in Section 10 of the Health Carrier External Review Act. ""Clinical peer"" means a health care professional who is in the same profession and the same or similar specialty as the health care provider who typically manages the medical condition, procedures, or treatment under review. ""Department"" means the Department of Insurance. ""Emergency medical condition"" means a medical condition manifesting itself by acute symptoms of sufficient severity, regardless of the final diagnosis given, such that a prudent layperson, who possesses an average knowledge of health and medicine, could reasonably expect the absence of immediate medical attention to result in: (1) placing the health of the individual (or, with respect to a pregnant woman, the health of the woman or her unborn child) in serious jeopardy; (2) serious impairment to bodily functions; (3) serious dysfunction of any bodily organ or part; (4) inadequately controlled pain; or (5) with respect to a pregnant woman who is having contractions: (A) inadequate time to complete a safe transfer to another hospital before delivery; or (B) a transfer to another hospital may pose a threat to the health or safety of the",https://www.ilga.gov/legislation/publicacts/103/103-0656.htm,en,
1723,National Standard of the People’s Republic of China: Cybersecurity Technology – Basic Safety Requirements for Generative Artificial Intelligence Services (Draft for Feedback),Chinese central government,China,China,Chinese law and policy,Other,2024-05-17,2024,5,positive,0.9847,medium,0.6667,202,0.7,Proposed,"Cybersecurity Technology - Basic Safety Requirements for Generative Artificial Intelligence Services 1 Scope This document specifies the basic safety requirements for generative artificial intelligence (AI) services, including training data safety, model safety, and safety measures, and provides safety assessment requirements. This document applies to service providers carrying out safety assessments, and also provides the relevant main oversight department (主管部门) a reference. 2 Normative Reference Documents The contents of the following documents, through normative references in this text, constitute indispensable provisions of this document. Among them, for dated references, only the edition corresponding to that date applies to this document. For undated references, the latest edition (including all amendments) applies to this document. Information security technology terminology GB/T 25069-2022 3 Terminology and Definitions The terms and definitions defined in GB/T 25069-2022 and listed below apply to this document. 3.1 Generative Artificial Intelligence Services The use of generative AI technology to provide text, graphics, audio, video, and other content generation services to the public. 3.2 Service Provider An organization or individual that provides generative AI services in the form of interactive interfaces, programmable interfaces, etc. 3.3 Training Data All data that serve directly as input for model training, including pre-training and optimization training data",https://cset.georgetown.edu/wp-content/uploads/t0603_China_gen_AI_safety_standard_draft_EN.pdf,en,"Risk factors: Safety, Risk factors: Security, Risk factors: Security: Cybersecurity, Risk factors: Privacy, Harms: Violation of civil or human rights, including privacy, Strategies: Evaluation, Strategies: Input controls, Strategies: Input controls: Data use, Harms: Discrimination, Risk factors: Bias, Harms: Harm to property, Strategies: Tiering, Strategies: Tiering: Tiering based on inputs, Strategies: Disclosure, Strategies: Disclosure: About inputs"
1725,"Utah Senate Bill 149, Section 13-2-12",Utah,United States,State governments,U.S. state and local documents,Law/Act,2024-03-13,2024,3,positive,0.1015,low,0.0,229,0.5,Enacted,"13-2-12. Generative artificial intelligence -- Impact on liability for violation of consumer protection law. (1) As used in this section: (a) ""Generative artificial intelligence"" means an artificial system that: (i) is trained on data; (ii) interacts with a person using text, audio, or visual communication; and (iii) generates non-scripted outputs similar to outputs created by a human, with limited or no human oversight. (b) ""License"" means a state-granted authorization for a person to engage in a specified occupation: (i) based on the person meeting personal qualifications established under state law; and (ii) where state law requires the authorization before the person may lawfully engage in the occupation for compensation. (c) ""Regulated occupation"" means an occupation regulated by the Department of Commerce that requires a person to obtain a license or state certification to practice the occupation. (d) ""State certification"" means a state-granted authorization given to a person to use the term ""state certified"" as part of a designated title related to engaging in a specified occupation: (i) based on the person meeting personal qualifications established under state law; and (ii) where state law prohibits a noncertified person from using the term ""state certified"" as part of a designated title but does not otherwise prohibit a noncertified person from engaging in the occupation for compensation. (2) It is not a defense to the violation of any statute administered and enfor",https://le.utah.gov/~2024/bills/static/SB0149.html,en,
1726,"Utah Senate Bill 149, Chapter 70",Utah,United States,State governments,U.S. state and local documents,Law/Act,2024-03-13,2024,3,positive,0.9846,low,0.0,206,0.5,Enacted,"Chapter 70. ARTIFICIAL INTELLIGENCE POLICY ACT Part 1. General Provisions Section 4, Section 13-70-101 is enacted to read: 13-70-101. Definitions. As used in this chapter: (1) ""Applicant"" means a person that applies for participation in the regulatory learning laboratory. (2) ""Artificial intelligence"" means a machine-based system that makes predictions, recommendations, or decisions influencing real or virtual environments. (3) ""Artificial intelligence technology"" means a computer system, application, or other product that uses or incorporates one or more forms of artificial intelligence. (4) ""Department"" means the Department of Commerce. (5) ""Director"" means the director of the office. (6) ""Executive director"" means the executive director of the Department of Commerce. (7) ""Learning agenda"" means the areas of artificial intelligence applications, risks, and policy considerations selected by the office for focus by the learning laboratory. (8) ""Learning laboratory"" means the artificial intelligence analysis and research program created in Section 13-70-301. (9) ""Office"" means the Office of Artificial Intelligence Policy created in Section 13-70-201. (10) ""Participant"" means a person that is accepted to participate in the learning laboratory. (11) ""Regulatory mitigation agreement"" means an agreement between a participant, the office, and relevant state agencies described in Section 13-70-302. (12) ""Regulatory mitigation"" means: (a) when restitution to users may be required; (b",https://le.utah.gov/~2024/bills/static/SB0149.html,en,
1728,"Utah Senate Bill 84, Part 13",Utah,United States,State governments,U.S. state and local documents,Law/Act,2024-03-13,2024,3,positive,0.9949,low,0.0,232,0.5,Enacted,"Part 13. Innovation in Artificial Intelligence Grant Pilot Program Section 29, Section 63N-3-1301 is enacted to read: 63N-3-1301. Definitions. As used in this part: (1) ""Business entity"" means a for-profit or nonprofit organization. (2) ""Pilot program"" means the Innovation in Artificial Intelligence Grant Pilot Program created in Section 63N-3-1302. (3) ""Student"" means a child enrolled in a public or private school, grades kindergarten through twelfth grade. Section 30, Section 63N-3-1302 is enacted to read: 63N-3-1302. Innovation in Artificial Intelligence Grant Pilot Program created -- Purpose -- Requirements -- Report. (1) There is created the Innovation in Artificial Intelligence Grant Pilot Program, to be administered subject to the availability of funds by the office as described in this section. (2) (a) The purpose of the pilot program is to award a grant to a business entity to develop a program, material, and curriculum to: (i) teach a course on artificial intelligence to students, with an emphasis on practical training; and (ii) prepare students for career opportunities in technology. (b) A business entity that is awarded a grant under this section shall work in partnership with a public or private school. (3) A business entity that submits an application for a grant to the office shall include the following details in the application: (a) how the business entity proposes to fulfill the purpose described in Subsection (2)(a); (b) how the business entity proposes to",https://le.utah.gov/~2024/bills/static/SB0084.html,en,
1729,Massachusetts House Bill 4885,Massachusetts,United States,State governments,U.S. state and local documents,Law/Act,2024-07-25,2024,7,positive,0.8176,low,0.0,241,0.5,Enacted,"SECTION 148. (a) As used in this section, the following words shall, unless the context clearly requires otherwise, have the following meanings: “Microstamp”, a microscopic array of characters identifying the make, model, or serial number of a firearm, etched or otherwise imprinted in 2 or more places on the interior surface or the internal working parts of the firearm, that are transferred by imprinting on each cartridge case when the firearm is fired. “Personalized firearm”, a firearm manufactured with incorporated design technology or converted with such technology so that it: (i) allows the firearm to be fired only by an authorized user; or (ii) prevents any of the safety characteristics of the firearm from being readily deactivated. (b) There is hereby established, pursuant to section 2A of chapter 4 of the General Laws, a special legislative commission to study and investigate emerging firearm technology. (c) The special legislative commission shall consist of 13 members: the chairs of the joint committee on the judiciary or their designees, who shall serve as co-chairs; the secretary of public safety and security or a designee; the colonel of the state police or a designee; 2 members appointed by the speaker of the house of representatives; 2 members appointed by the president of the senate; 1 member appointed by the minority leader of the house of representatives; 1 member appointed by the minority leader of the senate; 1 member appointed by the governor, who shall be",https://malegislature.gov/Bills/193/H4885,en,
1730,"An Act Authorizing And Adjusting Bonds Of The State And Concerning Provisions Related To State And Municipal Tax Administration, General Government And School Building Projects",Connecticut,United States,State governments,U.S. state and local documents,Law/Act,2024-06-06,2024,6,positive,0.9684,low,0.0,231,0.5,Enacted,"Sec. 143. (Effective July 1, 2024) (a) For the fiscal year ending June 30, 2025, the Department of Education shall administer an artificial intelligence education tool pilot program. Under such pilot program, the Commissioner of Education shall award a grant to assist such boards in implementing an existing artificial intelligence tool, selected by the commissioner, that will be used by educators and students for classroom instruction and student learning. (b) The commissioner shall select five local or regional boards of education to participate in the pilot program, provided such participation includes at least one rural school district, one suburban school district and one urban school district and reflects the racial and ethnic diversity of the state. The commissioner and each such participating board of education shall jointly select the grade level in which such artificial intelligence tool will be implemented in the school district, provided such grade level is grade seven, eight, nine, ten, eleven or twelve. (c) Such artificial intelligence tool shall comply with the laws governing the use of artificial intelligence and the protection of student data and privacy, including, but not limited to, the Family Educational Rights and Privacy Act of 1974, 20 USC 1232g, as amended from time to time, and sections 10-234aa to 10-234gg, inclusive, of the general statutes. (d) As used in this section, ""artificial intelligence"" means any technology, including, but not limited to, m",https://search.cga.state.ct.us/dl2024/PA/DOC/2024PA-00151-R00HB-05524-PA.DOCX,en,
1734,"California AB 2355 (2024), Section 8",California,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-09-17,2024,9,positive,0.7506,low,0.1111,224,0.7,Enacted,"SEC. 8. Section 84514 is added to the Government Code, immediately following Section 84513, to read: 84514. (a) (1) If a committee, as defined in Section 82013, creates, originally publishes, or originally distributes a qualified political advertisement, the qualified political advertisement shall include, in a clear and conspicuous manner, the following disclosure: “Ad generated or substantially altered using artificial intelligence.” (2) The disclosure required by paragraph (1) shall be displayed or spoken in the manner prescribed in Section 84504, 84504.1, 84504.2, 84504.3, 84504.4, or 84504.5, as applicable. (b) This section does not alter or negate any rights, obligations, or immunities of an interactive service provider under Section 230 of Title 47 of the United States Code. (c) (1) If a committee does not comply with the requirements of subdivision (a), the Commission may take either of the following actions: (A) Seek injunctive relief to compel compliance pursuant to Section 90009. (B) Pursue any administrative or civil remedies available under Chapter 3 (commencing with Section 83100) or Chapter 11 (commencing with Section 91000). (2) A violation of subdivision (a) shall not constitute a misdemeanor under Chapter 11 (commencing with Section 91000). (d) For purposes of this section, the following definitions apply: (1) “Artificial intelligence” means an engineered or machine-based system that varies in its level of autonomy and that can, for explicit or implicit obje",https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240AB2355,en,"Strategies: Disclosure: In deployment, Incentives: Civil liability, Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content, Applications: Broadcasting and media production"
1736,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 125 (""Designation of official responsible for autonomous surface and underwater dual-modality vehicles"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.872,low,0.0,102,1.0,Enacted,"SEC. 125. Designation of official responsible for autonomous surface and underwater dual-modality vehicles. (a) Designation required.--Not later than 180 days after the date of the enactment of this Act, the Secretary of the Navy shall designate an appropriate official within the Department of the Navy to have primary responsibility for the development and acquisition of surface and underwater dual-modality, advanced autonomous vehicles, consistent with warfighter requirements. (b) Program element.--The Secretary of the Navy shall ensure, within budget program elements for the Navy, that there is a dedicated program element for the development and acquisition of surface and underwater dual-modality, advanced autonomous vehicles.",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Applications: Government: military and public safety, Strategies: Government support, Applications: Transportation, Strategies: Government support: For R&D"
1737,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section Title XV, Subtitle D (""Artificial Intelligence"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9897,low,0.0556,210,0.7,Enacted,"Subtitle D--Artificial Intelligence SEC. 1531. Artificial Intelligence Human Factors Integration Initiative. (a) Initiative required.-- (1) IN GENERAL.--The Under Secretary of Defense for Research and Engineering, in coordination with the Under Secretary of Defense for Acquisition and Sustainment and the Chief Digital and Artificial Intelligence Officer of the Department of Defense, shall establish an initiative-- (A) to improve the human usability of artificial intelligence systems and information derived from such systems through the application of cognitive ergonomics techniques; and (B) to improve the human usability and cognitive effectiveness of artificial intelligence systems adopted by the Department of Defense by ensuring that design tools and metrics are available for artificial intelligence and machine learning programs that ensure human factors considerations are included for such systems. (2) DESIGNATION.--The initiative established pursuant to paragraph (1) shall be known as the ""Artificial Intelligence Human Factors Integration Initiative"" (in this section the ""Initiative""). (b) Briefing.--Not later than one year after the date of the enactment of this Act, the Under Secretary of Defense for Research and Engineering, the Under Secretary of Defense for Acquisition and Sustainment, and the Chief Digital and Artificial Intelligence Officer of the Department of Defense shall jointly brief the Committee on Armed Services of the Senate and the Committee on Armed Serv",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Strategies: Convening, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About evaluation, Strategies: Performance requirements, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Government support: AI workforce-related, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Strategies: Governance development, Applications: Government: military and public safety, Risk factors: Interpretability and explainability, Strategies: Input controls: Compute use, Strategies: Input controls"
1738,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 6506 (""Enhancement of authority for intelligence community public-private talent exchanges"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9698,low,0.0,215,0.7,Enacted,"SEC. 6506. Enhancement of authority for intelligence community public-private talent exchanges. (a) Focus areas.--Subsection (a) of section 5306 of the Damon Paul Nelson and Matthew Young Pollard Intelligence Authorization Act for Fiscal Years 2018, 2019, and 2020 (50 U.S.C. 3334) is amended-- (1) by striking ""Not later than"" and inserting the following: ""(1) IN GENERAL.--Not later than""; and (2) by adding at the end the following: ""(2) FOCUS AREAS.--The Director shall ensure that the policies, processes, and procedures developed pursuant to paragraph (1) require exchanges under this section that relate to intelligence or counterintelligence with a focus on rotations described in such paragraph with private-sector organizations in the following fields: ""(A) Finance. ""(B) Acquisition. ""(C) Biotechnology. ""(D) Computing. ""(E) Artificial intelligence. ""(F) Business process innovation and entrepreneurship. ""(G) Cybersecurity. ""(H) Materials and manufacturing. ""(I) Any other technology or research field the Director determines relevant to meet evolving national security threats in technology sectors."". (b) Duration of temporary details.--Subsection (e) of section 5306 of the Damon Paul Nelson and Matthew Young Pollard Intelligence Authorization Act for Fiscal Years 2018, 2019, and 2020 (50 U.S.C. 3334) is amended-- (1) in paragraph (1), by striking ""3 years"" and inserting ""5 years""; and (2) in paragraph (2), by striking ""3 years"" and inserting ""5 years"". (c) Treatment of private-s",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Strategies: Government support, Strategies: Government support: AI workforce-related, Strategies: Convening, Strategies: Governance development, Strategies: Government study or report"
1739,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 6504 (""Establishment of Artificial Intelligence Security Center"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9934,low,0.0556,207,1.0,Enacted,"SEC. 6504. Establishment of Artificial Intelligence Security Center. (a) Definition of counter-artificial intelligence.--In this section, the term ""counter-artificial intelligence"" means techniques or procedures to extract information about the behavior or characteristics of an artificial intelligence system, or to learn how to manipulate an artificial intelligence system, in order to subvert the confidentiality, integrity, or availability of an artificial intelligence system or adjacent system. (b) Establishment.--Not later than 90 days after the date of the enactment of this Act, the Director of the National Security Agency shall establish an Artificial Intelligence Security Center (referred to in this section as the ""Center"") within the Cybersecurity Collaboration Center of the National Security Agency. (c) Functions.--The functions of the Artificial Intelligence Security Center shall be as follows: (1) Developing guidance to prevent or mitigate counter-artificial intelligence techniques. (2) Promoting secure artificial intelligence adoption practices for managers of national security systems (as defined in section 3552 of title 44, United States Code) and elements of the defense industrial base. (3) Such other functions as the Director considers appropriate. (d) Disestablishment.--The Director of the National Security Agency may disestablish the Center established in subsection (b) not earlier than 3 years after the date of the enactment of this Act provided that the Dire",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Strategies: New institution, Strategies: Governance development, Strategies: Evaluation, Strategies: Evaluation: Adversarial testing, Applications: Government: military and public safety, Risk factors: Security, Strategies: Government support"
1740,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 1638 (""Sense of Congress with respect to use of artificial intelligence to support strategic deterrence"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9811,low,0.1111,178,1.0,Enacted,"SEC. 1638. Sense of Congress with respect to use of artificial intelligence to support strategic deterrence. (a) Sense of Congress.--It is the sense of Congress that-- (1) the considered use of artificial intelligence and machine learning tools presents opportunities to strengthen the security of critical strategic communications and early warning networks, improve the efficiency of planning processes to reduce the risk of collateral damage, and enhance U.S. capabilities for modeling weapons functionality in support of stockpile stewardship; and (2) even with such applications, particular care must be taken to ensure that the incorporation of artificial intelligence and machine learning tools does not increase the risk that our Nation's most critical strategic assets can be compromised. (b) Statement of policy.--It is the policy of the United States that the use of artificial intelligence efforts should not compromise the integrity of nuclear safeguards, whether through the functionality of weapons systems, the validation of communications from command authorities, or the principle of requiring positive human actions in execution of decisions by the President with respect to the employment of nuclear weapons.",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Risk factors: Security, Applications: Government: military and public safety, Harms: Harm to health/safety"
1741,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 1547 (""Joint partner-sharing network capabilities for Middle East defense integration"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.988,low,0.0,230,0.7,Enacted,"SEC. 1547. Joint partner-sharing network capabilities for Middle East defense integration. (a) Initiative required.-- (1) IN GENERAL.--Not later than 180 days after the date of the enactment of this Act, the Secretary of Defense shall submit to the congressional defense committees a report on how to improve cooperation between the Department of Defense and allies and partners of the United States located in the Middle East to improve the use of partner-sharing network capabilities to facilitate joint defense efforts among the United States and such allies and partners to protect the people, infrastructure, and territory of the United States and such allies and partners from state and non-state actors determined by the Secretary to undermine the national security interests of the United States. (2) CONTENTS.--The report submitted pursuant to paragraph (1) shall include the following: (A) A summary of ongoing efforts by United States Central Command, or in which United States Central Command is participating, to implement a joint partner-sharing network capability integrated with the assets of allies and partners of the United States who are located in the Middle East. (B) A summary of challenges to further facilitate the implementation of a joint partner-sharing network capability integrated with the assets of Middle Eastern allies and partners, including actions or decisions that need to be taken by other organizations. (C) A recommendation of actions that can be taken to add",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Applications: Government: military and public safety, Strategies: Convening, Strategies: Governance development, Strategies: Government study or report"
1742,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 1515 (""Protective measures for mobile devices within the Department of Defense"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9432,low,0.1111,201,0.7,Enacted,"SEC. 1515. Protective measures for mobile devices within the Department of Defense. (a) In general.--The Secretary of Defense shall carry out a detailed evaluation of the cybersecurity products and services for mobile devices to identify products and services that may improve the cybersecurity of mobile devices used by the Department of Defense, including mitigating the risk to the Department of Defense from cyber attacks against mobile devices. (b) Cybersecurity technologies.--In carrying out the evaluation required under subsection (a), the Secretary of Defense shall evaluate each of the following technologies: (1) Anonymizing-enabling technologies, including dynamic selector rotation, un-linkable payment structures, and anonymous onboarding. (2) Network-enabled full content inspection. (3) Mobile-device case hardware solutions. (4) On-device virtual private networks. (5) Protected Domain Name Server infrastructure. (6) Extended coverage for mobile device endpoint detection. (7) Smishing, phishing, and business text or email compromise protection leveraging generative artificial intelligence. (8) Any other emerging or established technologies determined appropriate by the Secretary. (c) Elements.--In carrying out the evaluation required under subsection (a), for each technology described in subsection (b), the Secretary of Defense shall-- (1) assess the efficacy and value of the cybersecurity provided by the technology for mobile devices; (2) assess the feasibility of scali",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Strategies: Evaluation: Impact assessment, Strategies: Evaluation, Risk factors: Security, Risk factors: Security: Cybersecurity, Strategies: Tiering, Strategies: Government study or report"
1743,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 1514 (""Management and cybersecurity of multi-cloud environments"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9794,low,0.1111,214,0.7,Enacted,"SEC. 1514. Management and cybersecurity of multi-cloud environments. (a) In general.--Not later than 180 days after the date of the enactment of this Act, the Secretary of Defense shall, acting through the Chief Information Officer of the Department of Defense, develop a strategy for the management and cybersecurity of the multi-cloud environments of the Department. (b) Strategy.--The strategy required under subsection (a) shall-- (1) align with the zero trust strategy of the Department of Defense entitled ""DoD Zero Trust Strategy"" and dated October 21, 2022, or any successor thereto; (2) provide the Department with network visibility and interoperability across the entirety of the multi-cloud environments of the Department; (3) rationalize user identities across such multi-cloud environments, including through the implementation of identity, credential, and access management technologies; (4) maintain the same means to secure endpoints across the Department; (5) provide means for improving the identification and resolution of security concerns for each cloud environment prior to and during the adoption of such cloud environment by the Department; (6) assess means to increase the adoption of artificial intelligence applications into the multi-cloud environments of the Department; (7) increase the transparency of the reporting by the Department on the usage of such multi-cloud environments by the Department to improve planning for capacity demand, budgeting, and predictability",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Applications: Government: military and public safety, Strategies: Input controls, Risk factors: Security, Risk factors: Security: Cybersecurity, Strategies: Input controls: Data use"
1744,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 1087 (""Establishment of Department of Defense working group on multilateral artificial intelligence coordination"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9871,low,0.0556,213,0.7,Enacted,"SEC. 1087. Establishment of Department of Defense working group on multilateral artificial intelligence coordination. (a) Establishment.--Not later than 90 days after the date of the enactment of this Act, the Secretary of Defense shall establish a working group, or designated a working group of a similar nature, to develop and coordinate artificial intelligence initiatives among the allies and partners of the United States. (b) Organization.-- (1) DESIGNATION OF HEAD.--The Secretary shall designate a senior civilian officer of the Department of Defense or senior military officer with experience leading relevant efforts, as determined by the Secretary, to serve as the head of the working group. (2) PARTICIPATION BY OTHER MEMBER COUNTRIES.--The Secretary shall establish a process to determine which allies and partners of the United States shall be asked to participate as member countries in the working group. (c) Responsibilities.--The responsibilities of the working group shall be to develop and coordinate efforts to implement an artificial intelligence initiative between the Department of Defense and allies and partners of the United States, including by-- (1) comparing tools and practices for artificial intelligence systems for covered operational uses by member countries; (2) identifying (including by experimenting, testing, and evaluating) potential solutions to advance and accelerate the interoperability of artificial intelligence systems used for intelligence sharing, b",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Strategies: New institution, Strategies: Convening, Applications: Government: military and public safety, Strategies: Evaluation, Strategies: Governance development, Risk factors: Security"
1745,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 1078 (""Study and report on Department of Defense use of unmanned ground vehicle systems manufactured by certain foreign entities"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.765,low,0.1111,228,0.7,Enacted,"SEC. 1078. Study and report on Department of Defense use of unmanned ground vehicle systems manufactured by certain foreign entities. (a) Study on Department of Defense use of certain unmanned ground vehicle systems.-- (1) STUDY.--The Secretary of Defense shall conduct a study on the use by the Department of Defense of covered unmanned ground vehicle systems manufactured by covered foreign entities. (2) REPORT.--Not later than 180 days after the date of the enactment of this Act, the Secretary shall submit to the congressional defense committees a report on the study required under paragraph (1). Such report shall include each of the following: (A) An assessment of the extent to which covered unmanned ground vehicle systems manufactured by covered foreign entities are used by the Department, including a list of all such covered unmanned ground vehicle systems. (B) An assessment of the national security threats associated with using covered unmanned ground vehicle systems in applications of the Department, including with respect to-- (i) cybersecurity; (ii) technological maturity of the systems; and (iii) technological vulnerabilities in the systems that may be exploited by foreign adversaries of the United States. (C) A description of any actions taken by the Department to identify covered foreign entities that-- (i) develop or manufacture covered unmanned ground vehicle systems; and (ii) have a military-civil nexus on the list maintained by the Department under section 1260H",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Strategies: Government study or report, Applications: Government: military and public safety, Applications: Transportation, Strategies: Evaluation, Risk factors: Security: Cybersecurity, Risk factors: Security"
1746,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 1069 (""Biodefense posture reviews"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,negative,-0.6908,low,0.1111,200,0.7,Enacted,"SEC. 1069. Biodefense posture reviews. (a) Strategy and implementation plan required.--Not later than December 31, 2026, and December 31, 2029, the Secretary of Defense shall conduct a comprehensive examination of the biodefense policies, practices, programs, and initiatives of the Department of Defense. (b) Elements.--Each review conducted under subsection (a) shall include each of the following: (1) An inventory and assessment of all existing strategies, plans, policies, laws, and interagency agreements of the Department of Defense related to biodefense, including prevention, deterrence, preparedness, detection, response, attribution, recovery, and mitigation. (2) An identification of relevant biological threats, including biological warfare, bioterrorism, naturally occurring infectious diseases, and accidental exposures. (3) An identification of the current programs, efforts, or activities of the Department of Defense with respect to-- (A) preventing the acquisition, proliferation, and use of a biological weapon; (B) preventing an accidental or naturally occurring biological outbreak; and (C) mitigating the effects of a biological epidemic. (4) An identification of the roles and responsibilities of the elements of the Department of Defense, including internal and external coordination procedures, in identifying and sharing information related to, warning of, and regarding protection against, acts of terrorism using biological agents and weapons and accidental or naturally",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Risk factors: Safety, Harms: Harm to health/safety, Strategies: Evaluation, Strategies: Government study or report, Strategies: Governance development, Applications: Government: military and public safety"
1747,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 1066 (""Reports on approval and deployment of lethal autonomous weapon systems"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9708,low,0.0,228,1.0,Enacted,"SEC. 1066. Reports on approval and deployment of lethal autonomous weapon systems. (a) In general.--Not later than December 31, 2025, and annually thereafter until the termination date specified in subsection (d), the Secretary of Defense shall submit to the congressional defense committees a comprehensive report on the approval and deployment of lethal autonomous weapon systems by the United States. (b) Elements.--Each report under subsection (a) shall include, with respect to the period covered by the report, the following: (1) A comprehensive list of any lethal autonomous weapon systems that have been approved by senior defense officials for use by the United States military under Department of Defense Directive 3000.09, or any successor document, and the dates of such approvals. (2) A comprehensive list of any lethal autonomous weapon systems that have received a waiver of the requirement for review by senior defense officials under such directive, or any successor document, and the dates such waivers were issued. (3) A comprehensive list of any lethal autonomous weapon systems that are undergoing review under such directive, or any successor document. (4) A comprehensive list of any lethal autonomous weapon systems not approved during review under such directive, or any successor document. (c) Period covered by reports.-- (1) INITIAL REPORT.--The period covered by the first report submitted under subsection (a) shall be all relevant time periods, as determined by the Sec",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Strategies: Government study or report, Applications: Government: military and public safety"
1748,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 1032 (""Competitive demonstration of large and extra large unmanned underwater vehicles"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9804,low,0.1111,210,1.0,Enacted,"SEC. 1032. Competitive demonstration of large and extra large unmanned underwater vehicles. (a) Competitive demonstration required.--Not later than June 1, 2025, the Secretary of the Navy, in coordination with the Commander of the United States Indo-Pacific Command and in consultation with the Director of the Defense Innovation Unit, shall carry out a competitive demonstration of large and extra large unmanned underwater vehicle capabilities, including non-developmental items from commercial or foreign partner sources that leverage commercial solutions openings. (b) Criteria.--In developing and evaluating the competitive demonstration required by subsection (a), the Secretary of the Navy shall consider the following: (1) The ability of large and extra large unmanned underwater vehicles to integrate with mission autonomy planning capability and joint command and control systems. (2) The ability of such vehicles to execute high-value missions in a contested environment. (3) Vehicle performance with respect to navigation, endurance, and concepts of employment. (4) The technical maturity, reliability, and maintainability of such vehicles. (5) Feedback from military users, especially with respect to user interface, mission functionality, ease of use and deployment, and command and control. (6) Initial assessments of the total cost to procure, operate, and sustain a persistent large and extra large unmanned underwater vehicle presence in support of the operational requirements of t",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Risk factors: Reliability, Risk factors: Reliability: Robustness, Strategies: Evaluation, Applications: Transportation, Applications: Government: military and public safety, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Disclosure, Strategies: Government study or report"
1749,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 1031 (""Requirements for the unmanned maritime autonomy architecture"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.8834,low,0.0,157,0.7,Enacted,"SEC. 1031. Requirements for the unmanned maritime autonomy architecture. Not later than 180 days after the date of the enactment of this Act, the Secretary of the Navy shall-- (1) provide a forum and resources to facilitate industry participation in the creation and management of a vendor-agnostic and platform-agnostic modular open systems architecture and associated standards for maritime unmanned systems; (2) adopt or join a governance model for the standards described in paragraph (1) that includes Government and industry participation; (3) implement a frequent or continuous process for incorporating industry feedback into the standards described in paragraph (1) and conforming those standards with leading industry practices; (4) for each relevant Navy program or contract, tailor the standards described in paragraph (1) to the minimum standards necessary to enable desired operational capabilities for the program or contract; and (5) label and distribute the standards described in paragraph (1) as open, publicly releasable information, to the greatest extent possible.",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Strategies: Evaluation, Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Applications: Government: military and public safety"
1750,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 1007 (""Use of technology using artificial intelligence to facilitate audit of the financial statements of the Department of Defense for fiscal year 2025"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9766,low,0.0,142,1.0,Enacted,"SEC. 1007. Use of technology using artificial intelligence to facilitate audit of the financial statements of the Department of Defense for fiscal year 2025. (a) Use of AI technology for audits.--The Secretary of Defense, the Secretary of the Army, the Secretary of the Navy, and the Secretary of the Air Force shall encourage, to the greatest extent practicable, the use of technology that uses artificial intelligence or machine learning for the purpose of facilitating audits of the financial statements of the Department of Defense. (b) Implementation of AI technology for audits.--The Director of the Chief Digital and Artificial Intelligence Office of the Department, in coordination with the Under Secretary of Defense for Research and Engineering and the Inspector General of the Department, shall oversee the adoption of artificial intelligence and machine learning technologies in support of financial management and enterprise business operations.",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Applications: Business services and analytics, Strategies: Government support, Applications: Government: other applications/unspecified"
1751,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 237 (""Pilot program on use of artificial intelligence for certain workflow and operations tasks"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9808,low,0.0,220,1.0,Enacted,"SEC. 237. Pilot program on use of artificial intelligence for certain workflow and operations tasks. (a) Pilot program required.--Beginning not later than 60 days after the date of the enactment of this Act, the Secretary of Defense shall carry out a pilot program to assess the feasibility and advisability of using artificial intelligence-enabled software to optimize the workflow and operations for-- (1) depots, shipyards, or other manufacturing facilities run by the Department of Defense; and (2) contract administration for the Department, including-- (A) the adjudication and review of contracts; and (B) activities related to the Modernization and Analytics Initiative managed by the Defense Contract Management Agency. (b) Method of implementation.--The Secretary of Defense may carry out subsection (a) through-- (1) the establishment of a new pilot program; or (2) the designation of an existing initiative of the Department of Defense to serve as the pilot program required under such subsection. (c) Software.--In carrying out the pilot program required by subsection (a), the Secretary shall-- (1) use best in breed software platforms; (2) consider industry best practices in the selection of software programs; (3) implement the program based on human centered design practices to best identify the business needs for improvement; and (4) demonstrate connection to enterprise platforms of record with authoritative data sources. (d) Consultation.--In carrying out the activities descr",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Applications: Government: military and public safety, Strategies: Pilots and testbeds, Applications: Manufacturing and process automation, Strategies: Convening, Strategies: Government study or report"
1752,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 236 (""Pilot program on development of near-term use cases and demonstration of artificial intelligence toward biotechnology applications for national security"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9638,low,0.1111,218,0.7,Enacted,"SEC. 236. Pilot program on development of near-term use cases and demonstration of artificial intelligence toward biotechnology applications for national security. (a) Pilot program required.--The Secretary of Defense shall carry out a pilot program to develop near-term use cases and demonstrations of artificial intelligence for national security-related biotechnology applications. (b) Public-private partnerships.--The Secretary of Defense shall carry out the pilot program required by subsection (a) through one or more public-private partnerships entered into for purposes of the pilot program. (c) Laboratory support and infrastructure.--In support of a public-private partnership entered into under subsection (b), the Secretary of Defense may, on a reimbursable basis, make available-- (1) the facilities and services of a Department of Defense laboratory to perform experimentation for biotechnology applications to aid in the validation of artificial intelligence models; and (2) computing and data storage infrastructure and capabilities of the Department of Defense. (d) Duration.--The pilot program required by subsection (a) shall-- (1) commence not later than one year after the date of the enactment of this Act; and (2) terminate five years after the date of the on which the program commences under paragraph (1). (e) Annual report.-- (1) IN GENERAL.--Not later than one year after the date of the enactment of this Act, and not later than December 1 of every other year thereafter",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Strategies: Pilots and testbeds, Applications: Government: military and public safety, Strategies: Convening, Applications: Medicine, life sciences and public health, Strategies: Evaluation, Risk factors: Security: Cybersecurity, Risk factors: Security"
1753,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 235 (""Competitive demonstration of automated target recognition algorithms"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.7717,low,0.0,145,0.7,Enacted,"SEC. 235. Competitive demonstration of automated target recognition algorithms. (a) Venue, process, and scenarios.--Not later than June 1, 2025, the Chief Digital and Artificial Intelligence Officer of the Department of Defense, in coordination with appropriate counterparts in the military departments, shall develop a venue and processes, including a specified set of baseline scenarios, for comparative testing of automated target recognition algorithms to evaluate mission efficacy. (b) Demonstration.--Not later than September 1, 2025, the Secretary of Defense shall use the venue developed under subsection (a) to test the mission capability of at least two relevant programs included in the Replicator initiative. (c) Briefing.--Not later than one year after the date of the enactment of this Act, the Secretary of Defense shall provide to the Committees on Armed Services of the Senate and the House of Representatives a briefing on the activities carried out under this section.",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Pilots and testbeds, Applications: Government: military and public safety"
1754,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 233 (""Management and utilization of digital data to enhance maintenance activities"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9761,low,0.0,209,0.7,Enacted,"SEC. 233. Management and utilization of digital data to enhance maintenance activities. (a) Policies required.--Not later than one year after the date of the enactment of this Act, the Under Secretary of Defense for Acquisition and Sustainment, in consultation with the Secretaries of the military departments and the Chief Digital and Artificial Intelligence Officer of the Department of Defense, shall develop and implement policies to manage and utilize data derived from digital data systems for aircraft, ships, and ground vehicles to inform and support maintenance activities conducted with respect to such aircraft, ships, and vehicles. (b) Elements.--The policies required by subsection (a) shall include investment in advanced and scalable data infrastructure to efficiently record, transmit, categorize, and otherwise process data generated by digital data systems described in such subsection. Such policies shall-- (1) require development of a strategy to invest in advanced technologies, including automated systems and artificial intelligence, to streamline the process of organizing, indexing, and categorizing data; (2) require work with vendors to address and resolve limitations imposed by proprietary information and data, including through the adoption of open data and open mission systems approaches; (3) address data transmission capabilities, such as-- (A) implementing high-speed data transfer technologies; (B) optimizing network infrastructure; and (C) developing secure an",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Strategies: Government study or report, Strategies: Government support, Strategies: Government support: For R&D, Strategies: Convening, Strategies: Governance development, Applications: Government: military and public safety"
1755,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 232 (""Expansion of participation in the Digital On-Demand Program"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9595,low,0.0,191,1.0,Enacted,"SEC. 232. Expansion of participation in the Digital On-Demand Program. (a) In general.--The Secretary of Defense shall take such steps as may be necessary-- (1) to expand the availability of the Digital On-Demand Program to-- (A) all organizations and elements of the Department of Defense; and (B) all members of the Armed Forces and civilian employees of the Department; and (2) to actively promote the Program throughout the Department. (b) Report.--Not later than 180 days after the date of the enactment of this Act, and on an annual basis thereafter through 2029, the Secretary of Defense shall submit to the Committees on Armed Services of the Senate and the House of Representatives a report on the progress of the Secretary in expanding and promoting the Digital On-Demand Program as described in subsection (a). (c) Digital on Demand Program defined.--In this section, the term ""Digital On-Demand Program"" means the program overseen by the Chief Digital and Artificial Intelligence Officer pursuant to which educational resources on artificial intelligence, emerging technologies, data literacy, and related topics are made available to personnel of the Department of Defense through a digital platform on an on-demand basis.",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Strategies: Government study or report, Strategies: Disclosure, Strategies: Government support, Strategies: Government support: AI workforce-related"
1756,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 225 (""Duties of Chief Digital and Artificial Intelligence Officer Governing Council relating to artificial intelligence models and advanced artificial intelligence technologies"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9896,low,0.0556,154,0.7,Enacted,"SEC. 225. Duties of Chief Digital and Artificial Intelligence Officer Governing Council relating to artificial intelligence models and advanced artificial intelligence technologies. Section 238(d)(3)(E) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Public Law 115-232; 10 U.S.C. note prec. 4061) is amended-- (1) by redesignating clause (x) as clause (xi); and (2) by inserting after clause (ix) the following new clause (x): ""(x) With respect to artificial intelligence models and advanced artificial intelligence technologies-- ""(I) to identify and assess artificial intelligence models and advanced artificial intelligence technologies that could pose a national security risk if accessed by an adversary of the United States; ""(II) to develop strategies to prevent unauthorized access and usage of potent artificial intelligence models by countries that are adversaries of the United States; and ""(III) to make recommendations to Congress and relevant Federal agencies for legislative or administrative action in the field of artificial intelligence."".",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Risk factors: Security, Strategies: Evaluation"
1757,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 222 (""Modification to artificial intelligence education strategy"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9849,low,0.0,188,1.0,Enacted,"SEC. 222. Modification to artificial intelligence education strategy. Section 256 of the National Defense Authorization Act for Fiscal Year 2020 (Public Law 116-92; 133 Stat. 1290) is amended by adding at the end the following new subsection: ""(d) Artificial intelligence and machine learning education platforms.-- ""(1) IN GENERAL.--Not later than 180 days after the date of the enactment of the National Defense Authorization Act for Fiscal Year 2025, the Chief Digital and Artificial Intelligence Officer of the Department of Defense, in coordination with the Under Secretary of Defense for Personnel and Readiness, shall-- ""(A) develop a set of distance education courses on-- ""(i) the foundational concepts of artificial intelligence and machine learning; and ""(ii) the responsible and ethical design, development, acquisition and procurement, deployment, and use of artificial intelligence and machine learning applications; and ""(B) make such courses available to members of the Armed Forces. ""(2) REPORT.--Not later than 270 days after the date of the enactment of this subsection, the Secretary of Defense shall submit to the congressional defense committees a report on the progress of the Chief Digital and Artificial Intelligence Officer in implementing paragraph (1)."".",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Strategies: Government support: AI workforce-related, Strategies: Government support, Strategies: Government study or report"
1758,"Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025, Section 221 (""Improvements relating to defining, identifying, and planning the artificial intelligence workforce of the Department of Defense"")",United States Congress,United States,Federal government,FY2025 NDAA,Law/Act,2024-12-23,2024,12,positive,0.9861,low,0.0,205,0.7,Enacted,"SEC. 221. Improvements relating to defining, identifying, and planning the artificial intelligence workforce of the Department of Defense. (a) Appointment of responsible official .--Section 230 of the National Defense Authorization Act for Fiscal Year 2020 (Public Law 116-92; 10 U.S.C. note prec. 501) is amended by striking subsection (c) and inserting the following: ""(c) Responsibility.-- ""(1) APPOINTMENT OF OFFICER.--Not later than April 30, 2025, the Secretary of Defense shall appoint a civilian official responsible for the development and implementation of the policy and implementation plan set forth in subsections (a) and (b), respectively. The official shall be known as the 'Chief Digital Engineering Recruitment and Management Officer of the Department of Defense'. ""(2) ADDITIONAL RESPONSIBILITIES.--In addition to the responsibilities specified in paragraph (1), the Officer appointed under such paragraph shall-- ""(A) fully define and identify the artificial intelligence workforce of the Department of Defense, including by-- ""(i) clarifying the roles and responsibilities of the artificial intelligence workforce and the relationship between the artificial intelligence workforce and the overall Department of Defense innovation workforce and digital workforce; ""(ii) coding artificial intelligence workforce roles in workforce data systems; and ""(iii) developing a qualification program for artificial intelligence workforce roles; and ""(B) update the Department of Defense Huma",https://www.congress.gov/bill/118th-congress/house-bill/5009/text,en,"Applications: Government: military and public safety, Strategies: Government support, Strategies: Government support: AI workforce-related, Strategies: Government study or report, Strategies: Governance development"
1759,Michigan House Bill 5507,Michigan,United States,State governments,U.S. state and local documents,Law/Act,2024-07-30,2024,7,positive,0.9022,low,0.0,231,0.5,Enacted,"Sec. 98. (1) From the general fund money appropriated in section 11, there is allocated an amount not to exceed $9,800,000.00 for 2024-2025 for the purposes described in this section. It is the intent of the legislature that, for 2025-2026, the allocation from the general fund money appropriated in section 11 for purposes described in this section will be $8,000,000.00. The Michigan Virtual University shall provide a report to the legislature not later than November 1 of each fiscal year for which funding is allocated under this section that includes its mission, its plans, and proposed benchmarks it must meet, including a plan to achieve the organizational priorities identified in this section, to receive full funding for the next fiscal year for which funding is allocated under this section. By not later than March 1 of each fiscal year for which funding is allocated under this section, the Michigan Virtual University shall provide an update to the house and senate appropriations subcommittees on school aid to show the progress being made to meet the benchmarks identified. (2) The Michigan Virtual University shall operate the Michigan Virtual Learning Research Institute. The Michigan Virtual Learning Research Institute shall do all of the following: (a) Support and accelerate innovation in education through the following activities: (i) Test, evaluate, and recommend as appropriate new technology-based instructional tools and resources. (ii) Research, design, and recommend v",https://www.legislature.mi.gov/documents/2023-2024/publicact/pdf/2024-PA-0120.pdf,en,
1760,Maryland House Bill 1390,Maryland,United States,State governments,U.S. state and local documents,Law/Act,2024-04-25,2024,4,positive,0.2263,low,0.0,49,0.5,Enacted,"SECTION 5. AND BE IT FURTHER ENACTED, That the Interagency Commission on School Construction, on or before December 15, 2024, shall report to the General Assembly, in accordance with § 2–1257 of the State Government Article, on the eligibility for school construction funding for artificial intelligence weapon detection systems.",https://mgaleg.maryland.gov/2024RS/bills/hb/hb1390e.pdf,en,
1761,New Mexico Senate Bill 192,New Mexico,United States,State governments,U.S. state and local documents,Law/Act,2023-04-07,2023,4,positive,0.3607,low,0.0,209,0.5,Enacted,"SECTION 9. PUBLIC EDUCATION FISCAL YEAR 2023 APPROPRIATIONS.--The following appropriations to the public education department are from the general fund for expenditure in fiscal years 2023 and 2024 for the purposes specified and, unless otherwise indicated, the unexpended or unencumbered balance of an appropriation in this section at the end of fiscal year 2024 shall revert to the general fund: A. for statewide projects: (1) three hundred seventy-five thousand dollars ($375,000) for school-based inclusion programs that foster one-to-one friendships between students with and without intellectual and developmental disabilities; (2) one hundred twenty thousand dollars ($120,000) for a brain education program; (3) one hundred thousand dollars ($100,000) for high school dropout prevention programs serving at-risk populations; (4) one hundred fifty thousand dollars ($150,000) to contract for statewide in-person and virtual training to community and youth groups and to provide media literacy and multi-room production studio equipment; and (5) seventy-five thousand dollars ($75,000) to contract for a school re-engagement program that helps at-risk high school students graduate and attend college; B. one hundred thousand dollars ($100,000) to purchase stadium equipment and crew lights for the Alamogordo public school district; C. for the Albuquerque public school district: (1) one hundred fifty thousand dollars ($150,000) to provide enhanced six-week summer and other out-of-school-tim",https://www.nmlegis.gov/Sessions/23%20Regular/final/SB0192.pdf,en,
1762,Minnesota House Bill 4772,Minnesota,United States,State governments,U.S. state and local documents,Law/Act,2024-05-17,2024,5,negative,-0.9881,low,0.0,249,0.5,Enacted,"Sec. 76. Minnesota Statutes 2023 Supplement,section 609.771,subdivision 2, is amended to read: Subd. 2. Use of deep fake to influence an election; violation. (a) A person who disseminates a deep fake or enters into a contract or other agreement to disseminate a deep fake is guilty of a crime and may be sentenced as provided in subdivision 3 if the person knows or reasonably should know that acts with reckless disregard about whether the item being disseminated is a deep fake and dissemination: (1) takes place within 90 days before an election; (2) (1) is made without the consent of the depicted individual; and (3) (2) is made with the intent to injure a candidate or influence the result of an election; and (3) takes place either: (i) within 90 days before a political party nominating convention; or (ii) after the start of the absentee voting period prior to a presidential nomination primary, or a regular or special state or local primary or general election. (b) This subdivision does not apply to a broadcaster or cable television system that disseminates a deep fake produced by a candidate if the broadcaster's or cable television system's dissemination is required by federal law. Sec. 77. Minnesota Statutes 2023 Supplement,section 609.771,subdivision 3, is amended to read: Subd. 3. Use of deep fake to influence an election; penalty. (a) A person convicted of violating subdivision 2 may be sentenced as follows: (1) if the person commits the violation within five years of one o",https://www.revisor.mn.gov/bills/text.php?number=HF4772&type=bill&version=3&session=ls93&session_year=2024&session_number=0,en,
1763,Executive Order on Advancing United States Leadership in Artificial Intelligence Infrastructure (EO 14141),Executive Office of the President,United States,Federal government,Editors' Picks,Executive Order,2025-01-14,2025,1,positive,0.9953,low,0.2778,218,0.7,Enacted,"January 14, 2025 Executive Order on Advancing United States Leadership in Artificial Intelligence Infrastructure By the authority vested in me as President by the Constitution and the laws of the United States of America, it is hereby ordered as follows: Section 1. Purpose. Artificial intelligence (AI) is a defining technology of our era. Recent advancements in AI demonstrate its rapidly growing relevance to national security, including with respect to logistics, military capabilities, intelligence analysis, and cybersecurity. Building AI in the United States will help prevent adversaries from gaining access to, and using, powerful future systems to the detriment of our military and national security. It will also enable the United States Government to continue harnessing AI in service of national-security missions while preventing the United States from becoming dependent on other countries’ infrastructure to develop and operate powerful AI tools. Advances at the frontier of AI will also have significant implications for United States economic competitiveness. These imperatives require building AI infrastructure in the United States on the time frame needed to ensure United States leadership over competitors who, already, are racing to take the lead in AI development and adoption. Building AI in the United States requires enormous private-sector investments in infrastructure, especially for the advanced computing clusters needed to train AI models and the energy infrastructu",https://www.whitehouse.gov/briefing-room/presidential-actions/2025/01/14/executive-order-on-advancing-united-states-leadership-in-artificial-intelligence-infrastructure/,en,"Strategies: Governance development, Harms: Ecological harm, Strategies: Government study or report, Strategies: Convening, Strategies: Government support, Strategies: Government support: AI workforce-related, Strategies: Government support: For R&D, Harms: Harm to health/safety, Risk factors: Safety, Risk factors: Security, Risk factors: Security: Cybersecurity, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Applications: Government: other applications/unspecified"
1764,Minnesota Senate Bill 2909,Minnesota,United States,State governments,U.S. state and local documents,Law/Act,2023-05-16,2023,5,positive,0.5106,low,0.0,229,0.5,Enacted,"Sec. 28. [299C.055] LEGISLATIVE REPORT ON FUSION CENTER ACTIVITIES. (a) The superintendent must prepare an annual report for the public and the legislature on the Minnesota Fusion Center (MNFC) that includes general information about the MNFC; the types of activities it monitors; the scale of information it collects; the local, state, and federal agencies with which it shares information; and the quantifiable benefits it produces. None of the reporting requirements in this section supersede chapter 13 or any other state or federal law. The superintendent must report on activities for the preceding calendar year unless another time period is specified. The report must include the following information, to the extent allowed by other law: (1) the MNFC's operating budget for the current biennium, number of staff, and staff duties; (2) the number of publications generated and an overview of the type of information provided in the publications, including products such as law enforcement briefs, partner briefs, risk assessments, threat assessments, and operational reports; (3) a summary of audit findings for the MNFC and what corrective actions were taken pursuant to audits; (4) the number of data requestsreceived by the MNFC and a general description of those requests; (5) the types of surveillance and data analysis technologies utilized by the MNFC, such as artificial intelligence or social media analysis tools; (6) a description of the commercial and governmental databases utili",https://www.revisor.mn.gov/bills/text.php?number=SF2909&version=latest&session=ls93&session_year=2023&session_number=0,en,
1765,New York Assembly Bill A8808A,New York,United States,State governments,U.S. state and local documents,Law/Act,2024-04-20,2024,4,positive,0.8934,low,0.0,261,0.5,Enacted,"PART MM Section 1. Short title. This act shall be known and may be cited as the ""artificial intelligence deceptive practices act"". § 2. This act enacts into law major components of legislation neces- sary to implement the artificial intelligence deceptive practices act. Each component is wholly contained within a Subpart identified as Subparts A through C. The effective date for each particular provision contained within such Subpart is set forth in the last section of such Subpart. Any provision in any section contained within a Subpart, including the effective date of the Subpart, which makes a reference to a section ""of this act"", when used in connection with that particular component, shall be deemed to mean and refer to the corresponding section of the Subpart in which it is found. Section four of this act sets forth the general effective date of this act. SUBPART A Section 1. Section 50 of the civil rights law is amended to read as follows: § 50. Right of privacy. A person, firm or corporation that uses for advertising purposes, or for the purposes of trade, the name, portrait [or], picture, LIKENESS, OR VOICE of any living person without having first obtained the written consent of such person, or if a minor of [his or her] SUCH MINOR'S parent or guardian, is guilty of a misdemeanor. § 2. Section 51 of the civil rights law, as amended by chapter 674 of the laws of 1995, is amended to read as follows: § 51. Action for injunction and for damages. Any person whose name, p",https://www.nysenate.gov/legislation/bills/2023/A8808/amendment/A,en,
1766,Wyoming House Bill 1,Wyoming,United States,State governments,U.S. state and local documents,Law/Act,2024-03-22,2024,3,positive,0.6369,low,0.0,223,0.5,Enacted,"Section 067. UNIVERSITY OF WYOMING PROGRAM | Amount | Additional | Total ----------------------------------------------------------------------------------- State Aid 1., 2., 3., 4., 5., | 401,227,647 | | 401,227,647 12., 13. | | | School of Energy Res. 6., | 23,857,808 | 19,000,000 S13 | 42,857,808 7., 8., 9. | | | Tier 1 Engineering | 18,584,703 | | 18,584,703 NCAR MOU | 1,528,316 | | 1,528,316 Endowments & Matching | 39,500,000 | | 39,500,000 10., 11., 12., 14. | | | ----------------------------------------------------------------------------------- TOTALS | 484,698,474 | 19,000,000 | 503,698,474 AUTHORIZED EMPLOYEES Full Time | 0 Part Time | 0 TOTAL | 0 1. Of this general fund appropriation, three million dollars ($3,000,000.00) is to fund graduate assistantship stipends. This appropriation shall not be transferred or expended for any other purpose. 2. Of this general fund appropriation, two million five hundred thousand dollars ($2,500,000.00) is for building artificial intelligence expertise. Expenditure of this appropriation is conditioned upon a match of funds in the ratio of one dollar ($1.00) of appropriated general funds to not less than one dollar ($1.00) of matching funds from any person. For purposes of this footnote, ""person"" includes an individual, partnership, corporation, joint stock company or any other association or entity, excluding all public entities. It is the intent of the legislature that this appropriation not be included in the University of Wyomi",https://wyoleg.gov/2024/Enroll/HB0001.pdf,en,
1768,South Carolina 2023 H 4754 (Section 4),South Carolina,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-05-21,2024,5,positive,0.296,low,0.0,73,0.5,Enacted,"SECTION 4. Article 7, Chapter 57, Title 40 of the S.C. Code is amended by adding: Section 40-57-820. A licensee under this chapter is responsible for any and all work product produced by him or with the assistance of artificial intelligence, machine learning, or similar programs. A violation of this chapter that is committed through the use of these programs will be treated as if the violation was committed directly by the licensee.",https://www.scstatehouse.gov/sess125_2023-2024/bills/4754.htm,en,
1769,Oregon Senate Bill 5701,Oregon,United States,State governments,U.S. state and local documents,Law/Act,2024-04-17,2024,4,positive,0.6369,low,0.0,76,0.5,Enacted,"SECTION 488. Notwithstanding any other provision of law, the General Fund appropriation made to the Higher Education Coordinating Commission by section 1 (9), chapter 454, Oregon Laws 2023, for the biennium ending June 30, 2025, for public university statewide programs, is increased by $100,000, for distribution to the University of Oregon Labor Education and Research Center to research the potential workforce impacts across Oregon’s key economic industries to understand the impact of automation and artificial intelligence.",https://olis.oregonlegislature.gov/liz/2024R1/Downloads/MeasureDocument/SB5701/Enrolled,en,
1770,"G20 Ministerial Statement on Trade and Digital Economy (Section I, Subsection 3 ""Human-centered Artificial Intelligence"")",Other multinational,Multinational,Multinational,Multinational,Other,2019-06-09,2019,6,positive,0.995,low,0.0,224,0.5,Proposed,"3. Human-centered Artificial Intelligence (AI) 17. Recognizing the efforts undertaken so far by all stakeholders in their respective roles including governments, international organizations, academia, civil society and the private sector, and mindful of how technology impacts society, the G20 endeavors to provide an enabling environment for human-centered AI that promotes innovation and investment, with a particular focus on digital entrepreneurship, research and development, scaling up of startups in this area, and adoption of AI by MSMEs which face disproportionally higher costs to adopt AI. 18. We recognize that AI technologies can help promote inclusive economic growth, bring great benefits to society, and empower individuals. The responsible development and use of AI can be a driving force to help advance the SDGs and to realize a sustainable and inclusive society, mitigating risks to wider societal values. The benefits brought by the responsible use of AI can improve the work environment and quality of life, and create potential for realizing a human centered future society with opportunities for everyone, including women and girls as well as vulnerable groups. 19. At the same time, we also recognize that AI, like other emerging technologies, may present societal challenges, including the transitions in the labor market, privacy, security, ethical issues, new digital divides and the need for AI capacity building. To foster public trust and confidence in AI technologies",https://wp.oecd.ai/app/uploads/2021/06/G20-AI-Principles.pdf,en,
1771,"G20 Ministerial Statement on Trade and Digital Economy (Annex ""G20 AI Principles"")",Other multinational,Multinational,Multinational,Multinational,Other,2019-06-09,2019,6,positive,0.9963,low,0.0,204,0.5,Proposed,"G20 AI Principles The G20 supports the Principles for responsible stewardship of Trustworthy AI in Section 1 and takes note of the Recommendations in Section 2. Section 1: Principles for responsible stewardship of trustworthy AI 1.1. Inclusive growth, sustainable development and well-being Stakeholders should proactively engage in responsible stewardship of trustworthy AI in pursuit of beneficial outcomes for people and the planet, such as augmenting human capabilities and enhancing creativity, advancing inclusion of underrepresented populations, reducing economic, social, gender and other inequalities, and protecting natural environments, thus invigorating inclusive growth, sustainable development and well-being. 1.2. Human-centered values and fairness a) AI actors should respect the rule of law, human rights and democratic values, throughout the AI system lifecycle. These include freedom, dignity and autonomy, privacy and data protection, non-discrimination and equality, diversity, fairness, social justice, and internationally recognized labor rights. b) To this end, AI actors should implement mechanisms and safeguards, such as capacity for human determination, that are appropriate to the context and consistent with the state of art. 1.3. Transparency and explainability AI Actors should commit to transparency and responsible disclosure regarding AI systems. To this end, they should provide meaningful information, appropriate to the context, and consistent with the state of",https://wp.oecd.ai/app/uploads/2021/06/G20-AI-Principles.pdf,en,
1773,"Dubai International Financial Centre Data Protection Regulations, Regulation 10 (""Personal data processed through autonomous and semi-autonomous systems"")",Government of the United Arab Emirates,Other countries,Other countries,Miscellaneous documents,Regulation,2023-09-01,2023,9,positive,0.9545,low,0.0,249,0.5,Enacted,"10. PERSONAL DATA PROCESSED THROUGH AUTONOMOUS AND SEMI-AUTONOMOUS SYSTEMS 10.1 Autonomous and Semi-Autonomous Systems 10.1.1 For the purposes of this Regulation 10, unless otherwise specified herein: (a) “System” or “Systems” shall mean any machine-based system operating in an autonomous or semiautonomous manner, that can: (i) Process Personal Data for human-defined purposes or purposes that the system itself defines, or both; and (ii) generate output as a result of or on the basis of such Processing. (b) “Deployer” means, with respect to a System, the natural or legal person (i) under whose authority or on whose direction or for whose benefit the System is operated, or (ii) who receives the benefit of the operation of the System or any output generated by the System in each case without regard to whether or not the System is operated, supervised or hosted by such person, or such person defines or determines any of the purposes of which Personal Data is Processed by such System. (c) “Operator” means a Provider that operates or supervises a System on behalf or otherwise for the benefit, and on the direction of a Deployer, in each case without regard to whether or not that Provider exercises any control over the Processing of Personal Data by the System. (d) “Provider” means a natural or legal person that develops a System, or procures that a System is developed for or on behalf of such person, in each case with a view to providing, commercialising or otherwise making such Sys",https://www.dataguidance.com/sites/default/files/data_protection_regualtions_final.pdf,en,
1774,Utah House Bill 534,Utah,United States,State governments,U.S. state and local documents,Law/Act,2024-03-21,2024,3,positive,0.9729,low,0.0,197,0.5,Enacted,"Section 55, Section 53B-26-301 is amended to read: 53B-26-301 (Effective 05/01/24). Definitions. As used in this part: (1) ""Advisory council"" means the Deep Technology Talent Advisory Council created in Section 53B-26-303. (2) (1) (a)""Deep technology"" means technology that leads to new products and innovations based on scientific discovery or meaningful engineering innovation. (b)""Deep technology"" may include technology that leads to new products and innovations related to one or more of the following: (i)advanced materials; (ii)artificial intelligence; (iii)augmented and virtual reality; (iv)biotechnology; (v)photonics; (vi)quantum computing; (vii)robotics; (viii)secure computing; and (ix)other emerging technologies as determined by the advisory council board. (3) (2) ""Institution of higher education"" means the University of Utah, Utah State University, Southern Utah University, Weber State University, Snow College, Utah Tech University, Utah Valley University, or Salt Lake Community College. Section 56, Section 53B-26-302 is amended to read: 53B-26-302 (Effective 05/01/24). Deep technology initiative. (1)Subject to appropriations from the Legislature and in accordance with the proposal process and other provisions of this section, the board shall develop and oversee a deep technology talent initiative that includes providing funding for expanded programs in deep technology. (2)The board shall facilitate collaborations that create expanded, multidisciplinary programs or stac",https://le.utah.gov/~2024/bills/static/HB0534.html,en,
1775,Washington Senate Bill 5950,Washington,United States,State governments,U.S. state and local documents,Law/Act,2024-03-29,2024,3,positive,0.7351,low,0.0,66,0.5,Enacted,"(50) $300,000 of the general fund—state appropriation for fiscal year 2024 and $500,000 of the general fund—state appropriation for fiscal year 2025 are provided solely for the city of Seattle to lease space for nonprofit and academic institutions to incubate technology business startups, especially those focusing on artificial intelligence and develop and teach curricula to skill up workers to use artificial intelligence as a business resource.",https://fiscal.wa.gov/statebudgets/2024proposals/Documents/co/5950-S.SL.pdf,en,
1777,"Illinois HB 4844 (2024), Section 90 (""Generative AI and Natural Language Processing Task Force"")",Illinois,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-07-01,2024,7,positive,0.9578,low,0.0,236,0.5,Enacted,"Section 90. The Department of Innovation and Technology Act is amended by changing Section 1-80 as follows: (20 ILCS 1370/1-80) Sec. 1-80. Generative AI and Natural Language Processing Task Force. (a) As used in this Section, ""Task Force"" means the Generative AI and Natural Language Processing Task Force established by this Section. (b) The Department shall establish the Generative AI and Natural Language Processing Task Force. The Task Force shall investigate and provide a report on generative artificial intelligence software and natural language processing software. (c) The Task Force shall be composed of all of the following members: (1) One member appointed by the Speaker of the House of Representatives, who shall serve as a co-chairperson. (2) One member appointed by the Minority Leader of the House of Representatives. (3) One member appointed by the President of the Senate, who shall serve as a co-chairperson. (4) One member appointed by the Minority Leader of the Senate. (5) The Secretary of Innovation and Technology or his or her designee. (6) The State Superintendent of Education or his or her designee. (7) The Executive Director of the Illinois Community College Board or his or her designee. (8) The Executive Director of the Board of Higher Education or his or her designee. (9) Two teachers recommended by a statewide association representing teachers, appointed by the Governor. (10) Two principals recommended by a statewide principals association, appointed by the G",https://www.ilga.gov/legislation/publicacts/103/PDF/103-0605.pdf,en,
1778,North Carolina House Bill 259,North Carolina,United States,State governments,U.S. state and local documents,Law/Act,2023-10-03,2023,10,positive,0.9543,low,0.0,212,0.5,Enacted,"SECTION 7.36.(h) Artificial Intelligence (AI) Pilot. – Of the funds appropriated to the Department of Public Instruction by this act for the grants provided in this section for the 2023-2024 fiscal year, the Department shall allocate (i) three million two hundred thousand dollars ($3,200,000) as a directed grant to New Hanover County Schools and (ii) two million dollars ($2,000,000) as a directed grant to Davidson County Schools for an AI School Safety Pilot Program. In conducting the Pilot Program, participating public school units shall comply with the following: (1) Funds allocated for the Pilot Program shall be used for the implementation of a school safety system that integrates AI technology into existing access controls, alerting protocols, and intercom systems. (2) No later than January 15, 2025, the participating public school units, in coordination with the Department of Public Instruction, shall report to the Joint Legislative Education Oversight Committee the following information: a. The schools that participated in the Pilot Program. b. How grant funds were spent. c. The impact the Pilot Program had on school safety outcomes. d. Any noted capabilities of the AI system that could not be accomplished by more traditional safety measures. e. Any other information the participating public school units or the Department deem relevant to the report.",https://www.ncleg.gov/Sessions/2023/Bills/House/PDF/H259v6.pdf,en,
1779,Maryland Senate Bill 360,Maryland,United States,State governments,U.S. state and local documents,Law/Act,2024-05-16,2024,5,positive,0.8271,low,0.0,68,0.5,Enacted,"(50) $500,000 in general funds is added to the appropriation for program R75T00.01 Support for State Operated Institutions of Higher Education for R13M00 Morgan State University for the purpose of supporting the Center for Equitable Artificial Intelligence and Machine Learning Systems. Funds not expended for this added purpose may not be transferred by budget amendment or otherwise to any other purpose and shall revert to the General Fund;",https://legiscan.com/MD/text/SB360/2024,en,
1780,Executive Order on Removing Barriers To American Leadership In Artificial Intelligence,Executive Office of the President,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Executive Order,2025-01-23,2025,1,positive,0.9946,low,0.1111,236,0.7,Enacted,"REMOVING BARRIERS TO AMERICAN LEADERSHIP IN ARTIFICIAL INTELLIGENCE EXECUTIVE ORDER January 23, 2025 By the authority vested in me as President by the Constitution and the laws of the United States of America, it is hereby ordered as follows: Section 1. Purpose. The United States has long been at the forefront of artificial intelligence (AI) innovation, driven by the strength of our free markets, world-class research institutions, and entrepreneurial spirit. To maintain this leadership, we must develop AI systems that are free from ideological bias or engineered social agendas. With the right Government policies, we can solidify our position as the global leader in AI and secure a brighter future for all Americans. This order revokes certain existing AI policies and directives that act as barriers to American AI innovation, clearing a path for the United States to act decisively to retain global leadership in artificial intelligence. Sec. 2. Policy. It is the policy of the United States to sustain and enhance America’s global AI dominance in order to promote human flourishing, economic competitiveness, and national security. Sec. 3. Definition. For the purposes of this order, “artificial intelligence” or “AI” has the meaning set forth in 15 U.S.C. 9401(3). Sec. 4. Developing an Artificial Intelligence Action Plan. (a) Within 180 days of this order, the Assistant to the President for Science and Technology (APST), the Special Advisor for AI and Crypto, and the Assistant to the",https://www.whitehouse.gov/presidential-actions/2025/01/removing-barriers-to-american-leadership-in-artificial-intelligence/,en,"Risk factors: Bias, Strategies: Government support, Risk factors: Security, Strategies: Governance development"
1781,Mississippi Executive Order No. 1584,Mississippi,United States,State governments,U.S. state and local documents,Executive Order,2025-01-08,2025,1,positive,0.9675,low,0.2778,233,0.7,Enacted,"STATE OF MISSISSIPPI Office of the Governor EXECUTIVE ORDER NO. 1584 WHEREAS, the State of Mississippi (""the State"") recognizes that artificial intelligence technologies (""AI"") are already being utilized by state agencies, that such emerging technologies will transform the way the State conducts business and provides services to its citizens, and that such technologies must also be carefully deployed to mitigate potential risks and harms; and WHEREAS, the State aspires to fully harness AI to modernize the delivery of services to its citizens in a more efficient and effective manner, while at the same time protecting and respecting the privacy, security and confidentiality rights of all Mississippians; and WHEREAS, to address AI, state agencies should identify and prepare for potential risks and harms as they deploy AI tools and systems throughout state government. To this end, the State needs to support stakeholders as they gather information and decide what, when, where, and how to utilize and oversee the use of these technologies; and WHEREAS, the State acknowledges AI cannot completely replace human creativity or involvement and wishes to promote the responsible use of AI tools and systems in a manner that aligns and is consistent with the State's policies, goals, values, and missions while maintaining citizen trust and balancing the benefits, risks, and potential harms of AI; and WHEREAS, as the use of AI has implications for state, national, and personal security and pri",https://mcusercontent.com/08cb3e52aa1308600f84d49ea/files/e91a16a0-1bae-0eb8-4c6d-04ffa4f82a6d/Executive_Order_1584_AI.pdf,en,"Strategies: Evaluation, Strategies: Governance development, Risk factors: Privacy, Risk factors: Security, Risk factors: Safety, Risk factors: Transparency, Risk factors: Reliability, Strategies: Convening, Strategies: Disclosure"
1782,New York artificial intelligence act (New York AI act),New York,United States,State governments,U.S. state and local documents,Law/Act,2025-01-08,2025,1,positive,0.9663,medium,0.6111,241,0.7,Proposed,"S T A T E O F N E W Y O R K ________________________________________________________________________ 1169 2025-2026 Regular Sessions I N S E N A T E January 8, 2025 ___________ Introduced by Sen. GONZALEZ -- read twice and ordered printed, and when printed to be committed to the Committee on Internet and Technology AN ACT to amend the civil rights law and the executive law, in relation to the use of artificial intelligence systems THE PEOPLE OF THE STATE OF NEW YORK, REPRESENTED IN SENATE AND ASSEM- BLY, DO ENACT AS FOLLOWS: Section 1. This act shall be known and may be cited as the ""New York artificial intelligence act (New York AI act)"". § 2. Legislative findings and intent. The legislature finds and declares the following: (a) A revolution in artificial intelligence (AI) has advanced to the point that comprehensive regulations must be enacted to protect New Yorkers. (b) Artificial intelligence is already an integral part of New York- ers' daily lives. In the private sector, AI is currently in use in areas such as education, health care, employment, insurance, credit scoring, public safety, retail, banking and financial services, media, and more with little transparency or oversight. A growing body of research shows that AI systems that are deployed without adequate testing, sufficient oversight and robust guardrails can harm consumers and deny historically disadvantaged groups the full measure of their civil rights and liber- ties, thereby further entrenching inequalities.",https://www.nysenate.gov/legislation/bills/2025/S1169,en,"Risk factors: Bias, Risk factors: Privacy, Harms: Violation of civil or human rights, including privacy, Risk factors: Safety, Harms: Harm to health/safety, Applications: Education, Applications: Medicine, life sciences and public health, Applications: Government: judicial and law enforcement, Applications: Government: benefits and welfare, Applications: Consumer goods, Harms: Discrimination, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: In standard form, Risk factors: Transparency"
1783,Framework to Mitigate AI-Enabled Extreme Risks,Federal government,United States,United States,Editors' Picks,Other,2024-04-16,2024,4,positive,0.5552,low,0.1667,223,1.0,Enacted,"Framework to Mitigate AI-Enabled Extreme Risks The following proposal establishes a framework for federal oversight of frontier model hardware, development, and deployment to mitigate AI-enabled extreme risks, including biological, chemical, cyber, and nuclear threats. Frontier Models: Frontier models – those covered under this framework – would be only the most advanced AI models developed in the future – those that are both: (1) trained on an enormous amount of computing power – greater than 10^26 operations, and that (2) are either broadly-capable, general purpose, and able to complete a variety of downstream tasks, or are intended to be used for bioengineering, chemical engineering, cybersecurity, or nuclear development. The 10^26 operations compute threshold is the standard identified by Executive Order 14110, and it represents a metric which would be reevaluated on a regular basis to ensure it remains appropriate as technological advancements occur. Oversight of Frontier Models: I. Hardware Training a frontier model would require tremendous computing resources. Entities that sell or rent the use of a large amount of computing hardware, potentially set at the level specified by E.O. 14110, for AI development would report large acquisitions or usage of such computing resources to the oversight entity and exercise due diligence to ensure that customers are known and vetted, particularly with respect to foreign persons. II. Development of Frontier Models Developers would no",https://www.king.senate.gov/imo/media/doc/bipartisan_ai_framework_letter.pdf,en,"Applications: Security, Applications: Medicine, life sciences and public health, Applications: Manufacturing and process automation, Risk factors: Security: Cybersecurity, Risk factors: Security, Strategies: Disclosure, Strategies: Disclosure: About inputs, Strategies: Input controls, Strategies: Input controls: Compute circulation, Risk factors: Security: Dissemination, Strategies: Performance requirements, Strategies: Licensing, registration, and certification, Strategies: Evaluation, Strategies: Tiering, Strategies: Evaluation: Conformity assessment"
1801,AI in America: OpenAI's Economic Blueprint,Private-sector companies,,,Corporate policies and commitments,Other,2025-01-13,2025,1,positive,0.9969,medium,0.3889,241,0.7,Enacted,"[foreword omitted] Where We Stand The enclosed policy proposals reflect OpenAI’s position that: - We believe in America because America believes in innovation. - Chips, data, energy and talent are the keys to winning on AI—and this is a race America can and must win. - With an estimated $175 billion sitting in global funds awaiting investment in AI projects, if the US doesn’t attract those funds, they will flow to China-backed projects—strengthening the Chinese Communist Party’s global influence. - Rules and regulations for the development and use of AI should be based on the democratic values the country has always stood for—what we think of as “democratic AI.” - As for any industry, we need common-sense rules of the road that safeguard the public while helping innovators thrive by encouraging investment, competition, and greater freedom for everyone—and to best achieve this, these rules should apply nationwide. Competitiveness and Security We believe that making sure AI benefits the most people possible means enabling AI through common-sense rules aimed at protecting people from actual harms, and building democratic AI shaped by the values the US has always stood for, including: - A free market promoting free and fair competition that drives innovation - Freedom for developers and users to work with and direct our tools as they see fit, in exchange for following clear, common-sense standards that help keep AI safe for everyone, and being held accountable when they don’t - P",https://cdn.openai.com/global-affairs/ai-in-america-oai-economic-blueprint-20250113.pdf,en,"Harms: Violation of civil or human rights, including privacy, Risk factors: Security, Risk factors: Security: Dissemination, Strategies: Governance development, Strategies: Government support, Risk factors: Security: Cybersecurity, Harms: Harm to health/safety, Risk factors: Safety, Strategies: Convening, Harms: Detrimental content, Strategies: Disclosure, Strategies: Pilots and testbeds"
1802,AI Safety Governance Framework v1.0 (National Technical Committee 260 on Cybersecurity of SAC),Other authorities,,,Chinese law and policy,Other,2024-09-01,2024,9,positive,0.9965,high,0.8333,198,0.7,Enacted,"AI Safety Governance Framework (V1.0) Artificial Intelligence (AI), a new area of human development, presents significant opportunities to the world while posing various risks and challenges. Upholding a people-centered approach and adhering to the principle of developing AI for good, this framework has been formulated to implement the Global AI Governance Initiative and promote consensus and coordinated efforts on AI safety governance among governments, international organizations, companies, research institutes, civil organizations, and individuals, aiming to effectively prevent and defuse AI safety risks. 1. Principles for AI safety governance -Commit to a vision of common, comprehensive, cooperative, and sustainable security while putting equal emphasis on development and security -Prioritize the innovative development of AI -Take effectively preventing and defusing AI safety risks as the starting point and ultimate goal -Establish governance mechanisms that engage all stakeholders, integrate technology and management, and ensure coordinated efforts and collaboration among them -Ensure that all parties involved fully shoulder their responsibilities for AI safety -Create a whole-process, all-element governance chain -Foster a safe, reliable, equitable, and transparent AI for the technical research, development, and application -Promote the healthy development and regulated application of AI -Effectively safeguard national sovereignty, security and development interests -Pr",https://www.tc260.org.cn/upload/2024-09-09/1725849192841090989.pdf,en,"Risk factors: Security, Risk factors: Safety, Strategies: Convening, Risk factors: Transparency, Harms: Violation of civil or human rights, including privacy, Strategies: Governance development, Risk factors: Reliability, Risk factors: Reliability: Robustness, Strategies: Evaluation, Risk factors: Interpretability and explainability, Harms: Discrimination, Strategies: Input controls, Risk factors: Privacy, Strategies: Input controls: Data use, Strategies: Input controls: Data circulation"
1803,Freedom Online Coalition Joint Statement on Responsible Government Practices for AI Technologies,Other multinational,Multinational,Multinational,Multinational,Law/Act,2024-09-23,2024,9,positive,0.9914,medium,0.5556,206,1.0,Enacted,"Media Note Office of the Spokesperson September 23, 2024 The following is the joint statement released by the Freedom Online Coalition, whose member states include Argentina, Australia, Austria, Cabo Verde, Canada, Chile, Costa Rica, Czech Republic, Denmark, Estonia, Finland, France, Georgia, Germany, Ghana, Ireland, Iceland, Italy, Japan, Kenya, Republic of Korea, Latvia, Lithuania, Luxembourg, Maldives, Mexico, Moldova, Mongolia, the Netherlands, New Zealand, Norway, Poland, Slovakia, Slovenia, Spain, Sweden, Switzerland, Tunisia, the United Kingdom, and the United States. Begin text: We, the member countries of the Freedom Online Coalition (FOC), recognize that safe, secure, and trustworthy artificial intelligence (AI) systems, when designed, developed, procured, deployed, used, and decommissioned responsibly, offer immense opportunities for governments to improve public service delivery, increase efficiency, and foster sustainable, inclusive development for all and advance the achievement of the 2030 Agenda for Sustainable Development. At the same time, the design, development, procurement, deployment, use, and decommissioning of AI systems without adequate safeguards or in a manner inconsistent with international law pose risks that can undermine the protection of, promotion of, and ability to exercise and enjoy human rights and fundamental freedoms. AI tools can create, contribute to, or exacerbate risks related to safety and privacy; the full exercise or enjoyment of h",https://pl.usembassy.gov/freedom-online-coalition-joint-statement-on-responsible-government-practices-for-ai-technologies/,en,"Strategies: Governance development, Strategies: Performance requirements, Harms: Violation of civil or human rights, including privacy, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Risk factors: Bias, Risk factors: Safety, Strategies: Evaluation: Conformity assessment, Strategies: Convening, Strategies: Evaluation: Adversarial testing, Risk factors: Reliability, Risk factors: Reliability: Robustness, Harms: Discrimination, Strategies: Tiering, Strategies: Tiering: Tiering based on domain of application"
1804,Joint Statement on Risk Assessment of Advanced AI Systems (International Network of AI Safety Institutes),Other multinational,Multinational,Multinational,Multinational,Other,2024-11-20,2024,11,positive,0.9371,low,0.1667,221,0.7,Enacted,"Assessing the risks of advanced AI systems, which include systems referred to as frontier AI systems, dual-use foundation models, general-purpose AI models, and advanced generative AI systems, presents novel challenges. Advanced AI systems have capabilities across a broad range of contexts, enabling them to be used and misused, accidentally or intentionally, in ways that can be difficult to predict, measure, and mitigate. Addressing these challenges is core to the mission of the International Network of AI Safety Institutes. Following commitments made in the Bletchley Declaration and the Seoul Statement of Intent, as well as the progress made through the OECD, G7 Hiroshima Process, the Frontier AI Safety Commitments, and other relevant initiatives, in this document the International Network of AI Safety Institutes highlights six key aspects of risk assessment of advanced AI systems. The Network is committed to building on these six key aspects to establish a shared scientific basis for risk assessments of advanced AI systems. This may involve conducting joint risk assessments and cooperative scientific research, recognizing that the science and practice of advanced AI risk assessment continues to evolve. Individual network members retain flexibility to conduct, apply, and adapt any risk assessments or risk-benefit trade-offs in line with international and domestic frameworks. Key aspects of risk assessment of advanced AI systems: 1. Actionable Risk assessments should be carri",https://www.nist.gov/system/files/documents/2024/11/20/Joint%20Statement%20on%20Risk%20Assessment%20of%20Advanced%20AI%20Systems.pdf,en,"Strategies: Evaluation, Strategies: Convening, Strategies: Governance development, Risk factors: Safety, Strategies: Tiering, Strategies: Performance requirements, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Risk factors: Privacy, Harms: Ecological harm, Strategies: Evaluation: Post-market monitoring, Strategies: Evaluation: External auditing"
1805,Provisions Pertaining to U.S. Investments in Certain National Security Technologies and Products in Countries of Concern,Department of the Treasury,United States,Federal government,Editors' Picks,Regulation,2024-11-15,2024,11,positive,0.9787,low,0.1111,208,0.7,Enacted,"PART 850—PROVISIONS PERTAINING TO U.S. INVESTMENTS IN CERTAIN NATIONAL SECURITY TECHNOLOGIES AND PRODUCTS IN COUNTRIES OF CONCERN Subpart A—General § 850.101 Scope. (a) This part implements Executive Order 14105 of August 9, 2023, “Addressing United States Investments in Certain National Security Technologies and Products in Countries of Concern” (the Order), directing the Secretary of the Treasury (the Secretary), in consultation with the Secretary of Commerce and, as appropriate, the heads of other relevant executive departments and agencies, to issue, subject to public notice and comment, regulations that require U.S. persons to provide notification of information relative to certain transactions involving covered foreign persons and that prohibit U.S. persons from engaging in certain other transactions involving covered foreign persons. (b) The regulations identify certain types of transactions that are covered transactions—that is, transactions that are either notifiable or prohibited. Additionally, the regulations identify other instances where a U.S. person has obligations with respect to certain transactions. The regulations prescribe exceptions to the definition of covered transaction. A transaction that meets an exception is not a covered transaction and is referred to as an excepted transaction. Finally, the regulations prescribe a process for the Secretary to exempt certain covered transactions from the rules otherwise prohibiting or requiring notification of cove",https://www.federalregister.gov/documents/2024/11/15/2024-25422/provisions-pertaining-to-us-investments-in-certain-national-security-technologies-and-products-in#print,en,"Applications: Security, Applications: Government: military and public safety, Risk factors: Security, Risk factors: Security: Cybersecurity, Strategies: Tiering, Strategies: Tiering: Tiering based on domain of application, Strategies: Tiering: Tiering based on inputs, Incentives: Access to business opportunities, Incentives: Civil liability"
1806,Common Intelligence Community Interim Guidance Regarding the Acquisition and Use of Foundation AI Models,Federal government,United States,United States,"U.S. regulations, executive orders, and agency policies",Regulation,2024-10-24,2024,10,positive,0.9915,low,0.2222,202,0.7,Proposed,"Common Intelligence Community Interim Guidance Regarding the Acquisition and Use of Foundation AI Models The Intelligence Community (IC) is authorized to collect, retain, and disseminate U.S. person information for approved purposes in accordance with Executive Order (E.O.) 12333 and Attorney General-approved Guidelines (AG Guidelines) promulgated thereunder. The principles and protections provided through E.O. 12333 and the AG Guidelines are core to ensuring that the IC can acquire, analyze, and produce intelligence while simultaneously protecting individual rights and interests, including the freedoms, civil liberties, and privacy rights guaranteed by law. With respect to commercially available information and artificial intelligence (AI), these principles and protections are supplemented by, among other things, The Principles of Artificial Intelligence Ethics for the Intelligence Community, the Intelligence Community Policy Framework for Commercially Available Information (CAI Framework), and the Framework to Advance AI Governance and Risk Management in National Security (AI Framework). As recognized in E.O. 14110 and the forthcoming National Security Memorandum (NSM) on AI, foundation models (FMs), especially frontier models such as large language models (LLMs), can play an important role in protecting national security. IC elements may therefore seek to use such technologies responsibly in furtherance of their authorized missions, consistent with applicable law and guida",https://static01.nyt.com/newsgraphics/documenttools/4bdb5f4804e797e6/6fe2f6c0-full.pdf?ref=forever-wars.com,en,"Applications: Government: military and public safety, Strategies: Governance development, Strategies: Convening, Risk factors: Privacy, Harms: Violation of civil or human rights, including privacy, Risk factors: Security, Strategies: Evaluation, Risk factors: Security: Dissemination, Strategies: Input controls, Strategies: Input controls: Data circulation, Strategies: Input controls: Data use, Strategies: Disclosure, Strategies: Disclosure: About inputs, Strategies: Disclosure: In deployment, Strategies: Disclosure: In standard form"
1808,JSP 936 V1.1 Dependable Artificial Intelligence (AI) in Defence (part 1: directive),Government of the United Kingdom,Other countries,Other countries,Miscellaneous documents,Other,2024-11-01,2024,11,positive,0.9752,low,0.0,239,0.5,Enacted,"JSP 936 V1.1 Dependable Artificial Intelligence (AI) in Defence Part 1: Directive [Introductory material omitted. Figures and footnotes omitted throughout.] 1 Introduction Policy 1. The Defence AI Strategy [1] and associated policy statement [2] (known as the Ambitious, Safe, Responsible, or ASR, document) set out how MOD will adopt and deploy AI in ways that are both effective and aligned to the UK’s democratic values. 2. A holistic approach should be adopted when considering the AI Strategy; for example, it is closely linked to the MOD’s strategies for data [3] and digital backbone [4]. 3. In keeping with broad consensus, the MOD adopts the UK National AI Strategy [5] position that no single definition of AI is suitable across its range of applications. Therefore, a general characterisation is made for AI as follows: ‘Machines that perform tasks normally requiring human intelligence, especially when the machines learn from data how to do those tasks.’ Note that Machine Learning (ML) is a subset of AI but has become so prevalent that AI is often referred to as AI/ML. ML is not further characterised here as it is encompassed in the characterisation above. 4. UK Government has also set out a legal definition in the National Security and Investments Act (see [6] for more information) which has greater clarity but is arguably less helpful for practical purposes in the context of this document: ‘Technology designed to approximate cognitive abilities including reasoning, perceptio",https://assets.publishing.service.gov.uk/media/6735fc89f6920bfb5abc7b62/JSP936_Part1.pdf,en,
1809,"AMBITIOUS, SAFE, RESPONSIBLE: Our approach to the delivery of AI-enabled capability in Defence",Government of the United Kingdom,Other countries,Other countries,Miscellaneous documents,Other,2022-06-14,2022,6,positive,0.9902,low,0.0,232,0.5,Enacted,"Ministry of Defence AMBITIOUS, SAFE, RESPONSIBLE Our approach to the delivery of AI-enabled capability in Defence June 2022 This policy statement should be read in conjunction with the Defence AI Strategy 2022 Ambitious, Safe, Responsible 2022 v1.0 June 2022 Conditions of Release This publication is UK Ministry of Defence (MOD) Crown copyright. Material and information contained in this publication may be reproduced, stored in a retrieval system and transmitted for UK government and MOD use only, except where authority for use by other organisations or individuals has been authorised. Executive Summary Defining Artificial Intelligence Defence understands Artificial Intelligence (AI) as a family of general-purpose technologies, any of which may enable machines to perform tasks normally requiring human or biological intelligence, especially when the machines learn from data how to do those tasks. The Defence AI Strategy sets out our view of the strategic opportunities and challenge presented by the emergence of AI as a transformative and disruptive new technology. Realising the benefits of AI – and countering threats and challenges associated with the use of AI by others – is one of the most critical strategic challenges of our time. AI will enable our people to make powerful use of previously unimaginable quantities of data. It will improve decision-making and the delivery of operational effect. There is a strong case for the development and use of an AI system where it would",https://assets.publishing.service.gov.uk/media/62a9b1d1e90e07039e31b8cb/20220614-Ambitious_Safe_and_Responsible.pdf,en,
1815,Texas Responsible Artificial Intelligence Governance Act (HB 1709),Texas,United States,State governments,Editors' Picks,Law/Act,2024-12-23,2024,12,positive,0.9888,medium,0.4444,219,0.7,Proposed,"AN ACT relating to the regulation and reporting on the use of artificial intelligence systems by certain business entities and state agencies; providing civil penalties. BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF TEXAS: SECTION 1. This Act may be cited as the Texas Responsible Artificial Intelligence Governance Act. SECTION 2. Title 11, Business & Commerce Code, is amended by adding Subtitle D to read as follows: SUBTITLE D. ARTIFICIAL INTELLIGENCE PROTECTION CHAPTER 551. ARTIFICIAL INTELLIGENCE PROTECTION SUBCHAPTER A. GENERAL PROVISIONS Sec. 551.001. DEFINITIONS. In this chapter: (1) ""Algorithmic discrimination"" means any condition in which an artificial intelligence system when deployed creates an unlawful discrimination of a protected classification in violation of the laws of this state or federal law. (A) ""Algorithmic discrimination"" does not include the offer, license, or use of a high-risk artificial intelligence system by a developer or deployer for the sole purpose of the developer's or deployer's self-testing, for a non-deployed purpose, to identify, mitigate, or prevent discrimination or otherwise ensure compliance with state and federal law. (2) ""Artificial intelligence system"" means the use of machine learning and related technologies that use data to train statistical models for the purpose of enabling computer systems to perform tasks normally associated with human intelligence or perception, such as computer vision, speech or natural language processing",https://capitol.texas.gov/BillLookup/Actions.aspx?LegSess=89R&Bill=HB1709,en,"Harms: Discrimination, Risk factors: Bias, Strategies: Disclosure, Strategies: Disclosure: About incidents, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Disclosure: About evaluation, Strategies: Disclosure: In deployment, Strategies: Disclosure: About inputs, Harms: Violation of civil or human rights, including privacy, Risk factors: Privacy, Harms: Detrimental content, Risk factors: Transparency, Incentives: Civil liability, Incentives: Fines"
1816,Guidance on Algorithmic Discrimination and the New Jersey Law Against Discrimination,New Jersey,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2025-01-08,2025,1,neutral,0.0237,low,0.1667,215,0.7,Enacted,"Guidance on Algorithmic Discrimination and the New Jersey Law Against Discrimination The New Jersey Office of the Attorney General and the Division on Civil Rights (DCR) issue this guidance to clarify how the New Jersey Law Against Discrimination (LAD) applies to algorithmic discrimination resulting from the use of new and emerging data-driven technologies, such as artificial intelligence (AI), by employers, housing providers, places of public accommodation, and other entities covered by the LAD. [Opening recitals and factual discussion omitted.] II. THE LAD PROHIBITS ALGORITHMIC DISCRIMINATION The LAD applies to discrimination stemming from the use of automated decision-making tools in the same way it has long applied to other forms of discriminatory conduct. The LAD prohibits all forms of discrimination, irrespective of whether discriminatory conduct is facilitated by automated decision-making tools or driven by purely human practices. Indeed, consistent with its broad remedial purpose of eliminating discrimination in New Jersey, the LAD draws no distinctions based on the mechanism of discrimination. Thus, a covered entity—that is, an employer, housing provider, place of public accommodation, credit provider, contractor, or any other party subject to the LAD’s requirements—is not immunized from liability for violating the LAD merely because its discriminatory policy or practice involves using or relying on an automated decision-making tool. A covered entity can violate the",https://www.nj.gov/oag/newsreleases25/2025-0108_DCR-Guidance-on-Algorithmic-Discrimination.pdf,en,"Harms: Discrimination, Harms: Violation of civil or human rights, including privacy, Risk factors: Bias"
1820,Framework for Artificial Intelligence Diffusion,Department of Commerce,United States,Federal government,Editors' Picks,Regulation,2025-05-13,2025,5,negative,-0.128,low,0.0,267,0.5,Defunct,"PART 732—STEPS FOR USING THE EAR 1. The authority citation for part 732 continues to read as follows: Authority: 50 U.S.C. 4801-4852; 50 U.S.C. 4601 et seq.;50 U.S.C. 1701 et seq.;E.O. 13026, 61 FR 58767, 3 CFR, 1996 Comp., p. 228; E.O. 13222, 66 FR 44025, 3 CFR, 2001 Comp., p. 783. 2. Supplement No. 3 to part 732 is amended by adding paragraph 28 under “Red Flags” to read as follows: Supplement No. 3 to Part 732—BIS's “Know Your Customer” Guidance and Red Flags * * * * * Red Flags * * * * * 28. You will be providing Infrastructure-as-a-Service (IaaS) products or services, or other computing products or services, to assist in training an AI model with model weights captured by ECCN 4E091 for an entity headquartered, or whose ultimate parent is headquartered, in any destination other than those listed in paragraph (a) of supplement no. 5 to part 740 of the EAR. Such assistance creates a substantial risk that such AI model weights, due to their digital nature, will be exported or reexported to a destination for which a license is required and, if a license is not obtained, that the IaaS provider will have aided and abetted in a violation of the EAR. In such cases, the IaaS provider should inquire if the customer intends to export the model and if so, apply for a license as required or inform the customer of their obligation to do so prior to export. PART 734—SCOPE OF THE EXPORT ADMINISTRATION REGULATIONS 3. The authority citation for part 734 continues to read as follows: Autho",https://www.federalregister.gov/documents/2025/01/15/2025-00636/framework-for-artificial-intelligence-diffusion,en,
1826,New York 2025-A768,New York,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2025-01-08,2025,1,positive,0.9416,low,0.2778,220,0.7,Proposed,"§ 2. The general business law is amended by adding a new article 45-A to read as follows: ARTICLE 45-A NEW YORK ARTIFICIAL INTELLIGENCE CONSUMER PROTECTION ACT Section 1550. Definitions. 1551. Required documentation. 1552. Risk management. 1553. Technical documentation. 1554. Required disclosure. 1555. Preemption. 1556. Enforcement. § 1550. Definitions. For the purposes of this article, the following terms shall have the following meanings: 1. ""Algorithmic discrimination"": (a) shall mean any condition in which the use of an artificial intelligence decision system results in any unlawful differential treatment or impact that disfavors any individual or group of individuals on the basis of their actual or perceived age, color, disability, ethnicity, genetic information, English language proficiency, national origin, race, religion, reproductive health, sex, veteran status, or other classification protected pursuant to state or federal law; and (b) shall not include: (i) the offer, license, or use of a high-risk artificial intelligence decision system by a developer or deployer for the sole purpose of: (A) such developer's or deployer's self-testing to identify, mitigate, or prevent discrimination or otherwise ensure compliance with state and federal law; or (B) expanding an applicant, customer, or participant pool to increase diversity or redress historic discrimination; or (ii) an act or omission by or on behalf of a private club or other establishment not open to the general",https://nyassembly.gov/leg/?default_fld=&leg_video=&bn=A00768&term=2025&Summary=Y&Actions=Y&Text=Y#,en,"Harms: Discrimination, Risk factors: Bias, Strategies: Evaluation, Strategies: Evaluation: External auditing, Strategies: Disclosure, Strategies: Disclosure: About inputs, Strategies: Disclosure: In deployment, Strategies: Disclosure: About incidents, Strategies: Disclosure: About evaluation, Strategies: Disclosure: In standard form, Risk factors: Security, Strategies: Governance development, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Post-market monitoring, Risk factors: Transparency"
1828,Virginia 2025-HB2094,Virginia,United States,State governments,Editors' Picks,State/Local Law or Policy,2025-03-24,2025,3,positive,0.9504,medium,0.5,217,0.7,Defunct,"A BILL to amend the Code of Virginia by adding in Title 59.1 a chapter numbered 58, consisting of sections numbered 59.1-607 through 59.1-612, relating to high-risk artificial intelligence; development, deployment, and use; civil penalties. Be it enacted by the General Assembly of Virginia: 1. That the Code of Virginia is amended by adding in Title 59.1 a chapter numbered 58, consisting of sections numbered 59.1-607 through 59.1-612, as follows: CHAPTER 58. HIGH-RISK ARTIFICIAL INTELLIGENCE DEVELOPER AND DEPLOYER ACT. § 59.1-607. Definitions. As used in this chapter, unless the context requires a different meaning: ""Algorithmic discrimination"" means the use of an artificial intelligence system that results in an unlawful differential treatment or impact that disfavors an individual or group of individuals on the basis of their actual or perceived age, color, disability, ethnicity, genetic information, limited proficiency in the English language, national origin, race, religion, reproductive health, sex, sexual orientation, veteran status, or other classification protected under state or federal law. ""Algorithmic discrimination"" does not include (i) the offer, license, or use of a high-risk artificial intelligence system by a developer or deployer for the sole purpose of the developer's or deployer's self-testing to identify, mitigate, or prevent discrimination or otherwise ensure compliance with state and federal law; (ii) the expansion of an applicant, customer, or participa",https://lis.virginia.gov/bill-details/20251/HB2094/text/HB2094,en,"Incentives: Civil liability, Incentives: Fines, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: About inputs, Strategies: Tiering, Strategies: Tiering: Tiering based on impact, Risk factors: Safety, Risk factors: Bias, Harms: Discrimination, Risk factors: Reliability, Strategies: Evaluation, Strategies: Evaluation: Adversarial testing, Risk factors: Privacy, Strategies: Disclosure: About evaluation"
1829,Massachusetts HD 396 (2025-2026),Massachusetts,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2025-01-08,2025,1,positive,0.9432,low,0.2778,198,0.7,Proposed,"Be it enacted by the Senate and House of Representatives in General Court assembled, and by the authority of the same, as follows: SECTION 1. Chapter 93M of the General Laws is hereby established as follows: CHAPTER 93M: Artificial Intelligence Accountability and Consumer Protection Section 1. Definitions For the purposes of this Chapter: (1) Algorithmic Discrimination: Differential treatment or impact resulting from an artificial intelligence system that disadvantages individuals or groups based on actual or perceived age, race, ethnicity, gender, disability, national origin, religion, genetic information, reproductive health, veteran status, or any protected classification under Massachusetts or federal law. (2) Artificial Intelligence System: Any machine-based system that processes inputs to generate outputs, including content, decisions, predictions, or recommendations, that influence physical or virtual environments. (3) High-Risk Artificial Intelligence System: AI systems that materially influence consequential decisions, including but not limited to: (a) Education opportunities; (b) Employment decisions; (c) Financial or lending services; (d) Housing access; (e) Healthcare services; (f) Insurance decisions; (g) Legal or government services. (4) Consequential Decision: A decision with significant legal, financial, or personal implications for a consumer, such as denying housing, employment, or healthcare. For clarity, material influence refers to decisions where AI syst",https://malegislature.gov/Bills/194/HD396,en,"Harms: Violation of civil or human rights, including privacy, Harms: Financial loss, Strategies: Disclosure, Harms: Discrimination, Risk factors: Bias, Strategies: Performance requirements, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Risk factors: Transparency, Strategies: Disclosure: In standard form, Applications: Government: other applications/unspecified, Strategies: New institution"
1830,New Mexico 2025 HB 60,New Mexico,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2025-01-22,2025,1,positive,0.9672,low,0.0,228,0.5,Proposed,"BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF NEW MEXICO: SECTION 1. [NEW MATERIAL] SHORT TITLE.--This act may be cited as the ""Artificial Intelligence Act"". SECTION 2. [NEW MATERIAL] DEFINITIONS.--As used in the Artificial Intelligence Act: A. ""algorithmic discrimination"" means any condition in which the use of an artificial intelligence system results in an unlawful differential treatment or impact that disfavors a person on the basis of the person's actual or perceived age, color, disability, ethnicity, gender, genetic information, proficiency in the English language, national origin, race, religion, reproductive health, veteran status or other status protected by state or federal law, but does not include: (1) the offer, license or use of a high-risk artificial intelligence system by a developer or deployer for the sole purpose of: (a) the developer's or deployer's self-testing to identify, mitigate or ensure compliance with state and federal law; or (b) expanding an applicant, customer or participant pool to increase diversity or redress historical discrimination; or (2) an act or omission by or on behalf of a private club or other entity that is not open to the public pursuant to federal law; B. ""artificial intelligence system"" means any machine-based system that for an explicit or implicit objective infers from the inputs the system receives how to generate outputs, including content, decisions, predictions or recommendations, that can influence physical or virtual",https://www.nmlegis.gov/Sessions/25%20Regular/bills/house/HB0060.html,en,
1831,Artificial Intelligence Safety Commitments (China AI Industry Alliance),Other authorities,,,Chinese law and policy,Other,2024-12-01,2024,12,positive,0.9953,medium,0.5,214,0.7,Enacted,"The wave of artificial intelligence (Al) is sweeping across the globe, actively generating technological dividends and exerting profound influence on global economic and social development as well as the progress of human civilization. At the same time, we are acutely aware that Al brings about unpredictable risks and complicated challenges. To seize this new round of development opportunities, we solemnly launch the Al Safety Commitments. Through industry self-regulation, we will leverage high-level safety and security measures to support high-quality development, and collaborate to promote the robust development of Al. We deeply understand that self-discipline commitments are key to earning the trust of the global community. Guided by the Commitments as our code of conduct, and subject to the oversight of all stakeholders, we will continuously improve and refine our approach. By doing so, we will ensure that the application of Al technologies always remains people-centered and aligned with the principle of Al for good. Commitment I: Establish safety teams or organizational structures and build safety and security risk management mechanisms. Designate leader responsible for Al safety and security, establish specialized teams to conduct Al risk assessments and safety governance within the enterprise. Proactively define realistic safety risk baselines, adopt appropriate safety measures for open-source initiatives, and implement risk management practices throughout the entire A",https://mp.weixin.qq.com/s/s-XFKQCWhu0uye4opgb3Ng,en,"Risk factors: Safety, Risk factors: Security, Strategies: Evaluation, Strategies: Evaluation: Adversarial testing, Risk factors: Reliability, Strategies: Tiering, Applications: Education, Applications: Medicine, life sciences and public health, Applications: Finance and investment, Strategies: Tiering: Tiering based on domain of application, Strategies: Input controls, Risk factors: Privacy, Strategies: Input controls: Data use, Risk factors: Security: Dissemination, Risk factors: Transparency"
1886,A bill to require a study on the use of commercial-off-the-shelf products and artificial intelligence technologies by the Internal Revenue Service.,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9839,low,0.0,211,0.5,Defunct,"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. GAO study and report on use of commercial-off-the-shelf products and artificial intelligence technologies by IRS. (a) In general.—Not later than 12 months after the date of the enactment of this Act, the Comptroller General of the United States shall conduct a study and submit to Congress a report on the use of commercial-off-the-shelf products and artificial intelligence technologies by the Internal Revenue Service. (b) Factors considered.—The study described in subsection (a) shall identify how the Internal Revenue Service— (1) uses commercial-off-the-shelf products and artificial intelligence technologies to— (A) improve efficiency across Internal Revenue Service operations, (B) improve taxpayer services, (C) generate cost savings for the Internal Revenue Service, (D) increase fairness in enforcement, and (E) improve enforcement activities to reduce the disparity between tax liabilities owed to the United States and those liabilities actually collected by the Internal Revenue Service, and (2) manages risks associated with the use of artificial intelligence technologies, including technology errors, bias in audit selection, and data security. (c) Additional information.—The study described in subsection (a) shall include the following information with respect to projects relating to information technology modernization and software development for the I",https://www.congress.gov/bill/118th-congress/senate-bill/5620/text,en,
1887,Preserving American Dominance in Artificial Intelligence Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9839,low,0.0,216,0.5,Defunct,"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title; table of contents. (a) Short title.—This Act may be cited as the “Preserving American Dominance in Artificial Intelligence Act of 2024”. [table of contents omitted] SEC. 2. Findings; sense of Congress. (a) Findings.—Congress finds the following: (1) Advancements in artificial intelligence have the potential to dramatically improve and transform our way of life, but also present a broad spectrum of risks that could be harmful to the people of the United States. (2) According to the United States Government, academia, and distinguished experts, advancements in artificial intelligence have the potential to be misused by bad actors. (3) The Department of Defense, the Department of State, the intelligence community, and the National Security Commission on Artificial Intelligence, as well as senior officials at the Department of Energy, Argonne National Laboratory, the Cybersecurity and Infrastructure Security Agency, and the National Counterterrorism Center, have underscored that advanced artificial intelligence poses risks to United States national security, including through enabling the development of biological, chemical, cyber, radiological, or nuclear weapons. (4) Advanced artificial intelligence models could one day be leveraged by terrorists or adversarial nation state regimes to cause widespread harm or threaten United States national sec",https://www.congress.gov/bill/118th-congress/senate-bill/5616/text#toc-id89d5105a15eb44e1ab241fb3c9caaa8f,en,
1891,"A bill to prohibit and require notifications with respect to certain investments by United States persons in the People's Republic of China, and for other purposes.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9726,low,0.0,226,0.5,Defunct,"A BILL To prohibit and require notifications with respect to certain investments by United States persons in the People's Republic of China, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Prohibition and notification on investments relating to covered national security transactions. The Defense Production Act of 1950 (50 U.S.C. 4501 et seq.) is amended by adding at the end the following: “TITLE VIII—Prohibition and notification on investments relating to covered national security transactions “SEC. 801. Prohibition on investments. “(a) In general.—The Secretary may prohibit, in accordance with regulations issued under subsection (e), a United States person from knowingly engaging in a covered national security transaction in a prohibited technology. “(b) Evasion.—Any transaction by a United States person or within the United States that evades or avoids, has the purpose of evading or avoiding, causes a violation of, or attempts to violate the prohibition set forth in subsection (a) is prohibited. “(c) Waiver.—Subject to subsection (d), the Secretary is authorized to exempt from the prohibition set forth in subsection (a) any activity determined by the President, in consultation with the Secretary, the Secretary of Commerce and, as appropriate, the heads of other relevant Federal departments and agencies, to be in the national interest of the United States. “(d) Congressional no",https://www.congress.gov/bill/118th-congress/senate-bill/5598/text,en,
1894,"To prohibit the Secretary of Defense from entering into information technology contracts with entities that provide certain services to China, and for other purposes.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9666,low,0.0,243,0.5,Defunct,"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Prohibition on information technology contracts with entities that provide certain services to China. (a) Prohibition.—The Secretary of Defense may not enter into, renew, or extend an information technology contract with an entity, including a parent, subsidiary, affiliate, or subcontractor (at any tier) of such an entity, that— (1) owns, operates, substantially funds, or has a material interest in a facility or research organization located on the mainland of the People’s Republic of China if such facility or research organization has a primary purpose, as determined by the Secretary, of researching or developing artificial intelligence; (2) has enabled a covered Chinese entity to access a source code of software to be used by or on behalf of the United States Government, if such contract is for such software; (3) provides software with a military or law enforcement application or a dual-use application to a covered Chinese entity; or (4) operates a data center (as such term is defined in section 453 of the Energy Independence and Security Act of 2007 (42 U.S.C. 17112)) in the mainland of China, including a data center operated— (A) by a parent, subsidiary, or affiliate of an entity seeking to enter into, renew, or extend a contract with the Secretary; or (B) on behalf of such an entity by a covered Chinese entity. (b) Waiver authority.—The Secretary may",https://www.congress.gov/bill/118th-congress/house-bill/10453/text,en,
1896,Chinese Military and Surveillance Company Sanctions Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9661,low,0.0,218,0.5,Defunct,"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Chinese Military and Surveillance Company Sanctions Act of 2024”. SEC. 2. Findings and sense of Congress. (a) Findings.—Congress finds the following: (1) Under Executive Order 13959 of November 17, 2020, the President found that the People’s Republic of China “increases the size of the country’s military-industrial complex by compelling civilian Chinese companies to support its military and intelligence activities. Those companies, though remaining ostensibly private and civilian, directly support the PRC’s military, intelligence, and security apparatuses and aid in their development and modernization.”. The President further determined that “the PRC exploits United States investors to finance the development and modernization of its military.”. As a result, Executive Order 13959 restricted transactions in publicly traded securities of Communist Chinese military companies listed pursuant to section 1237 of the Strom Thurmond National Defense Authorization Act for Fiscal Year 1999 (Public Law 105–261; 50 U.S.C. 1701 note). (2) Although Executive Order 13959 targets transactions in some public securities, it does not fully address all public securities of concern or address financing options for Communist Chinese military companies through other forms of equity financing or debt financing, nor does it limit transac",https://www.congress.gov/bill/118th-congress/senate-bill/5571/text,en,
1900,Trustworthy By Design Artificial Intelligence Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9793,low,0.0,220,0.5,Defunct,"A BILL To require systematic review of artificial intelligence systems before deployment by the Federal Government, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Trustworthy By Design Artificial Intelligence Act of 2024” or the “TBD AI Act of 2024”. SEC. 2. Definitions. In this Act: (1) ARTIFICIAL INTELLIGENCE SYSTEM.—The term “artificial intelligence system” means a machine-based system that can, for a given set of machine-defined or human-defined objectives, make or inform predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use machine and human-based inputs to— (A) perceive real and virtual environments; (B) abstract such perceptions into models through analysis in an automated manner; and (C) use model inference to formulate options for information or action. (2) DIRECTOR.—The term “Director” means the Director of the National Institute of Standards and Technology. (3) FEDERAL AGENCY.—The term “Federal agency” means any Federal department, agency, or organization. SEC. 3. Guidelines for evaluation of trustworthiness of artificial intelligence systems. (a) Development required.— (1) IN GENERAL.—Not later than 1 year after the date of the enactment of this Act, the Director shall develop and release a set of guidelines for evaluation of the trustworthiness of artificia",https://www.congress.gov/bill/118th-congress/senate-bill/5539/text,en,
1901,Leadership in CET Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9474,low,0.0,221,0.5,Defunct,"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Leadership in Critical and Emerging Technologies Act” or the “Leadership in CET Act”. SEC. 2. Pilot program for expediting examination of certain critical and emerging technology patent applications. (a) Definitions.—In this section: (1) COVERED APPLICATION.—The term “covered application” means an application for patent with respect to an eligible critical or emerging technology. (2) DIRECTOR.—The term “Director” means the Under Secretary of Commerce for Intellectual Property and Director of the Office. (3) ELIGIBLE CRITICAL OR EMERGING TECHNOLOGY.—The term “eligible critical or emerging technology” means— (A) artificial intelligence, as defined in section 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401); (B) microelectronics, as defined in section 10731(a) of the Research and Development, Competition, and Innovation Act (42 U.S.C. 19331(a)); or (C) quantum information science, as defined in section 2 of the National Quantum Initiative Act (15 U.S.C. 8801). (4) EXPEDITE.—The term “expedite” means, with respect to a covered application, to advance that covered application out of turn through the use of a petition to make special. (5) OFFICE.—The term “Office” means the United States Patent and Trademark Office. (6) PILOT PROGRAM.—The term “pilot program” means the pilot program",https://www.congress.gov/bill/118th-congress/senate-bill/5537/text,en,
1903,Diabetes Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8748,low,0.0,222,0.5,Defunct,"A BILL To ensure continued access to diabetes technology upon Medicare enrollment, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Diabetes Interventions Addressing Barriers to Enrollment, Technology, and Education Services (DIABETES) Act” or the “Diabetes Act”. SEC. 2. Findings; Sense of Congress. (a) Findings.—Congress finds the following: (1) According to the Centers for Disease Control and Prevention, in 2021, an estimated 38,400,000 Americans, or 11.6 percent of the entire United States population, have diabetes. (2) The total number of individuals with diabetes is projected to increase to an estimated 54,900,000 individuals by 2030. (3) Diabetes disproportionately impacts the Medicare population, as the Centers for Medicare & Medicaid Services found in 2022, and 26 percent of Medicare beneficiaries have diabetes. (4) Both type 1 and 2 diabetes can significantly harm long-term health and is associated with numerous comorbidities such as cancer, heart disease, chronic kidney disease, blindness, and amputations. (5) The direct and indirect cost of diabetes is significant as the American Diabetes Association found that the total annual cost of diabetes in 2022 was $412,900,000,000, $306,600,000,000 of which is attributable to direct medical costs. (6) The American Diabetes Association and the American Association of Clinical Endocrino",https://www.congress.gov/bill/118th-congress/senate-bill/5502/text,en,
1904,Transparency in Bureaucratic Communications Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.6808,low,0.0,163,0.5,Defunct,"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Transparency in Bureaucratic Communications Act”. SEC. 2. Inspector General Act of 1978. Section 405(b) of title 5, United States Code, is amended by adding at the end the following: “(23) a detailed description of the contents and particular circumstances of any communication, or attempted communication, between the establishment and any internet computer service, information content provider, or access software provider (as defined under section 230(f) of the Communications Act of 1934 (47 U.S.C. 230(f)), including— “(A) communications regarding content moderation (as described under section 230(c)(2) of the Communications Act of 1934 (47 U.S.C. 230(c)(2)); “(B) user content, including posts, photos, and videos; and “(C) any other communications relating to the internet computer service, information content provider, or access software provider’s data inputs, algorithms, modeling and simulation processes, analysis tools, or any related tool.”.",https://www.congress.gov/bill/118th-congress/senate-bill/5500/text,en,
1912,Enable Intelligence Community Partnerships Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9955,low,0.0,214,0.5,Defunct,"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Enable Intelligence Community Partnerships Act of 2024”. SEC. 2. Definitions. In this Act: (1) CONGRESSIONAL INTELLIGENCE COMMITTEES.—The term “congressional intelligence committees” has the meaning given such term in section 3 of the National Security Act of 1947 (50 U.S.C. 3003). (2) INTELLIGENCE COMMUNITY.—The term “intelligence community” has the meaning given such term in such section. SEC. 3. Sense of Congress encouraging intelligence community to increase private sector capital partnerships and partnership with Federal partners to secure enduring technological advantages. It is the sense of Congress that— (1) acquisition leaders in the intelligence community should further explore the strategic use of private capital partnerships to secure enduring technological advantages for the intelligence community, including through the identification, development, and transfer of promising technologies to full-scale programs capable of meeting intelligence community requirements; and (2) the intelligence community should undertake consultation with Federal partners, including the Office of Strategic Capital of the Office of the Secretary of Defense and the Office of Domestic Finance of the Department of the Treasury, on best practices and lessons learned from their experiences integrating these resources so as to ac",https://www.congress.gov/bill/118th-congress/senate-bill/5444/text,en,
1913,Protecting AI and Cloud Competition in Defense Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9794,low,0.0,217,0.5,Defunct,"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Protecting AI and Cloud Competition in Defense Act of 2024”. SEC. 2. Ensuring competition in artificial intelligence procurement. (a) Definitions.—In this section: (1) ARTIFICIAL INTELLIGENCE; AI.—The terms “artificial intelligence” and “AI” have the meaning given the term “artificial intelligence” in section 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401). (2) CLOUD COMPUTING.—The term “cloud computing” has the meaning given the term in Special Publication 800–145 of the National Institute of Standards and Technology, or any successor document. (3) CLOUD PROVIDER.—The term “cloud provider” means any company engaged in the provision, sale, or licensing of cloud computing to customers, including individuals and businesses. (4) CONGRESSIONAL DEFENSE COMMITTEES.—The term “congressional defense committees” has the meaning given the term in section 101(a) of title 10, United States Code. (5) COVERED PROVIDER.—The term “covered provider” means any cloud provider, data infrastructure provider, or foundation model provider that has entered into contracts with the Department of Defense totaling at least $50,000,000 in any of the 5 previous fiscal years. (6) DATA INFRASTRUCTURE.—The term “data infrastructure” means the underlying computer, network, and software systems that enable the c",https://www.congress.gov/bill/118th-congress/senate-bill/5436/text,en,
1919,Emerging Innovative Border Technologies Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9828,low,0.0,224,0.5,Defunct,"SECTION 1. SHORT TITLE. This Act may be cited as the “Emerging Innovative Border Technologies Act”. SEC. 2. INNOVATIVE AND EMERGING BORDER TECHNOLOGY PLAN. (a) In General.—Not later than 180 days after the date of the enactment of this Act, the Secretary of Homeland Security, acting through the Commissioner for U.S. Customs and Border Protection (referred to in this section as “CBP”) and the Under Secretary for Science and Technology of the Department of Homeland Security, in consultation with the Department’s Chief Information Officer, Chief Procurement Officer, Privacy Officer, Civil Right and Civil Liberties Officer, General Counsel, and any other relevant offices and components of the Department of Homeland Security, shall submit a plan to the Committee on Homeland Security and Governmental Affairs of the Senate and the Committee on Homeland Security of the House of Representatives for identifying, integrating, and deploying new, innovative, disruptive, or other emerging or advanced technologies that are safe and secure to enhance CBP capabilities to meet its mission needs along international borders or at ports of entry. (b) Contents.—The plan required under subsection (a) shall include— (1) information regarding how CBP utilizes the CBP Innovation Team authority under subsection (c) and other mechanisms to carry out the purposes described in subsection (a); (2) an assessment of the contributions directly attributable to such utilization; (3) information regarding— (A) t",https://www.congress.gov/bill/118th-congress/senate-bill/5407/text,en,
1920,Responsible AI Disclosure Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9818,low,0.0,216,0.5,Defunct,"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Responsible AI Disclosure Act of 2024”. SEC. 2. Study and report on standardized description for vendor-provided artificial intelligence systems. (a) Study.—The heads of each covered agency may coordinate with other covered agencies and consult with other relevant Government agencies to carry out a study that— (1) establishes current and recommended definitions and standards for categorizing artificial intelligence data and methodologies used to train artificial intelligence models that are commonly utilized by regulated entities; (2) assesses current and recommended practices for regulated entities and vendors to identify data used to train artificial intelligence models that are utilized by regulated entities; (3) assesses current and recommended standards for the delineation and ratios of synthetic versus genuine data in the training of artificial intelligence models; (4) identifies the sources of such data; (5) assesses how such models are designed and function, including how the data submitted to such models are incorporated and other ways in which the data is typically used; and (6) examines best practices for complying with applicable Federal laws and regulations, including anti-discrimination, consumer protection, and investor protection requirements with respect to internal or vendor-provided artificial",https://www.congress.gov/bill/118th-congress/house-bill/10263/text,en,
1921,AI Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.6597,low,0.0,240,0.5,Defunct,"A BILL To require the financial regulators to carry out studies on the realized and potential benefits of artificial intelligence, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Analysis and Improvement Act of 2024” or the “AI Act of 2024”. SEC. 2. Study on AI benefits and risks by banking regulators. (a) Report required.—Not later than 180 days after the date of the enactment of this Act, the Board of Governors of the Federal Reserve System, the Federal Deposit Insurance Corporation Board, the Comptroller of the Currency, the Director of the Bureau of Consumer Financial Protection, and the National Credit Union Administration Board shall submit to the Committee on Financial Services of the House of Representatives and the Committee on Banking, Housing, and Urban Affairs of the Senate, and publish publicly, a report that examines— (1) realized and potential benefits and risks of AI technology, including— (A) banking institutions’ use of AI for customer service; (B) banking institutions’ use of AI in loan underwriting and servicing; (C) banking institutions’ use of AI in home valuation; (D) banking institutions’ use of AI to detect and deter fraud, money laundering, cybercrime, and other illicit activity; (E) the use of AI in debt collection, including foreclosures; (F) banking institutions’ use of AI for internal processes and complian",https://www.congress.gov/bill/118th-congress/house-bill/10262/text,en,
1922,SCAM Platform Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.7184,low,0.0,230,0.5,Defunct,"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Spam Communication Assessment and Mitigation Platform Act” or the “SCAM Platform Act”. SEC. 2. Scam identification tool. (a) In general.—Not later than 1 year after the date of the enactment of this Act, the Commission shall provide on the website of the Commission a tool that uses artificial intelligence to assist the public in identifying likely scams. (b) Requirements.—The tool described in subsection (a) shall— (1) accept a submission from an individual in a variety of formats, including emails, text messages, website addresses, and scans or photographs of physical materials; (2) evaluate the likelihood that such submission is a scam; and (3) provide such submission a rating, on a scale to be determined by the Commission, that reflects the likelihood that such submission is a scam. (c) Definitions.—In this section: (1) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence” has the meaning given such term in section 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401). (2) COMMISSION.—The term “Commission” means the Federal Communications Commission. (3) SCAM.—The term “scam” means a scheme or artifice to defraud, including a communication that attempts through false or misleading information to induce a recipient to pay money, provide personal information, or otherwise act",https://www.congress.gov/bill/118th-congress/house-bill/10212/text,en,
1923,Workforce Data Enhancement Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9927,low,0.0,221,0.5,Defunct,"A BILL To amend the Workforce Innovation and Opportunity Act to establish a grant program for a workforce data quality initiative, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Workforce Data Enhancement Act”. SEC. 2. Amendments to the Workforce Innovation and Opportunity Act. (a) In general.—Section 169 of the Workforce Innovation and Opportunity Act (29 U.S.C. 3224) is amended by adding at the end the following: “(d) Workforce data quality initiative.— “(1) GRANT PROGRAM.—The Secretary shall use not more than 10 percent of the total amount made available pursuant to section 132(a)(2)(A) for any program year, and may use amounts otherwise made available for purposes of carrying out this section, to competitively award grants to eligible entities to design, develop, implement, improve, or align a statewide longitudinal data system for the purposes of integrating data from education and workforce development systems, labor market outcomes, and other data sources toward strengthening program quality, building State capacity to produce evidence for decision making, meeting performance reporting requirements, promoting individual privacy and data security, improving transparency, moving toward improved workforce data standardization, and improving worker and employer capacity to identify and address skill needs. “(2) ELIGIBLE ENTITY.—In t",https://www.congress.gov/bill/118th-congress/senate-bill/5401/text,en,
1924,TRAIN Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9914,low,0.0,215,0.5,Defunct,"A BILL To create an administrative subpoena process to assist copyright owners in determining which of their copyrighted works have been used in the training of artificial intelligence models. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Transparency and Responsibility for Artificial Intelligence Networks Act” or the “TRAIN Act”. SEC. 2. Subpoena for copies or records relating to artificial intelligence models. (a) In general.—Chapter 5 of title 17, United States Code, is amended by adding at the end the following: “§ 514. Subpoena for copies or records relating to artificial intelligence models “(a) Definitions.—In this section: “(1) ARTIFICIAL INTELLIGENCE.—The term ‘artificial intelligence’ has the meaning given the term in section 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401). “(2) ARTIFICIAL INTELLIGENCE MODEL.—The term ‘artificial intelligence model’ means a component of an information system that implements artificial intelligence technology and uses computational, statistical, or machine-learning techniques to produce outputs from a given set of inputs. “(3) GENERATIVE ARTIFICIAL INTELLIGENCE MODEL.—The term ‘generative artificial intelligence model’ means an artificial intelligence model that emulates the structure and characteristics of input data in order to generate derived synthetic content, which may incl",https://www.congress.gov/bill/118th-congress/senate-bill/5379/text,en,
1926,DOGE Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9492,low,0.0,248,0.5,Defunct,"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Decreasing Overlapping Grants Efficiently Act” or the “DOGE Act”. SEC. 2. Prohibition on award of Federal grants to applicants submitting duplicative or fraudulent applications. (a) No award on basis of duplicative application.— (1) PROHIBITION.— (A) IN GENERAL.—Except as provided for under subparagraph (B), the head of an executive agency may not award a grant to an applicant determined by the head of the agency or the Inspector General of the agency to have received another grant from the head of another executive agency for the same or identical purpose. (B) EXCEPTION.—The prohibition under subparagraph (A) related to the award of grants for the same or identical purposes shall not apply to an applicant that is an institution of higher education. (2) DETERMINATION.—In the case that the head of an executive agency or the Inspector General of the agency determines that an applicant for a grant has submitted an application for another grant from another executive agency for the same or identical purpose, the heads of such agencies shall jointly determine which agency is the appropriate agency to award the grant, if such grant is to be awarded to such applicant. (b) No award on basis of fraudulent application.—The head of an executive agency may not award a grant to an applicant determined by the head of the agenc",https://www.congress.gov/bill/118th-congress/house-bill/10177/text,en,
1927,Improving Atmospheric River Forecasts Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9451,low,0.0,210,0.5,Defunct,"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Improving Atmospheric River Forecasts Act”. SEC. 2. Atmospheric rivers forecast improvement program. (a) In general.—The Under Secretary, in collaboration with the weather enterprise in the United States and institutions of higher education, shall establish an atmospheric river forecast improvement program (in this section referred to as the “program”). (b) Program elements.—In carrying out the program, the Under Secretary shall seek to reduce the loss of life and property and economic losses from atmospheric rivers through the development and extension of, and research on, accurate, effective, and actionable forecasts and warnings, including by— (1) establishing quantitative atmospheric river forecast skill metrics that include the benefits of dynamical modeling, data assimilation, and machine learning improvements in the probabilistic forecasts of landfall location, extreme wind and precipitation, and cascading impacts; (2) developing an atmospheric river forecast system within a unified forecast system, and advancing next-generation coupled modeling systems, with the capability of providing seasonal to short-range atmospheric river forecasts that include forecast of snow accumulation and other hydrologic components; (3) advancing scientific understanding of the roles of atmospheric rivers in subseasonal to sea",https://www.congress.gov/bill/118th-congress/senate-bill/5361/all-actions,en,
1929,S5344 Advancing Digital Freedom Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9964,low,0.0,231,0.5,Defunct,"A BILL To provide for international protection of digital freedom, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Advancing Digital Freedom Act of 2024”. SEC. 2. Statement of policy. It is the policy of the United States— (1) to ensure that technology is developed, deployed, and governed in accordance with universal human rights, the rule of law, and democratic values; (2) to protect and promote digital freedom as a cornerstone of United States foreign policy and prioritize digital freedom to the highest extent possible in diplomatic engagements with foreign countries; (3) to cooperate and engage with like-minded countries committed to developing, deploying, and using technology in a manner that respects democracy, the rule of law, and human rights; and (4) to lead global efforts to protect digital freedom, counter disinformation and misinformation, and advance democratic governance in the digital space consistent with guidelines outlined in the United States International Cyberspace and Digital Policy Strategy. SEC. 3. Coordinator for Digital Freedom defined. In this Act, the term “Coordinator for Digital Freedom” means the Coordinator for Digital Freedom in the Bureau of Cyberspace and Digital Policy in the United States Department of State. SEC. 4. Role of the Coordinator for Digital Freedom. (a) Central objective.—The central objec",https://www.congress.gov/bill/118th-congress/senate-bill/5344/text,en,
1955,Federal Register Doc. No. 2024-28335 (Securing the Information and Communications Technology and Services Supply Chain),Department of Commerce,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2025-02-04,2025,2,negative,-0.7507,low,0.0,233,0.5,Enacted,"PART 791—SECURING THE INFORMATION AND COMMUNICATIONS TECHNOLOGY AND SERVICES SUPPLY CHAIN 1. The authority citation for 15 CFR Part 791 continues to read as follows: Authority: 50 U.S.C. 1701 et seq.;50 U.S.C. 1601 et seq.;E.O. 13873, 84 FR 22689; E.O. 14034, 86 FR 31423. 2. In Part 791, remove the text “initial determination” wherever it appears, and add, in its place, the text “Initial Determination”. 3. In Part 791, remove the text “final determination” wherever it appears, and add, in its place, the text “Final Determination”. 4. Amend § 791.1 by revising paragraph (a)(1) to read as follows: § 791.1 Purpose. (a) * * * (1) Determine whether any acquisition, importation, transfer, installation, dealing in, or use of any information and communications technology or service, including but not limited to connected software applications, (ICTS Transaction) that has been designed, developed, manufactured, or supplied by persons owned by, controlled by, or subject to the jurisdiction or direction of foreign adversaries poses certain undue or unacceptable risks as identified in the Executive Order 13873. For purposes of these regulations, the Secretary will consider information and communications technology and services (ICTS) to be designed, developed, manufactured, or supplied by a person owned by, controlled by, or subject to the jurisdiction of a foreign adversary where such a person operates, manages, maintains, repairs, updates, or services the ICTS; * * * * * 5. Amend § 791",https://www.federalregister.gov/documents/2024/12/06/2024-28335/securing-the-information-and-communications-technology-and-services-supply-chain#h-54,en,
1961,"American Foreign Affairs Talent Expansion Act: Diversity in Diplomacy and Development, Section 112 (Mitigating bias in artificial intelligence use.)",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9892,low,0.0,199,0.5,Defunct,"SEC. 112. Mitigating bias in artificial intelligence use. (a) Sense of Congress.—It is the sense of Congress that, with the integration of artificial intelligence into agency work and operations, measures should be taken to address bias in artificial intelligence models to reduce the likelihood of negative results or discriminatory outcomes. (b) Experts and technologists.—The head of each international affairs agency shall employ experts, including technologists, social scientists, and legal experts, and fellows from established programs, to support the development of a risk-mitigation framework that promotes trustworthy artificial intelligence systems, including testing and correcting for racial, ethnic, gender, age, national origin, geographic, and other bias in artificial intelligence training data and applications. (c) Reports.—Not later than 1 year after the date of the enactment of this Act, and every 2 years thereafter for the following 8 years, the head of each agency shall submit a report to the appropriate congressional committees that— (1) describes the agency's efforts to support the safe, secure, and trustworthy development and use of artificial intelligence; and (2) includes agency efforts to test and correct for any bias in artificial intelligence training data and applications, and any resources needed to improve the effectiveness of such efforts.",https://www.congress.gov/bill/118th-congress/senate-bill/5581/text#toc-id0684d27619444b1fb01727d1ca69003d,en,
1962,Code of Practice for the Cyber Security of AI,Government of the United Kingdom,Other countries,Other countries,Miscellaneous documents,Law/Act,2025-01-31,2025,1,positive,0.9442,medium,0.3889,211,0.7,Proposed,"Code of Practice Principles Secure Design Principle 1: Raise awareness of AI security threats and risks Primarily applies to: System Operators, Developers, and Data Custodians [NIST 2022, NIST 2023, ASD 2023, WEF 2024, OWASP 2024, MITRE 2024, Google 2023, ESLA 2023, Cisco 2022, Deloitte 2023, Microsoft 2022]. 1.1. Organisations’ cyber security training programme shall include AI security content which shall be regularly reviewed and updated, such as if new substantial AI-related security threats emerge. 1.1.1 AI security training shall be tailored to the specific roles and responsibilities of staff members. 1.2. As part of an Organisation’s wider staff training programme, they shall require all staff to maintain awareness of the latest security threats and vulnerabilities that are AI-related. Where available, this awareness shall include proposed mitigations. 1.2.1. These updates should be communicated through multiple channels, such as security bulletins, newsletters, or internal knowledge-sharing platforms. This will ensure broad dissemination and understanding among the staff. 1.2.2 Organisations shall provide developers with training in secure coding and system design techniques specific to AI development, with a focus on preventing and mitigating security vulnerabilities in AI algorithms, models, and associated software. Principle 2: Design your AI system for security as well as functionality and performance Primarily applies to: System Operators and Developers [OWASP 20",https://www.gov.uk/government/publications/ai-cyber-security-code-of-practice/code-of-practice-for-the-cyber-security-of-ai#code-of-practice-principles,en,"Risk factors: Security, Risk factors: Security: Cybersecurity, Strategies: Evaluation, Risk factors: Reliability, Risk factors: Reliability: Robustness, Strategies: Evaluation: Conformity assessment, Strategies: Performance requirements, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Evaluation: Post-market monitoring, Risk factors: Interpretability and explainability, Risk factors: Privacy, Strategies: Input controls: Data circulation, Strategies: Input controls, Strategies: Input controls: Data use"
1970,Meta Frontier AI Framework (Version 1.1),Private-sector companies,,,Corporate policies and commitments,Other,2025-02-03,2025,2,negative,-0.987,medium,0.5556,239,0.7,Enacted,"[Preliminary material omitted. Most footnotes omitted.] Section 01 Introduction 1.1 Scope In line with the Frontier AI Safety Commitments, which Meta signed in May 2024, our Frontier AI Framework relates to our forthcoming most advanced models and systems that match or exceed the capabilities present in the most advanced models. It defines processes to manage and mitigate the risk of frontier AI models or systems producing catastrophic outcomes, and to keep risks of such outcomes within tolerable levels. This Framework is one component of our wider AI governance program. It deals with catastrophic outcomes that could arise as a direct result of the development or release of the frontier AI model. The Framework does not, therefore, reflect the full spectrum of risks that we assess for, nor all of the evaluations that we conduct. Our Framework is structured around a set of catastrophic outcomes. We have used threat modelling to develop threat scenarios pertaining to each of our catastrophic outcomes. We have identified the key capabilities that would enable the threat actor to realize a threat scenario. We have taken into account both state and non-state actors, and our threat scenarios distinguish between high- or low-skill actors. We define our thresholds based on the extent to which frontier AI would uniquely enable the execution of any of the threat scenarios we have identified as being potentially sufficient to produce a catastrophic outcome. If a frontier AI is assessed t",https://ai.meta.com/static-resource/meta-frontier-ai-framework,en,"Strategies: Evaluation: Post-market monitoring, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Convening, Strategies: Governance development, Strategies: Evaluation: Adversarial testing, Strategies: Evaluation: Conformity assessment, Risk factors: Transparency, Strategies: Disclosure, Strategies: Disclosure: In standard form, Strategies: Disclosure: About evaluation, Strategies: Evaluation: External auditing, Strategies: Performance requirements, Strategies: Tiering, Strategies: Tiering: Tiering based on impact"
1972,Legal Advisory on the Application of Existing California Law to Artificial Intelligence in Healthcare (California Attorney General),California,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2025-01-13,2025,1,positive,0.9643,medium,0.5,205,0.7,Enacted,"[footnotes omitted] California Attorney General’s Legal Advisory on the Application of Existing California Law to Artificial Intelligence in Healthcare The California Attorney General’s Office (AGO) issues this advisory to provide guidance to healthcare providers, insurers, vendors, investors, and other healthcare entities that develop, sell, and use artificial intelligence (AI) and other automated decision systems1 about their obligations under California law, including under the state’s consumer protection, civil rights, competition, and data privacy laws.2 Artificial Intelligence in the Healthcare Sector AI systems are already widespread within healthcare. As of May 2024, the federal Food and Drug Administration (FDA) had authorized for medical use 981 artificial intelligence or machine learning software devices, and counting.3 These and other AI systems are being used to guide medical diagnosis and treatment decisions. Hospitals and insurers routinely use non-FDA-approved AI systems for tasks such as appointment scheduling, medical risk assessment, and bill processing. AI tools have the potential to help improve patient and population health, increase health equity, reduce administrative burdens, and facilitate appropriate information sharing. At the same time, AI risks causing discrimination, denials of needed care and other misallocations of healthcare resources, and interference with patient autonomy and privacy. For example, AI models trained on data that reflect exis",https://oag.ca.gov/system/files/attachments/press-docs/Final%20Legal%20Advisory%20-%20Application%20of%20Existing%20CA%20Laws%20to%20Artificial%20Intelligence%20in%20Healthcare.pdf,en,"Applications: Medicine, life sciences and public health, Risk factors: Bias, Harms: Discrimination, Risk factors: Transparency, Harms: Violation of civil or human rights, including privacy, Risk factors: Privacy, Harms: Detrimental content, Harms: Financial loss, Incentives: Civil liability, Strategies: Evaluation, Strategies: Evaluation: External auditing, Risk factors: Reliability, Strategies: Input controls, Strategies: Input controls: Data use, Strategies: Disclosure"
1974,California Attorney General’s Legal Advisory on the Application of Existing California Laws to Artificial Intelligence,California,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2025-01-01,2025,1,positive,0.8979,medium,0.6111,222,0.7,Enacted,"California Attorney General’s Legal Advisory on the Application of Existing California Laws to Artificial Intelligence The California Attorney General’s Office (AGO) issues this advisory to provide guidance to consumers and entities that develop, sell, and use artificial intelligence (AI)1 about their rights and obligations under California law, including under the state’s consumer protection, civil rights, competition, and data privacy laws.2 1 While the definition of AI may vary depending upon the context, for the purposes of this advisory, AI includes “a machinebased system that can, for a given set of human-defined objectives, make predictions, recommendations or decisions influencing real or virtual environments. Artificial intelligence systems use machine and human-based inputs to—(A) perceive real and virtual environments; (B) abstract such perceptions into models through analysis in an automated manner; and (C) use model inference to formulate options for information or action.” (15 U.S.C. § 9401(3).) California has also recently passed a law defining the term in certain instances as “an engineered or machine-based system that varies in its level of autonomy and that can, for explicit or implicit objectives, infer from the input it receives how to generate outputs that can influence physical or virtual environments.” (See Gov. Code § 11546.45.5 et seq., added by AB 2885, Stats. 2024, ch. 843.) 2 This advisory provides the AGO’s guidance on general application of Calif",https://oag.ca.gov/system/files/attachments/press-docs/Legal%20Advisory%20-%20Application%20of%20Existing%20CA%20Laws%20to%20Artificial%20Intelligence.pdf,en,"Strategies: Disclosure, Strategies: Disclosure: Accuracy thereof, Harms: Detrimental content, Harms: Financial loss, Risk factors: Safety, Harms: Harm to health/safety, Applications: Sales, retail, and customer relations, Harms: Violation of civil or human rights, including privacy, Harms: Discrimination, Risk factors: Bias, Applications: Finance and investment, Risk factors: Privacy, Risk factors: Security: Dissemination, Strategies: Input controls: Data circulation, Strategies: Input controls"
1975,Stop Smuggling Illicit Synthetic Drugs on U.S. Transportation Networks Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9413,low,0.0,217,0.5,Defunct,"SEC. 103. Development of strategy to accelerate research and development of non-intrusive, advanced inspection technologies to detect illicit synthetic drugs. (a) Defined term.—In this section, the term “appropriate congressional committees” means— (1) the Committee on Commerce, Science, and Transportation of the Senate; (2) the Committee on Homeland Security and Governmental Affairs of the Senate; (3) the Committee on Finance of the Senate; (4) the Committee on the Judiciary of the Senate; (5) the Committee on Energy and Commerce of the House of Representatives; (6) the Committee on Homeland Security of the House of Representatives; (7) the Committee on Financial Services of the House of Representatives; and (8) the Committee on the Judiciary of the House of Representatives. (b) In general.—The Director of the Office of Science and Technology Policy and the Director of the Office of National Drug Control Policy, in consultation and coordination with the Director of the National Science Foundation, the Secretary of Commerce (acting through the Director of the National Institute of Standards and Technology), the Secretary of Energy, the Secretary of Homeland Security, the Administrator of the Transportation Security Administration, and the Attorney General, shall— (1) develop a joint strategy to accelerate research and development and deployment of non-intrusive, advanced inspection technologies and other advanced inspection technologies to detect illicit synthetic drugs, such",https://www.congress.gov/bill/118th-congress/senate-bill/5285/text#toc-ide20c574e72a440a8859c10e1241d4533,en,
1980,Rural Prosperity and Food Security Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9717,low,0.0,201,0.5,Defunct,"SEC. 7518. DEPARTMENT OF AGRICULTURE, DEPARTMENT OF ENERGY, AND NATIONAL SCIENCE FOUNDATION JOINT RESEARCH AND DEVELOPMENT ACTIVITIES. (a) In General.--The Secretary shall carry out, with the Secretary of Energy and the Director of the National Science Foundation, cross- cutting and collaborative research and development activities focused on the joint advancement of Department of Agriculture, Department of Energy, and National Science Foundation mission requirements and priorities. (b) Memoranda of Understanding.--The Secretary shall carry out and coordinate the activities under subsection (a) through the establishment of one or more memoranda of understanding, or other appropriate interagency agreements, with the Secretary of Energy and the Director of the National Science Foundation. (c) Coordination.--In carrying out the activities under subsection (a), the Secretary, the Secretary of Energy, and the Director of the National Science Foundation may-- (1) conduct collaborative research over a variety of focus areas, such as-- (A) modeling and simulation, machine learning, artificial intelligence, data assimilation, large-scale data analytics, and predictive analysis in order to optimize algorithms for purposes relating to agriculture and rural energy, such as life cycle analysis of agricultural or rural energy systems; (B) fundamental agricultural, biological, computational, and environmental science and engineering, including advanced crop science, crop protection, breedin",https://www.congress.gov/bill/118th-congress/senate-bill/5335/text,en,
1981,Rural Prosperity and Food Security Act of 2024,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7845,low,0.0,216,0.5,Defunct,"SEC. 7208. HIGH-PRIORITY RESEARCH AND EXTENSION INITIATIVES. (a) In General.--Section 1672(d) of the Food, Agriculture, Conservation, and Trade Act of 1990 (7 U.S.C. 5925(d)) is amended-- (1) by striking paragraph (9) and inserting the following: ``(9) Coffee plant health initiative.--Research and extension grants may be made under this section for the purposes of-- ``(A) developing and disseminating science-based tools and treatments to combat plant pests and noxious weeds (as those terms are defined in section 403 of the Plant Protection Act (7 U.S.C. 7702)) that impact coffee plants; ``(B) establishing an areawide integrated pest management program in areas affected by, or areas at risk of being affected by, plant pests or noxious weeds (as so defined) that impact coffee plants; ``(C) surveying and collecting data on coffee plant production and health; ``(D) investigating coffee plant biology, immunology, ecology, genomics, and bioinformatics; and ``(E) conducting research on-- ``(i) factors that may contribute to or be associated with coffee plant immune systems; ``(ii) other serious threats to coffee plants, including the sublethal effects of insecticides, herbicides, and fungicides on insects and plants beneficial to coffee plant growth; and ``(iii) the development of mitigating and preventative measures to improve habitat conservation and best management practices in coffee-growing regions.''; (2) by striking paragraph (11) and inserting the following: ``(11) Macadamia",https://www.congress.gov/bill/118th-congress/senate-bill/5335/text,en,
1986,To amend and reauthorize the Workforce Innovation and Opportunity Act and the Older Americans Act of 1965.,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.8115,low,0.0,219,0.5,Defunct,"SEC. 174. EVALUATIONS AND RESEARCH. (a) In General.--Section 169 of the Workforce Innovation and Opportunity Act (29 U.S.C. 3224) is amended-- (1) in subsection (a)-- (A) in paragraph (2)-- (i) by redesignating subparagraph (G) as subparagraph (H); (ii) in subparagraph (F)-- (I) by striking ``; and'' at the end; and (II) by inserting ``, including individuals with barriers to employment'' after ``demographic groups''; and (iii) by inserting the following after subparagraph (F): ``(G) the extent to which such programs or activities are using emerging technology to-- ``(i) collect, analyze, use, and disseminate accurate and transparent local and State level labor market information; ``(ii) integrate administrative data, in accordance with Federal and State privacy laws, to more comprehensively understand and improve education and workforce outcomes; and ``(iii) identify and address deficiencies in existing Federal, State, and local workforce data infrastructure and related source systems; and''; (B) in paragraph (3)-- (i) by striking ``The Secretary'' and inserting the following: ``(A) In general.--The Secretary''; and (ii) by adding at the end the following new subparagraph: ``(B) Limitation.--The Secretary may not use the authority described in subparagraph (A) if the evaluations required under paragraph (1) have not been initiated or completed in the time period required.''; and (C) in paragraph (4), in the second sentence-- (i) by striking ``The Secretary'' and inserting ``",https://www.congress.gov/bill/118th-congress/house-bill/10425/text,en,
1987,To amend and reauthorize the Workforce Innovation and Opportunity Act and the Older Americans Act of 1965.,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.872,low,0.0,102,0.5,Defunct,"SEC. 119. PERFORMANCE ACCOUNTABILITY SYSTEM. (c) Evaluation of State Programs.--Section 116(e) of the Workforce Innovation and Opportunity Act (29 U.S.C. 3141(e)) is amended-- (1) in paragraph (1)-- (A) in the first sentence, by striking ``shall conduct ongoing'' and inserting ``shall use data to conduct analyses and ongoing''; and (B) in the second sentence, by striking ``conduct the'' and inserting ``conduct such analyses and''; and (2) in paragraph (2), by adding ``A State may use various forms of analysis, such as machine learning or other advanced analytics, to improve program operations and outcomes and to identify areas for further evaluation.'' at the end.",https://www.congress.gov/bill/118th-congress/house-bill/10425/text,en,
1988,TAKE IT DOWN Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-05-19,2025,5,negative,-0.3612,low,0.0,211,0.5,Enacted,"AN ACT To require covered platforms to remove nonconsensual intimate visual depictions, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Tools to Address Known Exploitation by Immobilizing Technological Deepfakes on Websites and Networks Act” or the “TAKE IT DOWN Act”. SEC. 2. Criminal prohibition on intentional disclosure of nonconsensual intimate visual depictions. (a) In general.—Section 223 of the Communications Act of 1934 (47 U.S.C. 223) is amended— (1) by redesignating subsection (h) as subsection (i); and (2) by inserting after subsection (g) the following: “(h) Intentional disclosure of nonconsensual intimate visual depictions.— “(1) DEFINITIONS.—In this subsection: “(A) CONSENT.—The term ‘consent’ means an affirmative, conscious, and voluntary authorization made by an individual free from force, fraud, duress, misrepresentation, or coercion. “(B) DIGITAL FORGERY.—The term ‘digital forgery’ means any intimate visual depiction of an identifiable individual created through the use of software, machine learning, artificial intelligence, or any other computer-generated or technological means, including by adapting, modifying, manipulating, or altering an authentic visual depiction, that, when viewed as a whole by a reasonable person, is indistinguishable from an authentic visual depiction of the individual. “(C) IDENTIFIABLE INDIVID",https://www.congress.gov/bill/119th-congress/senate-bill/146/text?s=4&r=1&q=%7B%22search%22%3A%22take+it+down%22%7D,en,
1989,California Privacy Protection Agency Draft Risk Assessment and Automated Decisionmaking Technology Regulations,California,United States,State governments,U.S. state and local documents,Regulation,2024-03-08,2024,3,positive,0.936,low,0.0,202,0.5,Proposed,"[ADDITIONS TO] § 7001. Definitions. “Artificial intelligence” means a machine-based system that infers, from the input it receives, how to generate outputs that can influence physical or virtual environments. The artificial intelligence may do this to achieve explicit or implicit objectives. Outputs can include predictions, content, recommendations, or decisions. Different artificial intelligence varies in its levels of autonomy and adaptiveness after deployment. For example, artificial intelligence includes generative models, such as large language models, that can learn from inputs and create new outputs, such as text, images, audio, or video; and facial- or speech-recognition or -detection technology. “Automated decisionmaking technology” means any technology that processes personal information and uses computation to execute a decision, replace human decisionmaking, or substantially facilitate human decisionmaking. (1) For purposes of this definition, “technology” includes software or programs, including those derived from machine learning, statistics, other data-processing techniques, or artificial intelligence. (2) For purposes of this definition, to “substantially facilitate human decisionmaking” means using the output of the technology as a key factor in a human’s decisionmaking. This includes, for example, using automated decisionmaking technology to generate a score about a consumer that the human reviewer uses as a primary factor to make a significant decision abou",https://cppa.ca.gov/meetings/materials/20240308_item4_draft_risk.pdf,en,
1991,Illinois SB2203,Illinois,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2025-02-07,2025,2,positive,0.9022,low,0.2222,224,0.7,Proposed,"A BILL FOR AN ACT concerning business. Be it enacted by the People of the State of Illinois, represented in the General Assembly: Section 1. Short title. This Act may be cited as the Preventing Algorithmic Discrimination Act. Section 5. Definitions. As used in this Act: ""Algorithmic discrimination"" means the condition in which an automated decision tool contributes to unjustified differential treatment or impacts disfavoring people based on their actual or perceived race, color, ethnicity, sex, religion, age, national origin, limited English proficiency, disability, veteran status, genetic information, reproductive health, or any other classification protected by State law. ""Algorithmic discrimination"" does not include: (1) the offer, license, or use of a high-risk artificial intelligence system by a deployer for the sole purpose of: (A) the deployer's self-testing to identify, mitigate, or prevent discrimination or otherwise ensure compliance with state and federal law; or (B) expanding an applicant, customer, or participant pool to increase diversity or redress historical discrimination; or (2) an act or omission by or on behalf of a private club or other establishment that is not in fact open to the public, as set forth in the Civil Rights Act of 1964. ""Artificial intelligence system"" means a machine-based system that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions",https://ilga.gov/legislation/fulltext.asp?DocName=10400SB2203lv&SessionID=114&GA=104&DocTypeID=SB&DocNum=2203&SpecSess=&Session=&print=true,en,"Risk factors: Bias, Harms: Discrimination, Harms: Violation of civil or human rights, including privacy, Strategies: Evaluation: Impact assessment, Strategies: Evaluation, Strategies: Evaluation: Post-market monitoring, Strategies: Governance development, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Tiering, Strategies: Tiering: Tiering based on impact, Strategies: Disclosure: In standard form, Risk factors: Transparency, Strategies: Performance requirements, Incentives: Civil liability"
1993,Massachusetts House Docket 4053 (2025),Massachusetts,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2025-01-17,2025,1,positive,0.9517,low,0.0,226,0.5,Proposed,"SECTION 1. The General Laws, as appearing in the 2022 Official Edition, are hereby amended by inserting a new chapter: CHAPTER 93M. Consumer Protections in interactions with Artificial Intelligence Systems Section 1. Definitions The following words shall, unless the context clearly requires otherwise, have the following meanings:— ""Algorithmic discrimination"" means any condition in which the use of an artificial intelligence system results in an unlawful differential treatment or impact that disfavors an individual or group of individuals on the basis of their actual or perceived age, color, disability, ethnicity, genetic information, limited proficiency in the English language, national origin, race, religion, reproductive health, sex, veteran status, or other classification protected under the laws of this state or federal law. ""Algorithmic discrimination"" does not include: (1) the offer, license, or use of a high-risk artificial intelligence system by a developer or deployer for the sole purpose of: (i) the developer's or deployer's self-testing to identify, mitigate, or prevent discrimination or otherwise ensure compliance with state and federal law; or (ii) expanding an applicant, customer, or participant pool to increase diversity or redress historical discrimination; or (2) an act or omission by or on behalf of a private club or other establishment that is not in fact open to the public, as set forth in Title II of the federal ""Civil Rights Act of 1964"", 42 U.S.C. Sec.",https://malegislature.gov/Bills/194/HD4053,en,
1996,Oklahoma House Bill 1916,Oklahoma,United States,State governments,U.S. state and local documents,Law/Act,2025-02-04,2025,2,positive,0.6124,low,0.3333,231,0.7,Proposed,"BE IT ENACTED BY THE PEOPLE OF THE STATE OF OKLAHOMA: SECTION 1. NEW LAW A new section of law to be codified in the Oklahoma Statutes as Section 501 of Title 25, unless there is created a duplication in numbering, reads as follows: This act shall be known and may be cited as the ""Responsible Deployment of AI Systems Act."" SECTION 2. NEW LAW A new section of law to be codified in the Oklahoma Statutes as Section 502 of Title 25, unless there is created a duplication in numbering, reads as follows: As used in this act: 1. ""AI system"" means an artificial intelligence or machine learning–based or algorithmic technology designed to perform tasks that typically require human intelligence, including decision-making, prediction, or recommendation; 2. ""Deployer"" means any public entity, private organization, or individual that implements AI systems for operational use; 3. ""Risk classification"" means one of the following: a. Unacceptable Risk: (1) Means AI applications incompatible with social values and fundamental rights, (2) Includes social scoring, manipulative AI targeting vulnerable groups, and real-time biometric identification systems or may include any of the following: (a) deployment of AI systems for discriminatory lending practices or biased law enforcement profiling, (b) unauthorized use of biometric analysis tools for surveillance purposes in public and private spaces, (c) integration of AI into systems with unregulated access to sensitive government databases, or (d) AI-",https://www3.oklegislature.gov/cf_pdf/2025-26%20INT/hB/HB1916%20INT.PDF,en,"Harms: Discrimination, Harms: Violation of civil or human rights, including privacy, Harms: Detrimental content, Applications: Medicine, life sciences and public health, Applications: Government: judicial and law enforcement, Applications: Finance and investment, Risk factors: Privacy, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Evaluation: External auditing, Strategies: Governance development, Strategies: Disclosure: About evaluation"
1997,Illinois HB 3506,Illinois,United States,State governments,Editors' Picks,State/Local Law or Policy,2025-02-18,2025,2,positive,0.9812,medium,0.4444,222,0.7,Proposed,"104TH GENERAL ASSEMBLY State of Illinois 2025 and 2026 HB3506 Introduced , by Rep. Daniel Didech SYNOPSIS AS INTRODUCED: New Act Creates the Artificial Intelligence Safety and Security Protocol Act. Provides that a developer shall produce, implement, follow, and conspicuously publish a safety and security protocol that includes specified information. Provides that, no less than every 90 days, a developer shall produce and conspicuously publish a risk assessment report that includes specified information. Provides that, at least once every calendar year, a developer shall retain a reputable third-party auditor to produce a report assessing whether the developer has complied with its safety and security protocol. Sets forth provisions on the redaction of sensitive information and whistleblower protections. Provides for civil penalties for violations on the Act. A BILL FOR AN ACT concerning business. Be it enacted by the People of the State of Illinois, represented in the General Assembly: Section 1. Short title. This Act may be cited as the Artificial Intelligence Safety and Security Protocol Act. Section 5. Legislative findings and purpose. The General Assembly finds and declares: (a) Artificial intelligence, including new advances in generative artificial intelligence, has the potential to catalyze innovation and the rapid development of a wide range of benefits for Illinoisans and the Illinois economy, including advances in medicine, climate science, and education, and to pu",https://ilga.gov/legislation/fulltext.asp?DocName=&SessionId=114&GA=104&DocTypeId=HB&DocNum=3506&GAID=18&LegID=162191&SpecSess=&Session=,en,"Risk factors: Safety, Risk factors: Security, Risk factors: Security: Cybersecurity, Harms: Harm to property, Harms: Harm to health/safety, Harms: Financial loss, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: External auditing, Strategies: Disclosure: About incidents, Strategies: Disclosure, Risk factors: Transparency, Strategies: Tiering, Strategies: Tiering: Tiering based on impact, Strategies: Governance development"
1998,"Further Continuing Appropriations and Disaster Relief Supplemental Appropriations Act 2025 (Title IX ""Take It Down Act"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,negative,-0.6289,low,0.0,208,0.5,Defunct,"TITLE IX--TAKE IT DOWN ACT SEC. 1001. SHORT TITLE. This title may be cited as the ``Tools to Address Known Exploitation by Immobilizing Technological Deepfakes on Websites and Networks Act'' or the ``TAKE IT DOWN Act''. SEC. 1002. CRIMINAL PROHIBITION ON INTENTIONAL DISCLOSURE OF NONCONSENSUAL INTIMATE VISUAL DEPICTIONS. (a) In General.--Section 223 of the Communications Act of 1934 (47 U.S.C. 223) is amended-- (1) by redesignating subsection (h) as subsection (i); and (2) by inserting after subsection (g) the following: ``(h) Intentional Disclosure of Nonconsensual Intimate Visual Depictions.-- ``(1) Definitions.--In this subsection: ``(A) Consent.--The term `consent' means an affirmative, conscious, and voluntary authorization made by an individual free from force, fraud, duress, misrepresentation, or coercion. ``(B) Digital forgery.--The term `digital forgery' means any intimate visual depiction of an identifiable individual created through the use of software, machine learning, artificial intelligence, or any other computer-generated or technological means, including by adapting, modifying, manipulating, or altering an authentic visual depiction, that, when viewed as a whole by a reasonable person, is indistinguishable from an authentic visual depiction of the individual. ``(C) Identifiable individual.--The term `identifiable individual' means an individual-- ``(i) who appears in whole or in part in an intimate visual depiction; and ``(ii) whose face, likeness, or other d",https://www.congress.gov/bill/118th-congress/house-bill/10445/text,en,
1999,"Further Continuing Appropriations and Disaster Relief Supplemental Appropriations Act 2025 (Section 217 ""Report on Wearable Medical Devices"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9246,low,0.0,104,0.5,Defunct,"SEC. 217. REPORT ON WEARABLE MEDICAL DEVICES. Not later than 18 months after the date of the enactment of this Act, the Comptroller General of the United States shall conduct a technology assessment of, and submit to Congress a report on, the capabilities and limitations of wearable medical devices used to support clinical decision-making. Such report shall include a description of-- (1) the potential for such devices to accurately prescribe treatments; (2) an examination of the benefits and challenges of artificial intelligence to augment such capabilities; and (3) policy options to enhance the benefits and mitigate potential challenges of developing or using such devices.",https://www.congress.gov/bill/118th-congress/house-bill/10445/text,en,
2000,"Further Continuing Appropriations and Disaster Relief Supplemental Appropriations Act 2025 (Title VIII ""Prohibition and Notification on Investments Relating to Covered National Security Transactions"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9471,low,0.0,215,0.5,Defunct,"``TITLE VIII--PROHIBITION AND NOTIFICATION ON INVESTMENTS RELATING TO COVERED NATIONAL SECURITY TRANSACTIONS ``SEC. 801. PROHIBITION ON INVESTMENTS. ``(a) In General.--The Secretary may prohibit, in accordance with regulations issued under subsection (e), a United States person from knowingly engaging in a covered national security transaction in a prohibited technology. ``(b) Evasion.--Any transaction by a United States person or within the United States that evades or avoids, has the purpose of evading or avoiding, causes a violation of, or attempts to violate the prohibition set forth in subsection (a) is prohibited. ``(c) Waiver.--Subject to subsection (d), the Secretary is authorized to exempt from the prohibition set forth in subsection (a) any activity determined by the President, in consultation with the Secretary, the Secretary of Commerce and, as appropriate, the heads of other relevant Federal departments and agencies, to be in the national interest of the United States. ``(d) Congressional Notification.--The Secretary shall-- ``(1) notify the appropriate congressional committees not later than 5 business days after issuing a waiver under subsection (c); and ``(2) include in such notification an identification of the national interest justifying the use of the waiver. ``(e) Regulations.-- ``(1) In general.--The Secretary, in consultation with the Secretary of Commerce and, as appropriate, the heads of other relevant Federal departments and agencies, may issue regul",https://www.congress.gov/bill/118th-congress/house-bill/10445/text,en,
2001,"Further Continuing Appropriations and Disaster Relief Supplemental Appropriations Act 2025 (Title V ""Promoting Resilient Supply Chains"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.9201,low,0.0,213,0.5,Defunct,"TITLE V--PROMOTING RESILIENT SUPPLY CHAINS SEC. 501. SHORT TITLE. This title may be cited as the ``Promoting Resilient Supply Chains Act of 2024''. SEC. 502. ADDITIONAL RESPONSIBILITIES OF ASSISTANT SECRETARY OF COMMERCE FOR INDUSTRY AND ANALYSIS. In addition to the responsibilities of the Assistant Secretary on the day before the date of the enactment of this Act, the Assistant Secretary shall have the following responsibilities: (1) Promote the stability and resilience of critical supply chains and critical and emerging technologies that strengthen the national security of the United States. (2) Lead the Working Group established pursuant to section 503 and consult covered nongovernmental representatives, industry, institutions of higher education, and State and local governments in order to-- (A) promote resilient critical supply chains; and (B) identify, prepare for, and respond to supply chain shocks to-- (i) critical industries; (ii) critical supply chains; and (iii) critical and emerging technologies. (3) Encourage the growth and competitiveness of United States production and manufacturing in the United States of emerging technologies. (4) Assess the resilience, diversity, and strength of critical supply chains and critical and emerging technologies. (5) In consultation with the Secretary of State and the United States Trade Representative, support the availability of critical goods from domestic manufacturers, domestic enterprises, and manufacturing operations in cou",https://www.congress.gov/bill/118th-congress/house-bill/10445/text,en,
2002,New York City Department of Consumer and Worker Protection Amendment to Rules of NY City (Use of Automated Employment Decisionmaking Tools),"New York, NY",United States,Local governments,U.S. state and local documents,State/Local Law or Policy,2023-07-05,2023,7,positive,0.0516,low,0.0556,242,0.7,Enacted,"Section 1. Chapter 5 of Title 6 of the Rules of the City of New York is amended to add Subchapter T to read as follows: Subchapter T: Automated Employment Decision Tools § 5-300. Definitions. As used in this subchapter, the following terms have the following meanings: Automated Employment Decision Tool. “Automated employment decision tool” or “AEDT” means “Automated employment decision tool” as defined by § 20-870 of the Code where the phrase “to substantially assist or replace discretionary decision making” means: i. to rely solely on a simplified output (score, tag, classification, ranking, etc.), with no other factors considered; or ii. to use a simplified output as one of a set of criteria where the simplified output is weighted more than any other criterion in the set; or iii. to use a simplified output to overrule conclusions derived from other factors including human decision-making. Bias Audit. “Bias audit” means “Bias audit” as defined by § 20-870 of the Code. Candidate for Employment. “Candidate for employment” means a person who has applied for a specific employment position by submitting the necessary information or items in the format required by the employer or employment agency. Category. “Category” means any component 1 category required to be reported by employers pursuant to subsection (c) of section 2000e-8 of title 42 of the United States Code as specified in part 1602.7 of title 29 of the Code of Federal Regulations, as designated on the Equal Employment",https://rules.cityofnewyork.us/wp-content/uploads/2023/04/DCWP-NOA-for-Use-of-Automated-Employment-Decisionmaking-Tools-2.pdf,en,"Risk factors: Bias, Strategies: Evaluation: External auditing, Strategies: Evaluation, Applications: Business services and analytics, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Disclosure: In deployment, Strategies: Disclosure: About inputs"
2009,City of Seattle Generative Artificial Intelligence Policy,"Seattle, WA",United States,Local governments,U.S. state and local documents,Policy/Guidance,2023-10-23,2023,10,positive,0.9568,low,0.0,216,0.5,Enacted,"Generative Artificial Intelligence Policy POL-209 Purpose The purpose of this policy is to set forth requirements City departments will observe when acquiring and using software that meets the definition of “generative artificial intelligence.” Scope All City departments. Vendors, contractors, and volunteers who operate on behalf of the City are also subject to this policy. Definitions Generative Artificial Intelligence (Generative AI) is a class of computer software and systems, or functionality within systems, that use large language models, algorithms, deep-learning, and machine learning models, and are capable of generating new content, including but not limited to text, images, video, and audio, based on patterns and structures of input data. These also include systems capable of ingesting input and translating that input into another form, such as text-to-code systems. While this policy document includes principles that apply to AI technologies generally, the policy statements apply only to generative AI systems. Artificial Intelligence (AI) Principles Principles describe general codes of conduct that represent the City’s values and are aligned with our responsibilities to the residents we serve. These principles serve to guide City employees in their use of both generative and traditional AI technology. City employees shall adhere to the principles and requirements outlined in this policy, and will be held accountable for compliance with these commitments. 1. Innovatio",https://seattle.gov/documents/Departments/SeattleIT/City-of-Seattle-Generative-Artificial-Intelligence-Policy.pdf,en,
2010,City of San Jose Generative AI Guidelines,"San Jose, CA",United States,Local governments,U.S. state and local documents,State/Local Law or Policy,2023-09-23,2023,9,positive,0.9694,low,0.0,233,0.5,Enacted,"[table of contents, pictures and footnotes omitted] Executive Summary: Generative Artificial Intelligence (AI) is a new branch of AI technology that can generate content—such as stories, poetry, images, voice, and music— at the request of a user. Many organizations have banned Generative AI, while others allow unrestricted usage. The City recognizes the opportunity for a controlled and responsible approach that acknowledges the benefits to efficiency while minimizing the risks around AI bias, privacy, and cybersecurity. This is the first step in a collaborative process to develop the City’s overall AI policy. Registered users will be invited to join the Information Technology Department in a working group to share their experience and co-develop the City’s AI policies. At a baseline, users must follow these rules while using Generative AI for City work, this includes direct services like ChatGPT and extensions like Compose.ai: 1. Information you enter into Generative AI systems could be subject to a Public Records Act (PRA) request, may be viewable and usable by the company, and may be leaked unencrypted in a data breach. Do not submit any information to a Generative AI platform that should not be available to the general public (such as confidential or personally identifiable information). 2. Review, revise, and fact check via multiple sources any output from a Generative AI. Users are responsible for any material created with AI support. Many systems, like ChatGPT, only use",https://www.sanjoseca.gov/home/showpublisheddocument/100095/638314083307070000,en,
2012,City of Boston Interim Guidelines for Using Generative AI,"Boston, MA",United States,Local governments,U.S. state and local documents,State/Local Law or Policy,2023-05-18,2023,5,positive,0.9073,low,0.0,243,0.5,Proposed,"City of Boston Interim Guidelines for Using Generative AI Version 1.1 Prepared by Santiago Garces, Chief Information Officer, City of Boston Published: 5/18/2023 Applies to: all City agencies and departments with the exception of Boston Public Schools Purpose Generative AI is a set of relatively new technologies that leverages large (very large) volumes of data along with some machine learning (ML) techniques to produce content based on inputs from the users known as prompts. The new content can be written (e.g. ChatGPT or Bard), or visual (e.g. Dall-E). These tools are evolving rapidly, and are still the subject of active research: improving our understanding of how they actually work, and the impacts of their use in society. These tools are not actual intelligence in the human sense, rather, they are very sophisticated models that predict what the language, text, or video that satisfies the prompt should be. Because of their impact and potential usefulness, as well as the risks and dangers, these guidelines serve as an interim resource for employees of the City of Boston. Generative AI is a tool. We are responsible for the outcomes of our tools. For example, if autocorrect unintentionally changes a word - changing the meaning of something we wrote, we are still responsible for the text. Technology enables our work, it does not excuse our judgment nor our accountability. These guidelines should be replaced in the future with policies and standards. But we want to encourage r",https://www.boston.gov/sites/default/files/file/2023/05/Guidelines-for-Using-Generative-AI-2023.pdf,en,
2013,County of Santa Cruz Artificial Intelligence Appropriate Use Policy,"Santa Cruz County, CA",United States,Local governments,U.S. state and local documents,Policy/Guidance,2023-09-19,2023,9,positive,0.976,low,0.0,216,0.5,Enacted,"County of Santa Cruz Artificial Intelligence Appropriate Use Policy Purpose: The purpose of this policy is to establish County of Santa Cruz employee practices for the responsible and secure use of generative artificial intelligence (AI). The County is committed to utilizing Artificial Intelligence (AI) technologies responsibly and ethically to improve processes, enhance services to County residents, and support employees to do their best work. This AI Appropriate Use Policy provides simple, user-centric guidance for all employees, regardless of technical expertise. AI tools are developing at an exponential rate. The County will regularly review and update this policy to keep it aligned with ethical and legal standards and technological advancements in generative AI as frequently as needed. Scope: This policy applies to all employees, contractors, and any other third-party individuals or entities who have access to generative AI technologies or are involved in using generative AI tools or platforms on behalf of our organization. 1. Defining Artificial Intelligence (AI): For the purposes of this policy, Artificial Intelligence, also known as machine intelligence, is the simulation of human intelligence processes, such as problem solving by machines. 2. Defining Generative AI Tools: Generative AI tools are computer programs capable of many activities, including but not limited to completing general administrative office tasks, data analysis, programming, and image creation. Whi",https://www2.santacruzcountyca.gov/personnel/vpolandproc/ProceduresManual/PM6476.pdf,en,
2014,City of Tempe Ethical Artificial Intelligence Policy,"Tempe, AZ",United States,Local governments,U.S. state and local documents,Policy/Guidance,2023-06-15,2023,6,positive,0.9936,low,0.0,214,0.5,Enacted,"Ethical Artificial Intelligence (AI) Policy I. Purpose The City of Tempe established the Ethical Artificial Intelligence (AI) Policy to affirm Tempe’s commitment to responsible and ethical use of AI through the principles that ensure transparency, fairness, accountability, and the protection of individual rights in all AI-related activities conducted by the City of Tempe. Being intentional in our adoption and use of AI technologies will drive innovation, support increased efficiencies in operations and improved experiences for community engagement. This policy outlines the principles, guidelines, and procedures governing the responsible and ethical use of AI technologies within Tempe. II. Scope This policy applies to the design, development, and deployment of AI for: All departments, agencies, employees, contractors, and stakeholders involved in the development, deployment, and utilization of AI within Tempe. Categories of AI inclusive of predictive analytics, machine learning, deep learning, generative AI, and automated decision making All cases where AI functionality is known to be included, such as new tools for existing products, new products being considered for use or where AI technology is developed by Tempe employees, contractors, partner agencies or other stakeholders. III. Policy Statement The City of Tempe is committed to designing, developing, and deploying AI technologies in a responsible and ethical manner. We recognize that AI has the potential to significantly",https://tempe.hylandcloud.com/AgendaOnline/Documents/ViewDocument/ETHICAL%20ARTIFICAL%20INTELLIGENCE%20POLICY.DOCX.pdf?meetingId=1451&documentType=Agenda&itemId=5692&publishId=9354&isSection=false,en,
2019,Boise Regulations 4.30q City Use of Artificial Intelligence (AI),"Boise, ID",United States,Local governments,U.S. state and local documents,Regulation,2023-12-01,2023,12,positive,0.9911,low,0.2222,216,0.7,Enacted,"Document Type: Regulation Number: 4.30q Effective: 12-1-23 Revised: CITY USE OF ARTIFICIAL INTELLIGENCE (AI) Scope This regulation applies to all city departments, agencies, and entities involved in the development, procurement, deployment, or use of AI technologies. It also covers any third-party contractors or vendors that work with the City of Boise on AI-related projects. Regulation Owner Business Owner: Director, Innovation and Performance Technical Owner: Director, Information Technology 1. Regulation Purpose The purpose of this Regulation is to establish guidelines and principles for the responsible and ethical use of Artificial Intelligence (AI) technologies within the City of Boise. This document aims to harness the potential of AI to enhance public services, improve efficiency, and drive innovation, while ensuring that its deployment upholds the values of transparency, accountability, fairness, privacy, and inclusivity. Of particular interest is Generative AI, which is a set of relatively new technologies that leverages very large volumes of data along with some machine learning techniques to produce very sophisticated content based on inputs from the users known as prompts. The new content can be written (e.g., ChatGPT or Bard), or visual (e.g., Dall-E), and often cannot be distinguished from human-generated content. These tools are evolving rapidly and are still the subject of active research to improve the technical community’s understanding of how they actually",https://www.cityofboise.org/departments/human-resources/employee-policy-handbook/section-400-general-provisions/430q-city-use-of-artificial-intelligence-ai-regulation/,en,"Risk factors: Security, Risk factors: Security: Dissemination, Risk factors: Transparency, Strategies: Governance development, Applications: Government: other applications/unspecified, Strategies: Licensing, registration, and certification, Risk factors: Reliability, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: In standard form, Strategies: Convening, Strategies: Evaluation, Strategies: Evaluation: Post-market monitoring, Strategies: Evaluation: Conformity assessment"
2021,San Francisco Generative AI Guidelines,"San Francisco, CA",United States,Local governments,U.S. state and local documents,State/Local Law or Policy,2023-11-09,2023,11,positive,0.9738,low,0.0,222,0.5,Proposed,"Top 3 Guidelines for Exploring with Generative AI Always review and fact check AI-generated content before using it Always disclose usage of Generative AI in your output Never enter sensitive information into public Generative AI tools, like ChatGPT. The information you enter can be viewed by the companies that make the tools and, in some cases, members of the public Introduction Artificial Intelligence (AI) has great potential to provide public benefits, when used responsibly. Recently, Generative AI technology has gained mainstream attention and become available for use by staff of the City and County of San Francisco (City). Generative AI generates new data based on patterns learned from existing data and can produce content that mimics human creativity. Examples include text generation, image creation, and music composition. Generative AI differs from AI technology currently in use by the City, which supports informed decisions based on input data but does not create new content. Generative AI offers new opportunities and also poses unique challenges to ensure responsible and effective use. Scope of the Guidelines The following guidelines apply to all city department personnel, including employees, contractors, consultants, volunteers, and vendors while working on behalf of the City. The guidelines will evolve based on legislative and regulatory developments and changes to Generative AI technology. The City Administrator’s Office will update the guidelines as advancements",https://www.sf.gov/reports--december-2023--san-francisco-generative-ai-guidelines?_gl=1*zs7iu8*_ga*MTk1MjI0ODc1Mi4xNzA0OTA3NDUy*_ga_BT9NDE0NFC*MTcwNTQyODg0Ni41LjAuMTcwNTQyODg0Ni4wLjAuMA..*_ga_63SCS846YP*MTcwNTQyODg0Ni41LjAuMTcwNTQyODg0Ni4wLjAuMA,en,
2025,"Indianapolis City Council Proposal No.362, 2023","Indianapolis, IN",United States,Local governments,U.S. state and local documents,State/Local Law or Policy,2023-12-04,2023,12,positive,0.989,low,0.0,221,0.7,Enacted,"PROPOSAL FOR A COUNCIL RESOLUTION establishing a study commission to: (1) review the City and County’s (City) current use of artificial intelligence (AI) and its associated technologies, (2) gather information from AI experts, industry leaders, and community members as to how AI can be used in the future to provide better services to the citizens of the Consolidated City, (3) recommend to the Mayor and elected county officials policies for trustworthy and transparent usage AI as a part of the provision of services by departments and agencies, (5) recommend to the City-County Council the modification of any existing ordinances or the provision of new ordinances establishing trustworthy and transparent usage AI. WHEREAS, the rapid advancement of artificial intelligence presents both opportunities and challenges for cities, including Indianapolis; and WHEREAS, Indianapolis recognizes the potential of artificial intelligence to enhance city services, foster economic growth, and improve the quality of life for its residents; and WHEREAS, the responsible development and deployment of AI technologies require informed policymaking, rooted in robust public discourse and expert insight; and WHEREAS, the Council acknowledges the need to stay ahead of these technological shifts by monitoring its implications, developing strategic proposals, and educating our constituents on AI's role in the future of the city; now, therefore: BE IT RESOLVED BY THE CITY-COUNTY COUNCIL OF THE CITY OF INDIA",https://media.graphassets.com/nNzAtTfSNSHihpHfEPiG?_gl=1*12x446a*_ga*OTE3ODg5MjAyLjE2NTc4Mjk3NTA.*_ga_G6FYGSYGZ4*MTY5OTYyOTUxMi4xMzQuMS4xNjk5NjMyOTI5LjE3LjAuMA,en,"Strategies: Convening, Strategies: Government study or report, Strategies: Governance development, Strategies: New institution, Strategies: Government support"
2031,City of Long Beach Data Privacy Guidelines (2021),"Long Beach, CA",United States,Local governments,U.S. state and local documents,State/Local Law or Policy,2021-01-01,2021,1,positive,0.9872,low,0.1111,236,0.7,Enacted,"Overview: Data privacy and security are core values of our organization. To successfully provide a high quality of life for those that live, work, and play in Long Beach, it is critical that we build public trust through excellence in data privacy, data security, and community engagement. The following Data Privacy Guidelines assert the City’s core values on protecting the privacy and information security of our constituents. They are intended to provide a framework to help the City and partners incorporate privacy by design as we deploy new technologies and new services in Long Beach. Note: The California Consumer Protection Act (CCPA), which went into effect January 1, 2020, provides a set of consumer rights governing data collection requirements for businesses. It does not apply to public agencies at this time, though City vendors that meet CCPA eligibility requirements must comply. The City supports the intent behind the CCPA (and subsequent amendments such as the California Privacy Rights Act which passed in November 2020), and we strive to adhere to the guidelines below which are based upon CCPA requirements. The City is also required to comply with data transparency laws such as the California Public Records Act, which provides fundamental rights to the public to access government information. Key Terms: • Data privacy: The practices taken to govern the collection, protection, and sharing of personal and confidential information. • Smart city: A city that uses emerging",https://www.longbeach.gov/globalassets/smart-city/media-library/documents/final_data-privacy-guidelines,en,"Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Risk factors: Bias, Harms: Discrimination, Strategies: Performance requirements"
2034,Executive order No. 78 (St. Louis),"St. Louis, MO",United States,Local governments,U.S. state and local documents,Executive Order,2024-02-23,2024,2,positive,0.9856,low,0.0,198,0.5,Enacted,"An Executive Order relating to transparency and accountability in the use of surveillance technologies used for law enforcement and public safety purposes by the City of St. Louis Metropolitan Police Department (“SLMPD”): WHEREAS, governments have a responsibility to respect and protect democratic principles, human rights, and fundamental freedoms; and WHEREAS, governments should be transparent regarding the types of surveillance technologies they use for law enforcement purposes and the expenditure of public funds for such technologies; and WHEREAS, governments should be transparent regarding the retention, destruction, and access to information and data collected through surveillance technologies; and WHEREAS, the responsible use of surveillance technologies for law enforcement purposes works to protect individual privacy, personal data, human rights and fundamental freedoms, and fosters transparency, accountability, and civic participation, while appropriately and effectively pursuing legitimate public safety objectives; and WHEREAS, when used responsibly and in a manner consistent with democratic principles, human rights, and fundamental freedoms, surveillance technologies can ensure the rights and liberties of City residents are maintained, while serving as important tools for protecting, preserving, and promoting public safety; and WHEREAS, governments should also hold any vendors of surveillance technology being used for law enforcement purposes accountable for protect",https://www.stlouis-mo.gov/government/departments/mayor/documents/executive-orders/upload/EO-78-Surveillance-Transparency-1.pdf,en,
2035,"St Louis, MO Board Bill Number 185 2023-24","St. Louis, MO",United States,Local governments,U.S. state and local documents,Law/Act,2024-05-06,2024,5,positive,0.886,low,0.0,227,0.5,Enacted,"SECTION ONE. Definitions 1. “Artificial Intelligence” means a machine-based system that can, for a given set of human defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through analysis in an automated manner; and use model inference to formulate options for information or action. This definition shall comply with the meaning outlined in 15 U.S.C. 9401(3). 2. “City Entity” means any agency, department, bureau, unit, or commission of the City of St. Louis or any person or entity acting on behalf of any agency, department, bureau, unit, or commission of the City of St. Louis. A Special Tax District shall not be considered a City Entity. 3. “Committee” means a committee to which, pursuant to the Rules of the Board of Aldermen, bills affecting matters that are subject to this Ordinance are assigned. 4. “Discrimination” means the disparate treatment or consideration of, or making a distinction in favor or against a person based on the characteristics, real or perceived, for which discriminatory treatment is prohibited under the laws and regulations of the United States, the State of Missouri, and the Charter and ordinances of the City of St. Louis, which shall include the following characteristics; race, religion, national origin, age, sex, sexual orientation, gender identity,",https://www.stlouis-mo.gov/government/city-laws/upload/legislative/boardbills/introduced/BB185FS%20Combined2.pdf,en,
2037,City of St. Louis Information Technology Policy #2023-001 Guidance on Generative AI,"St. Louis, MO",United States,Local governments,U.S. state and local documents,Policy/Guidance,2023-10-09,2023,10,positive,0.8553,low,0.0,235,0.5,Enacted,"Generative Artificial Intelligence (AI) tools have been on the news a lot lately and causing understandable excitement with their potential uses. This technology will likely have a large impact on many organizations going forward. Generative AI tools can ingest vast amounts of information and generate content such as text, images, video, or audio, based on user prompts. This technology is also being incorporated into common online tools such as search engines. We are advising that employees follow these guidelines when using generative AI tools, such as ChatGPT, BingAI and Google Bard. Since the field is so new and rapidly evolving, policy around its use and mitigation of its risks are still being evaluated. In the interim, we are communicating some guidelines around its use by City employees as part of their job. 1. Use of these tools should follow the City’s Information Technology Acceptable Use Policy 2. Purchase of any AI related technology/software should be vetted through ITSA. 3. Security: if you’re using City email to logon to these sites, do NOT use your City password. Unfortunately, bad actors are also using these tools to make malware more sophisticated and thus increased awareness and caution are recommended. 4. Sensitive Information: do not utilize, upload, or include sensitive, confidential, or personally identifiable information when using these systems. 5. Bias & Accuracy: Since these tools are still maturing and the algorithms they use are evolving, there may",https://www.stlouis-mo.gov/government/departments/information-technology/documents/upload/Guidance-on-Generative-AI.pdf,en,
2038,Artificial Intelligence Law Proposal (Grand National Assembly of Turkey),Government of Turkey,Other countries,Other countries,Miscellaneous documents,Other,2024-06-24,2024,6,positive,0.9956,low,0.2778,209,0.7,Proposed,"Law Proposal on Artificial Intelligence Purpose and Scope ARTICLE 1 – The purpose of this Law is to ensure the safe, ethical, and fair use of artificial intelligence technologies, to assure that personal data protection and privacy rights are not violated, and to establish a regulatory framework for the development and use of artificial intelligence systems. This Law applies to providers, deployers, users, importers, and distributors of artificial intelligence systems, as well as to persons affected by such systems. Definitions ARTICLE 2 – For the purposes of this Law; Artificial Intelligence: Refers to computer-based systems capable of performing human-like cognitive functions, and have capabilities such as learning, reasoning, problem-solving, sensing, and understanding language. Provider: Refers to natural or legal persons who develop, produce, and market artificial intelligence systems. Deployer/User: Refers to natural or legal persons who distribute artificial intelligence systems for commercial purposes or use them within their own operations. Importer: Refers to natural or legal persons who import artificial intelligence systems from abroad. Distributor: Refers to natural or legal persons who market and sell artificial intelligence systems. Artificial Intelligence Operators: Refers to all providers, deployers, users, importers, and distributors. Fundamental Principles ARTICLE 3 – The following fundamental principles shall be adhered to in the development, usage and dep",https://turkishlawblog.com/insights/detail/english-translation-of-the-law-proposal-on-ai#purpose-and-scope,en,"Risk factors: Privacy, Risk factors: Safety, Risk factors: Transparency, Harms: Discrimination, Harms: Harm to health/safety, Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Conformity assessment, Incentives: Fines"
2039,National Artificial Intelligence Strategy 2024-2025 Action Plan (Turkey),Government of Turkey,Other countries,Other countries,Miscellaneous documents,Law/Act,2024-07-24,2024,7,positive,0.9899,low,0.1111,200,0.7,Enacted,"NATIONAL ARTIFICIAL INTELLIGENCE STRATEGY 2024-2025 ACTION PLAN No. 1 Strategic Priority: Training Artificial Intelligence Experts and Increasing Employment in the Field Institution Responsible for Action: Ministry of Industry and Technology Relevant Institution: Ministry of Labor and Social Security, Ministry of Foreign Affairs, Presidential Human Resources Office, Presidency for Turks Abroad and Related Communities Action Name: Action 1.1_Mechanisms for attracting talents in the field of AI to Turkey will be implemented under the TechVisa Program. No. 2 Strategic Priority: Training Artificial Intelligence Experts and Increasing Employment in the Field Institution Responsible for Action: Scientific and Technological Research Council of Turkey (TÜBİTAK) Relevant Institution: Ministry of Labor and Social Security, Ministry of Industry and Technology, Presidential Human Resources Office, Presidency for Turks Abroad and Related Communities Action Name: Action 1.2_In order to increase the competent workforce in the field of AI, the amount of support for the International Leader/Young Researchers and Industry Doctorate Program and the number of researchers benefiting from these programs will be increased. No. 3 Strategic Priority: Training Artificial Intelligence Experts and Increasing Employment in the Field Institution Responsible for Action: Council of Higher Education Relevant Institution: Ministry of Labor and Social Security, Ministry of Industry and Technology, Presidential",https://cbddo.gov.tr/SharedFolderServer/Genel/File/UlusalYapayZekaStratejisi2024-2025EylemPlani.pdf,en,"Strategies: Government support: AI workforce-related, Strategies: Government support, Strategies: Governance development, Strategies: New institution, Strategies: Performance requirements, Strategies: Government support: For R&D, Strategies: Tiering, Strategies: Evaluation, Strategies: Evaluation: External auditing, Risk factors: Security, Risk factors: Security: Cybersecurity"
2040,Google DeepMind Frontier Safety Framework Version 2.0,Private-sector companies,,,Corporate policies and commitments,Other,2025-02-04,2025,2,negative,-0.9881,medium,0.5,231,1.0,Enacted,"4th February 2025 Frontier Safety Framework Version 2.0 [Introductory material omitted. Notes omitted throughout.] Framework This section describes the central components of the Frontier Safety Framework. These protocols represent our current understanding of and recommended approach for how severe frontier AI risks may be anticipated and addressed. 1 - Critical Capability Levels The Framework is built around capability thresholds called “Critical Capability Levels.” These are capability levels at which, absent mitigation measures, AI models or systems may pose heightened risk of severe harm. CCLs can be determined by identifying and analyzing the main foreseeable paths through which a model could cause severe harm, and then defining the CCLs as the minimal set of capabilities a model must possess to do so. Note that we have selected our CCLs to be conservative; it is not clear to what extent CCLs might translate to harm in real-world contexts. We describe two sets of CCLs: misuse CCLs that can indicate heightened risk of severe harm from misuse if not addressed, and deceptive alignment CCLs that can indicate heightened risk of deceptive alignment-related events if not addressed. For misuse risk, we define CCLs in high-risk domains where, based on early research, we believe risks of severe harm may be most likely to arise from future models: - CBRN: Risks of models assisting in the development, preparation, and/or execution of a chemical, biological, radiological, or nuclear",https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/updating-the-frontier-safety-framework/Frontier%20Safety%20Framework%202.0%20(1).pdf,en,"Strategies: Evaluation, Strategies: Evaluation: Impact assessment, Strategies: Governance development, Risk factors: Security: Cybersecurity, Risk factors: Security, Strategies: Tiering, Strategies: Tiering: Tiering based on domain of application, Strategies: Tiering: Tiering based on planning ability, Strategies: Tiering: Tiering based on impact, Harms: Harm to health/safety, Risk factors: Safety, Strategies: Evaluation: External auditing, Harms: Detrimental content, Strategies: Evaluation: Conformity assessment, Strategies: Evaluation: Post-market monitoring"
2041,California SB 53,California,United States,State governments,Editors' Picks,State/Local Law or Policy,2025-01-07,2025,1,positive,0.9562,low,0.2222,230,0.7,Proposed,"SECTION 1. Section 11547.6.1 is added to the Government Code, to read: 11547.6.1. (a) There is hereby established within the Government Operations Agency a consortium that shall develop, pursuant to this section, a framework for the creation of a public cloud computing cluster to be known as “CalCompute.” (b) The consortium shall develop a framework for the creation of CalCompute that advances the development and deployment of artificial intelligence that is safe, ethical, equitable, and sustainable by doing, at a minimum, both of the following: (1) Fostering research and innovation that benefits the public. (2) Enabling equitable innovation by expanding access to computational resources. (c) The consortium shall make reasonable efforts to ensure that CalCompute is established within the University of California to the extent possible. (d) CalCompute shall include, but not be limited to, all of the following: (1) A fully owned and hosted cloud platform. (2) Necessary human expertise to operate and maintain the platform. (3) Necessary human expertise to support, train, and facilitate the use of CalCompute. (e) The consortium shall operate in accordance with all relevant labor and workforce laws and standards. (f) (1) On or before January 1, 2027, the Government Operations Agency shall submit, pursuant to Section 9795, a report from the consortium to the Legislature with the framework developed pursuant to subdivision (b) for the creation and operation of CalCompute. (2) The re",https://leginfo.legislature.ca.gov/faces/billCompareClient.xhtml?bill_id=202520260SB53&showamends=false,en,"Strategies: Convening, Strategies: New institution, Strategies: Government support, Strategies: Government support: AI workforce-related, Strategies: Disclosure, Strategies: Disclosure: About evaluation, Strategies: Evaluation, Strategies: Governance development, Strategies: Government study or report, Incentives: Civil liability, Risk factors: Safety, Harms: Financial loss, Harms: Harm to health/safety, Harms: Harm to property, Strategies: Input controls"
2042,"Los Angeles AI Roadmap 2024, Best Practices and Roadmap","Los Angeles, CA",United States,Local governments,U.S. state and local documents,Law/Act,2024-06-04,2024,6,positive,0.9635,low,0.0,235,0.5,Enacted,"BEST PRACTICE AI RECOMMENDATIONS FOR THE CITY OF LOS ANGELES For several years, the Information Technology Agency (ITA) has been monitoring trends and tools in artificial intelligence and other emerging technologies. In preparation of this report, the ITA also solicited best practice research from industry subject matter experts, Gartner Inc., a major Big 4 technology consulting company with a specialized AI practice, professors at the University of Southern California (USC) Viterbi School of Engineering, technology vendors, and various periodicals. While artificial intelligence is a rapidly changing field, the following is a summary of key recommendations for the City of Los Angeles based on best practices in artificial intelligence as understood in the industry today: Recommendation #1 - L.A. City AI Tools Should Tailor to Two Distinct User Segments Not everyone uses AI tools in the same way. At the City of Los Angeles, there are two distinct groups of users that we should consider and train to: 1. City Employees & Managers (AI Users) - These are the City employees who will use AI tools that are made available to them. These tools will most be used in Google Workspace, Salesforce, ServiceNow, or other existing software (i.e. AI Embedded Software). In addition, a much smaller set of City employees will use custom-developed AI tools for a specific purpose (e.g. call center software, fraud detection, environmental monitoring, etc). Training in basic AI usage (e.g. prompts, log",https://drive.google.com/file/d/12gbVV3Qk7qixa9BU8g8zcA5LZbnDPUsk/view,en,
2043,The City of Tulsa Municipal Court Rules 2024,"Tulsa, OK",United States,Local governments,U.S. state and local documents,State/Local Law or Policy,2024-04-01,2024,4,negative,-0.8779,low,0.0,118,0.5,Enacted,"Any attorney, pro se defendant, victim or other party using a generative AI tool in the preparation or drafting of a document filed with the Municipal Criminal Court must disclose in that filing that generative AI was used. Additionally, the name of the specific generative AI tool that was used must be stated. Generative AI shall include, but shall not be limited to, ChatGPT, Bing AI, or Google Bard. All filers should note that 12 O.S. §2011 continues to apply to all filings presented to the Municipal Criminal Court. Accordingly, the Municipal Criminal Court will continue to construe all such filings, as certified by the person signing the filed document, to be in compliance with 12 O.S. §2011(B)(2).",https://www.cityoftulsa.org/government/departments/municipal-court/court-rules/,en,
2044,Kendall County Generative AI Chatbot Usage Policy,"Kendall County, IL",United States,Local governments,U.S. state and local documents,Policy/Guidance,2023-06-27,2023,6,positive,0.8442,low,0.0,225,0.5,Proposed,"NEW PROPOSED POLICY FOR COUNTY HANDBOOK Section 9.6. Generative Artificial Intelligence (AI) Chatbot Usage Policy A. Purpose With the increasing popularity of generative AI chatbots such as OpenAI’s ChatGPT and Google’s Bard, it has become necessary to outline the proper use of such tools while working with the Employer. While we remain committed to adopting new technologies to aid our mission when possible, we also understand the risks and limitations of generative AI chatbots and want to ensure responsible use. Our goal is to protect employees, Executives, the public, and Kendall County from harm. B. Overview While AI chatbots can be used to perform a variety of functions, this policy addresses only the use of a web-based interface to ask or “prompt” the chatbot in a conversational manner to find answers to questions or to create or edit written content. Some examples of what could be created using an AI chatbot include: Emails and letters. Blog posts, reports and other publications. Sales and advertising copy. Policies and job descriptions. Spreadsheet calculations. Foreign language translations. Coding development or debugging. Document or information sorting. Outlines or summaries of internal or external information. There are, however, risks in using this technology, including uncertainty about who owns the AI-created content and security/privacy concerns with inputting proprietary information or sensitive information about an employee, elected official, a member of the",https://www.kendallcountyil.gov/home/showpublisheddocument/27425/638231336413395090,en,
2045,"Miami Dade County Artificial Intelligence Report: Policies, Principles & Guidelines","Miami Dade County, FL",United States,Local governments,U.S. state and local documents,Policy/Guidance,2024-03-22,2024,3,positive,0.993,low,0.0,209,0.5,Enacted,"AUTHORITY: Section 5.02 of the Miami-Dade County Home Rule Amendment and Charter. SCOPE: This Administrative Order applies to County employees under the purview of the Mayor. PURPOSE: The purpose of this Administrative Order (AO) is to guide Miami-Dade County employees in the responsible and ethical use of artificial intelligence (AI), including tools like ChatGPT. The objective is to utilize AI technologies in a manner that maximizes efficiency and security while adhering to the ethical standards and legal requirements specific to our County. The policy outlines key directives to: 1. Comply with Miami-Dade County’s public records policies and retention rules. 2. Ensure transparent use of AI in creating work products relevant to employee responsibilities. 3. Set protocols for handling County data, including maintaining security and confidentiality. The County’s priority is to ensure the safety of all employees and residents, while maintaining openness, flexibility, and productivity. By setting forth guiding principles, objectives, and actionable strategies, this document establishes a foundation that safeguards County values, ensures fairness, and upholds the highest standards of data privacy, integrity, and security. Through this policy, the administration seeks to navigate the evolving landscape of AI with a human-centric approach, fostering innovation while minimizing risks and challenges associated with security breaches, and other potential unintended consequences. This",https://documents.miamidade.gov/mayor/memos/03.22.24-Report-on-Miami-Dade-Countys-Policy-on-Artificial-Intelligence-Directive-No-231203.pdf,en,
2046,"Department of Energy Quantum Leadership Act of 2024, Section 2",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-03,2025,1,positive,0.7506,low,0.0,200,0.5,Defunct,"SEC. 2. Department of Energy quantum information science research program. Section 401 of the National Quantum Initiative Act (15 U.S.C. 8851) is amended— (1) by striking subsection (a) and inserting the following: “(a) In general.—The Secretary of Energy shall carry out a research, development, and demonstration program on quantum information science, engineering, and technology.”; (2) in subsection (b)— (A) in paragraph (1), by inserting “, engineering, and technology” after “science”; (B) in paragraph (2), by inserting “, engineering, and technology” after “science”; (C) by striking paragraph (3) and inserting the following: “(3) provide research experiences and training for additional undergraduate and graduate students in quantum information science, engineering, and technology, including in the fields specified in paragraph (4);”; (D) by redesignating paragraphs (3) through (5) as paragraphs (5) through (7), respectively; (E) by inserting after paragraph (2) the following: “(3) operate National Quantum Information Science Research Centers under section 402 to accelerate and scale scientific and technical breakthroughs in quantum information science, engineering, and technology, and maintain state-of-the-art infrastructure for quantum researchers and industry partners; “(4) conduct cooperative basic and applied research with industry, National Laboratories, institutions of higher education, and other research institutions to facilitate the development, demonstration, and",https://www.congress.gov/bill/118th-congress/senate-bill/4932/text,en,
2047,City of San Jose Artificial Intelligence Policy 1.7.12,"San Jose, CA",United States,Local governments,U.S. state and local documents,Policy/Guidance,2024-06-28,2024,6,positive,0.9726,medium,0.5,229,0.7,Enacted,"Artificial Intelligence (AI) Policy 1.7.12 PURPOSE This policy establishes a governance structure that allows the City of San José (hereafter referred to as “City”) to utilize Artificial Intelligence (AI) and AI systems (systems) while providing the necessary safeguards for purposeful and responsible use. The key objectives of the AI Policy are to: • Provide guidance that is clear, easy to follow, and supports decision-making for the staff, interns, consultants, contractors, partners, and volunteers who may be purchasing, configuring, developing, using, maintaining, or leveraging AI to provide services to the City; • Ensure that the use of AI systems adheres to the Guiding Principles with regard to how systems are purchased, configured, developed, operated, or maintained; • Define roles and responsibilities related to the usage of AI; • Establish and maintain processes to assess and manage risks presented by AI; • Align the governance of AI with existing data governance, security, and privacy measures in accordance with the City’s Information and Systems Security Policy and City Council’s Digital Privacy Policy; • Define prohibited uses of AI systems; • Establish “sunset” procedures to safely retire systems that no longer meet the needs of the City; and • Define how AI may be used for legitimate purposes in accordance with applicable local, state, and federal laws, and existing agency policies. AI systems and the data contained therein will be purchased, configured, developed",https://www.sanjoseca.gov/home/showpublisheddocument/112981/638593035034930000,en,"Risk factors: Reliability, Risk factors: Transparency, Risk factors: Bias, Risk factors: Privacy, Risk factors: Security, Strategies: Evaluation, Strategies: Government support, Strategies: Government support: AI workforce-related, Strategies: Performance requirements, Strategies: Disclosure, Strategies: Disclosure: In deployment, Harms: Violation of civil or human rights, including privacy, Risk factors: Safety, Harms: Harm to health/safety, Harms: Detrimental content"
2050,Alabama Executive Order No. 738,Alabama,United States,State governments,U.S. state and local documents,Executive Order,2024-02-08,2024,2,positive,0.9926,low,0.0,237,0.5,Enacted,"WHEREAS the State of Alabama is a pioneer in the development and use of advanced technologies, from manufacturing nanotechnology to empowering mankind to walk on the moon; WHEREAS Generative Artificial Intelligence (“GenAI”) represents a significant step forward in technology that will transform the way that the State and the world conduct business and serve the public; WHEREAS GenAI has the potential to catalyze innovation and the rapid development of a wide range of benefits for Alabamians, but must be deployed carefully to mitigate and guard against a new generation of risks; WHEREAS responsible and ethical use of GenAI should be conducted within a governance structure that ensures transparency, tests for bias, addresses privacy concerns, and safeguards our values; WHEREAS the State of Alabama seeks to realize the potential benefits of GenAI for the good of all Alabamians, through the development and deployment of GenAI tools that improve the delivery of services, while balancing the benefits and risks of these new technologies; WHEREAS the people of Alabama demand and expect that their state government operate in the most efficient way possible; and WHEREAS the Alabama state workforce is vital to Alabama’s continued prosperity and the State seeks to harness the potential of GenAI for the benefit of the state government workforce; NOW, THEREFORE, I, Kay Ivey, Governor of the State of Alabama, by virtue of the authority vested in me by the Constitution and laws of the State",https://governor.alabama.gov/assets/2024/02/EO-738-Artificial-Intelligence.pdf,en,
2052,California Executive Order N-12-23,California,United States,State governments,U.S. state and local documents,Executive Order,2023-09-06,2023,9,positive,0.9618,high,0.7222,225,0.7,Enacted,"WHEREAS the State of California is a global leader in innovation, research, development, human capital, and entrepreneurship; and WHEREAS Generative Artificial Intelligence (""GenAI"") represents a significant leap forward in technology, by generating novel text, images, and other content, which will transform the way that the State and the world conduct business and serve the public; and WHEREAS GenAI has the potential to catalyze innovation and the rapid development of a wide range of benefits for Californians and the California economy, such as advances in medicine, wildfire forecasting and prevention, and climate science, and to push the bounds of human creativity and capacity; and WHEREAS California is leading the world in GenAI innovation and research, and is home to 35 of the world's top 50 Artificial Intelligence (""Al"") companies; and WHEREAS San Francisco and San Jose are dominating this technological revolution, accounting for a quarter of all Al patents, conference papers, and companies globally; and WHEREAS the State of California endeavors to continue leading the world in the responsible development, adoption, and implementation of new technologies for the benefit of all Californians and the California economy; and WHEREAS GenAI can enhance human potential and creativity but must be deployed and regulated carefully to mitigate and guard against a new generation of risks; and WHEREAS the State of California is committed to accuracy, reliability, and ethical outcomes",https://www.gov.ca.gov/wp-content/uploads/2023/09/AI-EO-No.12-_-GGN-Signed.pdf,en,"Strategies: Government study or report, Strategies: Governance development, Strategies: Evaluation: Impact assessment, Strategies: Evaluation: Post-market monitoring, Harms: Harm to health/safety, Harms: Violation of civil or human rights, including privacy, Risk factors: Safety, Applications: Government: other applications/unspecified, Risk factors: Transparency, Strategies: Evaluation, Applications: Government: benefits and welfare, Harms: Financial loss, Risk factors: Security, Risk factors: Security: Cybersecurity, Harms: Harm to infrastructure"
2058,Georgia Technology Authority Artificial Intelligence Responsible Use (SS-23-002),Georgia,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-12-01,2024,12,positive,0.8843,low,0.0,209,0.5,Enacted,"PURPOSE As artificial intelligence (AI) technology continues to evolve and further integrates itself into the core of daily business operations, it becomes imperative for the State to engage with AI in an ethical, trustworthy and responsible manner. This Standard seeks to provide support of the appropriate use of AI tools, while mitigating the risks and undesired outcomes, including AI misapplication, unethical consequences, inherent biases, inaccuracies, and breaches of information security. It also delineates the protocols for the deployment of AI, Generative AI, Deep Learning, and Machine Learning tools within government services and operations, with special emphasis on their utilization in conjunction with sensitive data and state information. SCOPE and AUTHORITY O.C.G.A 50-25-4(a)(8) – State Government, Georgia Technology, General Powers O.C.G.A 50-25-4(a)(20) - State Government, Georgia Technology, General Powers PM-04-001 – Information Technology Policies, Standards and Guidelines PS-08-005 – Enterprise Information Security Policy TERMS AND DEFINITIONS Agency - every state department, agency, board, bureau, commission, and authority but shall not include any agency within the judicial or legislative branch of state government, the Georgia Department of Defense, departments headed by elected constitutional officers of the state, or the University System of Georgia and shall also not include any authority statutorily required to effectuate the provisions of Part 4 of Art",https://gta-psg.georgia.gov/psg/artificial-intelligence-responsible-use-ss-23-002,en,
2062,Maryland State Executive Order 01.01.2024.02,Maryland,United States,State governments,U.S. state and local documents,Executive Order,2024-01-08,2024,1,positive,0.9933,low,0.0,221,0.5,Enacted,"Catalyzing the Responsible and Productive Use of Artificial Intelligence in Maryland State Government WHEREAS, Artificial intelligence (AI) is transforming society and work in myriad ways, and the pace of that change will continue to accelerate - unlocking new opportunities and risks for Maryland's residents, workers, and economy; WHEREAS, To meet the moment, the State must begin its work to ensure the use of AI in Maryland state government is responsible, ethical, beneficial, and trustworthy; WHEREAS, Maryland is home to a rich and growing AI ecosystem of academic, industry, government, and civil society experts, researchers, builders, organizers, and stakeholders; WHEREAS To foster an environment for innovation while respecting individuals, employees, and civil rights, as AI technologies are developed and evolve, they should be analyzed and monitored by government officials, industry experts, consumer protection advocates, and other stakeholders; WHEREAS Given the rapid rate of change in AI technologies and industry, the State must chart a principled yet adaptable, pragmatic path forward, so that the technology's benefits can be confidently harnessed on behalf of Marylanders and in service of our mission to Leave No One Behind; and WHEREAS, Leaders across Maryland government share a common interest in establishing effective AI governance, and are committed to working together to develop the legal and policy framework for its responsible use in the State. NOW, THEREFORE, I,",https://governor.maryland.gov/Lists/ExecutiveOrders/Attachments/31/EO%2001.01.2024.02%20Catalyzing%20the%20Responsible%20and%20Productive%20Use%20of%20Artificial%20Intelligence%20in%20Maryland%20State%20Government_Accessible.pdf,en,
2066,Mississippi Senate Bill 2062,Mississippi,United States,State governments,U.S. state and local documents,Law/Act,2025-03-29,2025,3,positive,0.8885,low,0.0,232,0.5,Defunct,"BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF MISSISSIPPI: SECTION 1. This act shall be known and may be cited as the ""Artificial Intelligence in Education Task Force Act."" SECTION 2. The purpose of this act is to establish an Artificial Intelligence (""AI"") in Education Task Force within the state to evaluate the potential applications of artificial intelligence in K-12 and to develop policy recommendations for responsible and effective uses by students and educators. The task force may also identify workforce needs related to AI and provide policy recommendations to ensure the state develops education and workforce training programs that align with changing industry needs. SECTION 3. (1) The State Superintendent of Education shall serve as the Chair of the Task Force. The Department of Education shall provide administrative support for the task force, including, but not limited to, developing agendas, coordinating meetings and drafting reports for task force feedback. (2) The task force shall include members who possess knowledge or expertise in the following fields: education, technology, AI, ethics, data privacy, industry demands, state and local policy, and state procurement. (3) The task force shall consist of twelve (12) members, as follows: (a) The Governor shall appoint four (4) members to the committee, as follows: (i) A representative from the State Board of Education; (ii) A representative from an institution of higher learning; (iii) A representative of the Mis",https://billstatus.ls.state.ms.us/documents/2024/html/SB/2001-2099/SB2062PS.htm,en,
2067,North Carolina State Government Responsible Use of Artificial Intelligence Framework,North Carolina,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-08-21,2024,8,positive,0.9952,low,0.0,206,0.5,Enacted,"[table of contents omitted] Introduction Artificial intelligence (AI) is a broad term used to describe an engineered system where machines learn from experience, adjusting to new inputs, and potentially performing tasks previously done by humans. More specifically, it is a field of computer science dedicated to simulating intelligent behavior in computers. It may include automated decision-making (International Association of Privacy Professionals, Glossary, https://iapp.org/resources/glossary, 2024). 1 The state has leveraged certain AI technologies when building out its analytic capabilities to support improved insights. These technologies have the potential to transform society, drive economic growth, support scientific advancement, and help government serve people more effectively and efficiently. They also pose risks that can negatively impact people, organizations, and society. The State Chief Information Officer supports the use of AI, where appropriate, to improve government innovation, operations, and services in a manner that benefits the people, fosters public trust, builds confidence in AI, protects our state’s values, and remains consistent with all applicable laws. Opportunities for designing, developing, acquiring, and using AI should be sought to improve state government while carefully considering potential risks and how they could best be assessed and managed. 1 IAPP's definition provides a high-level summary of AI definitions found in NIST's The Language of",https://it.nc.gov/documents/nc-state-government-responsible-use-artificial-intelligence-framework/download?attachment,en,
2068,State of North Dakota Artificial Intelligence Policy,North Dakota,United States,State governments,U.S. state and local documents,Policy/Guidance,2024-02-08,2024,2,positive,0.991,low,0.0,214,0.5,Enacted,"[footnotes omitted] INTRODUCTION 1.0 PURPOSE The purpose of the Artificial Intelligence (AI) Policy is to embrace the innovative benefits AI can provide to increase productivity and citizen experience, while reducing risks and concerns in using this emerging technology. This policy protects the safety, privacy, and intellectual property rights of the State of North Dakota by ensuring all forms of AI are handled in a transparent, consistent, responsible, ethical and secure manner. 2.0 BACKGROUND Artificial Intelligence develops data processing systems that perform functions normally associated with human intelligence, such as reasoning, learning, and self-improvement. Generative AI is a prevalent example of AI and includes examples such as chatbots, virtual assistants, and other systems based on it, including: • Standalone systems (i.e. OpenAI – ChatGPT, DALL-E, Microsoft Copilot), • Integrated as features within search engines (i.e. Microsoft Bing chat, Google Bard), or • Embedded in other software tools. Generative AI tools can enhance productivity by assisting with tasks, like drafting documents, editing text, generating ideas, creating images, and software coding. However, these technologies also come with potential risks that include inaccuracies, bias, and unauthorized use of intellectual property in generated content. Content created by AI, and the public availability of information submitted to AI, could pose security and privacy concerns. The State of North Dakota con",https://www.ndit.nd.gov/sites/www/files/documents/Policies/artificial_intelligence_policy_2024.pdf,en,
2069,State of New Hampshire Use of Artificial Intelligence Technologies Policy,New Hampshire,United States,State governments,U.S. state and local documents,Policy/Guidance,2024-11-12,2024,11,positive,0.9584,low,0.0,213,0.5,Enacted,"1. Purpose This policy, guided by the New Hampshire Code of Ethics for the Use and Development of Generative Artificial Intelligence and Automated Decision Systems (AI System) outlines the principles, guidelines, and requirements for the responsible and ethical use of various AI technologies across State Government Departments and Agencies, with a strong emphasis on protecting Personal Identifying Information (PII) and restricted or sensitive data. This policy is part of the library of Statewide processes that supports the State of New Hampshire’s information security program that is collectively referred to as the Statewide Information Security Manual, or “SISM”. The SISM is applicable to all Departments, Agencies, Commissions, Boards, Bodies, or other instrumentalities of the Executive Branch of New Hampshire State Government. 2. Applicability All New Hampshire State Employees and affiliates are responsible and accountable to their supervisor and Agency Head to adhere to the following principles when using AI to enable the delivery of government services: • Human-Centric Approach: A human-centric approach shall be used to develop and deploy AI technologies, prioritizing the well-being, rights, and interests of users and stakeholders. • Transparency and Accountability: All AI systems used by State Government shall be transparent, explainable, and accountable, especially when handling PII and sensitive data. • Fairness and Nondiscrimination: AI technologies shall be designed",https://mm.nh.gov/files/uploads/doit/documents/sonh-use-of-artificial-intelligence-technologies-policy.pdf,en,
2070,New Jersey Executive Order No. 346,New Jersey,United States,State governments,U.S. state and local documents,Executive Order,2023-10-10,2023,10,positive,0.9896,low,0.0,211,0.5,Enacted,"WHEREAS, New Jersey has a long history of leading the next frontiers of discovery and is a national leader for innovation and the development of new technologies; and WHEREAS, New Jersey endeavors to foster an environment for continued investment, advancement, and economic potential for New Jersey residents, companies, and public institutions; and WHEREAS, New Jersey is a hub for commercial activity, business formation, and research and development involving artificial intelligence, including generative artificial intelligence technologies, which generate new content – such as textual, visual, spoken, or musical content – in response to user inputs of data; and WHEREAS, universities in New Jersey are institutional leaders in research and development and discoveries in the studies of new artificial intelligence technologies; and WHEREAS, New Jersey is a trailblazer in the pharmaceutical, biotechnology, and life sciences industries, among other sectors, which have the opportunity to apply artificial intelligence technologies to advance medical and scientific breakthroughs; and WHEREAS, the use of artificial intelligence technologies is advancing at an unprecedented pace and has the potential to be transformative across public and private sectors; and WHEREAS, New Jersey aspires to harness new artificial intelligence technologies and realize their benefits to better serve all New Jersey residents, encourage innovation and economic growth, and promote social and economic equity;",https://nj.gov/infobank/eo/056murphy/pdf/EO-346.pdf,en,
2074,State of Ohio Administrative Policy on AI,Ohio,United States,State governments,U.S. state and local documents,Policy/Guidance,2023-12-04,2023,12,positive,0.9823,low,0.0,222,0.5,Enacted,"[footnotes and tables omitted] I. Purpose The purpose of this policy is to provide statewide planning, implementation, procurement, security, privacy, and governance requirements forthe use of Artificial Intelligence (AI). The policy authorizes the implementation of AI, while establishing an operational framework that will assist in protecting Ohioans’ Data and the Integrity and Quality of the information delivered through AI solutions. The first occurrence of a defined term in the policy is in bold, italic type, and is hyperlinked to the definition in Section IV. II. Scope This policy applies to all state agencies, boards, and commissions under the authority of the Governor (collectively referred to as Agency or Agencies). III. Policy While AI can deliver significant business value to the State of Ohio, responsible implementation requires a deliberate and detailed approach. Agencies considering the implementation of AI shall ensure that processes are in place to effectively manage the technology and achieve the desired results. This policy details the requirements for integrating AI technologies into state solutions. A. AI Solution Development: As part of AI planning and implementation, Agencies shall follow the iterative activities outlined below: 1. Defining a formal process for identifying, documenting, reviewing, and approving AI use cases. Agency use cases and solutions shall align with the core AI Principles. 2. Submission of Agency approved use cases to the AI Council",https://das.ohio.gov/wps/wcm/connect/gov/de987825-6f6d-41e7-86b9-31c957551975/IT-17.pdf?MOD=AJPERES&CONVERT_TO=url&CACHEID=ROOTWORKSPACE.Z18_M1HGGIK0N0JO00QO9DDDDM3000-de987825-6f6d-41e7-86b9-31c957551975-oMRScaB,en,
2081,Rhode Island Executive Order 24-06,Rhode Island,United States,State governments,U.S. state and local documents,Executive Order,2024-02-29,2024,2,positive,0.9485,low,0.0,210,0.5,Enacted,"WHEREAS, a modern government requires access to timely and accurate data to make informed decisions and maximize the effectiveness and efficiency of public programs; WHEREAS, external researchers have a substantial interest in government data to improve public understanding and programs; WHEREAS, state agencies create, acquire, use, and maintain substantial amounts of data in their operations, with data stored on numerous systems or platforms; WHEREAS, the integrity, confidentiality and availability of data must be maintained in accordance with federal and state laws, regulations and policies; WHEREAS, the Rhode Island Longitudinal Data System (RILDS) Executive Board, established by R.I. Gen. Laws § 42-165-5, issued the Rhode Island Data Governance Program Plan on November 1, 2023; WHEREAS, Rhode Island has two platforms that integrate data to improve state operations, the Office of Post Secondary Commissioner (OPC) RILDS and the Executive Office of Health and Human Services (EOHHS) Ecosystem; WHEREAS, the federal Family Educational Rights and Privacy Act and its accompanying regulations (“FERPA”) govern the access to and disclosure of personally identifiable information from student education records, which includes those records and data developed and maintained by OPC, Rhode Island Department of Education (RIDE), and other educational agencies and institutions which receive federal funding; WHEREAS, the federal Health Insurance Portability and Accountability Act (“HIPAA”)",https://governor.ri.gov/executive-orders/executive-order-24-06,en,
2089,"Vermont Agency of Digital Services Report regarding Inventory of Artificial Intelligence Usage, pursuant to 3 V.S.A. § 3305",Vermont,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2022-12-01,2022,12,positive,0.9698,low,0.0,223,0.5,Enacted,"[AI Inventory chart excluded] I. Background In May of 2022 the Legislature passed H410/Act 132, an Act relating to the use and oversight of Artificial Intelligence in State Government. Section 3 created an inventory of “automated decision systems being developed, employed, or procured by State Government.” Section 4 describes a report including “recommendations for any changes to the inventory, including how it should be maintained, the frequency of updates, and remediation measures needed to address systems deemed problematic.” While the inventory itself will be maintained on an ongoing basis, this report documents initial findings and makes recommendations for the questions described above. Artificial Intelligence systems (AI) in use by the State of Vermont are considered as a component of the human system and processes they enable. Artificial Intelligences must be designed, developed, implemented, and used as a part of human processes. They must be monitored to ensure the process as a whole is meeting standards and expectations. The goal of this inventory as it is being collected by the Agency of Digital Services Division of Artificial Intelligence is to identify the systems and processes that use artificial intelligence, especially where such usage could have impacts on Vermonters. II. Recommendations A. Inventory Maintenance The Inventory of Artificial Intelligence Usage should be maintained by the Division of Artificial Intelligence within the Agency of Digital Services",https://legislature.vermont.gov/assets/Legislative-Reports/Agency-of-Digital-Services-Report-on-AI-Inventory.pdf,en,
2092,Wisconsin Executive Order #211,Wisconsin,United States,State governments,U.S. state and local documents,Executive Order,2023-08-23,2023,8,positive,0.9781,low,0.0,207,0.5,Enacted,"EXECUTIVE ORDER #211 Relating to the Creation of the Governor’s Task Force on Workforce and Artificial Intelligence WHEREAS, Wisconsin is experiencing one of the strongest economic periods in state history, evidenced by the state’s record-low unemployment rate of 2.4 percent in May, and in July, record-high labor force participation and a Wisconsin record for total nonfarm jobs with 3,007,200; WHEREAS, artificial intelligence technology has the potential to reshape labor markets, and Wisconsin is well-positioned to ensure this transition is an opportunity for all Wisconsin workers, employers, and job seekers; WHEREAS, this administration continues to invest in education and technical training, developing Wisconsin’s workforce and tailoring programming to the needs of employers and prospective employees, and putting forward solutions to train and upskill Wisconsinites to fill family-sustaining jobs across the state; WHEREAS, artificial intelligence systems, the next generation of technology being produced, can learn from data without being explicitly programmed, create new content, and predict future outcomes; WHEREAS, artificial intelligence systems are increasingly being used in a range of industries important to Wisconsin, from manufacturing and healthcare to education, transportation, and agriculture, among other sectors key to Wisconsin’s future economic success; WHEREAS, due to the novelty of the technology that is being developed and implemented, Wisconsin must identify",https://content.govdelivery.com/attachments/WIGOV/2023/08/23/file_attachments/2591849/Evers_EO211.pdf,en,
2096,Measures for Labeling of AI-Generated Synthetic Content,Chinese central government,China,China,Chinese law and policy,Other,2025-03-07,2025,3,positive,0.9681,low,0.1667,198,0.7,Enacted,"Measures for Labeling of AI-Generated Synthetic Content Article 1: These Measures are drafted on the basis of the PRC Cybersecurity Law, the Provisions on the Management of Algorithmic Recommendations in Internet Information Services, the Provisions on the Administration of Deep Synthesis Internet Information Services, the Measures on the Administration of Generative Artificial Intelligence Services, and other relevant laws, administrative regulations, and departmental rules, so as to promote the healthy development of artificial intelligence, standardize the labeling of AI-generated synthesized content, protect the lawful rights and interests of citizens, legal persons, and other organizations, and preserve the societal public interest. Article 2: These Measures apply to the labeling of AI-generated synthetic content by Online information service providers that meet the requirements of the Provisions on the Management of Algorithmic Recommendations in Internet Information Services, the Provisions on the Administration of Deep Synthesis Internet Information Services, the Measures on the Administration of Generative Artificial Intelligence Services (hereinafter ""service providers""). Article 3: ""AI-generated synthetic content"" refers to text, images, audio, video, virtual scenes, or other information that is generated or synthesized using AI technology. The labeling of AI-generated synthetic content includes explicit and implicit labeling. ""Explicit labels"" refers to labels add",https://www.chinalawtranslate.com/en/ai-labeling/,en,"Harms: Violation of civil or human rights, including privacy, Applications: Broadcasting and media production, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: In standard form, Risk factors: Transparency, Strategies: Disclosure: About inputs, Strategies: Disclosure: Accuracy thereof, Strategies: Evaluation, Strategies: Evaluation: Conformity assessment, Incentives: Civil liability, Risk factors: Safety"
2097,Texas Responsible Artificial Intelligence Governance Act (HB 149),Texas,United States,State governments,Editors' Picks,Law/Act,2025-06-22,2025,6,positive,0.9875,medium,0.3889,226,0.7,Enacted,"AN ACT relating to the regulation of the use of artificial intelligence systems in this state; providing civil penalties. BE IT ENACTED BY THE LEGISLATURE OF THE STATE OF TEXAS: SECTION 1. This Act may be cited as the Texas Responsible Artificial Intelligence Governance Act SECTION 2. Title 11, Business & Commerce Code, is amended by adding Subtitle D to read as follows: SUBTITLE D. ARTIFICIAL INTELLIGENCE PROTECTION CHAPTER 551. ARTIFICIAL INTELLIGENCE PROTECTION SUBCHAPTER A. GENERAL PROVISIONS Sec. 551.001. DEFINITIONS. In this chapter: (1) ""Artificial intelligence system"" means the use of machine learning and related technologies that use data to train statistical models for the purpose of enabling computer systems to perform tasks normally associated with human intelligence or perception, such as computer vision, speech or natural language processing, and content generation. (2) ""Biometric identifier"" means a retina or iris scan, fingerprint, voiceprint, or record of hand or face geometry. (3) ""Council"" means the Artificial Intelligence Council established under Chapter 553. (4) ""Consumer"" means an individual who is a resident of this state acting only in an individual or household context. The term does not include an individual acting in a commercial or employment context. (5) ""Deploy"" means to put into effect or commercialize. (6) ""Deployer"" means a person doing business in this state that deploys an artificial intelligence system. (7) ""Developer"" means a person doing",https://www.legis.state.tx.us/tlodocs/89R/billtext/html/HB00149I.htm,en,"Strategies: Tiering, Strategies: Tiering: Tiering based on domain of application, Strategies: Disclosure, Strategies: Disclosure: In deployment, Strategies: Disclosure: In standard form, Risk factors: Transparency, Harms: Harm to health/safety, Harms: Violation of civil or human rights, including privacy, Applications: Government: other applications/unspecified, Strategies: Input controls, Strategies: Input controls: Data use, Harms: Discrimination, Strategies: Governance development, Strategies: Disclosure: About inputs, Strategies: Disclosure: About evaluation"
2098,Guiding Opinions on Strengthening the Governance of Science and Technology Ethics (Draft for Feedback),Chinese central government,China,China,Chinese law and policy,Other,2021-07-28,2021,7,positive,0.989,low,0.0,215,0.5,Proposed,"Guiding Opinions on Strengthening the Governance of Science and Technology Ethics (Draft for Feedback) Scientific and technological (S&T) ethics is the application of ethical thinking to scientific research, technology development, and other S&T activities. It is the value concepts and behavioral norms that S&T activities must abide by, and an important assurance for the healthy development of S&T undertakings. The following opinions are put forward in order to further strengthen the governance of S&T ethics, effectively prevent ethical risks that S&T innovation may bring about, promote science and technology for good ends, and achieve a high level of S&T self-reliance (自立自强). I. Overall Requirements (1) Guiding ideology. Taking Xi Jinping Thought on Socialism with Chinese Characteristics for a New Era as the guide, comprehensively implementing the spirit of the 19th Party Congress and the Second, Third, Fourth, and Fifth Plenums of the 19th Chinese Communist Party (CCP) Central Committee, and conscientiously putting into practice the decisions and arrangements of the CCP Central Committee and the State Council, we shall accelerate the construction of an S&T ethics system with Chinese characteristics, and improve the institutions and mechanisms of S&T ethics governance with multilateral participation and collaborative governance; adhering to the governance principles of unifying innovation promotion and risk prevention, and of combining institutional regulation and self-restr",https://cset.georgetown.edu/wp-content/uploads/t0613_science_ethics_opinions_draft_EN.pdf,en,
2099,(Trial) Measures for Science and Technology Ethics Reviews (Draft for Feedback),Chinese central government,China,China,Chinese law and policy,Other,2023-04-04,2023,4,positive,0.9825,low,0.0,215,0.5,Proposed,"(Trial) Measures for Scientific and Technological Ethics Reviews (Draft for Feedback) Chapter 1 General Provisions Article 1 [Purpose and Basis] These Measures have been formulated in accordance with the Law of the People’s Republic of China on Progress of Science and Technology, the Opinions on Strengthening the Governance of Science and Technology Ethics, and other laws and regulations and relevant provisions, in order to regulate scientific and technological (S&T) ethics reviews in scientific research, technology development, and other S&T activities, strengthen the prevention and control of S&T ethical risks, and promote responsible innovation. Article 2 [Ethical Requirements of S&T Activities] Those carrying out S&T activities shall adhere to the unity of advancing innovation and preventing risks, objectively assess and treat with caution uncertainties and S&T application risks, abide by the S&T ethics principles of promoting human well-being, respecting the right to life, upholding fairness and justice, reasonably controlling risks, and maintaining openness and transparency, and comply with S&T ethics norms. Article 3 [Scope of Application] The following S&T activities shall be subject to S&T ethics reviews in accordance with these Measures: (1) S&T activities involving human beings, including testing, surveys, observational studies, etc., in which human participants are involved in research, as well as the use of human genes, human embryos, human biological samples, pe",https://cset.georgetown.edu/wp-content/uploads/t0611_science_ethics_trial_measures_draft_EN.pdf,en,
2107,Illinois House Bill 2557 (2019),Illinois,United States,State governments,U.S. state and local documents,Law/Act,2019-02-13,2019,2,positive,0.9615,low,0.0,222,0.5,Enacted,"Be it enacted by the People of the State of Illinois, represented in the General Assembly: Section 1. Short title. This Act may be cited as the Artificial Intelligence Video Interview Act. Section 5. Disclosure of the use of artificial intelligence analysis. An employer that asks applicants to record video interviews and uses an artificial intelligence analysis of the applicant-submitted videos shall do all of the following when considering applicants for positions based in Illinois before asking applicants to submit video interviews: (1) Notify each applicant before the interview that artificial intelligence may be used to analyze the applicant's video interview and consider the applicant's fitness for the position. (2) Provide each applicant with information before the interview explaining how the artificial intelligence works and what general types of characteristics it uses to evaluate applicants. (3) Obtain, before the interview, consent from the applicant to be evaluated by the artificial intelligence program as described in the information provided. An employer may not use artificial intelligence to evaluate applicants who have not consented to the use of artificial intelligence analysis. Section 10. Sharing videos limited. An employer may not share applicant videos, except with persons whose expertise or technology is necessary in order to evaluate an applicant's fitness for a position. Section 15. Destruction of videos. Upon request from the applicant, employers, wit",https://www.ilga.gov/legislation/fulltext.asp?DocName=&SessionId=108&GA=101&DocTypeId=HB&DocNum=2557&GAID=15&LegID=&SpecSess=&Session=,en,
2111,Delaware House Concurrent Resolution 7 (2019-2020),Delaware,United States,State governments,U.S. state and local documents,Resolution,2019-03-07,2019,3,positive,0.9888,low,0.0,220,0.5,Enacted,"HOUSE CONCURRENT RESOLUTION NO. 7 RECOGNIZING THE IMPORTANCE OF PLANNING FOR THE POSITIVE AND NEGATIVE IMPACTS OF THE DEVELOPMENT OF ROBOTICS, AUTOMATION AND OTHER MANIFESTATIONS OF ARTIFICIAL INTELLIGENCE THAT ARE POISED TO INFLUENCE THE LANDSCAPE OF THE WORKPLACE. WHEREAS, the rapid rise of technologies related to automation, robotics and artificial intelligence has the potential to the change the nature of work; and WHEREAS, now that humankind stands on the threshold of a period when ever more sophisticated robots, automation and other manifestations of artificial intelligence are likely poised to unleash a new industrial revolution, which will leave no aspect of society untouched, it is vitally important for the legislature to consider its legal and ethical implications and effects, without stifling innovation; and WHEREAS, the trend towards automation requires that those involved in the development and commercialization of artificial intelligence applications build in security and ethics at the outset; and WHEREAS, the developments in automation, robotics and artificial intelligence can and should be designed in such a way that they preserve the dignity, autonomy and self-determination of the individual; and WHEREAS, many Delawareans currently work in jobs and fields of employment that may be displaced by technology; and WHEREAS, the likely effect of technological displacement will influence all levels of the public and private sectors. NOW, THEREFORE: BE IT RESOLVED, by",https://legis.delaware.gov/json/BillDetail/GenerateHtmlDocument?legislationId=47166&legislationTypeId=3&docTypeId=2&legislationName=HCR7,en,
2112,New York Senate Bill S3971B (2019),New York,United States,State governments,U.S. state and local documents,Law/Act,2020-12-31,2020,12,positive,0.9847,low,0.0,215,0.5,Defunct,"AN ACT creating a temporary state commission to study and investigate how to regulate artificial intelligence, robotics and automation; and providing for the repeal of such provisions upon expiration thereof THE PEOPLE OF THE STATE OF NEW YORK, REPRESENTED IN SENATE AND ASSEMBLY, DO ENACT AS FOLLOWS: Section 1. A temporary state commission, to be known as the New York state artificial intelligence, robotics and automation commission (hereinafter ""commission""), is hereby created to study and make determinations on issues including but not limited to: (a) current law within this state addressing artificial intelligence, robotics and automation; (b) comparative state policies that have aided in creating a regulatory structure for artificial intelligence, robotics and automation, and whether such measures would be similarly effective in this state; (c) criminal and civil liability regarding violations of law caused by entities equipped with artificial intelligence, robotics and automation; (d) the impact of artificial intelligence, robotics and automation on employment in this state; (e) the impact of artificial intelligence, robotics and automation on the acquiring and disclosure of confidential information; (f) potential restrictions on the use of artificial intelligence, robotics and automation in weaponry; (g) the potential impact on the technology industry of any regulatory measures proposed by this study; and (h) public sector applications of artificial intelligence and cog",https://www.nysenate.gov/legislation/bills/2019/S3971,en,
2117,Maryland 2020 HB49,Maryland,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2021-07-01,2021,7,negative,-0.9591,low,0.0,237,0.5,Enacted,"SECTION 1. BE IT ENACTED BY THE GENERAL ASSEMBLY OF MARYLAND, That the Laws of Maryland read as follows: Article – Criminal Procedure 5–103. (A) IN THIS SECTION, “PRETRIAL RISK SCORING INSTRUMENT” MEANS A TOOL, A METRIC, AN ALGORITHM, OR SOFTWARE THAT IS USED TO ASSIST IN DETERMINING THE ELIGIBILITY OF A DEFENDANT FOR PRETRIAL RELEASE IN A PRETRIAL PROCEEDING BASED ON THE DEFENDANT’S FLIGHT RISK AND THREAT TO COMMUNITY SAFETY. (B) A JURISDICTION THAT USES A PRETRIAL RISK SCORING INSTRUMENT TO DETERMINE THE ELIGIBILITY OF A DEFENDANT FOR PRETRIAL RELEASE SHALL HAVE AN INDEPENDENT VALIDATION STUDY OF THE PRETRIAL RISK SCORING INSTRUMENT CONDUCTED AT LEAST ONCE EVERY 3 5 YEARS. Article – Public Safety 4–1101. (a) In this subtitle the following words have the meanings indicated. (b) “Eligible county” means: (1) a county that does not provide defendants with pretrial services; or (2) a county that does provide defendants with pretrial services, but seeks to improve the pretrial services to comply with § 4–1104 of this subtitle. (c) “Executive Director” means the Executive Director of the Governor’s Office of Crime Control and Prevention. (d) “Fund” means the Pretrial Services Program Grant Fund. (e) “PRETRIAL RISK SCORING INSTRUMENT VALIDATION” MEANS AN INDEPENDENT VALIDATION STUDY OF A PRETRIAL RISK SCORING TOOL UNDER § 5–103 OF THE CRIMINAL PROCEDURE ARTICLE. (F) “Pretrial services program” means a program established in accordance with § 4–1104 of this subtitle. 4–1102. (a) The",https://mgaleg.maryland.gov/2020rs/bills_noln/hb/thb0049.pdf,en,
2120,New York SB5959 (2020),New York,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2020-11-30,2020,11,positive,0.9378,low,0.0,245,0.5,Enacted,"AN ACT to amend the civil rights law, in relation to establishing the right of publicity and to providing a private right of action for unlawful dissemination or publication of a sexually explicit depiction of an individual THE PEOPLE OF THE STATE OF NEW YORK, REPRESENTED IN SENATE AND ASSEMBLY, DO ENACT AS FOLLOWS: Section 1. The civil rights law is amended by adding a new section 50-f to read as follows: § 50-F. RIGHT OF PUBLICITY. 1. FOR PURPOSES OF THIS SECTION: A. ""DECEASED PERFORMER"" MEANS A DECEASED NATURAL PERSON DOMICILED IN THIS STATE AT THE TIME OF DEATH WHO, FOR GAIN OR LIVELIHOOD, WAS REGULARLY ENGAGED IN ACTING, SINGING, DANCING, OR PLAYING A MUSICAL INSTRUMENT. B. ""DECEASED PERSONALITY"" MEANS ANY DECEASED NATURAL PERSON DOMICILED IN THIS STATE AT THE TIME OF DEATH WHOSE NAME, VOICE, SIGNATURE, PHOTOGRAPH, OR LIKENESS HAS COMMERCIAL VALUE AT THE TIME OF HIS OR HER DEATH, OR BECAUSE OF HIS OR HER DEATH, WHETHER OR NOT DURING THE LIFETIME OF THAT NATURAL PERSON THE PERSON USED HIS OR HER NAME, VOICE, SIGNATURE, PHOTOGRAPH, OR LIKENESS ON OR IN PRODUCTS, MERCHANDISE, OR GOODS, OR FOR PURPOSES OF ADVERTISING OR SELLING, OR SOLICITATION OF PURCHASE OF, PRODUCTS, MERCHANDISE, GOODS, OR SERVICES. C. ""DIGITAL REPLICA"" MEANS A NEWLY CREATED, ORIGINAL, COMPUTER-GENERATED, ELECTRONIC PERFORMANCE BY AN INDIVIDUAL IN A SEPARATE AND NEWLY CREATED, ORIGINAL EXPRESSIVE SOUND RECORDING OR AUDIOVISUAL WORK IN WHICH THE INDIVIDUAL DID NOT ACTUALLY PERFORM, THAT IS SO REALISTIC THA",https://www.nysenate.gov/legislation/bills/2019/S5959,en,
2121,Utah SB 96,Utah,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2020-03-30,2020,3,positive,0.9661,low,0.0,206,0.5,Enacted,"Part 3. Deep Technology Initiative 53B-26-301. Definitions. As used in this part: (1) ""Advisory council"" means the Deep Technology Talent Advisory Council created 53B-26-303. (2) (a) ""Deep technology"" means technology that leads to new products and innovations based on scientific discovery or meaningful engineering innovation. (b) ""Deep technology"" may include technology that leads to new products and innovations related to one or more of the following: (i) advanced materials; (ii) artificial intelligence; (iii) augmented and virtual reality; (iv) biotechnology; (v) photonics; (vi) quantum computing; (vii) robotics; (viii) secure computing; and (ix) other emerging technologies as determined by the advisory council. (3) ""Institution of higher education"" means the University of Utah, Utah State University, Southern Utah University, Weber State University, Snow College, Dixie State University, Utah Valley University, or Salt Lake Community College. Section 2. Section 53B-26-302 is enacted to read: 53B-26-302. Deep technology initiative. (1) Subject to appropriations from the Legislature and in accordance with the proposal process and other provisions of this section, the board shall develop and oversee a deep technology talent initiative that includes providing funding for expanded programs in deep technology. (2) The board shall facilitate collaborations that create expanded, multidisciplinary programs or stackable credential programs in both undergraduate and graduate studies",https://le.utah.gov/~2020/bills/static/SB0096.html,en,
2125,Colorado SB21-169,Colorado,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2021-07-06,2021,7,positive,0.5647,low,0.0,219,0.5,Enacted,"Be it enacted by the General Assembly of the State of Colorado: SECTION 1. Legislative declaration. (1) The general assembly finds that: (a) Increasingly, insurers use external consumer data and information sources, as well as algorithms and predictive models using external consumer data and information sources, in their insurance rating, underwriting, claims, and other business practices; (b) Although such tools have the potential to benefit insurers and consumers by simplifying and expediting insurance rating, underwriting, and claims processes, the accuracy and reliability of external consumer data and information sources can vary greatly, and some algorithms and predictive models may lack a sufficient rationale for use in insurance practices; and (c) The use of particular external consumer data and information sources, as well as algorithms and predictive models using external consumer data and information sources, by insurers may have a significant negative impact not only on the availability and affordability of insurance for protected classes of consumers, but also on the utilization of such insurance. (2) The general assembly therefore declares that in order to ensure that all Colorado residents have fair and equitable access to insurance products, it is necessary to: (a) Prohibit: (I) Unfair discrimination based on race, color, national or ethnic origin, religion, sex, sexual orientation, disability, gender identity, or gender expression in any insurance practice; an",https://leg.colorado.gov/sites/default/files/2021a_169_signed.pdf,en,
2127,Illinois House Bill 53 (2021),Illinois,United States,State governments,U.S. state and local documents,Law/Act,2022-01-22,2022,1,positive,0.9094,low,0.0,193,0.5,Enacted,"Be it enacted by the People of the State of Illinois, represented in the General Assembly: Section 5. The Artificial Intelligence Video Interview Act is amended by adding Section 20 as follows: (820 ILCS 42/20 new) Sec. 20. Report of demographic data. (a) An employer that relies solely upon an artificial intelligence analysis of a video interview to determine whether an applicant will be selected for an in-person interview must collect and report the following demographic data: (1) the race and ethnicity of applicants who are and are not afforded the opportunity for an in-person interview after the use of artificial intelligence analysis; and (2) the race and ethnicity of applicants who are hired. (b) The demographic data collected under subsection (a) must be reported to the Department of Commerce and Economic Opportunity annually by December 31. The report shall include the data collected in the 12-month period ending on November 30 preceding the filing of the report. (c) The Department must analyze the data reported and report to the Governor and General Assembly by July 1 of each year whether the data discloses a racial bias in the use of artificial intelligence.",https://www.ilga.gov/legislation/fulltext.asp?DocName=&SessionId=110&GA=102&DocTypeId=HB&DocNum=53&GAID=16&LegID=127865&SpecSess=&Session=,en,
2145,Rhode Island HB 6654 (2022),Rhode Island,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2022-06-29,2022,6,positive,0.9471,low,0.0,234,0.5,Enacted,"SECTION 1. Title 23 of the General Laws entitled ""HEALTH AND SAFETY"" is hereby amended by adding thereto the following chapter: CHAPTER 97 THE CONSUMER PROTECTION IN EYE CARE ACT 23-97-1. Short title. This act shall be known and may be cited as ""the Consumer Protection in Eye Care Act."" 23-97-2. Definitions. (a) As used in this chapter: (1) ""Assessment mechanism"" means automated or virtual equipment, application, or technology designed to be used on a telephone, a computer, or an Internet-accessible device that may be used either in person or remotely to conduct an eye assessment, and includes artificial intelligence devices and any equipment, electronic or nonelectronic, that is used to perform an eye assessment. (2) ""Contact lens"" means any lens placed directly on the surface of the eye, regardless of whether or not it is intended to correct a visual defect, including any cosmetic, therapeutic, or corrective lens. (3) ""Eye assessment"" means an assessment of the ocular health and visual status of a patient that may include, but is not limited to, objective refractive data or information generated by an automated testing device, including an autorefractor, in order to establish a medical diagnosis for the correction of vision disorders. (4) ""Person"" means an individual, corporation, trust, partnership, incorporated or unincorporated association, and any other legal entity. (5) ""Prescription"" means a handwritten or electronic order issued by a provider that includes: (i) In th",https://webserver.rilegislature.gov/Billtext/BillText22/HouseText22/H6654.htm,en,
2146,Rhode Island SB 2083 (2022),Rhode Island,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2022-06-29,2022,6,positive,0.9032,low,0.0,235,0.5,Enacted,"23-97-1. Short title. This act shall be known and may be cited as ""the Consumer Protection in Eye Care Act."" 23-97-2. Definitions. (a) As used in this chapter: (1) ""Assessment mechanism"" means automated or virtual equipment, application, or technology designed to be used on a telephone, a computer, or an Internet-accessible device that may be used either in person or remotely to conduct an eye assessment, and includes artificial intelligence devices and any equipment, electronic or nonelectronic, that is used to perform an eye assessment. (2) ""Contact lens"" means any lens placed directly on the surface of the eye, regardless of whether or not it is intended to correct a visual defect, including any cosmetic, therapeutic, or corrective lens. (3) ""Eye assessment"" means an assessment of the ocular health and visual status of a patient that may include, but is not limited to, objective refractive data or information generated by an automated testing device, including an autorefractor, in order to establish a medical diagnosis for the correction of vision disorders. (4) ""Person"" means an individual, corporation, trust, partnership, incorporated or unincorporated association, and any other legal entity. (5) ""Prescription"" means a handwritten or electronic order issued by a provider that includes: (i) In the case of contact lenses, all information required by the Fairness to Contact Lens Consumers Act, 15 U.S.C. §§ 7601 et seq.; (ii) In the case of visual aid glasses, all informatio",https://webserver.rilegislature.gov/BillText22/SenateText22/S2083.htm,en,
2151,California 2023 SCR 17 (Relative to AI),California,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2023-08-23,2023,8,positive,0.9876,low,0.2222,222,0.7,Enacted,"WHEREAS, The use of technology, data, and automated systems poses significant challenges to democracy and the rights of the public, as evidenced by incidents of unsafe, ineffective, or biased systems in health care, discriminatory algorithms in hiring and credit decisions, and unchecked data collection that threatens privacy and opportunities; and WHEREAS, Automated systems also have the potential to bring about extraordinary benefits, including increasing efficiency in agriculture and revolutionizing industries through data analysis; and WHEREAS, President Joseph R. Biden has affirmed civil rights and democratic values as a cornerstone of his administration and has ordered the federal government to work toward rooting out inequity and advancing civil rights, equal opportunity, and racial justice; and WHEREAS, The White House Office of Science and Technology Policy has developed the “Blueprint for an AI Bill of Rights,” a set of five principles to guide the design, use, and deployment of automated systems in a manner that protects the rights of the public while leveraging the benefits of AI; now, therefore, be it Resolved by the Senate of the State of California, the Assembly thereof concurring, That the California Legislature affirms its commitment to President Biden’s vision for safe AI and the principles outlined in the “Blueprint for an AI Bill of Rights,” including: Safe and Effective Systems, Algorithmic Discrimination Protections, Data Privacy, Notice and Explanation,",https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240SCR17,en,"Harms: Harm to health/safety, Harms: Financial loss, Harms: Discrimination, Risk factors: Privacy, Applications: Medicine, life sciences and public health, Applications: Finance and investment, Applications: Business services and analytics, Applications: Agriculture and resource extraction, Strategies: Governance development"
2159,Louisiana SCR 49,Louisiana,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2023-06-12,2023,6,positive,0.9765,low,0.0,211,0.5,Enacted,"A CONCURRENT RESOLUTION To urge and request the Joint Legislative Committee on Technology and Cybersecurity to study the impact of artificial intelligence on operations, procurement, and policy, and submit a written report of its findings to the House Committee on Commerce and the Senate Committee on Commerce, Consumer Protection and International Affairs not later than sixty days prior to the beginning of the 2024 Regular Session of the Legislature of Louisiana. WHEREAS, artificial intelligence combines computer science and robust datasets to enable problem-solving measures directly to consumers; and WHEREAS, ninety-seven percent of mobile users are using artificial intelligence powered voice assistants, thirty-five percent of companies are using artificial intelligence powered applications, and ninety-one percent of leading businesses invest in artificial intelligence on an ongoing basis; and WHEREAS, artificial intelligence has become prevalent in both individual and commercial use including private industry vendors doing business with the state of Louisiana. THEREFORE, BE IT RESOLVED that the Legislature of Louisiana does hereby urge and request the Joint Legislative Committee on Technology and Cybersecurity to study the impact of artificial intelligence on operations, procurement, and policy; research rapidly advancing technology and science to update and maintain policies, processes, and systems in state agencies, and submit a written report of its findings to the House",https://www.legis.la.gov/legis/ViewDocument.aspx?d=1331619,en,
2171,Rhode Island House Resolution 6423,Rhode Island,United States,State governments,U.S. state and local documents,Resolution,2023-06-13,2023,6,positive,0.9797,low,0.0,213,0.5,Enacted,"WHEREAS, Rhode Island and the United States are entering an era of unprecedented change that could impact tens of millions of people. As artificial intelligence technologies continue to advance, our financial, medical, legal, and personal security are potentially impacted; and WHEREAS, Artificial Intelligence (AI) is defined as computerized methods and tools, including, but not limited to, machine learning and natural language processing, that act in a way that resembles human cognitive abilities when it comes to solving problems or performing certain tasks; and WHEREAS, An automated decision system is a computer program, method, statistical model or process that aims to aid or replace human decision-making using algorithms or artificial intelligence. These systems can include analyzing complex datasets about human populations and government services or other activities to generate scores, predictions, classifications, or recommendations used by agencies to make decisions that impact human welfare; and WHEREAS, Monitoring systemic changes, as well as the procedures for enforcing the principles, policies, financing, and guidelines regarding their use, and any gaps in training, regulation, and enforcement of security protocols is essential; now, therefore be it RESOLVED, That this House of Representatives of the State of Rhode Island hereby requests the Department of Administration and the RI Division of Information Technology report the extent of algorithmic decision-making us",https://webserver.rilegislature.gov/BillText23/HouseText23/H6423A.htm,en,
2189,Hawaii House Concurrent Resolution 71,Hawaii,United States,State governments,U.S. state and local documents,Resolution,2024-05-01,2024,5,positive,0.9891,low,0.0,219,0.5,Enacted,"[introductory comments omitted] BE IT RESOLVED by the House of Representatives of the Thirty-second Legislature of the State of Hawaii, Regular Session of 2024, the Senate concurring, that the Department of Health is requested to convene a Stakeholder Working Group to make recommendations to enhance meaningful access to health care in the State through the provision of language assistance services; and BE IT FURTHER RESOLVED that the Department of Health is requested to invite stakeholders, including at least one LEP individual with experience accessing health services, health care providers, insurers, representatives of community-based organizations, language service providers, and the Healthcare Association of Hawaii, to participate in the Stakeholder Working Group; and BE IT FURTHER RESOLVED that the Stakeholder Working Group is requested to: (1) Study and assess language access in health care settings across the State and on each island in the State, including but not limited to: (A) Experiences of LEP populations using language assistance services; (B) Existing language assistance services and workforce; (C) Disparities faced by LEP individuals in access to health care; (D) Practice of using family members and friends as interpreters in health care settings; (E) Availability of interpreters; (F) Requirements for providing interpretation services in medical and health care settings; and (G) Benefits and impacts of technologies such as artificial intelligence; and (2) Make",https://www.capitol.hawaii.gov/sessions/session2024/bills/HCR71_SD1_.htm,en,
2198,Louisiana (2024) HCR 66,Louisiana,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-05-31,2024,5,positive,0.8807,low,0.0,217,0.5,Enacted,"A CONCURRENT RESOLUTION To request the Joint Legislative Committee on Technology and Cybersecurity to study and make recommendations with respect to the use and regulation of artificial intelligence. WHEREAS, the Legislature of Louisiana recognizes its responsibility for the health, safety, and welfare of the state's citizens and is increasingly concerned about how artificial intelligence, if used with nefarious intent, may pose a threat to the well-being of those citizens; and WHEREAS, the potential threats are multifaceted and do not fall squarelywithin the subject matter jurisdiction of any particular legislative committee as prescribed by the rules of the respective chambers; and WHEREAS, education policy is implicated in the potential for using artificial intelligence to assist in test-taking and paper-writing, thus threatening the most common methods teachers at all levels use to assess what students have learned; and WHEREAS, administration of criminal justice policy is implicated in the potential for manufacturing or otherwise manipulating evidence used in the prosecution of crimes; and WHEREAS, financial policy is implicated in the potential for disruption of commercial transactions and currencyexchanges and the undermining of the trust that makes free enterprise possible; and WHEREAS, health and welfare policy is implicated in the potential for artificial intelligence to be used for purposes of diagnosis and treatment of medical conditions and in the determination o",https://legis.la.gov/legis/ViewDocument.aspx?d=1380434,en,
2210,New Hampshire H1688 (2024),New Hampshire,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-07-22,2024,7,positive,0.4498,low,0.0,238,0.5,Enacted,"CHAPTER 5-D USE OF ARTIFICIAL INTELLIGENCE BY STATE AGENCIES 5-D:1 Definitions. In this chapter: I. ""Artificial intelligence"" or ""AI"" is the ability of a machine to display human-like capabilities for cognitive tasks such as reasoning, learning, planning, and creativity. AI systems may adapt their behavior to a certain degree by analyzing the effects of previous actions and operating under varying and unpredictable circumstances without significant human oversight. II. ""Generative AI"" is AI that can generate text, images, or other media in response to prompts. III. ""Deepfake"" means a video, audio, or any other media of a person in which his or her face, body, or voice has been digitally altered so that he or she appears to be someone else, he or she appears to be saying something that he or she has never said, or he or she appears to be doing something that he or she has never done. IV. ""State agency"" means any department, commission, board, institution, bureau, office, law enforcement, or other entity, by whatever name called, including the legislative and judicial branches of state government, established in the state constitution, statutes, session laws or executive orders. 5-D:2 Applicability. This chapter shall apply to all computer systems operated by any state agency as defined in RSA 5-D:1, IV. Excepted are systems used in research by state-funded institutions of higher learning. Also excepted are installed consumer systems in common personal use, including, but not l",https://gc.nh.gov/bill_status/legacy/bs2016/billText.aspx?id=1597&txtFormat=html&sy=2024,en,
2212,New Jersey Assembly Resolution 141 (2024),New Jersey,United States,State governments,U.S. state and local documents,Resolution,2024-06-28,2024,6,positive,0.9196,low,0.0,198,0.5,Enacted,"Whereas, “Deepfake” and “cheapfake” media are artificially produced content which manipulate public understandings of evidence and truth; and Whereas, Deepfakes are defined as video recordings, motion picture films, sound recordings, electronic images, photographs, or technological representations of speech or conduct that appear to authentically depict the speech or conduct of a person who did not engage in those behaviors, which were substantially dependent upon technical means; and Whereas, Cheapfakes are any software-generated audiovisual alteration; and Whereas, These audiovisual manipulations have become easier to produce, with open-source animation technology allowing even inexperienced creators to forge media; and Whereas, Generative artificial-intelligence platforms may anticipate and prevent the creation of harmful content; and Whereas, With the proliferation of social media and other digital communication platforms, deepfakes and cheapfakes can earn wide viewership and exert a powerful influence over public opinion; and Whereas, Social media and other content sharing forums may take steps to remove this harmful media; and Whereas, Deepfake and cheapfake content has been used for libel, misrepresentation, blackmail, hacking, and intimidation; and Whereas, Online disinformation and political interference campaigns may be magnified or accelerated through the use of artificial intelligence technology; and Whereas, Generative artificial intelligence and content sharing",https://njleg.state.nj.us/bill-search/2024/AR141/bill-text?f=AR&n=141_I1,en,
2239,West Virginia House Resolution 3,West Virginia,United States,State governments,U.S. state and local documents,Resolution,2024-01-10,2024,1,positive,0.9732,low,0.0,170,0.5,Enacted,"Whereas, Artificial Intelligence is a current and evolving technology; and Whereas, This technology should be studied to ensure its proper application; and Whereas, The State continues to seek methods which would address these issues, which would ensure an educated, skilled, dedicated and diversified workforce, and this issue can, and has, been addressed through appropriate legislative action; therefore, be it Resolved by the House of Delegates: That for the remainder of the 86th Legislature, there is hereby created a Select Committee on Artificial Intelligence, consisting of not more than eleven members of the House of Delegates, to be appointed by the Speaker. Notwithstanding the provisions of any House rule to the contrary, the Select Committee hereby created shall receive testimony, consider legislation, and recommend action to the Speaker of the House regarding all issues relating to Artificial Intelligence in the State of West Virginia; and, be it Further Resolved, That the rules of the House governing Standing Committees shall govern the actions and proceedings of this Select Committee insofar as applicable.",https://www.wvlegislature.gov/Bill_Status/bills_text.cfm?billdoc=hr3%20intr.htm&yr=2024&sesstype=RS&i=3&houseorig=h&billtype=r,en,
2242,Alaska Senate Bill No. 177,Alaska,United States,State governments,U.S. state and local documents,Law/Act,2025-03-29,2025,3,positive,0.8225,low,0.0,231,0.5,Defunct,"Section 1. AS 15.13 is amended by adding a new section to read: Sec. 15.13.093. Deepfake disclosure statement. (a) If a person knows or reasonably should know that a communication includes a deepfake depicting a candidate or political party in a manner intended to injure the reputation of the candidate or party or otherwise deceive a voter, the person shall include the following statement with the communication: ""This communication has been manipulated or generated by artificial intelligence."" In a communication that includes an audio component, the statement must be read in a manner that is easily heard. If the communication includes a print or video component, the statement must be placed in the communication so the statement is easily discernible, and, for a broadcast, cable, satellite, Internet, or other digital communication, the statement must remain onscreen throughout the entirety of the communication. (b) In this section, ""deepfake"" means an image, audio recording, or video recording of an individual's appearance, conduct, or spoken words that has been created or manipulated with machine learning, natural language processing, or another computational processing technique of similar or greater complexity in a manner to create a realistic but false image, audio, or video that (1) appears to a reasonable person to depict a real individual saying or doing something that did not actually occur; or (2) provides a fundamentally different understanding or impression of an in",https://www.akleg.gov/basis/Bill/Text/33?Hsid=SB0177A,en,
2243,Alaska Senate Bill No. 177,Alaska,United States,State governments,U.S. state and local documents,Law/Act,2025-03-29,2025,3,positive,0.8402,low,0.0,238,0.5,Defunct,"Sec. 2. AS 44.99 is amended by adding new sections to read: Article 7. Use by State Agencies of Artificial Intelligence and Data about Individuals. Sec. 44.99.700. Inventory. (a) Every two years, the department shall conduct an inventory of all systems used by state agencies that employ artificial intelligence for consequential decisions. Each state agency shall assist the department as necessary. An inventory must include, at a minimum, the following information for each system: (1) the name of the system; (2) the vendor that provides the system, if any; (3) a description of the general capabilities and uses of the system; and (4) whether the state agency completed an impact assessment of the system under AS 44.99.710 before the system's implementation. (b) Upon completion, the department shall publish each inventory on the department's Internet website. Sec. 44.99.710. Impact assessments. (a) At least once every two years, the head of a state agency that uses a system that employs artificial intelligence for consequential decisions shall conduct an impact assessment of the system. An impact assessment must include, at a minimum, an analysis of (1) the efficacy of the system; (2) the human oversight involved in the system; (3) the accountability mechanisms in place for the system; (4) the process by which an individual may appeal a decision made or facilitated by the system; (5) the current and potential benefits, liability, and risks to the state from the system, including",https://www.akleg.gov/basis/Bill/Text/33?Hsid=SB0177A,en,
2244,Security Management Measures for the Application of Facial Recognition Technology,Chinese central government,China,China,Chinese law and policy,Other,2025-03-21,2025,3,positive,0.9743,low,0.2222,213,0.7,Enacted,"Measures for the Security Management of Facial Recognition Technology Applications Article 1 These Measures are formulated to regulate the use of facial recognition technology for processing facial information and to protect personal information rights and interests, in accordance with the Cybersecurity Law of the People's Republic of China, the Data Security Law of the People's Republic of China, the Personal Information Protection Law of the People's Republic of China, the Regulations on Network Data Security Management (网络数据安全管理条例), and other laws and administrative regulations. Article 2 These Measures apply to activities using facial recognition technology to process facial information within the People's Republic of China (PRC). These Measures do not apply to the use of facial recognition technology to process facial information for research and development or algorithm training purposes within the PRC. Article 3 Activities using facial recognition technology to process facial information shall comply with laws and regulations, respect social morality and ethics, comply with business and professional ethics, be honest and trustworthy, fulfill obligations to protect personal information, and bear responsibility to society, and shall not jeopardize national security or the public interest, or harm the legitimate rights and interests of individuals. Article 4 The use of facial recognition technology to process facial information shall have a specific purpose and sufficient",https://cset.georgetown.edu/publication/china-facial-recognition-security-measures/,en,"Risk factors: Privacy, Harms: Violation of civil or human rights, including privacy, Risk factors: Transparency, Strategies: Disclosure, Strategies: Evaluation: Impact assessment, Risk factors: Safety"
2245,"Washington SB 5092 (2021-22), Section 151",Washington,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2021-05-18,2021,5,positive,0.8979,low,0.0,214,0.5,Enacted,"NEW SECTION. Sec. 151. FOR THE CONSOLIDATED TECHNOLOGY SERVICES AGENCY General Fund – State Appropriation (FY 2022) $581,000 General Fund – State Appropriation (FY 2023) $531,000 Consolidated Technology Services Revolving Account – State Appropriation $53,030,000 TOTAL APPROPRIATION $54,142,000 The appropriations in this section are subject to the following conditions and limitations: (1) $11,623,000 of the consolidated technology services revolving account – state appropriation is provided solely for the office of the chief information officer. Of this amount: (a) $2,000,000 of the consolidated technology services revolving account – state appropriation is provided solely for experienced information technology project managers to provide critical support to agency IT projects that are under oversight from the office of the chief information officer. The staff or vendors will: (i) Provide master level project management guidance to agency IT stakeholders; (ii) Consider statewide best practices from the public and private sectors, independent review and analysis, vendor management, budget and timing quality assurance and other support of current or past IT projects in at least Washington state and share these with agency IT stakeholders and legislative fiscal staff at least quarterly and post these to the statewide IT dashboard; and (iii) Provide independent recommendations to legislative fiscal committees by December of each calendar year on oversight of IT projects to includ",https://lawfilesext.leg.wa.gov/biennium/2021-22/Pdf/Bills/Senate%20Passed%20Legislature/5092-S.PL.pdf?q=20250401184223,en,
2247,Kansas Policy and Procedures Memorandum 8200.00,Kansas,United States,State governments,U.S. state and local documents,Policy/Guidance,2023-07-31,2023,7,positive,0.9704,low,0.0,214,0.5,Enacted,"1.0 SUBJECT: Generative Artificial Intelligence Policy 2.0 DISTRIBUTION: Executive Branch Cabinet and Non-Cabinet Agencies 3.0 FROM: Jeff Maxon, Interim Chief Information Technology Officer 4.0 PURPOSE: The purpose of this policy is to outline the acceptable use of generative artificial intelligence (AI). The policy is created to protect the safety, privacy, and intellectual property rights of the State of Kansas. 5.0 BACKGROUND: As generative AI technology progresses, chatbots, virtual assistants, and other systems based on it are becoming more prevalent. These can include standalone systems, be integrated as features within search engines, or be overtly or transparently embedded in all manner of other software tools. Examples include ChatGPT and DALL-E from OpenAI, Microsoft Bing’s chat, Microsoft 365 Copilot, and Bard from Google. Generative AI tools have the potential to enhance productivity by assisting with tasks like drafting documents, editing text, generating ideas, and software coding. However, these technologies also come with potential risks that include inaccuracies, bias and unauthorized use of intellectual property in the content generated. In addition, content created by AI, and the public availability of information submitted to the AI, could pose security or privacy concerns. 6.0 ORGANIZATIONS AFFECTED: Executive Branch Cabinet and Non-Cabinet Agencies 7.0 REFERENCES: 7.1 ITEC Policy 7230A 7.2 State of Kansas Social Media Policy 8.0 DEFINITIONS: 8.1 Generati",https://www.governor.ks.gov/home/showpublisheddocument/405/638744386434630000,en,
2248,DC Mayor's Orders 2024-028,District of Columbia,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2024-02-08,2024,2,positive,0.9873,low,0.0,230,0.5,Enacted,"ORIGINATING AGENCY: Office of the Mayor By virtue of the authority vested in me as Mayor of the District of Columbia by sections 422(4) and (11) of the District of Columbia Home Rule Act of 1973, 87 Stat. 790, Pub. L No. 93-198, D.C. Official Code§§ 1-204.22(4) and (11), it is hereby ORDERED that: I. PURPOSES AND BACKGROUND This Order: A. Articulates six overarching Artificial Intelligence (AI) Values which District government agencies must consider before deploying an AI tool; B. Establishes an AI Advisory Group on AI Values Alignment to conduct regular community and stakeholder engagement concerning these AI Values; C. Identifies a series of AI strategic benchmarks, in the form of internal governance standards and strategic plans, to be created within prescribed deadlines; and D. Establishes an AI Taskforce to examine the District's current internal AI governance posture and to support agency leadership in meeting the prescribed AI Strategic Benchmarks, and to provide the Mayor with advice and recommendations to further the goals of responsible and effective use of AI tools by District government agencies. II. DEFINITIONS When used in this Order, the following terms shall have the meanings ascribed: A. ""AI"" refers to the broad class of technologies developed or marketed to be capable of performing tasks otherwise requiring an intelligent human agent. Relevant tasks include, without limitation, natural language processing including text and speech generation, image analysis",https://mayor.dc.gov/sites/default/files/dc/sites/mayormb/release_content/attachments/Mayor%27sOrder2024-028ArticulatingDCsArtificialIntelligenceValues.pdf,en,
2249,Washington Executive Order 24-01,Washington,United States,State governments,U.S. state and local documents,Executive Order,2024-01-30,2024,1,positive,0.983,low,0.0,226,0.5,Enacted,"EXECUTIVE ORDER 24-01 ARTIFICIAL INTELLIGENCE WHEREAS, generative Artificial Intelligence (AI) represents a significant leap forward in technology, by generating novel text, images, and other content, which has the capacity to transform the way that the State conducts business and serves the public; and WHEREAS, generative AI has the potential to catalyze innovation and the rapid development of a wide range of benefits for Washingtonians; and WHEREAS, generative AI can enhance human potential and creativity but must be deployed and regulated carefully to mitigate and guard against a new generation of risks, harms, and perpetuation of existing inequities; and WHEREAS, the state of Washington is committed to accuracy, reliability, and ethical outcomes when adopting generative AI technology, engaging and supporting historically vulnerable and marginalized communities that are also denied a voice in the data collected about them and how it is used, and serving all those who reside, work, or do business in Washington in a transparent, engaged, and equitable way; and WHEREAS, the state of Washington seeks to realize the potential benefits of generative AI for the good of all those who call Washington home, through the development and deployment of generative AI tools that improve the equitable and timely delivery of services, while balancing the benefits and risks of these new technologies; and WHEREAS, the Washington state workforce is vital to Washington's continued prosperity an",https://governor.wa.gov/sites/default/files/exe_order/24-01%20-%20Artificial%20Intelligence%20%28tmp%29_0.pdf,en,
2250,Virginia Executive Directive 5 (2023),Virginia,United States,State governments,U.S. state and local documents,State/Local Law or Policy,2023-09-20,2023,9,positive,0.9932,low,0.0,213,0.5,Enacted,"EXECUTIVE DIRECTIVE NUMBER FIVE (2023) RECOGNIZING THE RISKS AND SEIZING THE OPPORTUNITIES OF ARTIFICIAL INTELLIGENCE By virtue of the authority vested in me as Governor, I hereby issue this Executive Directive to ensure the responsible, ethical and transparent use of artificial intelligence technology by state government in order to protect the rights of Virginians and develop targeted, innovative uses for this emerging technology to help deliver a best-in-class state government. Importance of the Initiative The widespread availability of artificial intelligence (AI) products will rapidly expand our analytical power over the coming years. These enhanced computing systems have the potential to increase productivity, transform work and impact the way government operates. The technologies also pose significant challenges, including job displacement, social and privacy intrusion, and the potential for both positive and negative impacts on education. Policymakers at both the federal and state levels are working to understand this technology and establish necessary guardrails; however, the pace is too slow. The Commonwealth of Virginia is home to a rapidly evolving entrepreneurial ecosystem and one of the most innovative workforces in the nation. Virginia's colleges and universities lead the nation in technology research and development, and the most critical national security and military intelligence institutions in the United States are headquartered in Virginia. These unique f",https://www.governor.virginia.gov/media/governorvirginiagov/governor-of-virginia/pdf/ed/Executive-Directive-No.-5---Recognizing-the-Risks-and-Seizing-the-Opportunities-of-Artificial-Intelligence.pdf,en,
2252,Pennsylvania Executive Order 2023-19,Pennsylvania,United States,State governments,U.S. state and local documents,Executive Order,2023-09-20,2023,9,positive,0.988,low,0.0,211,0.5,Enacted,"Executive Order 2023-19 – Expanding and Governing the Use of Generative Artificial Intelligence Technologies Within the Commonwealth of Pennsylvania Date: September 20, 2023 By Direction of: Josh Shapiro, Governor WHEREAS, the integration of Generative Artificial Intelligence (AI) into Pennsylvania’s economy and the daily lives of Pennsylvanians requires the Commonwealth to ensure it is used responsibly and ethically in the Commonwealth’s operations; and WHEREAS, responsible use of Generative AI can help Commonwealth agencies more efficiently communicate with and serve Pennsylvania’s customers, residents, visitors, and industry when the technology is made available for the agency’s use; and WHEREAS, Generative AI cannot and should never replace human creativity, moral judgment, or lived experiences of Pennsylvanians; and WHEREAS, Generative AI’s full potential can only be achieved by the Commonwealth when its use is grounded in a balanced approach prioritizing our employees, encouraging the innovative uses of technology to better serve Pennsylvanians, and aligning with industry standards on proportionate and adaptive policies; and WHEREAS, responsible and ethical use of Generative AI by the Commonwealth should be conducted within a governance structure that ensures transparency, tests for bias, addresses privacy concerns, and safeguards our values. NOW, THEREFORE, I, Josh Shapiro, Governor of the Commonwealth of Pennsylvania, by virtue of the authority vested in me by the Con","https://www.pa.gov/content/dam/copapwp-pagov/en/oa/documents/policies/eo/2023-19.pdf#:~:text=Governor%E2%80%99s%20Office%20Executive%20Order%202023,AI%29%20into%20Pennsylvania%E2%80%99s",en,
2257,Massachusetts Executive Order 629,State governments,United States,United States,U.S. state and local documents,Executive Order,2024-02-15,2024,2,positive,0.9828,low,0.0,214,0.5,Enacted,"EXECUTIVE ORDER NO. 629 KIMBERLEY DRJSCOLL LIEUTENANT GOVERNOR ESTABLISHING AN ARTIFICIAL INTELLIGENCE STRATEGIC TASK FORCE WHEREAS, Massachusetts leads the nation in achieving prosperity through scientific discovery and technological innovation; WHEREAS, Artificial Intelligence (""AI"") is a transformative technology that is likely to impact many aspects of work across many sectors of the economy; WHEREAS, Massachusetts can be a global leader in the effective and responsible use of AI· , WHEREAS, the state must empower its people, business community, and its many industries by studying, assessing, and navigating through the changes caused by AI and the opportunities this technology presents to make our state a place where eve1yone can succeed; WHEREAS, the Executive Office of Economic Development (""EOED"") is actively advancing a new economic development strategy that strives to make Massachusetts the best place for talent and businesses, including by lengthening the state's lead in key sectors; WHEREAS, the Executive Office of Technology Services and Security (""EOTSS"") is charged by Chapter 7D of the General Laws with supervising all executive depaiiment activities related to information technology, including digital services and information; WHEREAS, EOTSS and EOED are committed to exploring and studying the current state of AI, its capabilities, potential applications, and associated risks for the state; WHEREAS, input and feedback from leaders, experts, and other stakeholde",https://www.mass.gov/doc/executive-order-629/download,en,
2261,Opinions on Strengthening the Governance of Science and Technology Ethics,Chinese central government,China,China,Chinese law and policy,Other,2022-03-20,2022,3,positive,0.9837,low,0.0,219,0.5,Enacted,"Opinions on Strengthening the Governance of Science and Technology Ethics Xinhua News Agency, Beijing, March 20, [2022]. Recently, the General Office of the Chinese Communist Party (CCP) Central Committee and the General Office of the State Council issued the Opinions on Strengthening the Governance of Science and Technology Ethics, and also issued a notice requiring all regions and departments to conscientiously implement this document in light of their actual conditions. The full text of the Opinions on Strengthening the Governance of Science and Technology Ethics is as follows: Scientific and technological (S&T) ethics are the value concepts and behavioral norms that must be followed in carrying out scientific research, technology development, and other S&T activities, and are an important assurance for the healthy development of S&T undertakings. China’s S&T innovation is developing rapidly at present, and while the S&T ethics challenges it faces are growing, problems exist in the governance of S&T ethics, such as imperfect institutional mechanisms, incomplete systems, and uneven development in different fields, and responding to the practical requirements of S&T innovation and development has become difficult. The following opinions on strengthening the governance of S&T ethics are put forward in order to further improve the system of S&T ethics, increase S&T ethics governance capabilities, effectively prevent and control S&T ethics risks, continuously promote the develo",https://cset.georgetown.edu/publication/china-science-ethics-opinions/,en,
2262,"West Virginia HB 2760 (2021), Sec 11-13Q ""Credit allowed for specified high technology manufacturers.""",West Virginia,United States,State governments,U.S. state and local documents,Law/Act,2021-04-10,2021,4,positive,0.6369,low,0.0,202,0.5,Enacted,"§11-13Q-1 Oa. Credit allowed for specified high technology manufacturers. (a) High technology manufacturing business defined. - For purposes of this section, the term ""high technology manufacturing business"" means and is limited to only those businesses engaged in a business enumerated in subdivision (1) of this subsection: Provided, That for tax years beginning on and after January 1, 2022, the term ""high technology manufacturing business"" means and is limited to only those businesses engaged in a business enumerated in subdivision (1) or subdivision (2), or both, of this subsection. (1) ""High technology manufacturing business"" means a manufacturing activity properly classified as having one or more of the following six-digit North American Industry Classification System code numbers. North American Industry Classification System Code Manufacturing Activity Computer & Peripheral Equipment 334111 Electronic Computers 334112 Computer Storage Devices Electronic Components 334411 Electron Tubes 334414 Electronic Capacitors Semiconductors 334413 Semiconductor & Related Devices 333295 Semiconductor Machinery (2) ""High technology manufacturing business"" means, in addition to those activities enumerated in subdivision (1) of this subsection: (A) The activity of manufacturing drones, target drones, unmanned aircraft or unmanned robotic aircraft, (B) The activity of manufacturing autonomous motor vehicles, (C) The activity of manufacturing robots, robotic medical machines or equipment",https://www.wvlegislature.gov/Bill_Text_HTML/2021_SESSIONS/RS/signed_bills/house/HB2760%20SUB%20ENR_SIGNED.pdf,en,
2263,(Trial) Measures for Science and Technology Ethics Reviews,Chinese central government,China,China,Chinese law and policy,Other,2023-10-08,2023,10,positive,0.9418,low,0.0,214,0.5,Enacted,"(Trial) Measures for Science and Technology Ethics Reviews Chapter 1 General Provisions Article 1 These Measures have been formulated in accordance with the Law of the People’s Republic of China on Progress of Science and Technology, the Opinions on Strengthening the Governance of Science and Technology Ethics, and other laws and regulations and relevant provisions, in order to regulate scientific and technological (S&T) ethics reviews in scientific research, technology development, and other S&T activities, strengthen the prevention and control of S&T ethical risks, and promote responsible innovation. Article 2 The following S&T activities shall be subject to S&T ethics reviews in accordance with these Measures: (1) S&T activities involving human research participants, including testing, surveys, observational studies, etc., with humans as research subjects, as well as scientific activities that use human biological samples, personal information or data, etc.; (2) S&T activities involving laboratory animals; (3) S&T activities that do not directly involve human beings or laboratory animals but may pose ethical risks and challenges in terms of life and health, the ecological environment, public order, sustainable development, etc.; (4) Other S&T activities that require S&T ethics review in accordance with laws, administrative regulations, and relevant national provisions. Article 3 Those carrying out S&T activities shall adhere to the unity of advancing innovation and prevent",https://cset.georgetown.edu/publication/china-science-ethics-review-trial-measures/,en,
2264,Mississippi House Bill 633 (2021),Mississippi,United States,State governments,U.S. state and local documents,Law/Act,2021-03-24,2021,3,positive,0.8316,low,0.0,229,0.5,Enacted,"SECTION 4. (1) The State Department of Education is authorized and directed to implement K-12 computer science curriculum based on the 2018 Mississippi College and Career-Readiness Standards for computer science, which includes instruction in, but not limited to: (a) Computational thinking; (b) Problem solving; (c) Programming; (d) Cyber security; (e) Data science; (f) Robotics; (g) Artificial intelligence and machine learning; and (h) Other computer science and cyber-related content. (2) The State Department of Education shall work with the Center for Cyber Education at Mississippi State University to identify and develop K-12 computer science curriculum and delivery options. (3) Beginning in the 2022-2023 school year: (a) Each local school district shall provide that all middle schools in its school system offer instruction in foundations of computer science; (b) Each local school district shall provide that fifty percent (50%) of elementary schools in its school system offer a minimum of one (1) hour of instruction in computer science each week; (c) Each charter school that serves middle or high school students shall offer a course in computer science; and (d) Each charter school that serves elementary school students shall offer instruction in computer science. (4) Beginning in the 2023-2024 school year: (a) Each local school district shall provide that at least fifty percent (50%) of the high schools in its school system offer a course in computer science; (b) Each local","https://billstatus.ls.state.ms.us/documents/2021/html/HB/0600-0699/HB0633SG.htm#:~:text=AN%20ACT%20TO%20CREATE%20THE,WHICH%20INCLUDES%20INSTRUCTION%20IN%2C%20BUT",en,
2265,"Vermont 2019 Act No.16, Section 20",Vermont,United States,State governments,U.S. state and local documents,Law/Act,2019-06-17,2019,6,positive,0.9087,low,0.0,153,0.5,Enacted,"* * * Artificial Intelligence Task Force * * * Sec. 20. 2018 Acts and Resolves No. 137, Sec. 1 is amended to read: Sec. 1. ARTIFICIAL INTELLIGENCE TASK FORCE; REPORT * * * (e) Meetings. * * * (3) The Task Force shall meet not more than 15 times, except that this limitation on meetings shall not apply to any public hearing the Task Force holds for the purpose of obtaining public testimony regarding artificial intelligence. The Task Force shall cease to exist on January 15, 2020. * * * (h) Reports. On or before February 15, 2019, the Task Force shall submit an update to the Senate Committee on Government Operations and the House Committee on Energy and Technology. On or before January 15, 2020, the Task Force shall submit a final report to the Senate Committee on Government Operations and the House Committee on Energy and Technology that shall include:",https://legislature.vermont.gov/Documents/2020/Docs/ACTS/ACT061/ACT061%20As%20Enacted.pdf,en,
2267,"Memorandum 25-21 (Accelerating Federal Use of AI through Innovation, Governance, and Public Trust)",Executive Office of the President,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2025-04-03,2025,4,positive,0.9959,low,0.0,213,0.5,Enacted,"OVERVIEW On January 23, 2025, President Trump signed Executive Order (E.O.) 14179, Removing Barriers to American Leadership in Artificial Intelligence, to advance the United States' global AI dominance and to promote responsible AI innovation. Now more than ever, agencies are empowered to drive AI innovation and seize the opportunity to apply the best of American AI. Through this memorandum, agencies are directed to provide improved services to the public, while maintaining strong safeguards for civil rights, civil liberties, and privacy. This memorandum provides guidance to agencies on ways to promote human flourishing, economic competitiveness and national security. Agencies must follow the detailed implementation instructions and requirements included in the Appendix. This memorandum rescinds and replaces Office of Management and Budget (0MB) Memorandum M-24-10, Advancing Governance, Innovation, and Risk Management for Agency Use ofArtificial Intelligence. SCOPE This memorandum is directed to the heads of all Executive Branch departments and agencies, including independent regulatory agencies. GUIDANCE ON FEDERAL USE OF AI The United States is at the forefront of AI development, and agencies must adopt a forward-leaning and pro-innovation approach that takes advantage of this technology to help shape the future of government operations. Agencies are encouraged to harness solutions that bring the best value to taxpayers, increase quality of public services, and enhance gove",https://www.whitehouse.gov/wp-content/uploads/2025/02/M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf,en,
2268,Memorandum 25-22 (Driving Efficient Acquisition of Artificial Intelligence in Government),Executive Office of the President,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Regulation,2025-04-03,2025,4,positive,0.9951,low,0.0,207,0.5,Enacted,"1. OVERVIEW Executive Order 13960, Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government, 1 charges Federal agencies with using safe and secure artificial intelligence (AI) in innovative ways to improve government efficiency and mission effectiveness. In carrying out this direction, agencies must procure effective and trustworthy AI capabilities in a timely and cost-effective manner. Consistent with the Advancing American AI Act, Executive Order 14179, Removing Barriers to American Leadership in Artificial Intelligence, and Office of Management and Budget (0MB) Memorandum M-25-21, Accelerating Federal Use ofAI through Innovation, Governance, and Public Trust, this memorandum provides guidance to agencies to improve their ability to acquire AI responsibly. This memorandum rescinds and replaces 0MB Memorandum M-24-18, Advancing the Responsible Acquisition of Artificial Intelligence in Government. To that end, there are three grounding themes that drive this memorandum's requirements: Ensuring the Government and the Public Benefit from a Competitive American Al Marketplace. Competition in the marketplace enables the government to acquire the best solutions at lower cost to the taxpayer. As agencies seek to accelerate the adoption of AI-enabled services, they must pay careful attention to vendor sourcing, data portability, and long-term interoperability to avoid significant and costly dependencies on a single vendor. The government must communicate cl",https://www.whitehouse.gov/wp-content/uploads/2025/02/M-25-22-Driving-Efficient-Acquisition-of-Artificial-Intelligence-in-Government.pdf,en,
2269,New York City Council No. 1806-A,"New York, NY",United States,Local governments,U.S. state and local documents,State/Local Law or Policy,2022-01-15,2022,1,positive,0.9549,low,0.0,231,0.5,Enacted,"A Local Law to amend the administrative code of the city of New York, in relation to reporting on algorithmic tools used by city agencies Be it enacted by the Council as follows: Section 1. Subchapter 1 of chapter 1 of title 3 of the administrative code of the city of New York is amended by adding a new section 3-119.5 to read as follows: § 3-119.5 Annual reporting on algorithmic tools. a. For purposes of this section, the term “algorithmic tool” means any technology or computerized process that is derived from machine learning, artificial intelligence, predictive analytics, or other similar methods of data analysis, that is used to make or assist in making decisions about and implementing policies that materially impact the rights, liberties, benefits, safety or interests of the public, including their access to available city services and resources for which they may be eligible. Such term includes, but is not limited to tools that analyze datasets to generate risk scores, make predictions about behavior, or develop classifications or categories that determine what resources are allocated to particular groups or individuals, but does not include tools used for basic computerized processes, such as calculators, spellcheck tools, autocorrect functions, spreadsheets, electronic communications, or any tool that relates only to internal management affairs such as ordering office supplies or processing payments, and does not materially affect the rights, liberties, benefits, safe",https://www.nyc.gov/assets/oti/downloads/pdf/reports/2022-algorithmic-%20tools-reporting.pdf,en,
2270,"Massachusetts (2020) House Bill 5250, Section 92",Massachusetts,United States,State governments,U.S. state and local documents,Law/Act,2021-01-14,2021,1,positive,0.9042,low,0.0,249,0.5,Enacted,"SECTION 92. (a) There shall be a special commission to conduct a comprehensive study relative to the impact of automation, artificial intelligence, global trade, access to new forms of data and the internet of things on the workforce, businesses and economy. The main objective of the commission shall be to ensure sustainable jobs, fair benefits and workplace safety standards for workers in all industries, including, but not limited to, access to adequate and affordable health insurance, financial security in retirement, unemployment insurance and disability insurance. The commission shall consist of: 2 persons appointed by the president of the senate, 1 of whom shall serve as co-chair; 2 persons appointed by the speaker of the house of representatives, 1 of whom shall serve as co-chair; 1 person appointed by the minority leader of the senate; 1 person appointed by the minority leader of the house of representatives; the secretary of labor and workforce development or a designee; 2 persons appointed by the governor, 1 of whom shall have expertise in the future of work issues and 1 of whom shall have experience in workforce training and education; 2 persons appointed by the attorney general, 1 of whom shall have expertise in fair labor and workers' rights and 1 of whom shall have expertise in future of work issues; and 6 persons appointed by the co-chairs, 3 of whom shall be members of the labor community with experience in future of work issues and 3 of whom shall be members o",https://malegislature.gov/Bills/191/H5250.pdf,en,
2273,Nondiscrimination in Health Programs and Activities,Department of Health and Human Services,United States,Federal government,"U.S. regulations, executive orders, and agency policies",Law/Act,2024-05-06,2024,5,positive,0.9538,low,0.0,136,0.5,Enacted,"§ 92.210 Nondiscrimination in the use of patient care decision support tools. (a) General prohibition. A covered entity must not discriminate on the basis of race, color, national origin, sex, age, or disability in its health programs or activities through the use of patient care decision support tools. (b) Identification of risk. A covered entity has an ongoing duty to make reasonable efforts to identify uses of patient care decision support tools in its health programs or activities that employ input variables or factors that measure race, color, national origin, sex, age, or disability. (c) Mitigation of risk. For each patient care decision support tool identified in paragraph (b) of this section, a covered entity must make reasonable efforts to mitigate the risk of discrimination resulting from the tool's use in its health programs or activities.",https://www.federalregister.gov/documents/2024/05/06/2024-08711/nondiscrimination-in-health-programs-and-activities#sectno-reference-92.210,en,
2276,Healthy Technology Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-07,2025,1,positive,0.9552,low,0.0,169,0.5,Proposed,"A BILL To amend the Federal Food, Drug, and Cosmetic Act to clarify that artificial intelligence and machine learning technologies can qualify as a practitioner eligible to prescribe drugs if authorized by the State involved and approved, cleared, or authorized by the Food and Drug Administration, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Healthy Technology Act of 2025”. SEC. 2. Prescription of drugs by artificial intelligence or machine learning technologies. Section 503(b) of Federal Food, Drug, and Cosmetic Act (21 U.S.C. 353(b)) is amended by adding at the end the following: “(6) In this subsection, the term ‘practitioner licensed by law to administer such drug’ includes artificial intelligence and machine learning technology that are— “(A) authorized pursuant to a statute of the State involved to prescribe the drug involved; and “(B) approved, cleared, or authorized under section 510(k), 513, 515, or 564.”.",https://www.congress.gov/bill/119th-congress/house-bill/238/text,en,
2297,S257 Promoting Resilient Supply Chains Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-04-28,2025,4,positive,0.6808,low,0.0,227,0.5,Proposed,"A BILL To improve the resilience of critical supply chains, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title; table of contents. (a) Short title.—This Act may be cited as the “Promoting Resilient Supply Chains Act of 2025”. (b) Table of contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. Sec. 2. Additional responsibilities of Assistant Secretary of Commerce for Industry and Analysis. Sec. 3. Critical supply chain resilience and crisis response working group. Sec. 4. Department of Commerce capability assessment. Sec. 5. No additional funds. Sec. 6. Sunset. Sec. 7. Definitions. SEC. 2. Additional responsibilities of Assistant Secretary of Commerce for Industry and Analysis. In addition to the responsibilities of the Assistant Secretary on the day before the date of the enactment of this Act, the Assistant Secretary shall have the following responsibilities: (1) Promote In consultation with the Secretary of Homeland Security, promote the stability and resilience of critical supply chains and critical and emerging technologies that strengthen the national security of the United States. (2) Lead the Working Group established pursuant to section 3 and consult covered nongovernmental representatives, industry, institutions of higher education, and State and local governments in order to— (A) promote resilient critical supply ch",https://www.congress.gov/bill/119th-congress/senate-bill/257/all-actions,en,
2301,Decoupling America's Artificial Intelligence Capabilities from China Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-29,2025,1,positive,0.9957,low,0.0,216,0.5,Proposed,"A BILL To amend title 18, United States Code, to prohibit United States persons from advancing artificial intelligence capabilities within the People’s Republic of China, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Decoupling America's Artificial Intelligence Capabilities from China Act of 2025”. SEC. 2. Definitions. In this Act: (1) ARTIFICIAL INTELLIGENCE; GENERATIVE ARTIFICIAL INTELLIGENCE.—The terms “artificial intelligence” and “generative artificial intelligence” have the meanings given those terms in section 2741 of title 18, United States Code, as added by section 3. (2) ARTIFICIAL INTELLIGENCE OR GENERATIVE ARTIFICIAL INTELLIGENCE TECHNOLOGY OR INTELLECTUAL PROPERTY.—The term “artificial intelligence or generative artificial intelligence technology or intellectual property” means technology or intellectual property that could be used to contribute to artificial intelligence or generative artificial intelligence capabilities. (3) CHINESE ENTITY OF CONCERN.—The term “Chinese entity of concern” has the meaning given the term in section 2741 of title 18, United States Code, as added by section 4. (4) INTEREST.—The term “interest”, with respect to an entity, includes an interest in the entity— (A) held directly or indirectly through any chain of ownership; or (B) held as a derivative financial instrument or other contractual arr",https://www.congress.gov/bill/119th-congress/senate-bill/321/text,en,
2304,S.305 Small Business Technological Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-29,2025,1,positive,0.4215,low,0.0,234,0.5,Proposed,"A BILL To authorize small business loans to finance access to modern business software, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Small Business Technological Act of 2025”. SEC. 2. Additional uses for small business administration business loans. (a) In general.—Section 7(a) of the Small Business Act (15 U.S.C. 636(a)) is amended by adding at the end the following: “(38) ACCESS TO MODERN BUSINESS SOFTWARE.—The Administration may provide loans under this subsection to finance, in whole or in part, business software or cloud computing services, or any such technology, that facilitates business operations, product or service delivery, the processing, payment, or tracking of payroll expenses, human resources, sales and billing functions, or accounting or tracking of supplies, inventory, records and expenses, including business tools that utilize artificial intelligence.”. (b) Rule of construction.—Nothing in the amendment made by subsection (a) shall be construed to— (1) provide that loans made under section 7(a) of the Small Business Act (15 U.S.C. 636(a)) before the date of enactment of this Act for the purposes described in paragraph (38) of such section 7(a), as added by subsection (a), were not permissible; (2) authorize the use of loans made under section 7(a) of the Small Business Act (15 U.S.C. 636(a)) for research and develop",https://www.congress.gov/bill/119th-congress/senate-bill/305/text,en,
2312,Emerging Innovative Border Technologies Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-03-11,2025,3,positive,0.9803,low,0.0,216,0.5,Proposed,"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Emerging Innovative Border Technologies Act”. SEC. 2. Innovative and emerging border technology plan. (a) In general.—Not later than 180 days after the date of the enactment of this Act, the Secretary of Homeland Security, acting through the Commissioner of U.S. Customs and Border Protection (CBP) and the Under Secretary for Science and Technology of the Department of Homeland Security, shall submit to the Committee on Homeland Security of the House of Representatives and the Committee on Homeland Security and Governmental Affairs of the Senate a plan to identify, integrate, and deploy new, innovative, disruptive, or other emerging or advanced technologies that may incorporate artificial intelligence, machine-learning, automation, fiber-optic sensing technology, nanotechnology, optical and cognitive radar, modeling and simulation technology, hyperspectral and LIDAR sensors, imaging, identification, and categorization systems, or other emerging or advanced technologies, to enhance, or address capability gaps in, border security operations. (b) Contents.—The plan required under subsection (a) shall include the following: (1) Information regarding how CBP utilizes CBP Innovation Team authority under subsection (c) and other mechanisms to carry out the purposes specified in subsection (a). (2) An assessment of the co",https://www.congress.gov/bill/119th-congress/house-bill/993/text,en,
2315,IRONDOME Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-02-05,2025,2,positive,0.4215,low,0.0,48,0.5,Proposed,(h) Accelerating development of autonomous agents To defend against cruise missiles and drones.—The Secretary shall use all authorities available to the Secretary to accelerate development of autonomous agents to cost-effectively defend the United States homeland and forward-deployed armed forces against raids of both large cruise missiles and drones.,https://www.congress.gov/bill/119th-congress/senate-bill/435/text,en,
2320,China Technology Transfer Control Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-02-07,2025,2,positive,0.9855,low,0.0,236,0.5,Proposed,"SECTION 1. Short title. This Act may be cited as the “China Technology Transfer Control Act of 2025”. SEC. 2. Definitions. In this Act: (1) CHINESE PERSON.—The term “Chinese person” means— (A) an individual who is a citizen or national of the People's Republic of China; or (B) an entity organized under the laws of the People's Republic of China or otherwise subject to the jurisdiction of the Government of the People's Republic of China. (2) COVERED NATIONAL INTEREST TECHNOLOGY OR INTELLECTUAL PROPERTY.—The term “covered national interest technology or intellectual property” includes the following: (A) Technology or intellectual property that would make a significant contribution to the military potential of the People’s Republic of China that would prove detrimental to the national security of the United States. (B) Technology or intellectual property that is a component of the production of products included in the most recent list required under section 183 of the Trade Act of 1974, as added by section 6(a), determined in consultation with the United States Trade Representative. (C) Technology used by the Government of the People's Republic of China to carry out violations of human rights or religious liberties. (3) FOREIGN PERSON.—The term “foreign person” means any person that is not a United States person. (4) KNOWINGLY.—The term “knowingly”, with respect to conduct, a circumstance, or a result, means that a person has actual knowledge, or should have known, of the condu",https://www.congress.gov/bill/119th-congress/house-bill/1122/all-actions,en,
2321,"H.R.1142 - To amend the Public Health Service Act to direct the Secretary of Health and Human Services to establish drug adherence guidelines, and for other purposes.",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-02-07,2025,2,positive,0.9062,low,0.0,215,0.5,Proposed,"A BILL To amend the Public Health Service Act to direct the Secretary of Health and Human Services to establish drug adherence guidelines, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Establishment of drug adherence guidelines. Title XVII of the Public Health Service Act (42 U.S.C. 300u et seq.) is amended by inserting after section 1711 (42 U.S.C. 300u–16) the following: “SEC. 1712. Establishment of drug adherence guidelines. “(a) In general.—The Secretary shall establish drug adherence guidelines with the goal of achieving 90 percent adherence for all Medicare part B and D drugs. “(b) Contents.—In establishing the guidelines under subsection (a), the Secretary shall— “(1) incorporate artificial intelligence and machine learning technologies; and “(2) to the maximum extent practicable, promote the use of generic and biosimilar drugs. “(c) Definitions.—In this section: “(1) MEDICARE PART B DRUG.—The term ‘Medicare part B drug’ means a drug or biological product for which payment may be made under part B of title XVIII of the Social Security Act (42 U.S.C. 1395j et seq.). “(2) MEDICARE PART D DRUG.—The term ‘Medicare part D drug’ means a covered part D drug (as defined in section 1860D–2(e) of the Social Security Act (42 U.S.C. 1395w–102(e))).”.",https://www.congress.gov/bill/119th-congress/house-bill/1142/text,en,
2325,Promoting Precision Agriculture Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-02-11,2025,2,positive,0.9745,low,0.0,216,0.5,Proposed,"A BILL To enhance the participation of precision agriculture in the United States, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Promoting Precision Agriculture Act of 2025 ”. SEC. 2. Definitions. In this Act: (1) ADVANCED WIRELESS COMMUNICATIONS TECHNOLOGY.—The term “advanced wireless communications technology” means advanced technology that contributes to mobile (5G or beyond) networks, next-generation Wi-Fi networks, or other future networks using other technologies, regardless of whether the network is operating on an exclusive licensed, shared licensed, or unlicensed frequency band. (2) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence” has the meaning given the term in section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Public Law 115–232; 10 U.S.C. note prec. 4061). (3) FOREIGN ADVERSARY.—The term “foreign adversary” means any foreign government or foreign nongovernment person engaged in a long-term pattern or serious instances of conduct significantly adverse to the national security of the United States, or security and safety of United States persons. (4) PRECISION AGRICULTURE.—The term “precision agriculture” means managing, tracking, or reducing crop or livestock production inputs, including seed, feed, fertilizer, chemicals, water, time, and such other inputs as the Secre",https://www.congress.gov/bill/119th-congress/senate-bill/507/text,en,
2334,Protecting Our Children in an AI World Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-02-13,2025,2,positive,0.875,low,0.0,240,0.5,Proposed,"A BILL To amend title 18, United States Code, to prohibit child pornography produced using artificial intelligence. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Protecting Our Children in an AI World Act of 2025”. SEC. 2. Child pornography produced using artificial intelligence. (a) Elimination of affirmative defense.—Section 2252A(c) of title 18, United States Code, is amended— (1) in subsection (c)— (A) paragraph (1), by striking “; or” at the end; and (B) by striking paragraph (2); and (2) in the matter following subsection (c), by striking “No affirmative defense under subsection (c)(2) shall be available in any prosecution that involves child pornography as described in section 2256(8)(C).”. (b) Definition of sexually explicit conduct.—Section 2256(2)(B) of title 18, United States Code, is amended— (1) in clause (ii)(III), by striking “or” at the end; (2) in clause (iii), by adding “or” at the end; and (3) by adding at the end the following: “(iv) actual or simulated obscene exhibition of the clothed or unclothed genitals, pubic area, buttocks, or female nipple;”. (c) Severability.—If any provision of this Act, or any amendment made by this Act, or the application of such provision to any person, entity, government, or circumstance, is held to be unconstitutional, the remainder of this Act, or any amendment made thereby, or the application of such prov",https://www.congress.gov/bill/119th-congress/house-bill/1283/text,en,
2336,HEARTS Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-02-13,2025,2,positive,0.8541,low,0.0,242,0.5,Proposed,"A BILL To amend the Public Health Service Act to ensure that nonanimal methods are prioritized, where applicable and feasible, in proposals for all research to be conducted or supported by the National Institutes of Health, to provide for the establishment of the National Center for Alternatives to Animals in Research and Testing, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Humane and Existing Alternatives in Research and Testing Sciences Act of 2025” or the “HEARTS Act of 2025”. SEC. 2. Findings. Congress finds the following: (1) The National Institutes of Health (NIH) has supported life-saving research that has greatly improved the health and well-being not only of Americans but also of people around the world. (2) Much of this research has relied on animals. It is estimated that between 17,000,000 and 100,000,000 animals are used annually in the United States in research, education, and testing. However, the precise number of animals used in research in the United States is unknown. Such imprecise numbers make it impossible to effectively track and reduce the numbers of animals used. (3) According to the NIH, “approximately 30 percent of promising medications have failed in human clinical trials because they are found to be toxic despite promising pre-clinical studies in animal models. About 60 percent of candidate drugs fail due",https://www.congress.gov/bill/119th-congress/house-bill/1291/text,en,
2345,H.R.1569 CATCH Fentanyl Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-04-09,2025,4,positive,0.9655,low,0.0,224,0.5,Proposed,"A BILL To establish a pilot program to assess the use of technology to speed up and enhance the cargo inspection process at land ports of entry along the border. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short titles. This Act may be cited as the “Contraband Awareness Technology Catches Harmful Fentanyl Act” or the “CATCH Fentanyl Act”. SEC. 2. Definitions. In this Act: (1) APPROPRIATE CONGRESSIONAL COMMITTEES.—The term “appropriate congressional committees” means— (A) the Committee on Homeland Security and Governmental Affairs of the Senate; and (B) the Committee on Homeland Security of the House of Representatives. (2) ARTIFICIAL INTELLIGENCE; AI.—The terms “artificial intelligence” and “AI” have the meaning given the term “artificial intelligence” in section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Public Law 115–232; 10 U.S.C. 4061 note). (3) CBP INNOVATION TEAM.—The term “CBP Innovation Team” means the U.S. Customs and Border Protection Innovation Team within the Office of the Commissioner. (4) NONINTRUSIVE INSPECTION TECHNOLOGY; NII TECHNOLOGY.—The terms “nonintrusive inspection technology” and “NII technology” means technical equipment and machines, such as X-ray or gamma-ray imaging equipment, that allow cargo inspections without the need to open the means of transport and unload the cargo. (5) PILOT PROJECTS.—The term “pilot projects” means th",https://www.congress.gov/bill/119th-congress/house-bill/1569/text,en,
2346,Department of Homeland Security Vehicular Terrorism Prevention and Mitigation Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-04-09,2025,4,negative,-0.9723,low,0.0,216,0.5,Proposed,"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Department of Homeland Security Vehicular Terrorism Prevention and Mitigation Act of 2025”. SEC. 2. Findings. Congress finds the following: (1) On January 1, 2025, a devastating vehicular terrorist attack occurred on Bourbon Street in New Orleans, Louisiana, when an assailant inspired by the Islamic State drove a vehicle into a crowd and engaged in a shootout with law enforcement. This tragic incident resulted in the loss of fifteen lives and injuries to at least thirty-five others, including two police officers. (2) Vehicle-ramming attacks and other vehicular terrorist incidents represent an enduring and evolving threat to public safety in the United States and around the world, targeting innocent civilians and first responders. (3) These attacks, carried out by both organized terrorist groups and individual actors, often aim to exploit high-density public gatherings, critical infrastructure, and key transportation hubs, causing mass casualties and widespread disruption. (4) Emerging automotive technologies, such as autonomous vehicles, Advanced Driver Assistance System (ADAS) capabilities, and ride-sharing platforms, create new vulnerabilities that could be leveraged by malicious actors to conduct sophisticated vehicle-based attacks. (5) The Department of Homeland Security, through agencies like the Transportat",https://www.congress.gov/bill/119th-congress/house-bill/1608/text,en,
2347,Generative AI Terrorism Risk Assessment Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-03-25,2025,3,negative,-0.9846,low,0.0,221,0.5,Proposed,"A BILL To require the Secretary of Homeland Security to conduct annual assessments on terrorism threats to the United States posed by terrorist organizations utilizing generative artificial intelligence applications, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Generative AI Terrorism Risk Assessment Act”. SEC. 2. Sense of Congress regarding the use of generative artificial intelligence applications for terrorist activity. It is the sense of Congress that— (1) the heightened terrorism threat landscape and the increasing utilization of generative artificial intelligence applications by terrorist organizations represent a national security threat, and the challenges posed by such threat are not well understood; and (2) the Department of Homeland Security, in consultation with the Office of the Director of National Intelligence, must take steps to recognize, assess, and address such threat, thereby reducing risks to the people of the United States. SEC. 3. Annual assessments on terrorism threats to the United States posed by terrorist organizations utilizing generative artificial intelligence applications. (a) Assessments.— (1) IN GENERAL.—Not later than 180 days after the date of the enactment of this Act and annually thereafter for five years, the Secretary of Homeland Security, in consultation with the Director of National Intelligen",https://www.congress.gov/bill/119th-congress/house-bill/1736/text,en,
2349,Supporting Innovation in Agriculture Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-02-27,2025,2,positive,0.9901,low,0.0,228,0.5,Proposed,"A BILL To amend the Internal Revenue Code of 1986 to establish a credit for investments in innovative agricultural technology. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Supporting Innovation in Agriculture Act of 2025”. SEC. 2. Credit for investment in innovative agricultural technology. (a) In general.—Subpart E of part IV of subchapter A of chapter 1 of the Internal Revenue Code of 1986 is amended by inserting after section 48E the following new section: “SEC. 48F. Innovative agricultural technology investment credit. “(a) In general.—For purposes of section 46, the innovative agricultural technology investment credit for any taxable year is an amount equal to 30 percent of the qualified investment for such taxable year with respect to any innovative agricultural technology project. “(b) Qualified investment.— “(1) IN GENERAL.—For purposes of subsection (a), the qualified investment with respect to any innovative agricultural technology project for any taxable year is the basis of any qualified property placed in service by the taxpayer during such taxable year which is part of an innovative agricultural technology project. “(2) QUALIFIED PROPERTY.—For purposes of this section, the term ‘qualified property’ means property— “(A) which is— “(i) tangible personal property, whether or not affixed to real property (including equipment, systems and their com",https://www.congress.gov/bill/119th-congress/house-bill/1705/text,en,
2351,PATHS Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-03-12,2025,3,positive,0.977,low,0.0,229,0.5,Proposed,"AN ACT To amend the Homeland Security Act of 2002 to enable secure and trustworthy technology through other transaction contracting authority, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Producing Advanced Technologies for Homeland Security Act” or the “PATHS Act”. SEC. 2. Research and development acquisition pilot program extension. (a) In general.—Section 831 of the Homeland Security Act of 2002 (6 U.S.C. 391) is amended— (1) in subsection (a)— (A) in the matter preceding paragraph (1), by striking “Until September 30, 2024, and subject to subsection (d)” and inserting “Until September 30, 2028, and subject to subsection (c)”; and (B) by adding at the end the following new paragraph: “(3) OTHER TRANSACTION AUTHORITY INVOLVING ARTIFICIAL INTELLIGENCE.—Not later than 72 hours after the use or extension of the transaction authority authorized under paragraph (1) involving artificial intelligence technology, the Secretary shall notify the Committee on Appropriations and the Committee on Homeland Security and Governmental Affairs of the Senate and the Committee on Appropriations and the Committee on Homeland Security of the House of Representatives and offer a briefing explaining the reason for the use or extension.”; and (2) in subsection (c)(1), in the matter preceding subparagraph (A), by striking “September 30, 2024” and inserting",https://www.congress.gov/bill/119th-congress/house-bill/1692/text,en,
2359,Fair Grocery Pricing Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-03-03,2025,3,positive,0.5859,low,0.0,224,0.5,Proposed,"A BILL To prohibit the use of algorithmic systems by food producers to artificially inflate the price or reduce the supply of their foods. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Fair Grocery Pricing Act”. SEC. 2. Definitions. In this Act: (1) CHAIR.—The term “Chair” means the Chair of the Commission. (2) COMMISSION.—The term “Commission” means the Federal Trade Commission. (3) CONSCIOUSLY PARALLEL PRICING COORDINATION.—The term “consciously parallel pricing coordination” means a tacit agreement between 2 or more food producers to raise, lower, change, maintain, or manipulate pricing for the purchase or sale of reasonably interchangeable food products. (4) COORDINATING FUNCTION.—The term “coordinating function” means— (A) collecting historical or contemporaneous food product prices or supply levels from 2 or more food producers; (B) analyzing or processing of the information described in subparagraph (A) using a system, software, or process that uses computation, including by using that information to train an algorithm; and (C) recommending food prices, supply or output, or other commercial term to a food producer. (5) COORDINATOR.—The term “coordinator” means any person that operates a software or data analytics service that performs a coordinating function for any food producer, including a food producer performing a coordinating function for their",https://www.congress.gov/bill/119th-congress/house-bill/1788/text,en,
2362,H.R.1851 Fighter Force Preservation and Recapitalization Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-03-05,2025,3,positive,0.9217,low,0.0,238,0.5,Proposed,"A BILL To amend title 10, United States Code, to preserve and recapitalize the fighter aircraft capabilities of the Air Force and its reserve components, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Fighter Force Preservation and Recapitalization Act of 2025”. SEC. 2. Minimum number of fighter aircraft in the Air Force and reserve components of the Air Force. Section 9062(i) of title 10, United Stats Code, is amended— (1) in paragraph (1)— (A) by striking “During” and inserting “Except as provided in paragraph (2), during”; (B) by striking “October 1, 2026” and inserting “October 1, 2030”; (C) by striking “1,800” and inserting “1,900”; and (D) by striking “1,145” and inserting “1,200”; (2) by redesignating paragraph (2) as paragraph (3); (3) by inserting after paragraph (1) the following new paragraph (2): “(2) (A) Subject to subparagraphs (B) and (C), the Secretary of Defense may temporarily reduce the total aircraft inventory required by paragraph (1) to enable recapitalization of units transitioning from one combat-coded mission fighter aircraft to a new combat-coded fighter aircraft. “(B) A temporary reduction authorized under subparagraph (A) shall not— “(i) result in less than 1,800 aircraft in the total aircraft inventory of fighter aircraft at any given time; or “(ii) exceed two years. “(C) (i) Before authorizing a temporary",https://www.congress.gov/bill/119th-congress/house-bill/1851/text,en,
2367,Promoting Precision Agriculture Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-03-28,2025,3,positive,0.9745,low,0.0,214,0.5,Proposed,"A BILL To enhance the participation of precision agriculture in the United States, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Promoting Precision Agriculture Act”. SEC. 2. Definitions. In this Act: (1) ADVANCED WIRELESS COMMUNICATIONS TECHNOLOGY.—The term “advanced wireless communications technology” means advanced technology that contributes to mobile (5G or beyond) networks, next-generation Wi-Fi networks, or other future networks using other technologies, regardless of whether the network is operating on an exclusive licensed, shared licensed, or unlicensed frequency band. (2) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence” has the meaning given the term in section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Public Law 115–232; 10 U.S.C. note prec. 4061). (3) FOREIGN ADVERSARY.—The term “foreign adversary” means any foreign government or foreign nongovernment person engaged in a long-term pattern or serious instances of conduct significantly adverse to the national security of the United States, or security and safety of United States persons. (4) PRECISION AGRICULTURE.—The term “precision agriculture” means managing, tracking, or reducing crop or livestock production inputs, including seed, feed, fertilizer, chemicals, water, time, and such other inputs as the Secretary dete",https://www.congress.gov/bill/119th-congress/house-bill/1985/text,en,
2381,AI PLAN Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-03-14,2025,3,positive,0.8625,low,0.0,232,0.5,Proposed,"A BILL To require a strategy to defend against the economic and national security risks posed by the use of artificial intelligence in the commission of financial crimes, including fraud and the dissemination of misinformation, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Artificial Intelligence Practices, Logistics, Actions, and Necessities Act” or the “AI PLAN Act”. SEC. 2. Strategy to defend against risks posed by the use of artificial intelligence. (a) Sense of Congress.—It is the sense of Congress that the development and use of artificial intelligence in the commission of financial crimes by adversarial actors poses a significant risk to the national and economic security of the United States. (b) Strategy To defend against risks posed by misinformation, fraud, and financial crime conducted with artificial intelligence.— (1) IN GENERAL.—Not later than 180 days after the date of the enactment of this Act and annually thereafter, the Secretary of the Treasury, the Secretary of Homeland Security, and the Secretary of Commerce, in consultation with the officials specified in paragraph (3), shall jointly submit to Congress a report that includes the following: (A) A description of interagency policies and procedures to defend United States financial markets, United States persons, United States businesses, and global supply chains f",https://www.congress.gov/bill/119th-congress/house-bill/2152/text,en,
2387,Foreign Investment Guardrails to Help Thwart (FIGHT) China Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-03-21,2025,3,positive,0.9797,low,0.0,223,0.5,Proposed,"A BILL To protect the national security of the United States by imposing sanctions with respect to certain persons of the People’s Republic of China and prohibiting and requiring notifications with respect to certain investments by United States persons in the People’s Republic of China, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title; table of contents. (a) Short title.—This title may be cited as the “Foreign Investment Guardrails to Help Thwart (FIGHT) China Act”. (b) Table of contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. Sec. 2. Secretary defined. Sec. 3. Severability. Sec. 4. Authorization of appropriations. Sec. 5. Termination. TITLE I—IMPOSITION OF SANCTIONS Sec. 101. Imposition of sanctions. Sec. 102. Definitions. TITLE II—PROHIBITION AND NOTIFICATION ON INVESTMENTS RELATING TO COVERED NATIONAL SECURITY TRANSACTIONS Sec. 201. Prohibition and notification on investments relating to covered national security transactions. TITLE III—SECURITIES AND RELATED MATTERS Sec. 301. Requirements relating to the Non-SDN Chinese Military-Industrial Complex Companies List. SEC. 2. Secretary defined. Except as otherwise provided, in this Act, the term “Secretary” means the Secretary of the Treasury. SEC. 3. Severability. If any provision of this Act, or the application thereof, is held invalid, the validity of the remainder",https://www.congress.gov/bill/119th-congress/house-bill/2246/text,en,
2390,Leveraging Artificial Intelligence to Streamline the Code of Federal Regulations Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-03-25,2025,3,positive,0.9695,low,0.0,224,0.5,Proposed,"A BILL To require the use of artificial intelligence to review agency regulations, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Leveraging Artificial Intelligence to Streamline the Code of Federal Regulations Act of 2025”. SEC. 2. Definitions. In this Act: (1) AGENCY.—The term “agency” has the meaning given that term in section 551 of title 5, United States Code. (2) ARTIFICIAL INTELLIGENCE SYSTEM.—The term “artificial intelligence system” means a machine-based system that, for an explicit or implicit objective, infers how to generate outputs, such as predictions, content, recommendations, or decisions that can influence physical or virtual environments, from the input the system receives. (3) REDUNDANT.—The term “redundant” means a regulation that duplicates, overlaps with, or serves the same purpose as another regulation, such that the elimination of the regulation would not result in a loss of essential information or regulatory function. (4) REGULATION.—The term “regulation” has the meaning given the term “rule” in section 551 of title 5, United States Code. (5) OUTDATED.—The term “outdated” means a regulation that has been superseded by more recent legislation, technological advances, or regulatory developments, rendering the regulation inapplicable or unenforceable. SEC. 3. Annual artificial intelligence review of the code of f",https://www.congress.gov/bill/119th-congress/senate-bill/1110/text,en,
2393,Create AI Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-03-26,2025,3,positive,0.993,low,0.0,218,0.5,Proposed,"A BILL To establish the National Artificial Intelligence Research Resource, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Creating Resources for Every American To Experiment with Artificial Intelligence Act of 2025” or the “CREATE AI Act of 2025”. SEC. 2. Findings. Congress finds the following: (1) Cutting-edge artificial intelligence research relies on access to computational resources and large datasets. (2) Access to the computational resources and datasets necessary for artificial intelligence research and development is often limited to very large technology companies. (3) The lack of access to computational and data resources has resulted in insufficient diversity in the artificial intelligence research and development community. (4) Engaging the full and diverse talent of the United States is critical for maintaining United States leadership in artificial intelligence and ensuring that artificial intelligence is developed in a manner that benefits all people of the United States. (5) The National Artificial Intelligence Research Resource Task Force, authorized under section 5106 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401 et seq.), recommended the establishment of a National Artificial Intelligence Research Resource in a report entitled “Strengthening and Democratizing the U.S. Artificial Inte",https://www.congress.gov/bill/119th-congress/house-bill/2385/text,en,
2396,H2444 Promoting Resilient Supply Chains Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-04-29,2025,4,positive,0.8176,low,0.0,222,0.5,Proposed,"AN ACT To establish a critical supply chain resiliency and crisis response program in the Department of Commerce, and to secure American leadership in deploying emerging technologies, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This title may be cited as the “Promoting Resilient Supply Chains Act of 2025”. SEC. 2. Additional responsibilities of Assistant Secretary of Commerce for Industry and Analysis. In addition to the responsibilities of the Assistant Secretary on the day before the date of the enactment of this Act, the Assistant Secretary shall have the following responsibilities: (1) Promote the stability and resilience of critical supply chains and critical and emerging technologies that strengthen the national security of the United States. (2) Lead the Working Group established pursuant to section 3 and consult covered nongovernmental representatives, industry, institutions of higher education, and State and local governments in order to— (A) promote resilient critical supply chains; and (B) identify, prepare for, and respond to supply chain shocks to— (i) critical industries; (ii) critical supply chains; and (iii) critical and emerging technologies. (3) Encourage the growth and competitiveness of United States production and manufacturing in the United States of emerging technologies. (4) Assess the resilience, diversity, and strength of critical suppl",https://www.congress.gov/bill/119th-congress/house-bill/2444/text,en,
2399,Protect Victims of Digital Exploitation and Manipulation Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-04-01,2025,4,negative,-0.6619,low,0.0,233,0.5,Proposed,"A BILL To amend title 18, United States Code, to prohibit the production or distribution of digital forgeries of intimate visual depictions of identifiable individuals, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Protect Victims of Digital Exploitation and Manipulation Act of 2025”. SEC. 2. Digital forgeries of intimate visual depictions. (a) In general.—Chapter 88 of title 18, United States Code, is amended by adding at the end the following: “§ 1802. Prohibition of production or distribution of digital forgeries of intimate visual depictions of identifiable individuals “(a) Offense.—Except as provided in subsection (b), whoever, in any circumstance described in subsection (c), acts with reckless disregard to produce or distribute, or causes to be produced or distributed, a digital forgery of an identifiable individual, without the consent of the identifiable individual, shall be fined under this title, imprisoned not more than 5 years, or both. “(b) Exceptions.— “(1) IN GENERAL.—This section shall not apply with respect to a distribution made in good faith— “(A) to a law enforcement officer or agency; “(B) as part of a legal proceeding; “(C) as part of medical education, diagnosis, or treatment; or “(D) in the reporting or investigation of— “(i) unlawful content; or “(ii) unsolicited or unwelcome conduct. “(2) SERVICE PROVIDERS.—T",https://www.congress.gov/bill/119th-congress/house-bill/2564/text,en,
2401,Promoting United States Leadership in Standards Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-04-02,2025,4,positive,0.9776,low,0.0,220,0.5,Proposed,"A BILL To promote United States leadership in technical standards by directing the National Institute of Standards and Technology and the Department of State to take certain actions to encourage and enable United States participation in developing standards and specifications for artificial intelligence and other critical and emerging technologies, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Promoting United States Leadership in Standards Act of 2025”. SEC. 2. Definitions. In this Act: (1) ARTIFICIAL INTELLIGENCE AND OTHER CRITICAL AND EMERGING TECHNOLOGIES.—The term “artificial intelligence and other critical and emerging technologies” means a subset of artificial intelligence and other critical and emerging technologies included in the list of such technologies identified and maintained by the National Science and Technology Council of the Office of Science and Technology Policy as the Director considers appropriate for purposes of this Act. (2) DIRECTOR.—The term “Director” means the Director of the National Institute of Standards and Technology. SEC. 3. United States participation in organizations developing standards and specifications for artificial intelligence and other critical and emerging technologies. (a) Briefing required.— (1) IN GENERAL.—Not later than 1 year after the date of the enactment of this Act, the Director s",https://www.congress.gov/bill/119th-congress/senate-bill/1269/text,en,
2402,Next Generation Pipelines Research and Development Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-04-29,2025,4,positive,0.891,low,0.0,237,0.5,Proposed,"A BILL To improve public-private partnerships and increase Federal research, development, and demonstration related to the evolution of next generation pipeline systems, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Next Generation Pipelines Research and Development Act”. SEC. 2. Definitions. In this Act: (1) DEPARTMENT.—The term “Department” means the Department of Energy. (2) ELIGIBLE ENTITY.—The term “eligible entity” means— (A) an institution of higher education (as such term is defined in section 101(a) of the Higher Education Act of 1965 (20 U.S.C. 1001(a))), including historically Black colleges and universities (within the meaning of the term “part B institution” in section 322 of the Higher Education Act of 1965 (20 U.S.C. 1061)), Tribal colleges and universities (as such term is defined in section 316 of the Higher Education Act of 1965 (20 U.S.C. 1059c)), and minority serving institutions (including the entities described in any of paragraphs (1) through (7) of section 371(a) of the Higher Education Act of 1965 (20 U.S.C. 1067q(a))); (B) a nonprofit research organization; (C) a National Laboratory (as such term is defined in section 2 of the Energy Policy Act of 2005 (42 U.S.C. 15801)); (D) a private commercial entity; (E) a partnership or consortium of two or more entities described in subparagraphs (A) through (D) that le",https://www.congress.gov/bill/119th-congress/house-bill/2613/text,en,
2403,Artificial Intelligence and Critical Technology Workforce Framework Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-04-03,2025,4,positive,0.8374,low,0.0,221,0.5,Proposed,"A BILL To expand the functions of the National Institute of Standards and Technology to include workforce frameworks for critical and emerging technologies, to require the Director of the National Institute of Standards and Technology to develop an artificial intelligence workforce framework, and periodically review and update the NICE Workforce Framework for Cybersecurity, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Artificial Intelligence and Critical Technology Workforce Framework Act of 2025”. SEC. 2. Workforce frameworks for critical and emerging technologies. (a) Definitions.— (1) IN GENERAL.—In this section, the terms “competencies”, “workforce categories”, and “workforce framework” have the meanings given such terms in subsection (f) of section 2 of the National Institute of Standards and Technology Act (15 U.S.C. 272), as added by subsection (b) of this section. (2) AMENDMENT TO NIST ACT.—Section 2 of such Act (15 U.S.C. 272) is amended by adding at the end the following: “(f) Definitions.—In this section: “(1) COMPETENCIES.—The term ‘competencies’ means knowledge and skills. “(2) WORKFORCE CATEGORIES.—The term ‘workforce categories’ means a high-level grouping of tasks across an organization as defined by work roles within the category. “(3) WORKFORCE FRAMEWORK.—The term ‘workforce framework’ means a common taxonomy and le",https://www.congress.gov/bill/119th-congress/senate-bill/1290/text,en,
2406,Transformational Artificial intelligence to Modernize the Economy against Extreme Weather and Wildfires Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-04-09,2025,4,positive,0.9823,low,0.0,213,0.5,Proposed,"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Transformational Artificial intelligence to Modernize the Economy against Extreme Weather and Wildfires Act” or the “TAME Extreme Weather and Wildfires Act”. SEC. 2. Artificial intelligence for weather forecasting. (a) Definitions.—In this section: (1) ARTIFICIAL INTELLIGENCE.—The term “artificial intelligence”— (A) has the meaning given that term in section 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401); and (B) includes machine learning, neural networks, and natural language processing. (2) ARTIFICIAL INTELLIGENCE WEATHER MODEL.—The term “artificial intelligence weather model” means a weather model based primarily on artificial intelligence technology to project future Earth system conditions based on machine learning using weather forecasting training datasets. (3) CURATE.—The term “curate”, with respect to a dataset, means— (A) to collect and maintain the dataset— (i) to ensure and document its quality; and (ii) to provide metadata on its provenance; and (B) to update the dataset periodically, as appropriate and practicable. (4) NUMERICAL WEATHER MODEL.—The term “numerical weather model” means a weather model based primarily on coupled Earth System processes that uses numerical computation to forecast future Earth system conditions. (5) OBSERVATIONAL DATA.—The term “obser",https://www.congress.gov/bill/119th-congress/senate-bill/1378/text,en,
2407,TAME Extreme Weather and Wildfires Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-04-09,2025,4,positive,0.9468,low,0.0,219,0.5,Proposed,"A BILL To direct the use of artificial intelligence by National Oceanic and Atmospheric Administration to adapt to extreme weather, and for other purposes. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title; table of contents. (a) Short title.—This Act may be cited as the “Transformational Artificial intelligence to Modernize the Economy against Extreme Weather and Wildfires Act” or the “TAME Extreme Weather and Wildfires Act”. (b) Table of contents.—The table of contents for this Act is as follows: Sec. 1. Short title; table of contents. Sec. 2. Definitions. Sec. 3. Earth system forecasting and information delivery. Sec. 4. Advanced artificial intelligence applications for weather and information delivery. Sec. 5. Technical assistance on use of artificial intelligence weather models. Sec. 6. Fire environment modeling program. Sec. 7. Partnerships for transformational innovation. Sec. 8. Federal Government workforce expertise. Sec. 9. Data access. SEC. 2. Definitions. In this Act: (1) ARTIFICIAL INTELLIGENCE.— (A) IN GENERAL.—The term “artificial intelligence” means a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments, including by using machine-based and human-based inputs— (i) to abstract such objectives into models through analysis in an automated manner; and (ii) to use model i",https://www.congress.gov/bill/119th-congress/house-bill/2770/text,en,
2408,Health Tech Investment Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-04-09,2025,4,positive,0.9677,low,0.0,233,0.5,Proposed,"A BILL To amend title XVIII of the Social Security Act to ensure appropriate payment of certain algorithm-based healthcare services under the Medicare program. Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. Short title. This Act may be cited as the “Health Tech Investment Act”. SEC. 2. Ensuring appropriate payment of certain algorithm-based healthcare services under the Medicare Program. (a) In general.—Section 1833(t) of the Social Security Act (42 U.S.C. 1395l(t)) is amended— (1) in paragraph (2)(E), by inserting “and new technology ambulatory payment classification of algorithm-based healthcare services under paragraph (16)(H)” after “(16)(G)”; and (2) in paragraph (16), by adding at the end the following new subparagraph: “(H) SPECIAL RULE FOR CERTAIN ALGORITHM-BASED HEALTHCARE SERVICES.— “(i) IN GENERAL.—In the case of a covered OPD service furnished on or after January 1, 2026, that is an algorithm-based healthcare service (as defined in clause (ii)) that is assigned to a new technology ambulatory payment classification (as described in the final rule entitled ‘Medicare Program; Changes to the Hospital Outpatient Prospective Payment System for Calendar Year 2002’ published by the Department of Health and Human Services on November 30, 2001 (66 Fed. Reg. 59897)) on or after the date of the enactment of this subparagraph or for which, as of such date, is currently and has been assigned to a new te",https://www.congress.gov/bill/119th-congress/senate-bill/1399/text,en,
2409,Bipartisan Health Care Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-03-06,2025,3,positive,0.9246,low,0.0,104,0.5,Proposed,"SEC. 217. Report on wearable medical devices. Not later than 18 months after the date of the enactment of this Act, the Comptroller General of the United States shall conduct a technology assessment of, and submit to Congress a report on, the capabilities and limitations of wearable medical devices used to support clinical decision-making. Such report shall include a description of— (1) the potential for such devices to accurately prescribe treatments; (2) an examination of the benefits and challenges of artificial intelligence to augment such capabilities; and (3) policy options to enhance the benefits and mitigate potential challenges of developing or using such devices.",https://www.congress.gov/bill/119th-congress/senate-bill/891/text,en,
2410,CORE Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-04-01,2025,4,positive,0.9729,low,0.0,199,0.5,Proposed,"(b) Report on transboundary hydrocarbon reservoirs.— (1) IN GENERAL.—Not later than 18 months after the date of enactment of this Act, the Secretaries shall jointly submit to the Committee on Energy and Natural Resources and the Committee on Foreign Relations of the Senate and the Committee on Energy and Commerce, the Committee on Natural Resources, and the Committee on Foreign Affairs of the House of Representatives a report that includes the following: (A) An identification and assessment of any existing transboundary hydrocarbon reservoirs, including those covered by bilateral maritime boundary treaties and agreements, and any potential transboundary areas for future exploration, development, and production of hydrocarbons. (B) An analysis of the legal frameworks established by relevant maritime boundary treaties and agreements, including provisions related to the equitable exploration, development, and production of transboundary hydrocarbon reservoirs and mechanisms for resolving disputes, and their adoption by counterparty nations. (C) An evaluation of the potential economic, environmental, and geopolitical implications of transboundary hydrocarbon exploration, development, and production, including impacts on domestic energy security, greenhouse gas emissions, and international relations. (D) Recommendations for enhancing cooperation and coordination among the United States and neighboring countries in the exploration, development, and production of transboundary hydro",https://www.congress.gov/bill/119th-congress/house-bill/2556/text,en,
2411,Air National Guard Squadron Preservation Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-03-25,2025,3,positive,0.9741,low,0.0,215,0.5,Proposed,"(c) Feasibility study on advanced capability fighter aircraft.— (1) STUDY.—The Secretary, in consultation with the Director of the Air National Guard, shall conduct a study to determine the need for procuring advanced capability fighter aircraft for use by the active and reserve components of the Air Force. (2) ELEMENTS.—The study under paragraph (1) shall— (A) take into account any plans of the Secretary to implement unmanned or autonomous capabilities in any fighter aircraft of the active or reserve components of the Air Force; (B) calculate any cost savings in long-lead time, supply chain acquisition, and labor attributed to any sales of the Block 70/72 variant or later variant of the F–16 fighter aircraft by the military of a foreign country; (C) identify which reserve and active fighter units of the Air Force would be eligible for recapitalization with advanced capability fighter aircraft; (D) identify how advanced capability fighter aircraft would meet steady state and contingency force presentation and mission requirements of combatant commanders; and (E) identify whether a multiyear contract would be the best method for acquiring advanced capability fighter aircraft. (3) REPORT.—Not later than 180 days after the date of the enactment of this Act, the Secretary shall submit to the congressional defense committees the findings of the study conducted pursuant to this subsection.",https://www.congress.gov/bill/119th-congress/house-bill/2327/text,en,
2412,Duplicative Grant Consolidation Act,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-03-14,2025,3,positive,0.8225,low,0.0,119,0.5,Proposed,"SEC. 4. Report on feasibility of leveraging artificial intelligence to identify duplicative Federal grant applications. The Director of the Office of Management and Budget, in consultation with the Secretary of Energy, the Director of the National Science Foundation, and the Director of the National Institute of Standards and Technology, shall submit to the appropriate Congressional committees a report on the feasibility of leveraging artificial intelligence to rapidly identify, with respect to an application for a grant submitted to the head of an executive agency— (1) whether an applicant for such grant has received, or submitted an application to the head of another executive agency for, another grant for the same or identical purpose; and (2) waste, fraud, and abuse.",https://www.congress.gov/bill/119th-congress/house-bill/2101/text,en,
2413,"Western Wildfire Support Act of 2025, Section 205 ""Study on modernizing wildfire response technologies""",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-14,2025,1,negative,-0.6494,low,0.0,206,0.5,Proposed,"SEC. 205. Study on modernizing wildfire response technologies. (a) In general.—The Secretaries shall conduct a study on— (1) necessary improvements to radio communications systems and infrastructure during wildland fire or prescribed fire operations, including— (A) an assessment of the quality and reliability of existing radio infrastructure; (B) for any instance in which existing radio communications infrastructure has failed, an assessment of the impacts on forest management or wildfire response activities; (C) a comparison of existing options to improve on-the-ground communications; and (D) a cost analysis and estimated timeline to install the most feasible option identified under subparagraph (C); (2) real-time or near-real-time situational awareness tools for operational firefighters, including— (A) standards and requirements for such tools to ensure interoperability between Federal firefighting entities and applicable State, local, Tribal, or other partners; (B) any requirements for additional remote sensing and mapping capabilities to fully leverage such situational awareness tools; and (C) a cost comparison between commercially available systems and internally developed systems; and (3) wildland fire predictive modeling, including— (A) an analysis of the data required to reduce predictive error for existing or developing models; (B) an analysis of computing needs to more swiftly or accurately model wildland fire using existing or developing models; (C) the feasibility",https://www.congress.gov/bill/119th-congress/senate-bill/91/text,en,
2414,"Wildfire Prevention Act of 2025, Section 302 ""Public-private wildfire technology deployment and testbed partnership.""",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-01-16,2025,1,positive,0.6597,low,0.0,211,0.5,Proposed,"SEC. 302. Public-private wildfire technology deployment and testbed partnership. (a) Definitions.—In this section: (1) APPROPRIATE COMMITTEES.—The term “appropriate committees” means— (A) the Committees on Agriculture, Nutrition, and Forestry, Energy and Natural Resources, and Commerce, Science, and Transportation of the Senate; and (B) the Committees on Agriculture, Natural Resources, and Science, Space, and Technology of the House of Representatives. (2) COVERED AGENCY.—The term “covered agency” means— (A) each Federal land management agency (as defined in section 802 of the Federal Lands Recreation Enhancement Act (16 U.S.C. 6801)); (B) the Department of Defense; (C) the National Oceanic and Atmospheric Administration; (D) the United States Fire Administration; (E) the Federal Emergency Management Agency; (F) the National Aeronautics and Space Administration; (G) the Bureau of Indian Affairs; and (H) any other Federal agency involved in wildfire response. (3) COVERED ENTITY.—The term “covered entity” means— (A) a private entity; (B) a nonprofit organization; and (C) an institution of higher education (as defined in section 101 of the Higher Education Act of 1965 (20 U.S.C. 1001)). (4) PILOT PROGRAM.—The term “Pilot Program” means the deployment and testbed pilot program established under subsection (b). (5) SECRETARIES.—The term “Secretaries” means the Secretary of Agriculture and the Secretary of the Interior, acting jointly. (b) Establishment.—Not later than 60 days afte",https://www.congress.gov/bill/119th-congress/senate-bill/140/text,en,
2415,Leading Ethical AI Development (LEAD) for Kids Act,California,United States,State governments,Editors' Picks,Law/Act,2025-04-23,2025,4,positive,0.9719,low,0.0,230,0.5,Proposed,"SECTION 1. Chapter 25.1 (commencing with Section 22757.20) is added to Division 8 of the Business and Professions Code, to read: CHAPTER 25.1. Leading Ethical AI Development (LEAD) for Kids 22757.20. This chapter shall be known as the Leading Ethical AI Development (LEAD) for Kids Act. 22757.21. For purposes of this chapter: (a) “Adverse impact” means a significant negative impact to a child’s health, safety, privacy, educational opportunities or outcomes, or access to essential services or benefits. (b) “Artificial intelligence” means an engineered or machine-based system that varies in its level of autonomy and that can, for explicit or implicit objectives, infer from the input it receives how to generate outputs that can influence physical or virtual environments. (c) “Biometric information” has the meaning defined in Section 1798.140 of the Civil Code. (d) “Board” means the LEAD for Kids Standards Board created pursuant to this chapter. (e) “Child” means a natural person under 18 years of age who resides in this state. (f) “Companion chatbot” means a generative artificial intelligence system with a natural language interface that provides adaptive, human-like responses to user inputs and is intended to, or foreseeably will, be used to meet a user’s social needs, exhibits anthropomorphic features, and is able to sustain a relationship with the user across multiple interactions. (g) “Consent” means affirmative, written agreement to a specific purpose that is disclosed in cl",https://leginfo.legislature.ca.gov/faces/billCompareClient.xhtml?bill_id=202520260AB1064&showamends=false,en,
2417,Advancing Artificial Intelligence Education for American Youth,Executive Office of the President,United States,Federal government,Editors' Picks,Regulation,2025-04-23,2025,4,positive,0.9905,low,0.0,224,0.5,Enacted,"Section 1. Background. Artificial intelligence (AI) is rapidly transforming the modern world, driving innovation across industries, enhancing productivity, and reshaping the way we live and work. To ensure the United States remains a global leader in this technological revolution, we must provide our Nation’s youth with opportunities to cultivate the skills and understanding necessary to use and create the next generation of AI technology. By fostering AI competency, we will equip our students with the foundational knowledge and skills necessary to adapt to and thrive in an increasingly digital society. Early learning and exposure to AI concepts not only demystifies this powerful technology but also sparks curiosity and creativity, preparing students to become active and responsible participants in the workforce of the future and nurturing the next generation of American AI innovators to propel our Nation to new heights of scientific and economic achievement. To achieve this vision, we must also invest in our educators and equip them with the tools and knowledge to not only train students about AI, but also to utilize AI in their classrooms to improve educational outcomes. Professional development programs focused on AI education will empower educators to confidently guide students through this complex and evolving field. Educators, industry leaders, and employers who rely on an AI-skilled workforce should partner to create educational programs that equip students with essent",https://www.whitehouse.gov/presidential-actions/2025/04/advancing-artificial-intelligence-education-for-american-youth/,en,
2418,United States-Israel Defense Partnership Act of 2025,United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-02-12,2025,2,positive,0.9909,low,0.0,215,0.5,Proposed,"SEC. 6. United States-Israel emerging technology capabilities cooperation. (a) Statement of policy.—It is the policy of the United States to support and encourage further defense collaboration with Israel in areas of emerging technologies capable of enabling the warfare capabilities of both the United States and Israel to meet emerging defense challenges, including in the areas of artificial intelligence, cybersecurity, robotics, quantum, and automation. (b) Authority To establish emerging defense technology capabilities program with Israel.— (1) IN GENERAL.—The Secretary of Defense, upon request by the Ministry of Defense of Israel and in consultation with the Secretary of State and the Director of National Intelligence, is authorized to carry out, jointly with Israel, research, development, test, and evaluation in areas of emerging technologies capable of enabling the warfare capabilities of the United States and Israel to meet emerging defense challenges, including in the areas of artificial intelligence, cybersecurity, robotics, quantum, and automation. (2) PROTECTION OF SENSITIVE INFORMATION.—Any activity carried out pursuant to the authority provided by paragraph (1) shall be conducted in a manner that appropriately protects sensitive information and the national security interests of the United States and Israel. (3) REPORT.—None of the activities described in paragraph (1) may be carried out until the date on which the Secretary of Defense submits to the Committees on",https://www.congress.gov/bill/119th-congress/senate-bill/554/text,en,
2419,"Coast Guard Authorization Act of 2025, Subtitle C--""Matters Involving Uncrewed Systems""",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-03-06,2025,3,positive,0.9136,low,0.0,213,0.5,Proposed,"Subtitle C--Matters Involving Uncrewed Systems SEC. 231. ESTABLISHMENT OF NATIONAL ADVISORY COMMITTEE ON AUTONOMOUS MARITIME SYSTEMS. (a) In General.--Chapter 151 of title 46, United States Code, is amended by adding at the end the following: Sec. 15110. Establishment of National Advisory Committee on Autonomous Maritime Systems (a) Establishment.--There is established a National Advisory Committee on Autonomous Maritime Systems (in this section referred to as the `Committee'). (b) Function.--The Committee shall advise the Secretary on matters relating to the regulation and use of Autonomous Systems within the territorial waters of the United States. (c) Membership.-- (1) In general.--The Committee shall consist of 15 members appointed by the Secretary in accordance with this section and section 15109. (2) Expertise.--Each member of the Committee shall have particular expertise, knowledge, and experience in matters relating to the function of the Committee. (3) Representation.--Each of the following groups shall be represented by at least 1 member on the Committee: (A) Marine safety or security entities. (B) Vessel design and construction entities. (C) Entities engaged in the production or research of uncrewed vehicles, including drones, autonomous or semi-autonomous vehicles, or any other product or service integral to the provision, maintenance, or management of such products or services. (D) Port districts, authorities, or terminal operators. (E) Vessel operators. (F) Nati",https://www.congress.gov/bill/119th-congress/senate-bill/524/text,en,
2420,"Department of Energy Quantum Leadership Act of 2025, Section 2 ""Department of Energy quantum information science research program""",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-02-13,2025,2,positive,0.7506,low,0.0,200,0.5,Proposed,"SEC. 2. Department of Energy quantum information science research program. Section 401 of the National Quantum Initiative Act (15 U.S.C. 8851) is amended— (1) by striking subsection (a) and inserting the following: “(a) In general.—The Secretary of Energy shall carry out a research, development, and demonstration program on quantum information science, engineering, and technology.”; (2) in subsection (b)— (A) in paragraph (1), by inserting “, engineering, and technology” after “science”; (B) in paragraph (2), by inserting “, engineering, and technology” after “science”; (C) by striking paragraph (3) and inserting the following: “(3) provide research experiences and training for additional undergraduate and graduate students in quantum information science, engineering, and technology, including in the fields specified in paragraph (4);”; (D) by redesignating paragraphs (3) through (5) as paragraphs (5) through (7), respectively; (E) by inserting after paragraph (2) the following: “(3) operate National Quantum Information Science Research Centers under section 402 to accelerate and scale scientific and technical breakthroughs in quantum information science, engineering, and technology, and maintain state-of-the-art infrastructure for quantum researchers and industry partners; “(4) conduct cooperative basic and applied research with industry, National Laboratories, institutions of higher education, and other research institutions to facilitate the development, demonstration, and",https://www.congress.gov/bill/119th-congress/senate-bill/579/text,en,
2421,Copyright and Artificial Intelligence Part 3: Generative AI Training Report Pre-Publication Version 2025,"Copyright Office, Library of Congress",United States,Federal government,Miscellaneous documents,Other,2025-05-09,2025,5,positive,0.9666,low,0.0,226,0.5,Proposed,"[removed all footnotes and sections other than Analysis and Recommendations] In assessing any form of licensing, it is important to recognize the wide variations in works and uses involved in AI training. Feasibility will depend on the types of works needed, the licensing practices of the relevant industries, the design of the AI system, and its intended uses. For instance, licensing a music model that can produce rudimentary jingles is different from licensing a state-of-the-art LLM that can compete on advanced reasoning benchmarks. And sophisticated commercial entities will be easier to find and negotiate with than individual non-professionals. As discussed above, a number of voluntary direct and collective licensing agreements for using copyrighted works in AI training have emerged over the past several years, with others in development. Some AI systems have now been trained exclusively on licensed or public domain works. These developments demonstrate that voluntary licensing may be workable, at least in certain contexts—particularly where training is focused on valuable content that can be licensed in relatively high volumes (e.g., popular music and stock photography), or in fields where the number of copyright owners is limited. The Office recognizes, however, that practical challenges remain in many areas. The growing licensing market does not itself establish that voluntary licensing is feasible at scale for all AI training needs. To the extent that the remaining gaps",https://www.copyright.gov/ai/Copyright-and-Artificial-Intelligence-Part-3-Generative-AI-Training-Report-Pre-Publication-Version.pdf,en,
2422,Copyright and Artificial Intelligence Part 1: Digital Replicas July 2024,"Copyright Office, Library of Congress",United States,Federal government,Miscellaneous documents,Other,2024-07-31,2024,7,positive,0.7557,low,0.0,182,0.5,Enacted,"[removed all parts of the report except the conclusion, which contained actionable recommendations] The Copyright Office agrees with the numerous commenters that have asserted an urgent need for new protection at the federal level. The widespread availability of generative AI tools that make it easy to create digital replicas of individuals’ images and voices has highlighted gaps in existing laws and raised concerns about the harms that can be inflicted by unauthorized uses. We recommend that Congress establish a federal right that protects all individuals during their lifetimes from the knowing distribution of unauthorized digital replicas. The right should be licensable, subject to guardrails, but not assignable, with effective remedies including monetary damages and injunctive relief. Traditional rules of secondary liability should apply, but with an appropriately conditioned safe harbor for OSPs. The law should contain explicit First Amendment accommodations. Finally, in recognition of well-developed state rights of publicity, we recommend against full preemption of state laws. The Office remains available as a resource to Congress, the courts, and the executive branch in considering the recommendations in this Report and future developments.",https://www.copyright.gov/ai/Copyright-and-Artificial-Intelligence-Part-1-Digital-Replicas-Report.pdf,en,
2425,"One Big Beautiful Bill Act 2025, Section 43201 (""Artificial intelligence and information technology modernization initiative"")",United States Congress,United States,Federal government,Editors' Picks,Law/Act,2025-05-20,2025,5,positive,0.9413,low,0.1667,203,0.7,Proposed,"(a) Appropriation of Funds.--There is hereby appropriated to the Department of Commerce for fiscal year 2025, out of any funds in the Treasury not otherwise appropriated, $500,000,000, to remain available until September 30, 2034, to modernize and secure Federal information technology systems through the deployment of commercial artificial intelligence, the deployment of automation technologies, and the replacement of antiquated business systems in accordance with subsection (b). (b) Authorized Uses.--The Secretary of Commerce shall use the funds appropriated under subsection (a) for the following: (1) To replace or modernize, within the Department of Commerce, legacy business systems with state-of-the-art commercial artificial intelligence systems and automated decision systems. (2) To facilitate, within the Department of Commerce, the adoption of artificial intelligence models that increase operational efficiency and service delivery. (3) To improve, within the Department of Commerce, the cybersecurity posture of Federal information technology systems through modernized architecture, automated threat detection, and integrated artificial intelligence solutions. (c) Moratorium.-- (1) In general.--Except as provided in paragraph (2), no State or political subdivision thereof may enforce, during the 10-year period beginning on the date of the enactment of this Act, any law or regulation of that State or a political subdivision thereof limiting, restricting, or otherwise regulat",https://www.congress.gov/bill/119th-congress/house-bill/1/text,en,"Strategies: Government support, Risk factors: Security, Risk factors: Security: Cybersecurity, Risk factors: Reliability, Applications: Government: other applications/unspecified, Strategies: Tiering"
2426,Responsible AI safety and education act,New York,United States,State governments,Editors' Picks,Law/Act,2025-03-05,2025,3,positive,0.8602,low,0.0,220,0.5,Proposed,"STATE OF NEW YORK ________________________________________________________________________ 6453--B 2025-2026 Regular Sessions IN ASSEMBLY March 5, 2025 ___________ Introduced by M. of A. BORES, LASHER, SEAWRIGHT, PAULIN, TAPIA, RAGA, SHIMSKY, REYES, EPSTEIN, BURKE, HEVESI, P. CARROLL, ZACCARO, HYNDMAN, LUPARDO, KASSAY, LEE, DAVILA, SCHIAVONI, LUNSFORD, K. BROWN, TANNOUS- IS, TORRES, HOOKS, GIBBS, ROMERO, COLTON, CONRAD, MEEKS, GLICK, CRUZ, CUNNINGHAM, FORREST, CHANDLER-WATERMAN, STIRPE, WRIGHT, SIMON, DAIS, JENSEN, ROZIC, GONZALEZ-ROJAS -- read once and referred to the Commit- tee on Science and Technology -- committee discharged, bill amended, ordered reprinted as amended and recommitted to said committee -- reported and referred to the Committee on Codes -- committee discharged, bill amended, ordered reprinted as amended and recommitted to said committee AN ACT to amend the general business law, in relation to the training and use of artificial intelligence frontier models The People of the State of New York, represented in Senate and Assem- bly, do enact as follows: Section 1. Short title. This act shall be known and may be cited as the ""Responsible AI safety and education act"" or ""RAISE act"". § 2. The general business law is amended by adding a new article 44-B to read as follows: ARTICLE 44-B RESPONSIBLE AI SAFETY AND EDUCATION (RAISE) ACT Section 1420. Definitions. 1421. Transparency requirements regarding frontier model train- ing and use. 1422. Violations. 1423. Dutie",https://nyassembly.gov/leg/?default_fld=&leg_video=&bn=A06453&term=&Text=Y,en,
2528,"One Big Beautiful Bill Act 2025, Section 112204 (""Implementing artificial intelligence tools for purposes of reducing and recouping improper payments under Medicare"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-05-20,2025,5,positive,0.977,low,0.0,217,0.5,Proposed,"(a) In General.--Part E of title XVIII of the Social Security Act (42 U.S.C. 1395x et seq.), as amended by the preceding provisions of this Act, is amended by adding at the end the following new section: ``SEC. 1899D. IMPLEMENTING ARTIFICIAL INTELLIGENCE TOOLS FOR PURPOSES OF REDUCING AND RECOUPING IMPROPER PAYMENTS. ``(a) In General.--Not later than January 1, 2027, the Secretary shall implement such artificial intelligence tools determined appropriate by the Secretary for purposes of-- ``(1) reducing improper payments made under parts A and B; and ``(2) identifying any such improper payments so made. ``(b) Contracts.--The Secretary shall seek to contract with a vendor of artificial intelligence tools and with data scientists for purposes of implementing the artificial intelligence tools required under subsection (a). ``(c) Recoupment.--The Secretary shall, to the extent practicable, recoup payments identified using the artificial intelligence tools implemented under subsection (a). ``(d) Report.--Not later than January 1, 2029, and not less frequently than annually thereafter, the Secretary shall report to Congress on the implementation of artificial intelligence tools under subsection (a) and the recoupment of improper payments under subsection (c). Such report shall include-- ``(1) a description of any opportunities for further reducing rates of improper payments described in subsection (a)(1) or further increasing rates of recoupment of such payments; ``(2) the total dol",https://www.congress.gov/bill/119th-congress/house-bill/1/text,en,
2529,"One Big Beautiful Bill Act 2025, Section 20002 (""Enhancement of Department of Defense resources for shipbuilding"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-05-20,2025,5,positive,0.936,low,0.0,193,0.5,Proposed,"In addition to amounts otherwise available, there are appropriated to the Secretary of Defense for fiscal year 2025, out of any money in the Treasury not otherwise appropriated, to remain available until September 30, 2029-- (1) $250,000,000 for the expansion of accelerated Training in Defense Manufacturing program; (2) $250,000,000 for United States production of turbine generators for shipbuilding industrial base; (3) $450,000,000 for United States additive manufacturing for wire production and machining capacity for shipbuilding industrial base; (4) $492,000,000 for next-generation shipbuilding techniques; (5) $85,000,000 for United States-made steel plate for shipbuilding industrial base; (6) $50,000,000 for machining capacity for naval propellers for shipbuilding industrial base; (7) $110,000,000 for rolled steel and fabrication facility for shipbuilding industrial base; (8) $400,000,000 for expansion of collaborative campus for naval shipbuilding; (9) $450,000,000 for application of autonomy and artificial intelligence to naval shipbuilding; (10) $500,000,000 for the adoption of advanced manufacturing techniques in the shipbuilding industrial base; (11) $500,000,000 for additional dry-dock capability; (12) $50,000,000 for the expansion of cold spray repair technologies; (13) $450,000,000 for additional maritime industrial workforce development programs; (14) $750,000,000 for additional supplier development across the naval shipbuilding industrial base; (15) $250,000,000",https://www.congress.gov/bill/119th-congress/house-bill/1/text,en,
2530,"One Big Beautiful Bill Act 2025, Section 20004 (""Enhancement of Department of Defense resources for munitions and defense supply chain resiliency"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-05-20,2025,5,positive,0.7184,low,0.0,196,0.5,Proposed,"(a) Appropriations.--In addition to amounts otherwise available, there are appropriated to the Secretary of Defense for fiscal year 2025, out of any money in the Treasury not otherwise appropriated, to remain available until September 30, 2029-- (1) $400,000,000 for the development, production, and integration of Navy and Air Force long-range anti-ship missiles; (2) $380,000,000 for production capacity expansion for Navy and Air Force long-range anti-ship missiles; (3) $490,000,000 for the development, production, and integration of Navy and Air Force long-range air-to-surface missiles; (4) $94,000,000 for the development, production, and integration of alternative Navy and Air Force long-range air- to-surface missiles; (5) $630,000,000 for the development, production, and integration of long-range Navy air defense and anti-ship missiles; (6) $688,000,000 for the development, production, and integration of long-range multi-service cruise missiles; (7) $250,000,000 for production capacity expansion and supplier base strengthening of long-range multi-service cruise missiles; (8) $70,000,000 for the development, production, and integration of short-range Navy and Marine Corps anti-ship missiles; (9) $100,000,000 for the development of an anti-ship seeker for short-range Army ballistic missiles; (10) $175,000,000 for production capacity expansion for next-generation Army medium-range ballistic missiles; (11) $50,000,000 for the mitigation of diminishing manufacturing sources for",https://www.congress.gov/bill/119th-congress/house-bill/1/text,en,
2531,"One Big Beautiful Bill Act 2025, Section 20005 (""Enhancement of Department of Defense resources for scaling low-cost weapons into production"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-05-20,2025,5,positive,0.93,low,0.0,202,0.5,Proposed,"(a) Appropriations.--In addition to amounts otherwise available, there are appropriated to the Secretary of Defense for fiscal year 2025, out of any money in the Treasury not otherwise appropriated, to remain available until September 30, 2029-- (1) $25,000,000 for the Office of Strategic Capital Global Technology Scout program; (2) $1,100,000,000 for the expansion of the small unmanned aerial system industrial base; (3) $400,000,000 for the development and deployment of the Joint Fires Network and associated joint battle management capabilities; (4) $400,000,000 for the expansion of advanced command-and- control tools to combatant commands and military departments; (5) $100,000,000 for the development of shared secure facilities for the defense industrial base; (6) $50,000,000 for the creation of additional Defense Innovation Unit OnRamp Hubs; (7) $250,000,000 for the acceleration of Strategic Capabilities Office programs; (8) $650,000,000 for the expansion of Mission Capabilities office joint prototyping and experimentation activities for military innovation; (9) $500,000,000 for the accelerated development and integration of advanced 5G/6G technologies for military use; (10) $25,000,000 for testing of simultaneous transmit and receive technology for military spectrum agility; (11) $50,000,000 for the development, procurement, and integration of high-altitude stratospheric balloons for military use; (12) $120,000,000 for the development, procurement, and integration of long",https://www.congress.gov/bill/119th-congress/house-bill/1/text,en,
2533,"One Big Beautiful Bill Act 2025, Section 20006 (""Enhancement of Department of Defense resources for improving the efficiency and cybersecurity of the Department of Defense"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-05-20,2025,5,positive,0.9552,low,0.0,136,0.5,Proposed,"In addition to amounts otherwise available, there are appropriated to the Secretary of Defense for fiscal year 2025, out of any money in the Treasury not otherwise appropriated, to remain available until September 30, 2029-- (1) $150,000,000 for business systems replacement to accelerate the audits of the financial statements of the Department of Defense pursuant to chapter 9A and section 2222 of title 10, United States Code; (2) $200,000,000 for the deployment of automation and artificial intelligence to accelerate the audits of the financial statements of the Department of Defense pursuant to chapter 9A and section 2222 of title 10, United States Code; (3) $10,000,000 for the improvement of the budgetary and programmatic infrastructure of the Office of the Secretary of Defense; and (4) $20,000,000 for defense cybersecurity programs of the Defense Advanced Research Projects Agency.",https://www.congress.gov/bill/119th-congress/house-bill/1/text,en,
2534,"One Big Beautiful Bill Act 2025, Section 60003 (""U.S. Customs and Border Protection technology, vetting activities, and other efforts to enhance border security"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-05-20,2025,5,positive,0.8591,low,0.0,215,0.5,Proposed,"(a) CBP Technology.--In addition to amounts otherwise available, there is appropriated to the Commissioner of U.S. Customs and Border Protection for fiscal year 2025, out of any money in the Treasury not otherwise appropriated, to remain available until September 30, 2029, the following: (1) $1,076,317,000 for necessary expenses relating to procurement and integration of new non-intrusive inspection equipment and associated civil works, artificial intelligence, integration, and machine learning, as well as other mission support, to combat the entry of illicit narcotics along the southwest, northern, and maritime borders. (2) $2,766,000,000 for necessary expenses relating to upgrades and procurement of border surveillance technologies along the southwest, northern, and maritime borders. (3) $673,000,000 for necessary expenses, including the deployment of technology, relating to the biometric entry and exit system under section 7208 of the Intelligence Reform and Terrorism Prevention Act of 2004 (8 U.S.C. 1365b). (b) Restrictions.--None of the funds made available pursuant to subsection (a)(2) may be used for the procurement or deployment of surveillance towers that have not been-- (1) tested, and (2) accepted, by the Federal Government to deliver autonomous capabilities. (c) Air and Marine Operations.--In addition to amounts otherwise available, there is appropriated to the Commissioner of U.S. Customs and Border Protection for fiscal year 2025, out of any money in the Treasur",https://www.congress.gov/bill/119th-congress/house-bill/1/text,en,
2535,"One Big Beautiful Bill Act 2025, Section 100001 (""Coast guard assets necessary to secure the maritime border and interdict migrants and drugs"")",United States Congress,United States,Federal government,U.S. federal laws,Law/Act,2025-05-20,2025,5,positive,0.9595,low,0.0,213,0.5,Proposed,"(a) In General.--For the purpose of the acquisition, sustainment, improvement, and operation of United States Coast Guard assets, in addition to amounts otherwise made available, there is appropriated to the Commandant of the Coast Guard for fiscal year 2025, out of any money in the Treasury not otherwise appropriated, to remain available until September 30, 2029-- (1) $571,500,000 for fixed wing aircraft and spare parts, training simulators, support equipment, and program management for such aircraft; (2) $1,283,000,000 for rotary wing aircraft and spare parts, training simulators, support equipment, and program management for such aircraft; (3) $140,000,000 for long-range unmanned aircraft systems and base stations, support equipment, and program management for such systems; (4) $4,300,000,000 for Offshore Patrol Cutters and spare parts and program management for such Cutters; (5) $1,000,000,000 for Fast Response Cutters and spare parts and program management for such Cutters; (6) $4,300,000,000 for Polar Security Cutters and spare parts and program management for such Cutters; (7) $4,978,000,000 for Arctic Security Cutters and domestic icebreakers and spare parts and program management for such Cutters and icebreakers; (8) $3,154,500,000 for design, planning, engineering, construction of, and program management for shoreside infrastructure, of which-- (A) $400,000,000 is provided for hangers and maintenance and crew facilities for the fixed wing aircraft for which funds ar",https://www.congress.gov/bill/119th-congress/house-bill/1/text,en,
